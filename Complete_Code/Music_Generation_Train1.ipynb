{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Generation Using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real World Problem\n",
    "\n",
    "This case-study focuses on generating music automatically using Recurrent Neural Network(RNN).<br> \n",
    "We do not necessarily have to be a music expert in order to generate music. Even a non expert can generate a decent quality music using RNN.<br>\n",
    "We all like to listen interesting music and if there is some way to generate music automatically, particularly decent quality music then it's a big leap in the world of music industry.<br><br>\n",
    "<b>Task:</b> Our task here is to take some existing music data then train a model using this existing data. The model has to learn the patterns in music that we humans enjoy. Once it learns this, the model should be able to generate new music for us. It cannot simply copy-paste from the training data. It has to understand the patterns of music to generate new music. We here are not expecting our model to generate new music which is of professional quality, but we want it to generate a decent quality music which should be melodious and good to hear.<br><br>\n",
    "Now, what is music? In short music is nothing but a sequence of musical notes. Our input to the model is a sequence of musical events/notes. Our output will be new sequence of musical events/notes. In this case-study we have limited our self to single instrument music as this is our first cut model. In future, we will extend this to multiple instrument music. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source:\n",
    "1. http://abc.sourceforge.net/NMD/\n",
    "2. http://trillian.mit.edu/~jc/music/book/oneills/1850/X/\n",
    "\n",
    "### From first data-source, we have downloaded first two files:\n",
    "* Jigs (340 tunes)\n",
    "* Hornpipes (65 tunes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"../Data/\"\n",
    "data_file = \"Data_Tunes.txt\"\n",
    "charIndex_json = \"char_to_index.json\"\n",
    "model_weights_directory = '../Data/Model_Weights/'\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_batches(all_chars, unique_chars):\n",
    "    length = all_chars.shape[0]\n",
    "    batch_chars = int(length / BATCH_SIZE) #155222/16 = 9701\n",
    "    \n",
    "    for start in range(0, batch_chars - SEQ_LENGTH, 64):  #(0, 9637, 64)  #it denotes number of batches. It runs everytime when\n",
    "        #new batch is created. We have a total of 151 batches.\n",
    "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH))    #(16, 64)\n",
    "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, unique_chars))   #(16, 64, 87)\n",
    "        for batch_index in range(0, 16):  #it denotes each row in a batch.  \n",
    "            for i in range(0, 64):  #it denotes each column in a batch. Each column represents each character means \n",
    "                #each time-step character in a sequence.\n",
    "                X[batch_index, i] = all_chars[batch_index * batch_chars + start + i]\n",
    "                Y[batch_index, i, all_chars[batch_index * batch_chars + start + i + 1]] = 1 #here we have added '1' because the\n",
    "                #correct label will be the next character in the sequence. So, the next character will be denoted by\n",
    "                #all_chars[batch_index * batch_chars + start + i + 1]\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model(batch_size, seq_length, unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = unique_chars, output_dim = 512, batch_input_shape = (batch_size, seq_length))) \n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(128, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(unique_chars)))\n",
    "\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(data, epochs = 80):\n",
    "    #mapping character to index\n",
    "    char_to_index = {ch: i for (i, ch) in enumerate(sorted(list(set(data))))}\n",
    "    print(\"Number of unique characters in our whole tunes database = {}\".format(len(char_to_index))) #87\n",
    "    \n",
    "    with open(os.path.join(data_directory, charIndex_json), mode = \"w\") as f:\n",
    "        json.dump(char_to_index, f)\n",
    "        \n",
    "    index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
    "    unique_chars = len(char_to_index)\n",
    "    \n",
    "    model = built_model(BATCH_SIZE, SEQ_LENGTH, unique_chars)\n",
    "    model.summary()\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    all_characters = np.asarray([char_to_index[c] for c in data], dtype = np.int32)\n",
    "    print(\"Total number of characters = \"+str(all_characters.shape[0])) #155222\n",
    "    \n",
    "    epoch_number, loss, accuracy = [], [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "        final_epoch_loss, final_epoch_accuracy = 0, 0\n",
    "        epoch_number.append(epoch+1)\n",
    "        \n",
    "        for i, (x, y) in enumerate(read_batches(all_characters, unique_chars)):\n",
    "            final_epoch_loss, final_epoch_accuracy = model.train_on_batch(x, y) #check documentation of train_on_batch here: https://keras.io/models/sequential/\n",
    "            print(\"Batch: {}, Loss: {}, Accuracy: {}\".format(i+1, final_epoch_loss, final_epoch_accuracy))\n",
    "            #here, above we are reading the batches one-by-one and train our model on each batch one-by-one.\n",
    "        loss.append(final_epoch_loss)\n",
    "        accuracy.append(final_epoch_accuracy)\n",
    "        \n",
    "        #saving weights after every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            if not os.path.exists(model_weights_directory):\n",
    "                os.makedirs(model_weights_directory)\n",
    "            model.save_weights(os.path.join(model_weights_directory, \"Weights_{}.h5\".format(epoch+1)))\n",
    "            print('Saved Weights at epoch {} to file Weights_{}.h5'.format(epoch+1, epoch+1))\n",
    "    \n",
    "    #creating dataframe and record all the losses and accuracies at each epoch\n",
    "    log_frame = pd.DataFrame(columns = [\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "    log_frame[\"Epoch\"] = epoch_number\n",
    "    log_frame[\"Loss\"] = loss\n",
    "    log_frame[\"Accuracy\"] = accuracy\n",
    "    log_frame.to_csv(\"../Data/log.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in our whole tunes database = 87\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (16, 64, 512)             44544     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (16, 64, 256)             787456    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (16, 64, 128)             197120    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (16, 64, 128)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (16, 64, 87)              11223     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (16, 64, 87)              0         \n",
      "=================================================================\n",
      "Total params: 1,040,343\n",
      "Trainable params: 1,040,343\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Total number of characters = 155222\n",
      "Epoch 1/80\n",
      "Batch: 1, Loss: 4.466339111328125, Accuracy: 0.005859375\n",
      "Batch: 2, Loss: 4.452466011047363, Accuracy: 0.150390625\n",
      "Batch: 3, Loss: 4.437885284423828, Accuracy: 0.1357421875\n",
      "Batch: 4, Loss: 4.419650077819824, Accuracy: 0.1044921875\n",
      "Batch: 5, Loss: 4.347679138183594, Accuracy: 0.14453125\n",
      "Batch: 6, Loss: 4.175968170166016, Accuracy: 0.166015625\n",
      "Batch: 7, Loss: 3.927647352218628, Accuracy: 0.1630859375\n",
      "Batch: 8, Loss: 3.850815773010254, Accuracy: 0.1416015625\n",
      "Batch: 9, Loss: 3.8215389251708984, Accuracy: 0.1357421875\n",
      "Batch: 10, Loss: 3.679567813873291, Accuracy: 0.1630859375\n",
      "Batch: 11, Loss: 3.4665279388427734, Accuracy: 0.171875\n",
      "Batch: 12, Loss: 3.602440595626831, Accuracy: 0.1513671875\n",
      "Batch: 13, Loss: 3.7855000495910645, Accuracy: 0.1201171875\n",
      "Batch: 14, Loss: 3.566101312637329, Accuracy: 0.12890625\n",
      "Batch: 15, Loss: 3.7493319511413574, Accuracy: 0.1171875\n",
      "Batch: 16, Loss: 3.4637646675109863, Accuracy: 0.1474609375\n",
      "Batch: 17, Loss: 3.3792624473571777, Accuracy: 0.154296875\n",
      "Batch: 18, Loss: 3.381369113922119, Accuracy: 0.1708984375\n",
      "Batch: 19, Loss: 3.6173253059387207, Accuracy: 0.126953125\n",
      "Batch: 20, Loss: 3.726820945739746, Accuracy: 0.109375\n",
      "Batch: 21, Loss: 3.5821568965911865, Accuracy: 0.126953125\n",
      "Batch: 22, Loss: 3.338289976119995, Accuracy: 0.166015625\n",
      "Batch: 23, Loss: 3.418591022491455, Accuracy: 0.1455078125\n",
      "Batch: 24, Loss: 3.5852255821228027, Accuracy: 0.11328125\n",
      "Batch: 25, Loss: 3.5072360038757324, Accuracy: 0.130859375\n",
      "Batch: 26, Loss: 3.492565155029297, Accuracy: 0.1162109375\n",
      "Batch: 27, Loss: 3.4572670459747314, Accuracy: 0.1328125\n",
      "Batch: 28, Loss: 3.2855730056762695, Accuracy: 0.1494140625\n",
      "Batch: 29, Loss: 3.4941952228546143, Accuracy: 0.1220703125\n",
      "Batch: 30, Loss: 3.7971792221069336, Accuracy: 0.087890625\n",
      "Batch: 31, Loss: 3.688584327697754, Accuracy: 0.1123046875\n",
      "Batch: 32, Loss: 3.4484119415283203, Accuracy: 0.1171875\n",
      "Batch: 33, Loss: 3.452495813369751, Accuracy: 0.142578125\n",
      "Batch: 34, Loss: 3.404656171798706, Accuracy: 0.1455078125\n",
      "Batch: 35, Loss: 3.5096893310546875, Accuracy: 0.115234375\n",
      "Batch: 36, Loss: 3.632293701171875, Accuracy: 0.0966796875\n",
      "Batch: 37, Loss: 3.49151611328125, Accuracy: 0.123046875\n",
      "Batch: 38, Loss: 3.4264841079711914, Accuracy: 0.1328125\n",
      "Batch: 39, Loss: 3.4877419471740723, Accuracy: 0.1279296875\n",
      "Batch: 40, Loss: 3.6227121353149414, Accuracy: 0.111328125\n",
      "Batch: 41, Loss: 3.6007163524627686, Accuracy: 0.1259765625\n",
      "Batch: 42, Loss: 3.4506189823150635, Accuracy: 0.1455078125\n",
      "Batch: 43, Loss: 3.3062262535095215, Accuracy: 0.1748046875\n",
      "Batch: 44, Loss: 3.3253371715545654, Accuracy: 0.166015625\n",
      "Batch: 45, Loss: 3.351013660430908, Accuracy: 0.150390625\n",
      "Batch: 46, Loss: 3.6638081073760986, Accuracy: 0.111328125\n",
      "Batch: 47, Loss: 3.661653757095337, Accuracy: 0.107421875\n",
      "Batch: 48, Loss: 3.4468979835510254, Accuracy: 0.1435546875\n",
      "Batch: 49, Loss: 3.3748056888580322, Accuracy: 0.1416015625\n",
      "Batch: 50, Loss: 3.3586666584014893, Accuracy: 0.1376953125\n",
      "Batch: 51, Loss: 3.362600326538086, Accuracy: 0.1435546875\n",
      "Batch: 52, Loss: 3.4547433853149414, Accuracy: 0.1201171875\n",
      "Batch: 53, Loss: 3.4397470951080322, Accuracy: 0.1328125\n",
      "Batch: 54, Loss: 3.48345947265625, Accuracy: 0.1328125\n",
      "Batch: 55, Loss: 3.385382652282715, Accuracy: 0.146484375\n",
      "Batch: 56, Loss: 3.4654366970062256, Accuracy: 0.15625\n",
      "Batch: 57, Loss: 3.47121000289917, Accuracy: 0.1376953125\n",
      "Batch: 58, Loss: 3.3460021018981934, Accuracy: 0.1474609375\n",
      "Batch: 59, Loss: 3.6833133697509766, Accuracy: 0.10546875\n",
      "Batch: 60, Loss: 3.4356229305267334, Accuracy: 0.140625\n",
      "Batch: 61, Loss: 3.4015307426452637, Accuracy: 0.1474609375\n",
      "Batch: 62, Loss: 3.5207650661468506, Accuracy: 0.1357421875\n",
      "Batch: 63, Loss: 3.4564208984375, Accuracy: 0.146484375\n",
      "Batch: 64, Loss: 3.4715521335601807, Accuracy: 0.134765625\n",
      "Batch: 65, Loss: 3.4887523651123047, Accuracy: 0.138671875\n",
      "Batch: 66, Loss: 3.4515175819396973, Accuracy: 0.146484375\n",
      "Batch: 67, Loss: 3.303887367248535, Accuracy: 0.17578125\n",
      "Batch: 68, Loss: 3.3789432048797607, Accuracy: 0.16796875\n",
      "Batch: 69, Loss: 3.4658126831054688, Accuracy: 0.142578125\n",
      "Batch: 70, Loss: 3.4653830528259277, Accuracy: 0.1533203125\n",
      "Batch: 71, Loss: 3.341254472732544, Accuracy: 0.15625\n",
      "Batch: 72, Loss: 3.3946454524993896, Accuracy: 0.1552734375\n",
      "Batch: 73, Loss: 3.527279853820801, Accuracy: 0.126953125\n",
      "Batch: 74, Loss: 3.453678846359253, Accuracy: 0.140625\n",
      "Batch: 75, Loss: 3.289426326751709, Accuracy: 0.1650390625\n",
      "Batch: 76, Loss: 3.1710519790649414, Accuracy: 0.17578125\n",
      "Batch: 77, Loss: 3.2681846618652344, Accuracy: 0.1748046875\n",
      "Batch: 78, Loss: 3.6166815757751465, Accuracy: 0.1259765625\n",
      "Batch: 79, Loss: 3.593578815460205, Accuracy: 0.1337890625\n",
      "Batch: 80, Loss: 3.151236057281494, Accuracy: 0.1953125\n",
      "Batch: 81, Loss: 2.9813055992126465, Accuracy: 0.2060546875\n",
      "Batch: 82, Loss: 3.0891616344451904, Accuracy: 0.2119140625\n",
      "Batch: 83, Loss: 3.2522530555725098, Accuracy: 0.181640625\n",
      "Batch: 84, Loss: 3.3173165321350098, Accuracy: 0.1748046875\n",
      "Batch: 85, Loss: 3.289517641067505, Accuracy: 0.1767578125\n",
      "Batch: 86, Loss: 3.0996148586273193, Accuracy: 0.1923828125\n",
      "Batch: 87, Loss: 3.170030117034912, Accuracy: 0.193359375\n",
      "Batch: 88, Loss: 3.140655040740967, Accuracy: 0.2060546875\n",
      "Batch: 89, Loss: 3.154217004776001, Accuracy: 0.205078125\n",
      "Batch: 90, Loss: 3.2039942741394043, Accuracy: 0.2138671875\n",
      "Batch: 91, Loss: 3.165191650390625, Accuracy: 0.216796875\n",
      "Batch: 92, Loss: 3.073147773742676, Accuracy: 0.2109375\n",
      "Batch: 93, Loss: 3.1107277870178223, Accuracy: 0.21484375\n",
      "Batch: 94, Loss: 3.0161051750183105, Accuracy: 0.2587890625\n",
      "Batch: 95, Loss: 2.814521312713623, Accuracy: 0.26953125\n",
      "Batch: 96, Loss: 3.0993399620056152, Accuracy: 0.2216796875\n",
      "Batch: 97, Loss: 3.0987958908081055, Accuracy: 0.2158203125\n",
      "Batch: 98, Loss: 3.088235378265381, Accuracy: 0.2255859375\n",
      "Batch: 99, Loss: 2.8822364807128906, Accuracy: 0.2353515625\n",
      "Batch: 100, Loss: 2.7543158531188965, Accuracy: 0.271484375\n",
      "Batch: 101, Loss: 2.878721237182617, Accuracy: 0.2578125\n",
      "Batch: 102, Loss: 2.875706195831299, Accuracy: 0.25390625\n",
      "Batch: 103, Loss: 3.1018331050872803, Accuracy: 0.21875\n",
      "Batch: 104, Loss: 2.8673605918884277, Accuracy: 0.2646484375\n",
      "Batch: 105, Loss: 2.83402156829834, Accuracy: 0.26171875\n",
      "Batch: 106, Loss: 2.9106767177581787, Accuracy: 0.24609375\n",
      "Batch: 107, Loss: 2.9566354751586914, Accuracy: 0.25\n",
      "Batch: 108, Loss: 2.9386706352233887, Accuracy: 0.2392578125\n",
      "Batch: 109, Loss: 2.8132381439208984, Accuracy: 0.2626953125\n",
      "Batch: 110, Loss: 2.819993495941162, Accuracy: 0.26171875\n",
      "Batch: 111, Loss: 2.6819207668304443, Accuracy: 0.296875\n",
      "Batch: 112, Loss: 2.948784828186035, Accuracy: 0.244140625\n",
      "Batch: 113, Loss: 2.9603915214538574, Accuracy: 0.24609375\n",
      "Batch: 114, Loss: 2.726891040802002, Accuracy: 0.275390625\n",
      "Batch: 115, Loss: 2.784428834915161, Accuracy: 0.2734375\n",
      "Batch: 116, Loss: 2.8101162910461426, Accuracy: 0.26953125\n",
      "Batch: 117, Loss: 2.9738848209381104, Accuracy: 0.2333984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 118, Loss: 2.957672119140625, Accuracy: 0.2470703125\n",
      "Batch: 119, Loss: 2.94547700881958, Accuracy: 0.23828125\n",
      "Batch: 120, Loss: 2.667551040649414, Accuracy: 0.283203125\n",
      "Batch: 121, Loss: 2.697852611541748, Accuracy: 0.2939453125\n",
      "Batch: 122, Loss: 2.977010488510132, Accuracy: 0.2373046875\n",
      "Batch: 123, Loss: 2.888855218887329, Accuracy: 0.2548828125\n",
      "Batch: 124, Loss: 2.84230899810791, Accuracy: 0.255859375\n",
      "Batch: 125, Loss: 2.7291135787963867, Accuracy: 0.2734375\n",
      "Batch: 126, Loss: 2.714336395263672, Accuracy: 0.2724609375\n",
      "Batch: 127, Loss: 2.8596792221069336, Accuracy: 0.255859375\n",
      "Batch: 128, Loss: 2.8016529083251953, Accuracy: 0.271484375\n",
      "Batch: 129, Loss: 2.747270107269287, Accuracy: 0.2734375\n",
      "Batch: 130, Loss: 2.761723518371582, Accuracy: 0.26171875\n",
      "Batch: 131, Loss: 2.7729458808898926, Accuracy: 0.2724609375\n",
      "Batch: 132, Loss: 2.8464207649230957, Accuracy: 0.24609375\n",
      "Batch: 133, Loss: 2.738624095916748, Accuracy: 0.2783203125\n",
      "Batch: 134, Loss: 2.674128532409668, Accuracy: 0.2744140625\n",
      "Batch: 135, Loss: 2.625662088394165, Accuracy: 0.283203125\n",
      "Batch: 136, Loss: 2.5851802825927734, Accuracy: 0.2978515625\n",
      "Batch: 137, Loss: 2.409923553466797, Accuracy: 0.3291015625\n",
      "Batch: 138, Loss: 2.5335841178894043, Accuracy: 0.3173828125\n",
      "Batch: 139, Loss: 2.536074161529541, Accuracy: 0.2978515625\n",
      "Batch: 140, Loss: 2.630683422088623, Accuracy: 0.2861328125\n",
      "Batch: 141, Loss: 2.6172890663146973, Accuracy: 0.294921875\n",
      "Batch: 142, Loss: 2.556365489959717, Accuracy: 0.2998046875\n",
      "Batch: 143, Loss: 2.685612678527832, Accuracy: 0.27734375\n",
      "Batch: 144, Loss: 2.665268659591675, Accuracy: 0.2919921875\n",
      "Batch: 145, Loss: 2.5218405723571777, Accuracy: 0.2978515625\n",
      "Batch: 146, Loss: 2.6466102600097656, Accuracy: 0.2802734375\n",
      "Batch: 147, Loss: 2.6251442432403564, Accuracy: 0.283203125\n",
      "Batch: 148, Loss: 2.5192694664001465, Accuracy: 0.3173828125\n",
      "Batch: 149, Loss: 2.606060743331909, Accuracy: 0.3046875\n",
      "Batch: 150, Loss: 2.549243211746216, Accuracy: 0.306640625\n",
      "Batch: 151, Loss: 2.686943531036377, Accuracy: 0.2900390625\n",
      "Epoch 2/80\n",
      "Batch: 1, Loss: 2.425673723220825, Accuracy: 0.3203125\n",
      "Batch: 2, Loss: 2.3030333518981934, Accuracy: 0.3427734375\n",
      "Batch: 3, Loss: 2.5628538131713867, Accuracy: 0.2978515625\n",
      "Batch: 4, Loss: 2.673455238342285, Accuracy: 0.2822265625\n",
      "Batch: 5, Loss: 2.528473377227783, Accuracy: 0.326171875\n",
      "Batch: 6, Loss: 2.3515894412994385, Accuracy: 0.3408203125\n",
      "Batch: 7, Loss: 2.3274502754211426, Accuracy: 0.3369140625\n",
      "Batch: 8, Loss: 2.4261560440063477, Accuracy: 0.33984375\n",
      "Batch: 9, Loss: 2.4611077308654785, Accuracy: 0.3388671875\n",
      "Batch: 10, Loss: 2.4213576316833496, Accuracy: 0.3525390625\n",
      "Batch: 11, Loss: 2.221996307373047, Accuracy: 0.3662109375\n",
      "Batch: 12, Loss: 2.445429801940918, Accuracy: 0.318359375\n",
      "Batch: 13, Loss: 2.547576665878296, Accuracy: 0.3056640625\n",
      "Batch: 14, Loss: 2.405156135559082, Accuracy: 0.3359375\n",
      "Batch: 15, Loss: 2.6043496131896973, Accuracy: 0.310546875\n",
      "Batch: 16, Loss: 2.314246654510498, Accuracy: 0.3349609375\n",
      "Batch: 17, Loss: 2.3165600299835205, Accuracy: 0.3515625\n",
      "Batch: 18, Loss: 2.3027291297912598, Accuracy: 0.3310546875\n",
      "Batch: 19, Loss: 2.4641025066375732, Accuracy: 0.3212890625\n",
      "Batch: 20, Loss: 2.550050735473633, Accuracy: 0.3212890625\n",
      "Batch: 21, Loss: 2.3832263946533203, Accuracy: 0.33203125\n",
      "Batch: 22, Loss: 2.371502161026001, Accuracy: 0.34375\n",
      "Batch: 23, Loss: 2.3153343200683594, Accuracy: 0.3466796875\n",
      "Batch: 24, Loss: 2.484682559967041, Accuracy: 0.310546875\n",
      "Batch: 25, Loss: 2.334214687347412, Accuracy: 0.3505859375\n",
      "Batch: 26, Loss: 2.2709150314331055, Accuracy: 0.361328125\n",
      "Batch: 27, Loss: 2.3449196815490723, Accuracy: 0.326171875\n",
      "Batch: 28, Loss: 2.2685704231262207, Accuracy: 0.33984375\n",
      "Batch: 29, Loss: 2.3463706970214844, Accuracy: 0.3291015625\n",
      "Batch: 30, Loss: 2.602905750274658, Accuracy: 0.296875\n",
      "Batch: 31, Loss: 2.5267436504364014, Accuracy: 0.3173828125\n",
      "Batch: 32, Loss: 2.2859930992126465, Accuracy: 0.3642578125\n",
      "Batch: 33, Loss: 2.34586238861084, Accuracy: 0.3427734375\n",
      "Batch: 34, Loss: 2.3836846351623535, Accuracy: 0.337890625\n",
      "Batch: 35, Loss: 2.384544849395752, Accuracy: 0.328125\n",
      "Batch: 36, Loss: 2.5169172286987305, Accuracy: 0.3134765625\n",
      "Batch: 37, Loss: 2.3482136726379395, Accuracy: 0.3583984375\n",
      "Batch: 38, Loss: 2.3139443397521973, Accuracy: 0.3583984375\n",
      "Batch: 39, Loss: 2.33237624168396, Accuracy: 0.36328125\n",
      "Batch: 40, Loss: 2.452350616455078, Accuracy: 0.3515625\n",
      "Batch: 41, Loss: 2.3614282608032227, Accuracy: 0.3505859375\n",
      "Batch: 42, Loss: 2.1455137729644775, Accuracy: 0.400390625\n",
      "Batch: 43, Loss: 2.1476378440856934, Accuracy: 0.3828125\n",
      "Batch: 44, Loss: 2.103566884994507, Accuracy: 0.40234375\n",
      "Batch: 45, Loss: 2.1461000442504883, Accuracy: 0.3955078125\n",
      "Batch: 46, Loss: 2.3646562099456787, Accuracy: 0.365234375\n",
      "Batch: 47, Loss: 2.4387662410736084, Accuracy: 0.34765625\n",
      "Batch: 48, Loss: 2.3289928436279297, Accuracy: 0.37109375\n",
      "Batch: 49, Loss: 2.2897987365722656, Accuracy: 0.3623046875\n",
      "Batch: 50, Loss: 2.2988080978393555, Accuracy: 0.3564453125\n",
      "Batch: 51, Loss: 2.3222899436950684, Accuracy: 0.3583984375\n",
      "Batch: 52, Loss: 2.3384180068969727, Accuracy: 0.3623046875\n",
      "Batch: 53, Loss: 2.187856674194336, Accuracy: 0.3828125\n",
      "Batch: 54, Loss: 2.310962438583374, Accuracy: 0.3740234375\n",
      "Batch: 55, Loss: 2.154707908630371, Accuracy: 0.3974609375\n",
      "Batch: 56, Loss: 2.2675838470458984, Accuracy: 0.392578125\n",
      "Batch: 57, Loss: 2.2413277626037598, Accuracy: 0.396484375\n",
      "Batch: 58, Loss: 2.252901792526245, Accuracy: 0.388671875\n",
      "Batch: 59, Loss: 2.2508063316345215, Accuracy: 0.3818359375\n",
      "Batch: 60, Loss: 2.1625051498413086, Accuracy: 0.392578125\n",
      "Batch: 61, Loss: 2.1610355377197266, Accuracy: 0.3935546875\n",
      "Batch: 62, Loss: 2.311594009399414, Accuracy: 0.369140625\n",
      "Batch: 63, Loss: 2.216143846511841, Accuracy: 0.3974609375\n",
      "Batch: 64, Loss: 2.19579815864563, Accuracy: 0.3935546875\n",
      "Batch: 65, Loss: 2.200857639312744, Accuracy: 0.3818359375\n",
      "Batch: 66, Loss: 2.108423948287964, Accuracy: 0.4140625\n",
      "Batch: 67, Loss: 2.1226255893707275, Accuracy: 0.41015625\n",
      "Batch: 68, Loss: 2.2626261711120605, Accuracy: 0.404296875\n",
      "Batch: 69, Loss: 2.2273964881896973, Accuracy: 0.388671875\n",
      "Batch: 70, Loss: 2.253329038619995, Accuracy: 0.3896484375\n",
      "Batch: 71, Loss: 2.1645750999450684, Accuracy: 0.3955078125\n",
      "Batch: 72, Loss: 2.1320271492004395, Accuracy: 0.4072265625\n",
      "Batch: 73, Loss: 2.282331943511963, Accuracy: 0.3896484375\n",
      "Batch: 74, Loss: 2.1790452003479004, Accuracy: 0.40234375\n",
      "Batch: 75, Loss: 2.0863866806030273, Accuracy: 0.4267578125\n",
      "Batch: 76, Loss: 2.091111898422241, Accuracy: 0.41015625\n",
      "Batch: 77, Loss: 2.148120880126953, Accuracy: 0.3916015625\n",
      "Batch: 78, Loss: 2.321145534515381, Accuracy: 0.3935546875\n",
      "Batch: 79, Loss: 2.2175283432006836, Accuracy: 0.4296875\n",
      "Batch: 80, Loss: 1.9983290433883667, Accuracy: 0.4404296875\n",
      "Batch: 81, Loss: 1.9990462064743042, Accuracy: 0.4248046875\n",
      "Batch: 82, Loss: 2.0134410858154297, Accuracy: 0.4287109375\n",
      "Batch: 83, Loss: 2.084951877593994, Accuracy: 0.4375\n",
      "Batch: 84, Loss: 2.1115834712982178, Accuracy: 0.4423828125\n",
      "Batch: 85, Loss: 2.094158411026001, Accuracy: 0.4423828125\n",
      "Batch: 86, Loss: 2.1131930351257324, Accuracy: 0.41015625\n",
      "Batch: 87, Loss: 2.1015992164611816, Accuracy: 0.43359375\n",
      "Batch: 88, Loss: 2.160337448120117, Accuracy: 0.4248046875\n",
      "Batch: 89, Loss: 2.118863582611084, Accuracy: 0.435546875\n",
      "Batch: 90, Loss: 2.0876622200012207, Accuracy: 0.4345703125\n",
      "Batch: 91, Loss: 2.0811352729797363, Accuracy: 0.4267578125\n",
      "Batch: 92, Loss: 2.1037774085998535, Accuracy: 0.4267578125\n",
      "Batch: 93, Loss: 2.050814628601074, Accuracy: 0.451171875\n",
      "Batch: 94, Loss: 2.0219833850860596, Accuracy: 0.4462890625\n",
      "Batch: 95, Loss: 1.9190342426300049, Accuracy: 0.451171875\n",
      "Batch: 96, Loss: 2.140688419342041, Accuracy: 0.4326171875\n",
      "Batch: 97, Loss: 2.059619426727295, Accuracy: 0.462890625\n",
      "Batch: 98, Loss: 1.9946221113204956, Accuracy: 0.4716796875\n",
      "Batch: 99, Loss: 1.9319040775299072, Accuracy: 0.46875\n",
      "Batch: 100, Loss: 1.890763282775879, Accuracy: 0.47265625\n",
      "Batch: 101, Loss: 1.9637203216552734, Accuracy: 0.4521484375\n",
      "Batch: 102, Loss: 1.9007644653320312, Accuracy: 0.4775390625\n",
      "Batch: 103, Loss: 2.1592111587524414, Accuracy: 0.439453125\n",
      "Batch: 104, Loss: 1.9108388423919678, Accuracy: 0.4951171875\n",
      "Batch: 105, Loss: 1.9625097513198853, Accuracy: 0.474609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 106, Loss: 2.0507140159606934, Accuracy: 0.439453125\n",
      "Batch: 107, Loss: 2.094038248062134, Accuracy: 0.4248046875\n",
      "Batch: 108, Loss: 2.140477180480957, Accuracy: 0.4462890625\n",
      "Batch: 109, Loss: 2.0874061584472656, Accuracy: 0.4443359375\n",
      "Batch: 110, Loss: 1.88535737991333, Accuracy: 0.4814453125\n",
      "Batch: 111, Loss: 1.929410457611084, Accuracy: 0.46484375\n",
      "Batch: 112, Loss: 2.1033430099487305, Accuracy: 0.4541015625\n",
      "Batch: 113, Loss: 2.1319150924682617, Accuracy: 0.4384765625\n",
      "Batch: 114, Loss: 2.051302671432495, Accuracy: 0.4345703125\n",
      "Batch: 115, Loss: 2.061023473739624, Accuracy: 0.4462890625\n",
      "Batch: 116, Loss: 2.076653242111206, Accuracy: 0.4189453125\n",
      "Batch: 117, Loss: 2.163181781768799, Accuracy: 0.4287109375\n",
      "Batch: 118, Loss: 2.000194787979126, Accuracy: 0.48046875\n",
      "Batch: 119, Loss: 2.0290579795837402, Accuracy: 0.466796875\n",
      "Batch: 120, Loss: 1.984151840209961, Accuracy: 0.453125\n",
      "Batch: 121, Loss: 1.9987012147903442, Accuracy: 0.458984375\n",
      "Batch: 122, Loss: 2.07409405708313, Accuracy: 0.4609375\n",
      "Batch: 123, Loss: 2.038313388824463, Accuracy: 0.4599609375\n",
      "Batch: 124, Loss: 2.021364688873291, Accuracy: 0.458984375\n",
      "Batch: 125, Loss: 1.9806759357452393, Accuracy: 0.44140625\n",
      "Batch: 126, Loss: 2.0056979656219482, Accuracy: 0.4248046875\n",
      "Batch: 127, Loss: 1.9906394481658936, Accuracy: 0.4677734375\n",
      "Batch: 128, Loss: 2.165541648864746, Accuracy: 0.412109375\n",
      "Batch: 129, Loss: 1.9870562553405762, Accuracy: 0.455078125\n",
      "Batch: 130, Loss: 2.1221985816955566, Accuracy: 0.419921875\n",
      "Batch: 131, Loss: 2.0223336219787598, Accuracy: 0.4580078125\n",
      "Batch: 132, Loss: 2.0665714740753174, Accuracy: 0.4521484375\n",
      "Batch: 133, Loss: 1.9873583316802979, Accuracy: 0.482421875\n",
      "Batch: 134, Loss: 2.0174784660339355, Accuracy: 0.4580078125\n",
      "Batch: 135, Loss: 1.8845572471618652, Accuracy: 0.4970703125\n",
      "Batch: 136, Loss: 1.8803989887237549, Accuracy: 0.4638671875\n",
      "Batch: 137, Loss: 1.7712358236312866, Accuracy: 0.4794921875\n",
      "Batch: 138, Loss: 1.7506022453308105, Accuracy: 0.51171875\n",
      "Batch: 139, Loss: 1.8202924728393555, Accuracy: 0.4775390625\n",
      "Batch: 140, Loss: 1.9433372020721436, Accuracy: 0.4755859375\n",
      "Batch: 141, Loss: 1.9392718076705933, Accuracy: 0.4921875\n",
      "Batch: 142, Loss: 1.923012614250183, Accuracy: 0.4677734375\n",
      "Batch: 143, Loss: 1.9934170246124268, Accuracy: 0.4560546875\n",
      "Batch: 144, Loss: 1.9315617084503174, Accuracy: 0.4716796875\n",
      "Batch: 145, Loss: 1.857112169265747, Accuracy: 0.46484375\n",
      "Batch: 146, Loss: 1.9719891548156738, Accuracy: 0.4375\n",
      "Batch: 147, Loss: 1.913641095161438, Accuracy: 0.474609375\n",
      "Batch: 148, Loss: 1.9641807079315186, Accuracy: 0.419921875\n",
      "Batch: 149, Loss: 1.9631879329681396, Accuracy: 0.4326171875\n",
      "Batch: 150, Loss: 1.8841443061828613, Accuracy: 0.4609375\n",
      "Batch: 151, Loss: 1.9407873153686523, Accuracy: 0.484375\n",
      "Epoch 3/80\n",
      "Batch: 1, Loss: 1.9358606338500977, Accuracy: 0.4287109375\n",
      "Batch: 2, Loss: 1.752284288406372, Accuracy: 0.4775390625\n",
      "Batch: 3, Loss: 1.8896604776382446, Accuracy: 0.4873046875\n",
      "Batch: 4, Loss: 1.8607769012451172, Accuracy: 0.5224609375\n",
      "Batch: 5, Loss: 1.880495309829712, Accuracy: 0.47265625\n",
      "Batch: 6, Loss: 1.8001255989074707, Accuracy: 0.48046875\n",
      "Batch: 7, Loss: 1.7533698081970215, Accuracy: 0.501953125\n",
      "Batch: 8, Loss: 1.7692614793777466, Accuracy: 0.505859375\n",
      "Batch: 9, Loss: 1.7419196367263794, Accuracy: 0.51953125\n",
      "Batch: 10, Loss: 1.8200575113296509, Accuracy: 0.482421875\n",
      "Batch: 11, Loss: 1.766340970993042, Accuracy: 0.4677734375\n",
      "Batch: 12, Loss: 1.9121289253234863, Accuracy: 0.4560546875\n",
      "Batch: 13, Loss: 1.7832140922546387, Accuracy: 0.51953125\n",
      "Batch: 14, Loss: 1.8576686382293701, Accuracy: 0.48046875\n",
      "Batch: 15, Loss: 1.8805464506149292, Accuracy: 0.5068359375\n",
      "Batch: 16, Loss: 1.7799863815307617, Accuracy: 0.498046875\n",
      "Batch: 17, Loss: 1.8002851009368896, Accuracy: 0.4765625\n",
      "Batch: 18, Loss: 1.8148407936096191, Accuracy: 0.4619140625\n",
      "Batch: 19, Loss: 1.8936365842819214, Accuracy: 0.4775390625\n",
      "Batch: 20, Loss: 1.8992395401000977, Accuracy: 0.486328125\n",
      "Batch: 21, Loss: 1.7375802993774414, Accuracy: 0.5263671875\n",
      "Batch: 22, Loss: 1.8675827980041504, Accuracy: 0.4453125\n",
      "Batch: 23, Loss: 1.7344081401824951, Accuracy: 0.51171875\n",
      "Batch: 24, Loss: 1.8571289777755737, Accuracy: 0.486328125\n",
      "Batch: 25, Loss: 1.7425518035888672, Accuracy: 0.4951171875\n",
      "Batch: 26, Loss: 1.6722806692123413, Accuracy: 0.5234375\n",
      "Batch: 27, Loss: 1.797729730606079, Accuracy: 0.45703125\n",
      "Batch: 28, Loss: 1.7791192531585693, Accuracy: 0.48046875\n",
      "Batch: 29, Loss: 1.8004469871520996, Accuracy: 0.486328125\n",
      "Batch: 30, Loss: 1.8938231468200684, Accuracy: 0.5087890625\n",
      "Batch: 31, Loss: 1.8584033250808716, Accuracy: 0.5078125\n",
      "Batch: 32, Loss: 1.7180511951446533, Accuracy: 0.51171875\n",
      "Batch: 33, Loss: 1.8595521450042725, Accuracy: 0.4677734375\n",
      "Batch: 34, Loss: 1.9396311044692993, Accuracy: 0.4658203125\n",
      "Batch: 35, Loss: 1.85288405418396, Accuracy: 0.4853515625\n",
      "Batch: 36, Loss: 1.8929837942123413, Accuracy: 0.48046875\n",
      "Batch: 37, Loss: 1.85088050365448, Accuracy: 0.48046875\n",
      "Batch: 38, Loss: 1.791464924812317, Accuracy: 0.4794921875\n",
      "Batch: 39, Loss: 1.8296494483947754, Accuracy: 0.4970703125\n",
      "Batch: 40, Loss: 1.9044930934906006, Accuracy: 0.5048828125\n",
      "Batch: 41, Loss: 1.8811640739440918, Accuracy: 0.4921875\n",
      "Batch: 42, Loss: 1.6304097175598145, Accuracy: 0.521484375\n",
      "Batch: 43, Loss: 1.6871800422668457, Accuracy: 0.49609375\n",
      "Batch: 44, Loss: 1.6516741514205933, Accuracy: 0.5068359375\n",
      "Batch: 45, Loss: 1.6025047302246094, Accuracy: 0.52734375\n",
      "Batch: 46, Loss: 1.8244850635528564, Accuracy: 0.5009765625\n",
      "Batch: 47, Loss: 1.8968020677566528, Accuracy: 0.474609375\n",
      "Batch: 48, Loss: 1.8099297285079956, Accuracy: 0.5029296875\n",
      "Batch: 49, Loss: 1.8754627704620361, Accuracy: 0.4697265625\n",
      "Batch: 50, Loss: 1.876180648803711, Accuracy: 0.4638671875\n",
      "Batch: 51, Loss: 1.912672758102417, Accuracy: 0.4638671875\n",
      "Batch: 52, Loss: 1.8811805248260498, Accuracy: 0.4814453125\n",
      "Batch: 53, Loss: 1.674689769744873, Accuracy: 0.517578125\n",
      "Batch: 54, Loss: 1.8058078289031982, Accuracy: 0.4970703125\n",
      "Batch: 55, Loss: 1.7025623321533203, Accuracy: 0.509765625\n",
      "Batch: 56, Loss: 1.8670153617858887, Accuracy: 0.4892578125\n",
      "Batch: 57, Loss: 1.7989938259124756, Accuracy: 0.5068359375\n",
      "Batch: 58, Loss: 1.8285844326019287, Accuracy: 0.474609375\n",
      "Batch: 59, Loss: 1.7135939598083496, Accuracy: 0.5458984375\n",
      "Batch: 60, Loss: 1.693960428237915, Accuracy: 0.5009765625\n",
      "Batch: 61, Loss: 1.747745394706726, Accuracy: 0.501953125\n",
      "Batch: 62, Loss: 1.7834135293960571, Accuracy: 0.5048828125\n",
      "Batch: 63, Loss: 1.7678823471069336, Accuracy: 0.490234375\n",
      "Batch: 64, Loss: 1.7508454322814941, Accuracy: 0.4970703125\n",
      "Batch: 65, Loss: 1.7694247961044312, Accuracy: 0.49609375\n",
      "Batch: 66, Loss: 1.672098159790039, Accuracy: 0.5234375\n",
      "Batch: 67, Loss: 1.7633284330368042, Accuracy: 0.51171875\n",
      "Batch: 68, Loss: 1.8261016607284546, Accuracy: 0.5107421875\n",
      "Batch: 69, Loss: 1.7722004652023315, Accuracy: 0.5\n",
      "Batch: 70, Loss: 1.8192427158355713, Accuracy: 0.501953125\n",
      "Batch: 71, Loss: 1.7457036972045898, Accuracy: 0.5078125\n",
      "Batch: 72, Loss: 1.663770079612732, Accuracy: 0.5166015625\n",
      "Batch: 73, Loss: 1.775065302848816, Accuracy: 0.50390625\n",
      "Batch: 74, Loss: 1.6738466024398804, Accuracy: 0.525390625\n",
      "Batch: 75, Loss: 1.6176819801330566, Accuracy: 0.5302734375\n",
      "Batch: 76, Loss: 1.6997864246368408, Accuracy: 0.4697265625\n",
      "Batch: 77, Loss: 1.7237974405288696, Accuracy: 0.4970703125\n",
      "Batch: 78, Loss: 1.8063392639160156, Accuracy: 0.517578125\n",
      "Batch: 79, Loss: 1.6952424049377441, Accuracy: 0.5556640625\n",
      "Batch: 80, Loss: 1.6018328666687012, Accuracy: 0.5234375\n",
      "Batch: 81, Loss: 1.715214490890503, Accuracy: 0.4677734375\n",
      "Batch: 82, Loss: 1.6710054874420166, Accuracy: 0.4775390625\n",
      "Batch: 83, Loss: 1.6215381622314453, Accuracy: 0.537109375\n",
      "Batch: 84, Loss: 1.6553627252578735, Accuracy: 0.5517578125\n",
      "Batch: 85, Loss: 1.6715354919433594, Accuracy: 0.529296875\n",
      "Batch: 86, Loss: 1.7889057397842407, Accuracy: 0.470703125\n",
      "Batch: 87, Loss: 1.6562161445617676, Accuracy: 0.521484375\n",
      "Batch: 88, Loss: 1.771605372428894, Accuracy: 0.4990234375\n",
      "Batch: 89, Loss: 1.74794340133667, Accuracy: 0.490234375\n",
      "Batch: 90, Loss: 1.6622990369796753, Accuracy: 0.5341796875\n",
      "Batch: 91, Loss: 1.6654484272003174, Accuracy: 0.525390625\n",
      "Batch: 92, Loss: 1.742356777191162, Accuracy: 0.5009765625\n",
      "Batch: 93, Loss: 1.657792091369629, Accuracy: 0.533203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 94, Loss: 1.6274139881134033, Accuracy: 0.517578125\n",
      "Batch: 95, Loss: 1.6308321952819824, Accuracy: 0.5\n",
      "Batch: 96, Loss: 1.710994839668274, Accuracy: 0.505859375\n",
      "Batch: 97, Loss: 1.6148775815963745, Accuracy: 0.53125\n",
      "Batch: 98, Loss: 1.6052021980285645, Accuracy: 0.5546875\n",
      "Batch: 99, Loss: 1.5704319477081299, Accuracy: 0.53125\n",
      "Batch: 100, Loss: 1.603724479675293, Accuracy: 0.5185546875\n",
      "Batch: 101, Loss: 1.6103531122207642, Accuracy: 0.515625\n",
      "Batch: 102, Loss: 1.5851283073425293, Accuracy: 0.5244140625\n",
      "Batch: 103, Loss: 1.7265279293060303, Accuracy: 0.5380859375\n",
      "Batch: 104, Loss: 1.5687236785888672, Accuracy: 0.541015625\n",
      "Batch: 105, Loss: 1.684617280960083, Accuracy: 0.4931640625\n",
      "Batch: 106, Loss: 1.7031844854354858, Accuracy: 0.4990234375\n",
      "Batch: 107, Loss: 1.7944755554199219, Accuracy: 0.4853515625\n",
      "Batch: 108, Loss: 1.8079833984375, Accuracy: 0.4873046875\n",
      "Batch: 109, Loss: 1.7943141460418701, Accuracy: 0.4873046875\n",
      "Batch: 110, Loss: 1.542128562927246, Accuracy: 0.546875\n",
      "Batch: 111, Loss: 1.6636708974838257, Accuracy: 0.51171875\n",
      "Batch: 112, Loss: 1.7185230255126953, Accuracy: 0.53125\n",
      "Batch: 113, Loss: 1.7591638565063477, Accuracy: 0.5205078125\n",
      "Batch: 114, Loss: 1.761265516281128, Accuracy: 0.486328125\n",
      "Batch: 115, Loss: 1.7915537357330322, Accuracy: 0.5029296875\n",
      "Batch: 116, Loss: 1.7704906463623047, Accuracy: 0.4755859375\n",
      "Batch: 117, Loss: 1.7963342666625977, Accuracy: 0.5146484375\n",
      "Batch: 118, Loss: 1.597172737121582, Accuracy: 0.5595703125\n",
      "Batch: 119, Loss: 1.6552557945251465, Accuracy: 0.5439453125\n",
      "Batch: 120, Loss: 1.7247719764709473, Accuracy: 0.48828125\n",
      "Batch: 121, Loss: 1.771925687789917, Accuracy: 0.486328125\n",
      "Batch: 122, Loss: 1.6718944311141968, Accuracy: 0.537109375\n",
      "Batch: 123, Loss: 1.653428077697754, Accuracy: 0.5283203125\n",
      "Batch: 124, Loss: 1.6743988990783691, Accuracy: 0.533203125\n",
      "Batch: 125, Loss: 1.7284808158874512, Accuracy: 0.490234375\n",
      "Batch: 126, Loss: 1.687896728515625, Accuracy: 0.4912109375\n",
      "Batch: 127, Loss: 1.5996513366699219, Accuracy: 0.5654296875\n",
      "Batch: 128, Loss: 1.849336862564087, Accuracy: 0.486328125\n",
      "Batch: 129, Loss: 1.6838395595550537, Accuracy: 0.5166015625\n",
      "Batch: 130, Loss: 1.9033970832824707, Accuracy: 0.46875\n",
      "Batch: 131, Loss: 1.7525577545166016, Accuracy: 0.4951171875\n",
      "Batch: 132, Loss: 1.7588880062103271, Accuracy: 0.513671875\n",
      "Batch: 133, Loss: 1.671900987625122, Accuracy: 0.5302734375\n",
      "Batch: 134, Loss: 1.6844021081924438, Accuracy: 0.5107421875\n",
      "Batch: 135, Loss: 1.6205644607543945, Accuracy: 0.546875\n",
      "Batch: 136, Loss: 1.6176066398620605, Accuracy: 0.5185546875\n",
      "Batch: 137, Loss: 1.538259506225586, Accuracy: 0.52734375\n",
      "Batch: 138, Loss: 1.44666588306427, Accuracy: 0.5546875\n",
      "Batch: 139, Loss: 1.4719083309173584, Accuracy: 0.552734375\n",
      "Batch: 140, Loss: 1.6347436904907227, Accuracy: 0.50390625\n",
      "Batch: 141, Loss: 1.6454226970672607, Accuracy: 0.5439453125\n",
      "Batch: 142, Loss: 1.6453752517700195, Accuracy: 0.50390625\n",
      "Batch: 143, Loss: 1.6853759288787842, Accuracy: 0.5107421875\n",
      "Batch: 144, Loss: 1.6534912586212158, Accuracy: 0.5244140625\n",
      "Batch: 145, Loss: 1.5408846139907837, Accuracy: 0.537109375\n",
      "Batch: 146, Loss: 1.693650722503662, Accuracy: 0.50390625\n",
      "Batch: 147, Loss: 1.6240856647491455, Accuracy: 0.517578125\n",
      "Batch: 148, Loss: 1.7516106367111206, Accuracy: 0.458984375\n",
      "Batch: 149, Loss: 1.6831834316253662, Accuracy: 0.474609375\n",
      "Batch: 150, Loss: 1.6026198863983154, Accuracy: 0.5244140625\n",
      "Batch: 151, Loss: 1.6174569129943848, Accuracy: 0.544921875\n",
      "Epoch 4/80\n",
      "Batch: 1, Loss: 1.7872778177261353, Accuracy: 0.4638671875\n",
      "Batch: 2, Loss: 1.5553069114685059, Accuracy: 0.5\n",
      "Batch: 3, Loss: 1.577460765838623, Accuracy: 0.5517578125\n",
      "Batch: 4, Loss: 1.541872501373291, Accuracy: 0.5673828125\n",
      "Batch: 5, Loss: 1.587024450302124, Accuracy: 0.5361328125\n",
      "Batch: 6, Loss: 1.6266244649887085, Accuracy: 0.501953125\n",
      "Batch: 7, Loss: 1.5708527565002441, Accuracy: 0.53515625\n",
      "Batch: 8, Loss: 1.522912859916687, Accuracy: 0.5400390625\n",
      "Batch: 9, Loss: 1.488161325454712, Accuracy: 0.5576171875\n",
      "Batch: 10, Loss: 1.5665769577026367, Accuracy: 0.52734375\n",
      "Batch: 11, Loss: 1.609691858291626, Accuracy: 0.4931640625\n",
      "Batch: 12, Loss: 1.7157373428344727, Accuracy: 0.490234375\n",
      "Batch: 13, Loss: 1.4685252904891968, Accuracy: 0.5859375\n",
      "Batch: 14, Loss: 1.6444754600524902, Accuracy: 0.505859375\n",
      "Batch: 15, Loss: 1.5927820205688477, Accuracy: 0.53515625\n",
      "Batch: 16, Loss: 1.5457595586776733, Accuracy: 0.5322265625\n",
      "Batch: 17, Loss: 1.5894700288772583, Accuracy: 0.509765625\n",
      "Batch: 18, Loss: 1.6204007863998413, Accuracy: 0.4951171875\n",
      "Batch: 19, Loss: 1.6616383790969849, Accuracy: 0.5029296875\n",
      "Batch: 20, Loss: 1.6224958896636963, Accuracy: 0.5400390625\n",
      "Batch: 21, Loss: 1.5188671350479126, Accuracy: 0.548828125\n",
      "Batch: 22, Loss: 1.6823148727416992, Accuracy: 0.4833984375\n",
      "Batch: 23, Loss: 1.5154564380645752, Accuracy: 0.529296875\n",
      "Batch: 24, Loss: 1.6309800148010254, Accuracy: 0.5283203125\n",
      "Batch: 25, Loss: 1.560789704322815, Accuracy: 0.5185546875\n",
      "Batch: 26, Loss: 1.4548392295837402, Accuracy: 0.5537109375\n",
      "Batch: 27, Loss: 1.5620492696762085, Accuracy: 0.5126953125\n",
      "Batch: 28, Loss: 1.5936944484710693, Accuracy: 0.509765625\n",
      "Batch: 29, Loss: 1.6106241941452026, Accuracy: 0.5224609375\n",
      "Batch: 30, Loss: 1.6159319877624512, Accuracy: 0.5498046875\n",
      "Batch: 31, Loss: 1.588160514831543, Accuracy: 0.5595703125\n",
      "Batch: 32, Loss: 1.5238299369812012, Accuracy: 0.552734375\n",
      "Batch: 33, Loss: 1.685943841934204, Accuracy: 0.4970703125\n",
      "Batch: 34, Loss: 1.7903696298599243, Accuracy: 0.482421875\n",
      "Batch: 35, Loss: 1.6009266376495361, Accuracy: 0.51953125\n",
      "Batch: 36, Loss: 1.6338093280792236, Accuracy: 0.5361328125\n",
      "Batch: 37, Loss: 1.658707857131958, Accuracy: 0.5263671875\n",
      "Batch: 38, Loss: 1.6021283864974976, Accuracy: 0.51171875\n",
      "Batch: 39, Loss: 1.6385915279388428, Accuracy: 0.5029296875\n",
      "Batch: 40, Loss: 1.6833133697509766, Accuracy: 0.5400390625\n",
      "Batch: 41, Loss: 1.6894159317016602, Accuracy: 0.5185546875\n",
      "Batch: 42, Loss: 1.4216430187225342, Accuracy: 0.5693359375\n",
      "Batch: 43, Loss: 1.538691520690918, Accuracy: 0.517578125\n",
      "Batch: 44, Loss: 1.5107691287994385, Accuracy: 0.51171875\n",
      "Batch: 45, Loss: 1.4125618934631348, Accuracy: 0.5654296875\n",
      "Batch: 46, Loss: 1.600648045539856, Accuracy: 0.54296875\n",
      "Batch: 47, Loss: 1.6541728973388672, Accuracy: 0.533203125\n",
      "Batch: 48, Loss: 1.5783917903900146, Accuracy: 0.544921875\n",
      "Batch: 49, Loss: 1.689007043838501, Accuracy: 0.5009765625\n",
      "Batch: 50, Loss: 1.700400710105896, Accuracy: 0.5009765625\n",
      "Batch: 51, Loss: 1.7323009967803955, Accuracy: 0.4921875\n",
      "Batch: 52, Loss: 1.683464765548706, Accuracy: 0.515625\n",
      "Batch: 53, Loss: 1.462192416191101, Accuracy: 0.552734375\n",
      "Batch: 54, Loss: 1.5991992950439453, Accuracy: 0.546875\n",
      "Batch: 55, Loss: 1.5495991706848145, Accuracy: 0.53515625\n",
      "Batch: 56, Loss: 1.6885534524917603, Accuracy: 0.505859375\n",
      "Batch: 57, Loss: 1.5751826763153076, Accuracy: 0.55078125\n",
      "Batch: 58, Loss: 1.6892783641815186, Accuracy: 0.5146484375\n",
      "Batch: 59, Loss: 1.4735486507415771, Accuracy: 0.5849609375\n",
      "Batch: 60, Loss: 1.4938533306121826, Accuracy: 0.53515625\n",
      "Batch: 61, Loss: 1.5765433311462402, Accuracy: 0.5185546875\n",
      "Batch: 62, Loss: 1.5867514610290527, Accuracy: 0.53125\n",
      "Batch: 63, Loss: 1.584302544593811, Accuracy: 0.5185546875\n",
      "Batch: 64, Loss: 1.5395172834396362, Accuracy: 0.54296875\n",
      "Batch: 65, Loss: 1.5856176614761353, Accuracy: 0.5322265625\n",
      "Batch: 66, Loss: 1.4642237424850464, Accuracy: 0.5693359375\n",
      "Batch: 67, Loss: 1.620079755783081, Accuracy: 0.5224609375\n",
      "Batch: 68, Loss: 1.653701901435852, Accuracy: 0.5478515625\n",
      "Batch: 69, Loss: 1.5681440830230713, Accuracy: 0.5400390625\n",
      "Batch: 70, Loss: 1.6135307550430298, Accuracy: 0.5263671875\n",
      "Batch: 71, Loss: 1.5734970569610596, Accuracy: 0.5302734375\n",
      "Batch: 72, Loss: 1.4999094009399414, Accuracy: 0.541015625\n",
      "Batch: 73, Loss: 1.5610392093658447, Accuracy: 0.54296875\n",
      "Batch: 74, Loss: 1.513522982597351, Accuracy: 0.546875\n",
      "Batch: 75, Loss: 1.4364038705825806, Accuracy: 0.5712890625\n",
      "Batch: 76, Loss: 1.5490509271621704, Accuracy: 0.494140625\n",
      "Batch: 77, Loss: 1.5646750926971436, Accuracy: 0.5078125\n",
      "Batch: 78, Loss: 1.5719523429870605, Accuracy: 0.548828125\n",
      "Batch: 79, Loss: 1.4569792747497559, Accuracy: 0.5830078125\n",
      "Batch: 80, Loss: 1.426580786705017, Accuracy: 0.5615234375\n",
      "Batch: 81, Loss: 1.5770268440246582, Accuracy: 0.4931640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 82, Loss: 1.5306901931762695, Accuracy: 0.5126953125\n",
      "Batch: 83, Loss: 1.425638198852539, Accuracy: 0.5810546875\n",
      "Batch: 84, Loss: 1.4679248332977295, Accuracy: 0.5869140625\n",
      "Batch: 85, Loss: 1.4591352939605713, Accuracy: 0.5712890625\n",
      "Batch: 86, Loss: 1.6338322162628174, Accuracy: 0.509765625\n",
      "Batch: 87, Loss: 1.4532408714294434, Accuracy: 0.587890625\n",
      "Batch: 88, Loss: 1.5881534814834595, Accuracy: 0.5283203125\n",
      "Batch: 89, Loss: 1.5803816318511963, Accuracy: 0.515625\n",
      "Batch: 90, Loss: 1.4890458583831787, Accuracy: 0.5439453125\n",
      "Batch: 91, Loss: 1.4976420402526855, Accuracy: 0.5576171875\n",
      "Batch: 92, Loss: 1.586625099182129, Accuracy: 0.5234375\n",
      "Batch: 93, Loss: 1.4662755727767944, Accuracy: 0.55859375\n",
      "Batch: 94, Loss: 1.4694645404815674, Accuracy: 0.556640625\n",
      "Batch: 95, Loss: 1.4774346351623535, Accuracy: 0.529296875\n",
      "Batch: 96, Loss: 1.5403748750686646, Accuracy: 0.541015625\n",
      "Batch: 97, Loss: 1.393653392791748, Accuracy: 0.5771484375\n",
      "Batch: 98, Loss: 1.4362659454345703, Accuracy: 0.5859375\n",
      "Batch: 99, Loss: 1.4067699909210205, Accuracy: 0.5654296875\n",
      "Batch: 100, Loss: 1.4860944747924805, Accuracy: 0.53125\n",
      "Batch: 101, Loss: 1.511242151260376, Accuracy: 0.5361328125\n",
      "Batch: 102, Loss: 1.437023401260376, Accuracy: 0.548828125\n",
      "Batch: 103, Loss: 1.564899206161499, Accuracy: 0.552734375\n",
      "Batch: 104, Loss: 1.4162489175796509, Accuracy: 0.56640625\n",
      "Batch: 105, Loss: 1.531049132347107, Accuracy: 0.5361328125\n",
      "Batch: 106, Loss: 1.547828197479248, Accuracy: 0.529296875\n",
      "Batch: 107, Loss: 1.6901795864105225, Accuracy: 0.5009765625\n",
      "Batch: 108, Loss: 1.6505153179168701, Accuracy: 0.5205078125\n",
      "Batch: 109, Loss: 1.6719423532485962, Accuracy: 0.5048828125\n",
      "Batch: 110, Loss: 1.3807047605514526, Accuracy: 0.5849609375\n",
      "Batch: 111, Loss: 1.5431445837020874, Accuracy: 0.5146484375\n",
      "Batch: 112, Loss: 1.5237486362457275, Accuracy: 0.5625\n",
      "Batch: 113, Loss: 1.5721379518508911, Accuracy: 0.560546875\n",
      "Batch: 114, Loss: 1.636391043663025, Accuracy: 0.5205078125\n",
      "Batch: 115, Loss: 1.6703739166259766, Accuracy: 0.529296875\n",
      "Batch: 116, Loss: 1.6395483016967773, Accuracy: 0.4990234375\n",
      "Batch: 117, Loss: 1.6585094928741455, Accuracy: 0.5390625\n",
      "Batch: 118, Loss: 1.3917133808135986, Accuracy: 0.5888671875\n",
      "Batch: 119, Loss: 1.480461597442627, Accuracy: 0.5673828125\n",
      "Batch: 120, Loss: 1.60206139087677, Accuracy: 0.513671875\n",
      "Batch: 121, Loss: 1.6535708904266357, Accuracy: 0.51171875\n",
      "Batch: 122, Loss: 1.5113930702209473, Accuracy: 0.560546875\n",
      "Batch: 123, Loss: 1.495962381362915, Accuracy: 0.5673828125\n",
      "Batch: 124, Loss: 1.5548512935638428, Accuracy: 0.5478515625\n",
      "Batch: 125, Loss: 1.6069998741149902, Accuracy: 0.529296875\n",
      "Batch: 126, Loss: 1.5892255306243896, Accuracy: 0.501953125\n",
      "Batch: 127, Loss: 1.4505274295806885, Accuracy: 0.58984375\n",
      "Batch: 128, Loss: 1.7054609060287476, Accuracy: 0.529296875\n",
      "Batch: 129, Loss: 1.5351701974868774, Accuracy: 0.5419921875\n",
      "Batch: 130, Loss: 1.7576746940612793, Accuracy: 0.4873046875\n",
      "Batch: 131, Loss: 1.584489345550537, Accuracy: 0.521484375\n",
      "Batch: 132, Loss: 1.6100579500198364, Accuracy: 0.5380859375\n",
      "Batch: 133, Loss: 1.4995545148849487, Accuracy: 0.5615234375\n",
      "Batch: 134, Loss: 1.517533779144287, Accuracy: 0.53515625\n",
      "Batch: 135, Loss: 1.48037850856781, Accuracy: 0.55859375\n",
      "Batch: 136, Loss: 1.500356674194336, Accuracy: 0.546875\n",
      "Batch: 137, Loss: 1.4323925971984863, Accuracy: 0.5439453125\n",
      "Batch: 138, Loss: 1.3240489959716797, Accuracy: 0.5849609375\n",
      "Batch: 139, Loss: 1.367250919342041, Accuracy: 0.56640625\n",
      "Batch: 140, Loss: 1.5030580759048462, Accuracy: 0.533203125\n",
      "Batch: 141, Loss: 1.5096237659454346, Accuracy: 0.5517578125\n",
      "Batch: 142, Loss: 1.5184202194213867, Accuracy: 0.525390625\n",
      "Batch: 143, Loss: 1.5555707216262817, Accuracy: 0.5390625\n",
      "Batch: 144, Loss: 1.49124276638031, Accuracy: 0.552734375\n",
      "Batch: 145, Loss: 1.4325840473175049, Accuracy: 0.5458984375\n",
      "Batch: 146, Loss: 1.5855531692504883, Accuracy: 0.51171875\n",
      "Batch: 147, Loss: 1.498549461364746, Accuracy: 0.541015625\n",
      "Batch: 148, Loss: 1.6526936292648315, Accuracy: 0.48828125\n",
      "Batch: 149, Loss: 1.55864679813385, Accuracy: 0.5185546875\n",
      "Batch: 150, Loss: 1.4636589288711548, Accuracy: 0.552734375\n",
      "Batch: 151, Loss: 1.458333969116211, Accuracy: 0.5615234375\n",
      "Epoch 5/80\n",
      "Batch: 1, Loss: 1.658653974533081, Accuracy: 0.4736328125\n",
      "Batch: 2, Loss: 1.456346035003662, Accuracy: 0.5302734375\n",
      "Batch: 3, Loss: 1.4386789798736572, Accuracy: 0.544921875\n",
      "Batch: 4, Loss: 1.3860909938812256, Accuracy: 0.5947265625\n",
      "Batch: 5, Loss: 1.4219212532043457, Accuracy: 0.5771484375\n",
      "Batch: 6, Loss: 1.5066845417022705, Accuracy: 0.509765625\n",
      "Batch: 7, Loss: 1.44431471824646, Accuracy: 0.5361328125\n",
      "Batch: 8, Loss: 1.395087718963623, Accuracy: 0.5673828125\n",
      "Batch: 9, Loss: 1.3659178018569946, Accuracy: 0.5732421875\n",
      "Batch: 10, Loss: 1.4081146717071533, Accuracy: 0.5615234375\n",
      "Batch: 11, Loss: 1.5257086753845215, Accuracy: 0.5224609375\n",
      "Batch: 12, Loss: 1.59407377243042, Accuracy: 0.501953125\n",
      "Batch: 13, Loss: 1.3209507465362549, Accuracy: 0.6103515625\n",
      "Batch: 14, Loss: 1.563340663909912, Accuracy: 0.5205078125\n",
      "Batch: 15, Loss: 1.4669303894042969, Accuracy: 0.5751953125\n",
      "Batch: 16, Loss: 1.4333574771881104, Accuracy: 0.552734375\n",
      "Batch: 17, Loss: 1.5001513957977295, Accuracy: 0.5234375\n",
      "Batch: 18, Loss: 1.5157709121704102, Accuracy: 0.5087890625\n",
      "Batch: 19, Loss: 1.5356271266937256, Accuracy: 0.541015625\n",
      "Batch: 20, Loss: 1.4935197830200195, Accuracy: 0.5615234375\n",
      "Batch: 21, Loss: 1.4063694477081299, Accuracy: 0.55078125\n",
      "Batch: 22, Loss: 1.5833241939544678, Accuracy: 0.5068359375\n",
      "Batch: 23, Loss: 1.4082493782043457, Accuracy: 0.5458984375\n",
      "Batch: 24, Loss: 1.5050190687179565, Accuracy: 0.5322265625\n",
      "Batch: 25, Loss: 1.441078782081604, Accuracy: 0.5615234375\n",
      "Batch: 26, Loss: 1.3397047519683838, Accuracy: 0.6005859375\n",
      "Batch: 27, Loss: 1.4640710353851318, Accuracy: 0.544921875\n",
      "Batch: 28, Loss: 1.4914356470108032, Accuracy: 0.5400390625\n",
      "Batch: 29, Loss: 1.5128765106201172, Accuracy: 0.533203125\n",
      "Batch: 30, Loss: 1.4877912998199463, Accuracy: 0.5703125\n",
      "Batch: 31, Loss: 1.4225257635116577, Accuracy: 0.5966796875\n",
      "Batch: 32, Loss: 1.3974477052688599, Accuracy: 0.5625\n",
      "Batch: 33, Loss: 1.6105616092681885, Accuracy: 0.515625\n",
      "Batch: 34, Loss: 1.6958413124084473, Accuracy: 0.4912109375\n",
      "Batch: 35, Loss: 1.5292198657989502, Accuracy: 0.53125\n",
      "Batch: 36, Loss: 1.5079162120819092, Accuracy: 0.552734375\n",
      "Batch: 37, Loss: 1.5281903743743896, Accuracy: 0.544921875\n",
      "Batch: 38, Loss: 1.4961168766021729, Accuracy: 0.53125\n",
      "Batch: 39, Loss: 1.5339374542236328, Accuracy: 0.533203125\n",
      "Batch: 40, Loss: 1.591812252998352, Accuracy: 0.5693359375\n",
      "Batch: 41, Loss: 1.585795283317566, Accuracy: 0.5400390625\n",
      "Batch: 42, Loss: 1.3143212795257568, Accuracy: 0.5908203125\n",
      "Batch: 43, Loss: 1.4356775283813477, Accuracy: 0.5517578125\n",
      "Batch: 44, Loss: 1.4200252294540405, Accuracy: 0.548828125\n",
      "Batch: 45, Loss: 1.3240022659301758, Accuracy: 0.5732421875\n",
      "Batch: 46, Loss: 1.4775575399398804, Accuracy: 0.57421875\n",
      "Batch: 47, Loss: 1.5257234573364258, Accuracy: 0.5595703125\n",
      "Batch: 48, Loss: 1.4643001556396484, Accuracy: 0.5654296875\n",
      "Batch: 49, Loss: 1.5897797346115112, Accuracy: 0.517578125\n",
      "Batch: 50, Loss: 1.5875542163848877, Accuracy: 0.5146484375\n",
      "Batch: 51, Loss: 1.630813717842102, Accuracy: 0.509765625\n",
      "Batch: 52, Loss: 1.589459776878357, Accuracy: 0.541015625\n",
      "Batch: 53, Loss: 1.3665297031402588, Accuracy: 0.5673828125\n",
      "Batch: 54, Loss: 1.471442461013794, Accuracy: 0.587890625\n",
      "Batch: 55, Loss: 1.441715955734253, Accuracy: 0.5546875\n",
      "Batch: 56, Loss: 1.5664658546447754, Accuracy: 0.5244140625\n",
      "Batch: 57, Loss: 1.470448613166809, Accuracy: 0.5556640625\n",
      "Batch: 58, Loss: 1.5949808359146118, Accuracy: 0.5283203125\n",
      "Batch: 59, Loss: 1.35210382938385, Accuracy: 0.6015625\n",
      "Batch: 60, Loss: 1.3704273700714111, Accuracy: 0.595703125\n",
      "Batch: 61, Loss: 1.4954184293746948, Accuracy: 0.544921875\n",
      "Batch: 62, Loss: 1.4969587326049805, Accuracy: 0.552734375\n",
      "Batch: 63, Loss: 1.4983866214752197, Accuracy: 0.529296875\n",
      "Batch: 64, Loss: 1.443305253982544, Accuracy: 0.5517578125\n",
      "Batch: 65, Loss: 1.479417085647583, Accuracy: 0.5478515625\n",
      "Batch: 66, Loss: 1.3727704286575317, Accuracy: 0.583984375\n",
      "Batch: 67, Loss: 1.5548861026763916, Accuracy: 0.53515625\n",
      "Batch: 68, Loss: 1.5719006061553955, Accuracy: 0.5556640625\n",
      "Batch: 69, Loss: 1.4682402610778809, Accuracy: 0.564453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 70, Loss: 1.5068652629852295, Accuracy: 0.5654296875\n",
      "Batch: 71, Loss: 1.494551181793213, Accuracy: 0.548828125\n",
      "Batch: 72, Loss: 1.3943723440170288, Accuracy: 0.576171875\n",
      "Batch: 73, Loss: 1.452277660369873, Accuracy: 0.5703125\n",
      "Batch: 74, Loss: 1.4025397300720215, Accuracy: 0.568359375\n",
      "Batch: 75, Loss: 1.3427338600158691, Accuracy: 0.580078125\n",
      "Batch: 76, Loss: 1.482668161392212, Accuracy: 0.5048828125\n",
      "Batch: 77, Loss: 1.4822945594787598, Accuracy: 0.5234375\n",
      "Batch: 78, Loss: 1.4613440036773682, Accuracy: 0.5908203125\n",
      "Batch: 79, Loss: 1.3233280181884766, Accuracy: 0.625\n",
      "Batch: 80, Loss: 1.355261206626892, Accuracy: 0.576171875\n",
      "Batch: 81, Loss: 1.500739336013794, Accuracy: 0.517578125\n",
      "Batch: 82, Loss: 1.4730803966522217, Accuracy: 0.53515625\n",
      "Batch: 83, Loss: 1.3222682476043701, Accuracy: 0.6044921875\n",
      "Batch: 84, Loss: 1.3670127391815186, Accuracy: 0.59765625\n",
      "Batch: 85, Loss: 1.3502237796783447, Accuracy: 0.5888671875\n",
      "Batch: 86, Loss: 1.5405606031417847, Accuracy: 0.5185546875\n",
      "Batch: 87, Loss: 1.3722758293151855, Accuracy: 0.5888671875\n",
      "Batch: 88, Loss: 1.4964327812194824, Accuracy: 0.560546875\n",
      "Batch: 89, Loss: 1.4995882511138916, Accuracy: 0.5283203125\n",
      "Batch: 90, Loss: 1.3661593198776245, Accuracy: 0.5673828125\n",
      "Batch: 91, Loss: 1.4275561571121216, Accuracy: 0.5537109375\n",
      "Batch: 92, Loss: 1.4924275875091553, Accuracy: 0.5439453125\n",
      "Batch: 93, Loss: 1.3888359069824219, Accuracy: 0.5810546875\n",
      "Batch: 94, Loss: 1.4003742933273315, Accuracy: 0.548828125\n",
      "Batch: 95, Loss: 1.4361225366592407, Accuracy: 0.5302734375\n",
      "Batch: 96, Loss: 1.4176998138427734, Accuracy: 0.5751953125\n",
      "Batch: 97, Loss: 1.2884925603866577, Accuracy: 0.6123046875\n",
      "Batch: 98, Loss: 1.3506512641906738, Accuracy: 0.60546875\n",
      "Batch: 99, Loss: 1.324336051940918, Accuracy: 0.5859375\n",
      "Batch: 100, Loss: 1.4122319221496582, Accuracy: 0.5556640625\n",
      "Batch: 101, Loss: 1.4189038276672363, Accuracy: 0.5537109375\n",
      "Batch: 102, Loss: 1.3557753562927246, Accuracy: 0.564453125\n",
      "Batch: 103, Loss: 1.4679906368255615, Accuracy: 0.578125\n",
      "Batch: 104, Loss: 1.3609082698822021, Accuracy: 0.572265625\n",
      "Batch: 105, Loss: 1.4819172620773315, Accuracy: 0.541015625\n",
      "Batch: 106, Loss: 1.4676437377929688, Accuracy: 0.544921875\n",
      "Batch: 107, Loss: 1.5945565700531006, Accuracy: 0.525390625\n",
      "Batch: 108, Loss: 1.549842119216919, Accuracy: 0.5361328125\n",
      "Batch: 109, Loss: 1.5889670848846436, Accuracy: 0.5205078125\n",
      "Batch: 110, Loss: 1.2682956457138062, Accuracy: 0.6015625\n",
      "Batch: 111, Loss: 1.4668049812316895, Accuracy: 0.5283203125\n",
      "Batch: 112, Loss: 1.4485262632369995, Accuracy: 0.5654296875\n",
      "Batch: 113, Loss: 1.4750540256500244, Accuracy: 0.5751953125\n",
      "Batch: 114, Loss: 1.5690205097198486, Accuracy: 0.533203125\n",
      "Batch: 115, Loss: 1.6030882596969604, Accuracy: 0.5322265625\n",
      "Batch: 116, Loss: 1.5476012229919434, Accuracy: 0.515625\n",
      "Batch: 117, Loss: 1.5533833503723145, Accuracy: 0.556640625\n",
      "Batch: 118, Loss: 1.3003658056259155, Accuracy: 0.61328125\n",
      "Batch: 119, Loss: 1.397372841835022, Accuracy: 0.587890625\n",
      "Batch: 120, Loss: 1.51359224319458, Accuracy: 0.5419921875\n",
      "Batch: 121, Loss: 1.5524265766143799, Accuracy: 0.521484375\n",
      "Batch: 122, Loss: 1.4079591035842896, Accuracy: 0.5791015625\n",
      "Batch: 123, Loss: 1.3994274139404297, Accuracy: 0.5947265625\n",
      "Batch: 124, Loss: 1.465805172920227, Accuracy: 0.5693359375\n",
      "Batch: 125, Loss: 1.5376877784729004, Accuracy: 0.525390625\n",
      "Batch: 126, Loss: 1.4765348434448242, Accuracy: 0.53125\n",
      "Batch: 127, Loss: 1.3629982471466064, Accuracy: 0.611328125\n",
      "Batch: 128, Loss: 1.6351780891418457, Accuracy: 0.5498046875\n",
      "Batch: 129, Loss: 1.4283185005187988, Accuracy: 0.560546875\n",
      "Batch: 130, Loss: 1.7158622741699219, Accuracy: 0.498046875\n",
      "Batch: 131, Loss: 1.514181137084961, Accuracy: 0.5439453125\n",
      "Batch: 132, Loss: 1.5277800559997559, Accuracy: 0.5419921875\n",
      "Batch: 133, Loss: 1.4183927774429321, Accuracy: 0.5732421875\n",
      "Batch: 134, Loss: 1.4467194080352783, Accuracy: 0.5537109375\n",
      "Batch: 135, Loss: 1.4004485607147217, Accuracy: 0.5693359375\n",
      "Batch: 136, Loss: 1.3881829977035522, Accuracy: 0.5615234375\n",
      "Batch: 137, Loss: 1.3462588787078857, Accuracy: 0.548828125\n",
      "Batch: 138, Loss: 1.2439265251159668, Accuracy: 0.603515625\n",
      "Batch: 139, Loss: 1.287070631980896, Accuracy: 0.5751953125\n",
      "Batch: 140, Loss: 1.41489839553833, Accuracy: 0.5458984375\n",
      "Batch: 141, Loss: 1.4335535764694214, Accuracy: 0.5703125\n",
      "Batch: 142, Loss: 1.454392671585083, Accuracy: 0.5400390625\n",
      "Batch: 143, Loss: 1.4777193069458008, Accuracy: 0.5419921875\n",
      "Batch: 144, Loss: 1.4274215698242188, Accuracy: 0.55078125\n",
      "Batch: 145, Loss: 1.343308448791504, Accuracy: 0.5693359375\n",
      "Batch: 146, Loss: 1.5014177560806274, Accuracy: 0.537109375\n",
      "Batch: 147, Loss: 1.4205412864685059, Accuracy: 0.5556640625\n",
      "Batch: 148, Loss: 1.6031529903411865, Accuracy: 0.4921875\n",
      "Batch: 149, Loss: 1.4684704542160034, Accuracy: 0.53125\n",
      "Batch: 150, Loss: 1.3751249313354492, Accuracy: 0.564453125\n",
      "Batch: 151, Loss: 1.3728690147399902, Accuracy: 0.583984375\n",
      "Epoch 6/80\n",
      "Batch: 1, Loss: 1.6444556713104248, Accuracy: 0.4765625\n",
      "Batch: 2, Loss: 1.4035457372665405, Accuracy: 0.515625\n",
      "Batch: 3, Loss: 1.3580574989318848, Accuracy: 0.580078125\n",
      "Batch: 4, Loss: 1.295238733291626, Accuracy: 0.6181640625\n",
      "Batch: 5, Loss: 1.3183300495147705, Accuracy: 0.591796875\n",
      "Batch: 6, Loss: 1.4318300485610962, Accuracy: 0.5322265625\n",
      "Batch: 7, Loss: 1.3640930652618408, Accuracy: 0.55078125\n",
      "Batch: 8, Loss: 1.3329721689224243, Accuracy: 0.5771484375\n",
      "Batch: 9, Loss: 1.3002188205718994, Accuracy: 0.607421875\n",
      "Batch: 10, Loss: 1.3414437770843506, Accuracy: 0.5703125\n",
      "Batch: 11, Loss: 1.4870262145996094, Accuracy: 0.501953125\n",
      "Batch: 12, Loss: 1.5331382751464844, Accuracy: 0.51953125\n",
      "Batch: 13, Loss: 1.2121837139129639, Accuracy: 0.634765625\n",
      "Batch: 14, Loss: 1.4890313148498535, Accuracy: 0.541015625\n",
      "Batch: 15, Loss: 1.3784563541412354, Accuracy: 0.578125\n",
      "Batch: 16, Loss: 1.3639622926712036, Accuracy: 0.5732421875\n",
      "Batch: 17, Loss: 1.437119960784912, Accuracy: 0.546875\n",
      "Batch: 18, Loss: 1.4668323993682861, Accuracy: 0.513671875\n",
      "Batch: 19, Loss: 1.4834644794464111, Accuracy: 0.564453125\n",
      "Batch: 20, Loss: 1.3955867290496826, Accuracy: 0.59375\n",
      "Batch: 21, Loss: 1.3374662399291992, Accuracy: 0.5712890625\n",
      "Batch: 22, Loss: 1.5146193504333496, Accuracy: 0.53515625\n",
      "Batch: 23, Loss: 1.350508689880371, Accuracy: 0.568359375\n",
      "Batch: 24, Loss: 1.427025318145752, Accuracy: 0.541015625\n",
      "Batch: 25, Loss: 1.3744137287139893, Accuracy: 0.5703125\n",
      "Batch: 26, Loss: 1.2870720624923706, Accuracy: 0.6005859375\n",
      "Batch: 27, Loss: 1.3735798597335815, Accuracy: 0.5673828125\n",
      "Batch: 28, Loss: 1.446009635925293, Accuracy: 0.541015625\n",
      "Batch: 29, Loss: 1.4420969486236572, Accuracy: 0.5380859375\n",
      "Batch: 30, Loss: 1.4035526514053345, Accuracy: 0.58203125\n",
      "Batch: 31, Loss: 1.3375401496887207, Accuracy: 0.6142578125\n",
      "Batch: 32, Loss: 1.3211183547973633, Accuracy: 0.583984375\n",
      "Batch: 33, Loss: 1.539118766784668, Accuracy: 0.521484375\n",
      "Batch: 34, Loss: 1.6285581588745117, Accuracy: 0.517578125\n",
      "Batch: 35, Loss: 1.4736835956573486, Accuracy: 0.5458984375\n",
      "Batch: 36, Loss: 1.4491177797317505, Accuracy: 0.57421875\n",
      "Batch: 37, Loss: 1.4701051712036133, Accuracy: 0.544921875\n",
      "Batch: 38, Loss: 1.43192458152771, Accuracy: 0.5380859375\n",
      "Batch: 39, Loss: 1.4601590633392334, Accuracy: 0.552734375\n",
      "Batch: 40, Loss: 1.4852755069732666, Accuracy: 0.5703125\n",
      "Batch: 41, Loss: 1.5139988660812378, Accuracy: 0.5400390625\n",
      "Batch: 42, Loss: 1.233182430267334, Accuracy: 0.619140625\n",
      "Batch: 43, Loss: 1.4089677333831787, Accuracy: 0.5341796875\n",
      "Batch: 44, Loss: 1.3747663497924805, Accuracy: 0.5517578125\n",
      "Batch: 45, Loss: 1.236713171005249, Accuracy: 0.6005859375\n",
      "Batch: 46, Loss: 1.4192957878112793, Accuracy: 0.572265625\n",
      "Batch: 47, Loss: 1.43393874168396, Accuracy: 0.5712890625\n",
      "Batch: 48, Loss: 1.3938686847686768, Accuracy: 0.5732421875\n",
      "Batch: 49, Loss: 1.5287120342254639, Accuracy: 0.521484375\n",
      "Batch: 50, Loss: 1.5179287195205688, Accuracy: 0.52734375\n",
      "Batch: 51, Loss: 1.5810614824295044, Accuracy: 0.51953125\n",
      "Batch: 52, Loss: 1.5410212278366089, Accuracy: 0.5458984375\n",
      "Batch: 53, Loss: 1.2943651676177979, Accuracy: 0.5986328125\n",
      "Batch: 54, Loss: 1.407212495803833, Accuracy: 0.6005859375\n",
      "Batch: 55, Loss: 1.4068548679351807, Accuracy: 0.552734375\n",
      "Batch: 56, Loss: 1.4935728311538696, Accuracy: 0.5380859375\n",
      "Batch: 57, Loss: 1.427091121673584, Accuracy: 0.5673828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 58, Loss: 1.5256849527359009, Accuracy: 0.5556640625\n",
      "Batch: 59, Loss: 1.2761104106903076, Accuracy: 0.6181640625\n",
      "Batch: 60, Loss: 1.3015273809432983, Accuracy: 0.609375\n",
      "Batch: 61, Loss: 1.4121716022491455, Accuracy: 0.552734375\n",
      "Batch: 62, Loss: 1.4071877002716064, Accuracy: 0.564453125\n",
      "Batch: 63, Loss: 1.4117423295974731, Accuracy: 0.5517578125\n",
      "Batch: 64, Loss: 1.380908727645874, Accuracy: 0.568359375\n",
      "Batch: 65, Loss: 1.422653317451477, Accuracy: 0.5615234375\n",
      "Batch: 66, Loss: 1.3035873174667358, Accuracy: 0.5966796875\n",
      "Batch: 67, Loss: 1.5030968189239502, Accuracy: 0.5517578125\n",
      "Batch: 68, Loss: 1.511474847793579, Accuracy: 0.56640625\n",
      "Batch: 69, Loss: 1.3991596698760986, Accuracy: 0.5693359375\n",
      "Batch: 70, Loss: 1.442969799041748, Accuracy: 0.576171875\n",
      "Batch: 71, Loss: 1.420261263847351, Accuracy: 0.564453125\n",
      "Batch: 72, Loss: 1.3300836086273193, Accuracy: 0.5947265625\n",
      "Batch: 73, Loss: 1.3842631578445435, Accuracy: 0.5810546875\n",
      "Batch: 74, Loss: 1.3210830688476562, Accuracy: 0.5888671875\n",
      "Batch: 75, Loss: 1.3091224431991577, Accuracy: 0.6005859375\n",
      "Batch: 76, Loss: 1.4396812915802002, Accuracy: 0.5224609375\n",
      "Batch: 77, Loss: 1.4027212858200073, Accuracy: 0.5576171875\n",
      "Batch: 78, Loss: 1.4047908782958984, Accuracy: 0.5947265625\n",
      "Batch: 79, Loss: 1.2676854133605957, Accuracy: 0.6396484375\n",
      "Batch: 80, Loss: 1.285794973373413, Accuracy: 0.580078125\n",
      "Batch: 81, Loss: 1.4472355842590332, Accuracy: 0.53125\n",
      "Batch: 82, Loss: 1.3890037536621094, Accuracy: 0.5537109375\n",
      "Batch: 83, Loss: 1.258335828781128, Accuracy: 0.634765625\n",
      "Batch: 84, Loss: 1.319215178489685, Accuracy: 0.609375\n",
      "Batch: 85, Loss: 1.282592535018921, Accuracy: 0.6015625\n",
      "Batch: 86, Loss: 1.510648488998413, Accuracy: 0.5244140625\n",
      "Batch: 87, Loss: 1.3090795278549194, Accuracy: 0.60546875\n",
      "Batch: 88, Loss: 1.4377342462539673, Accuracy: 0.560546875\n",
      "Batch: 89, Loss: 1.4266743659973145, Accuracy: 0.5498046875\n",
      "Batch: 90, Loss: 1.336652398109436, Accuracy: 0.5810546875\n",
      "Batch: 91, Loss: 1.3704766035079956, Accuracy: 0.572265625\n",
      "Batch: 92, Loss: 1.4412946701049805, Accuracy: 0.55859375\n",
      "Batch: 93, Loss: 1.312831997871399, Accuracy: 0.6005859375\n",
      "Batch: 94, Loss: 1.3466510772705078, Accuracy: 0.572265625\n",
      "Batch: 95, Loss: 1.3804206848144531, Accuracy: 0.5537109375\n",
      "Batch: 96, Loss: 1.366102695465088, Accuracy: 0.583984375\n",
      "Batch: 97, Loss: 1.2305858135223389, Accuracy: 0.59765625\n",
      "Batch: 98, Loss: 1.2658274173736572, Accuracy: 0.619140625\n",
      "Batch: 99, Loss: 1.2701313495635986, Accuracy: 0.60546875\n",
      "Batch: 100, Loss: 1.3533244132995605, Accuracy: 0.5634765625\n",
      "Batch: 101, Loss: 1.4050018787384033, Accuracy: 0.552734375\n",
      "Batch: 102, Loss: 1.312977910041809, Accuracy: 0.572265625\n",
      "Batch: 103, Loss: 1.4255105257034302, Accuracy: 0.583984375\n",
      "Batch: 104, Loss: 1.286900281906128, Accuracy: 0.5986328125\n",
      "Batch: 105, Loss: 1.4198102951049805, Accuracy: 0.5478515625\n",
      "Batch: 106, Loss: 1.4245519638061523, Accuracy: 0.5634765625\n",
      "Batch: 107, Loss: 1.5530309677124023, Accuracy: 0.5390625\n",
      "Batch: 108, Loss: 1.4995687007904053, Accuracy: 0.5390625\n",
      "Batch: 109, Loss: 1.5531718730926514, Accuracy: 0.5166015625\n",
      "Batch: 110, Loss: 1.2287192344665527, Accuracy: 0.6142578125\n",
      "Batch: 111, Loss: 1.4356151819229126, Accuracy: 0.5322265625\n",
      "Batch: 112, Loss: 1.3711459636688232, Accuracy: 0.5859375\n",
      "Batch: 113, Loss: 1.4164772033691406, Accuracy: 0.59765625\n",
      "Batch: 114, Loss: 1.5341637134552002, Accuracy: 0.529296875\n",
      "Batch: 115, Loss: 1.5414377450942993, Accuracy: 0.5546875\n",
      "Batch: 116, Loss: 1.5007989406585693, Accuracy: 0.537109375\n",
      "Batch: 117, Loss: 1.4682884216308594, Accuracy: 0.5712890625\n",
      "Batch: 118, Loss: 1.2469487190246582, Accuracy: 0.615234375\n",
      "Batch: 119, Loss: 1.3085730075836182, Accuracy: 0.6162109375\n",
      "Batch: 120, Loss: 1.4684865474700928, Accuracy: 0.556640625\n",
      "Batch: 121, Loss: 1.509441614151001, Accuracy: 0.53515625\n",
      "Batch: 122, Loss: 1.3405170440673828, Accuracy: 0.603515625\n",
      "Batch: 123, Loss: 1.3697274923324585, Accuracy: 0.5986328125\n",
      "Batch: 124, Loss: 1.4103808403015137, Accuracy: 0.57421875\n",
      "Batch: 125, Loss: 1.458355188369751, Accuracy: 0.552734375\n",
      "Batch: 126, Loss: 1.4425044059753418, Accuracy: 0.5419921875\n",
      "Batch: 127, Loss: 1.288196325302124, Accuracy: 0.6123046875\n",
      "Batch: 128, Loss: 1.5638091564178467, Accuracy: 0.546875\n",
      "Batch: 129, Loss: 1.3707959651947021, Accuracy: 0.580078125\n",
      "Batch: 130, Loss: 1.669290542602539, Accuracy: 0.5068359375\n",
      "Batch: 131, Loss: 1.4501041173934937, Accuracy: 0.5546875\n",
      "Batch: 132, Loss: 1.4805346727371216, Accuracy: 0.5478515625\n",
      "Batch: 133, Loss: 1.3455296754837036, Accuracy: 0.591796875\n",
      "Batch: 134, Loss: 1.4039647579193115, Accuracy: 0.556640625\n",
      "Batch: 135, Loss: 1.3379323482513428, Accuracy: 0.5869140625\n",
      "Batch: 136, Loss: 1.351605772972107, Accuracy: 0.5712890625\n",
      "Batch: 137, Loss: 1.31907320022583, Accuracy: 0.560546875\n",
      "Batch: 138, Loss: 1.17024564743042, Accuracy: 0.6220703125\n",
      "Batch: 139, Loss: 1.2529032230377197, Accuracy: 0.5849609375\n",
      "Batch: 140, Loss: 1.4057567119598389, Accuracy: 0.546875\n",
      "Batch: 141, Loss: 1.399204969406128, Accuracy: 0.580078125\n",
      "Batch: 142, Loss: 1.4148361682891846, Accuracy: 0.5556640625\n",
      "Batch: 143, Loss: 1.4210479259490967, Accuracy: 0.5576171875\n",
      "Batch: 144, Loss: 1.3591880798339844, Accuracy: 0.5732421875\n",
      "Batch: 145, Loss: 1.2881462574005127, Accuracy: 0.5810546875\n",
      "Batch: 146, Loss: 1.445474624633789, Accuracy: 0.5498046875\n",
      "Batch: 147, Loss: 1.3759299516677856, Accuracy: 0.5771484375\n",
      "Batch: 148, Loss: 1.5503034591674805, Accuracy: 0.4892578125\n",
      "Batch: 149, Loss: 1.4134511947631836, Accuracy: 0.53515625\n",
      "Batch: 150, Loss: 1.3199408054351807, Accuracy: 0.587890625\n",
      "Batch: 151, Loss: 1.3088034391403198, Accuracy: 0.6025390625\n",
      "Epoch 7/80\n",
      "Batch: 1, Loss: 1.5896105766296387, Accuracy: 0.4931640625\n",
      "Batch: 2, Loss: 1.3735805749893188, Accuracy: 0.5322265625\n",
      "Batch: 3, Loss: 1.3279117345809937, Accuracy: 0.5791015625\n",
      "Batch: 4, Loss: 1.2320239543914795, Accuracy: 0.6279296875\n",
      "Batch: 5, Loss: 1.2550485134124756, Accuracy: 0.6103515625\n",
      "Batch: 6, Loss: 1.400720238685608, Accuracy: 0.5205078125\n",
      "Batch: 7, Loss: 1.3294310569763184, Accuracy: 0.56640625\n",
      "Batch: 8, Loss: 1.2639485597610474, Accuracy: 0.6064453125\n",
      "Batch: 9, Loss: 1.2288358211517334, Accuracy: 0.609375\n",
      "Batch: 10, Loss: 1.2724658250808716, Accuracy: 0.5869140625\n",
      "Batch: 11, Loss: 1.4474351406097412, Accuracy: 0.5341796875\n",
      "Batch: 12, Loss: 1.4752751588821411, Accuracy: 0.5234375\n",
      "Batch: 13, Loss: 1.171675443649292, Accuracy: 0.640625\n",
      "Batch: 14, Loss: 1.4507057666778564, Accuracy: 0.544921875\n",
      "Batch: 15, Loss: 1.3296184539794922, Accuracy: 0.599609375\n",
      "Batch: 16, Loss: 1.3152122497558594, Accuracy: 0.58203125\n",
      "Batch: 17, Loss: 1.3982775211334229, Accuracy: 0.56640625\n",
      "Batch: 18, Loss: 1.4027687311172485, Accuracy: 0.5380859375\n",
      "Batch: 19, Loss: 1.407759666442871, Accuracy: 0.564453125\n",
      "Batch: 20, Loss: 1.334542989730835, Accuracy: 0.60546875\n",
      "Batch: 21, Loss: 1.2995326519012451, Accuracy: 0.58203125\n",
      "Batch: 22, Loss: 1.4672526121139526, Accuracy: 0.560546875\n",
      "Batch: 23, Loss: 1.316372036933899, Accuracy: 0.5869140625\n",
      "Batch: 24, Loss: 1.3768117427825928, Accuracy: 0.57421875\n",
      "Batch: 25, Loss: 1.3042324781417847, Accuracy: 0.58984375\n",
      "Batch: 26, Loss: 1.2404011487960815, Accuracy: 0.603515625\n",
      "Batch: 27, Loss: 1.2913572788238525, Accuracy: 0.5849609375\n",
      "Batch: 28, Loss: 1.3987683057785034, Accuracy: 0.556640625\n",
      "Batch: 29, Loss: 1.373925805091858, Accuracy: 0.55078125\n",
      "Batch: 30, Loss: 1.3283122777938843, Accuracy: 0.6142578125\n",
      "Batch: 31, Loss: 1.2988970279693604, Accuracy: 0.6240234375\n",
      "Batch: 32, Loss: 1.2903214693069458, Accuracy: 0.587890625\n",
      "Batch: 33, Loss: 1.4916492700576782, Accuracy: 0.5341796875\n",
      "Batch: 34, Loss: 1.5569682121276855, Accuracy: 0.513671875\n",
      "Batch: 35, Loss: 1.4066041707992554, Accuracy: 0.5439453125\n",
      "Batch: 36, Loss: 1.4126051664352417, Accuracy: 0.58203125\n",
      "Batch: 37, Loss: 1.4115080833435059, Accuracy: 0.5673828125\n",
      "Batch: 38, Loss: 1.3959290981292725, Accuracy: 0.5400390625\n",
      "Batch: 39, Loss: 1.4065933227539062, Accuracy: 0.568359375\n",
      "Batch: 40, Loss: 1.4213061332702637, Accuracy: 0.58984375\n",
      "Batch: 41, Loss: 1.4540202617645264, Accuracy: 0.5517578125\n",
      "Batch: 42, Loss: 1.183211088180542, Accuracy: 0.62109375\n",
      "Batch: 43, Loss: 1.3690879344940186, Accuracy: 0.5556640625\n",
      "Batch: 44, Loss: 1.3271995782852173, Accuracy: 0.5546875\n",
      "Batch: 45, Loss: 1.208091378211975, Accuracy: 0.6083984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 46, Loss: 1.3540241718292236, Accuracy: 0.5986328125\n",
      "Batch: 47, Loss: 1.3660839796066284, Accuracy: 0.5908203125\n",
      "Batch: 48, Loss: 1.3177140951156616, Accuracy: 0.59375\n",
      "Batch: 49, Loss: 1.486486554145813, Accuracy: 0.546875\n",
      "Batch: 50, Loss: 1.4564135074615479, Accuracy: 0.5478515625\n",
      "Batch: 51, Loss: 1.524770975112915, Accuracy: 0.5244140625\n",
      "Batch: 52, Loss: 1.482641577720642, Accuracy: 0.5673828125\n",
      "Batch: 53, Loss: 1.2593995332717896, Accuracy: 0.619140625\n",
      "Batch: 54, Loss: 1.3552682399749756, Accuracy: 0.603515625\n",
      "Batch: 55, Loss: 1.3625977039337158, Accuracy: 0.5693359375\n",
      "Batch: 56, Loss: 1.4353585243225098, Accuracy: 0.55078125\n",
      "Batch: 57, Loss: 1.3630626201629639, Accuracy: 0.5908203125\n",
      "Batch: 58, Loss: 1.4770121574401855, Accuracy: 0.552734375\n",
      "Batch: 59, Loss: 1.2319252490997314, Accuracy: 0.6357421875\n",
      "Batch: 60, Loss: 1.2498992681503296, Accuracy: 0.6142578125\n",
      "Batch: 61, Loss: 1.3848938941955566, Accuracy: 0.5546875\n",
      "Batch: 62, Loss: 1.353341817855835, Accuracy: 0.5771484375\n",
      "Batch: 63, Loss: 1.3594543933868408, Accuracy: 0.5615234375\n",
      "Batch: 64, Loss: 1.3221561908721924, Accuracy: 0.5771484375\n",
      "Batch: 65, Loss: 1.3851678371429443, Accuracy: 0.5576171875\n",
      "Batch: 66, Loss: 1.2542386054992676, Accuracy: 0.6162109375\n",
      "Batch: 67, Loss: 1.4450809955596924, Accuracy: 0.5546875\n",
      "Batch: 68, Loss: 1.4574205875396729, Accuracy: 0.578125\n",
      "Batch: 69, Loss: 1.3507969379425049, Accuracy: 0.5703125\n",
      "Batch: 70, Loss: 1.3733770847320557, Accuracy: 0.576171875\n",
      "Batch: 71, Loss: 1.3749935626983643, Accuracy: 0.568359375\n",
      "Batch: 72, Loss: 1.2771837711334229, Accuracy: 0.611328125\n",
      "Batch: 73, Loss: 1.321357011795044, Accuracy: 0.599609375\n",
      "Batch: 74, Loss: 1.282463788986206, Accuracy: 0.5966796875\n",
      "Batch: 75, Loss: 1.255828619003296, Accuracy: 0.619140625\n",
      "Batch: 76, Loss: 1.3828097581863403, Accuracy: 0.53515625\n",
      "Batch: 77, Loss: 1.3924345970153809, Accuracy: 0.556640625\n",
      "Batch: 78, Loss: 1.32882559299469, Accuracy: 0.6162109375\n",
      "Batch: 79, Loss: 1.2093470096588135, Accuracy: 0.6494140625\n",
      "Batch: 80, Loss: 1.239521861076355, Accuracy: 0.5966796875\n",
      "Batch: 81, Loss: 1.4284367561340332, Accuracy: 0.5234375\n",
      "Batch: 82, Loss: 1.3709161281585693, Accuracy: 0.5615234375\n",
      "Batch: 83, Loss: 1.2040050029754639, Accuracy: 0.6279296875\n",
      "Batch: 84, Loss: 1.2767980098724365, Accuracy: 0.6181640625\n",
      "Batch: 85, Loss: 1.2289295196533203, Accuracy: 0.6220703125\n",
      "Batch: 86, Loss: 1.4874701499938965, Accuracy: 0.5302734375\n",
      "Batch: 87, Loss: 1.2713714838027954, Accuracy: 0.6025390625\n",
      "Batch: 88, Loss: 1.4067513942718506, Accuracy: 0.5849609375\n",
      "Batch: 89, Loss: 1.3781700134277344, Accuracy: 0.5595703125\n",
      "Batch: 90, Loss: 1.2732222080230713, Accuracy: 0.607421875\n",
      "Batch: 91, Loss: 1.299601435661316, Accuracy: 0.583984375\n",
      "Batch: 92, Loss: 1.3863215446472168, Accuracy: 0.5712890625\n",
      "Batch: 93, Loss: 1.2685444355010986, Accuracy: 0.6142578125\n",
      "Batch: 94, Loss: 1.3011738061904907, Accuracy: 0.578125\n",
      "Batch: 95, Loss: 1.329758644104004, Accuracy: 0.5673828125\n",
      "Batch: 96, Loss: 1.3168833255767822, Accuracy: 0.595703125\n",
      "Batch: 97, Loss: 1.196791410446167, Accuracy: 0.6416015625\n",
      "Batch: 98, Loss: 1.2199550867080688, Accuracy: 0.6279296875\n",
      "Batch: 99, Loss: 1.2229790687561035, Accuracy: 0.6162109375\n",
      "Batch: 100, Loss: 1.325060486793518, Accuracy: 0.587890625\n",
      "Batch: 101, Loss: 1.3632071018218994, Accuracy: 0.572265625\n",
      "Batch: 102, Loss: 1.2721527814865112, Accuracy: 0.595703125\n",
      "Batch: 103, Loss: 1.3644593954086304, Accuracy: 0.6005859375\n",
      "Batch: 104, Loss: 1.266265630722046, Accuracy: 0.603515625\n",
      "Batch: 105, Loss: 1.3751509189605713, Accuracy: 0.5625\n",
      "Batch: 106, Loss: 1.3816230297088623, Accuracy: 0.5703125\n",
      "Batch: 107, Loss: 1.5150078535079956, Accuracy: 0.5400390625\n",
      "Batch: 108, Loss: 1.4485034942626953, Accuracy: 0.568359375\n",
      "Batch: 109, Loss: 1.5084524154663086, Accuracy: 0.5322265625\n",
      "Batch: 110, Loss: 1.2098090648651123, Accuracy: 0.6162109375\n",
      "Batch: 111, Loss: 1.379368543624878, Accuracy: 0.54296875\n",
      "Batch: 112, Loss: 1.3301290273666382, Accuracy: 0.6064453125\n",
      "Batch: 113, Loss: 1.3684208393096924, Accuracy: 0.5927734375\n",
      "Batch: 114, Loss: 1.4777815341949463, Accuracy: 0.5517578125\n",
      "Batch: 115, Loss: 1.5013070106506348, Accuracy: 0.5556640625\n",
      "Batch: 116, Loss: 1.440659761428833, Accuracy: 0.5615234375\n",
      "Batch: 117, Loss: 1.4515615701675415, Accuracy: 0.568359375\n",
      "Batch: 118, Loss: 1.1909120082855225, Accuracy: 0.6357421875\n",
      "Batch: 119, Loss: 1.247873306274414, Accuracy: 0.62890625\n",
      "Batch: 120, Loss: 1.412466049194336, Accuracy: 0.548828125\n",
      "Batch: 121, Loss: 1.4555867910385132, Accuracy: 0.5458984375\n",
      "Batch: 122, Loss: 1.3219122886657715, Accuracy: 0.5986328125\n",
      "Batch: 123, Loss: 1.2927438020706177, Accuracy: 0.599609375\n",
      "Batch: 124, Loss: 1.3643531799316406, Accuracy: 0.580078125\n",
      "Batch: 125, Loss: 1.4143236875534058, Accuracy: 0.5458984375\n",
      "Batch: 126, Loss: 1.390920639038086, Accuracy: 0.5634765625\n",
      "Batch: 127, Loss: 1.2448506355285645, Accuracy: 0.634765625\n",
      "Batch: 128, Loss: 1.5048424005508423, Accuracy: 0.5537109375\n",
      "Batch: 129, Loss: 1.3068346977233887, Accuracy: 0.58984375\n",
      "Batch: 130, Loss: 1.606870174407959, Accuracy: 0.5185546875\n",
      "Batch: 131, Loss: 1.4377241134643555, Accuracy: 0.5517578125\n",
      "Batch: 132, Loss: 1.4465805292129517, Accuracy: 0.5556640625\n",
      "Batch: 133, Loss: 1.2831361293792725, Accuracy: 0.6005859375\n",
      "Batch: 134, Loss: 1.3503113985061646, Accuracy: 0.5625\n",
      "Batch: 135, Loss: 1.2811007499694824, Accuracy: 0.607421875\n",
      "Batch: 136, Loss: 1.3201392889022827, Accuracy: 0.5908203125\n",
      "Batch: 137, Loss: 1.2798216342926025, Accuracy: 0.5654296875\n",
      "Batch: 138, Loss: 1.152012825012207, Accuracy: 0.6181640625\n",
      "Batch: 139, Loss: 1.206735610961914, Accuracy: 0.599609375\n",
      "Batch: 140, Loss: 1.3437771797180176, Accuracy: 0.5703125\n",
      "Batch: 141, Loss: 1.3707170486450195, Accuracy: 0.5849609375\n",
      "Batch: 142, Loss: 1.3561813831329346, Accuracy: 0.5673828125\n",
      "Batch: 143, Loss: 1.382286548614502, Accuracy: 0.57421875\n",
      "Batch: 144, Loss: 1.3354520797729492, Accuracy: 0.576171875\n",
      "Batch: 145, Loss: 1.2583515644073486, Accuracy: 0.5830078125\n",
      "Batch: 146, Loss: 1.4105772972106934, Accuracy: 0.5439453125\n",
      "Batch: 147, Loss: 1.3529460430145264, Accuracy: 0.568359375\n",
      "Batch: 148, Loss: 1.501821517944336, Accuracy: 0.5224609375\n",
      "Batch: 149, Loss: 1.3655933141708374, Accuracy: 0.55859375\n",
      "Batch: 150, Loss: 1.268648624420166, Accuracy: 0.587890625\n",
      "Batch: 151, Loss: 1.2523646354675293, Accuracy: 0.615234375\n",
      "Epoch 8/80\n",
      "Batch: 1, Loss: 1.5821681022644043, Accuracy: 0.4921875\n",
      "Batch: 2, Loss: 1.329771876335144, Accuracy: 0.5419921875\n",
      "Batch: 3, Loss: 1.292640209197998, Accuracy: 0.5830078125\n",
      "Batch: 4, Loss: 1.1827032566070557, Accuracy: 0.642578125\n",
      "Batch: 5, Loss: 1.247376561164856, Accuracy: 0.619140625\n",
      "Batch: 6, Loss: 1.3457026481628418, Accuracy: 0.5556640625\n",
      "Batch: 7, Loss: 1.2665969133377075, Accuracy: 0.5751953125\n",
      "Batch: 8, Loss: 1.2431659698486328, Accuracy: 0.611328125\n",
      "Batch: 9, Loss: 1.1886004209518433, Accuracy: 0.6318359375\n",
      "Batch: 10, Loss: 1.2250419855117798, Accuracy: 0.61328125\n",
      "Batch: 11, Loss: 1.3874025344848633, Accuracy: 0.548828125\n",
      "Batch: 12, Loss: 1.4415051937103271, Accuracy: 0.53125\n",
      "Batch: 13, Loss: 1.1424329280853271, Accuracy: 0.6494140625\n",
      "Batch: 14, Loss: 1.4053252935409546, Accuracy: 0.5546875\n",
      "Batch: 15, Loss: 1.2692962884902954, Accuracy: 0.6162109375\n",
      "Batch: 16, Loss: 1.2540218830108643, Accuracy: 0.5947265625\n",
      "Batch: 17, Loss: 1.3663461208343506, Accuracy: 0.5595703125\n",
      "Batch: 18, Loss: 1.355966567993164, Accuracy: 0.5625\n",
      "Batch: 19, Loss: 1.364628553390503, Accuracy: 0.5615234375\n",
      "Batch: 20, Loss: 1.2694294452667236, Accuracy: 0.6142578125\n",
      "Batch: 21, Loss: 1.2385902404785156, Accuracy: 0.595703125\n",
      "Batch: 22, Loss: 1.3965873718261719, Accuracy: 0.5654296875\n",
      "Batch: 23, Loss: 1.278593897819519, Accuracy: 0.59375\n",
      "Batch: 24, Loss: 1.3297064304351807, Accuracy: 0.5751953125\n",
      "Batch: 25, Loss: 1.2870509624481201, Accuracy: 0.580078125\n",
      "Batch: 26, Loss: 1.1960045099258423, Accuracy: 0.619140625\n",
      "Batch: 27, Loss: 1.2850546836853027, Accuracy: 0.5830078125\n",
      "Batch: 28, Loss: 1.369037389755249, Accuracy: 0.5654296875\n",
      "Batch: 29, Loss: 1.3362656831741333, Accuracy: 0.55859375\n",
      "Batch: 30, Loss: 1.285091757774353, Accuracy: 0.6181640625\n",
      "Batch: 31, Loss: 1.2674299478530884, Accuracy: 0.62890625\n",
      "Batch: 32, Loss: 1.2261463403701782, Accuracy: 0.59375\n",
      "Batch: 33, Loss: 1.450486183166504, Accuracy: 0.546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 34, Loss: 1.5227172374725342, Accuracy: 0.541015625\n",
      "Batch: 35, Loss: 1.3820686340332031, Accuracy: 0.5673828125\n",
      "Batch: 36, Loss: 1.3619102239608765, Accuracy: 0.59375\n",
      "Batch: 37, Loss: 1.3643648624420166, Accuracy: 0.5771484375\n",
      "Batch: 38, Loss: 1.3548799753189087, Accuracy: 0.568359375\n",
      "Batch: 39, Loss: 1.3627305030822754, Accuracy: 0.580078125\n",
      "Batch: 40, Loss: 1.3771164417266846, Accuracy: 0.59375\n",
      "Batch: 41, Loss: 1.415853500366211, Accuracy: 0.564453125\n",
      "Batch: 42, Loss: 1.1242029666900635, Accuracy: 0.6474609375\n",
      "Batch: 43, Loss: 1.3237450122833252, Accuracy: 0.583984375\n",
      "Batch: 44, Loss: 1.2884886264801025, Accuracy: 0.5830078125\n",
      "Batch: 45, Loss: 1.1503338813781738, Accuracy: 0.623046875\n",
      "Batch: 46, Loss: 1.3110525608062744, Accuracy: 0.5947265625\n",
      "Batch: 47, Loss: 1.3137738704681396, Accuracy: 0.587890625\n",
      "Batch: 48, Loss: 1.2856664657592773, Accuracy: 0.60546875\n",
      "Batch: 49, Loss: 1.4488558769226074, Accuracy: 0.5380859375\n",
      "Batch: 50, Loss: 1.42183256149292, Accuracy: 0.5517578125\n",
      "Batch: 51, Loss: 1.4999545812606812, Accuracy: 0.533203125\n",
      "Batch: 52, Loss: 1.4571669101715088, Accuracy: 0.5654296875\n",
      "Batch: 53, Loss: 1.2008824348449707, Accuracy: 0.6220703125\n",
      "Batch: 54, Loss: 1.283227801322937, Accuracy: 0.5986328125\n",
      "Batch: 55, Loss: 1.34755277633667, Accuracy: 0.5712890625\n",
      "Batch: 56, Loss: 1.4019157886505127, Accuracy: 0.5625\n",
      "Batch: 57, Loss: 1.2989156246185303, Accuracy: 0.59375\n",
      "Batch: 58, Loss: 1.4272253513336182, Accuracy: 0.5732421875\n",
      "Batch: 59, Loss: 1.176393747329712, Accuracy: 0.640625\n",
      "Batch: 60, Loss: 1.2109968662261963, Accuracy: 0.623046875\n",
      "Batch: 61, Loss: 1.342139482498169, Accuracy: 0.576171875\n",
      "Batch: 62, Loss: 1.3013501167297363, Accuracy: 0.5947265625\n",
      "Batch: 63, Loss: 1.3298206329345703, Accuracy: 0.5732421875\n",
      "Batch: 64, Loss: 1.2550383806228638, Accuracy: 0.5947265625\n",
      "Batch: 65, Loss: 1.340850591659546, Accuracy: 0.587890625\n",
      "Batch: 66, Loss: 1.2599949836730957, Accuracy: 0.6181640625\n",
      "Batch: 67, Loss: 1.4116950035095215, Accuracy: 0.5791015625\n",
      "Batch: 68, Loss: 1.3966809511184692, Accuracy: 0.5888671875\n",
      "Batch: 69, Loss: 1.3251302242279053, Accuracy: 0.5927734375\n",
      "Batch: 70, Loss: 1.3346216678619385, Accuracy: 0.5947265625\n",
      "Batch: 71, Loss: 1.3497021198272705, Accuracy: 0.58203125\n",
      "Batch: 72, Loss: 1.230790376663208, Accuracy: 0.6279296875\n",
      "Batch: 73, Loss: 1.2829394340515137, Accuracy: 0.60546875\n",
      "Batch: 74, Loss: 1.2511005401611328, Accuracy: 0.6201171875\n",
      "Batch: 75, Loss: 1.206341028213501, Accuracy: 0.625\n",
      "Batch: 76, Loss: 1.3576908111572266, Accuracy: 0.560546875\n",
      "Batch: 77, Loss: 1.3508696556091309, Accuracy: 0.5615234375\n",
      "Batch: 78, Loss: 1.2966946363449097, Accuracy: 0.61328125\n",
      "Batch: 79, Loss: 1.1837565898895264, Accuracy: 0.6630859375\n",
      "Batch: 80, Loss: 1.2143385410308838, Accuracy: 0.6162109375\n",
      "Batch: 81, Loss: 1.3783979415893555, Accuracy: 0.54296875\n",
      "Batch: 82, Loss: 1.3305211067199707, Accuracy: 0.56640625\n",
      "Batch: 83, Loss: 1.164509654045105, Accuracy: 0.634765625\n",
      "Batch: 84, Loss: 1.220034122467041, Accuracy: 0.6298828125\n",
      "Batch: 85, Loss: 1.1719233989715576, Accuracy: 0.6435546875\n",
      "Batch: 86, Loss: 1.4274852275848389, Accuracy: 0.544921875\n",
      "Batch: 87, Loss: 1.223865032196045, Accuracy: 0.6279296875\n",
      "Batch: 88, Loss: 1.346909999847412, Accuracy: 0.599609375\n",
      "Batch: 89, Loss: 1.3333438634872437, Accuracy: 0.5859375\n",
      "Batch: 90, Loss: 1.214760661125183, Accuracy: 0.6083984375\n",
      "Batch: 91, Loss: 1.288750171661377, Accuracy: 0.5830078125\n",
      "Batch: 92, Loss: 1.3384199142456055, Accuracy: 0.59375\n",
      "Batch: 93, Loss: 1.2234694957733154, Accuracy: 0.611328125\n",
      "Batch: 94, Loss: 1.2532522678375244, Accuracy: 0.6015625\n",
      "Batch: 95, Loss: 1.2933235168457031, Accuracy: 0.5859375\n",
      "Batch: 96, Loss: 1.2702964544296265, Accuracy: 0.61328125\n",
      "Batch: 97, Loss: 1.1474241018295288, Accuracy: 0.640625\n",
      "Batch: 98, Loss: 1.187628984451294, Accuracy: 0.6572265625\n",
      "Batch: 99, Loss: 1.1638222932815552, Accuracy: 0.62890625\n",
      "Batch: 100, Loss: 1.2862613201141357, Accuracy: 0.595703125\n",
      "Batch: 101, Loss: 1.323206901550293, Accuracy: 0.583984375\n",
      "Batch: 102, Loss: 1.2213331460952759, Accuracy: 0.6259765625\n",
      "Batch: 103, Loss: 1.349157452583313, Accuracy: 0.6005859375\n",
      "Batch: 104, Loss: 1.2045494318008423, Accuracy: 0.615234375\n",
      "Batch: 105, Loss: 1.340012788772583, Accuracy: 0.5830078125\n",
      "Batch: 106, Loss: 1.3386566638946533, Accuracy: 0.5751953125\n",
      "Batch: 107, Loss: 1.4683220386505127, Accuracy: 0.564453125\n",
      "Batch: 108, Loss: 1.4043034315109253, Accuracy: 0.5517578125\n",
      "Batch: 109, Loss: 1.4653191566467285, Accuracy: 0.5400390625\n",
      "Batch: 110, Loss: 1.145275592803955, Accuracy: 0.6416015625\n",
      "Batch: 111, Loss: 1.31704580783844, Accuracy: 0.556640625\n",
      "Batch: 112, Loss: 1.280076265335083, Accuracy: 0.609375\n",
      "Batch: 113, Loss: 1.353758692741394, Accuracy: 0.6064453125\n",
      "Batch: 114, Loss: 1.466869831085205, Accuracy: 0.5576171875\n",
      "Batch: 115, Loss: 1.472348690032959, Accuracy: 0.556640625\n",
      "Batch: 116, Loss: 1.40120530128479, Accuracy: 0.5615234375\n",
      "Batch: 117, Loss: 1.4101159572601318, Accuracy: 0.5732421875\n",
      "Batch: 118, Loss: 1.1719095706939697, Accuracy: 0.64453125\n",
      "Batch: 119, Loss: 1.2244224548339844, Accuracy: 0.6318359375\n",
      "Batch: 120, Loss: 1.387858271598816, Accuracy: 0.5693359375\n",
      "Batch: 121, Loss: 1.4097113609313965, Accuracy: 0.5771484375\n",
      "Batch: 122, Loss: 1.2630577087402344, Accuracy: 0.6201171875\n",
      "Batch: 123, Loss: 1.259342908859253, Accuracy: 0.6005859375\n",
      "Batch: 124, Loss: 1.3158807754516602, Accuracy: 0.5908203125\n",
      "Batch: 125, Loss: 1.362332820892334, Accuracy: 0.5712890625\n",
      "Batch: 126, Loss: 1.3481738567352295, Accuracy: 0.5615234375\n",
      "Batch: 127, Loss: 1.2185943126678467, Accuracy: 0.6328125\n",
      "Batch: 128, Loss: 1.4761786460876465, Accuracy: 0.572265625\n",
      "Batch: 129, Loss: 1.2873096466064453, Accuracy: 0.5859375\n",
      "Batch: 130, Loss: 1.5635402202606201, Accuracy: 0.5380859375\n",
      "Batch: 131, Loss: 1.3690121173858643, Accuracy: 0.5712890625\n",
      "Batch: 132, Loss: 1.4025423526763916, Accuracy: 0.560546875\n",
      "Batch: 133, Loss: 1.2525696754455566, Accuracy: 0.599609375\n",
      "Batch: 134, Loss: 1.3159326314926147, Accuracy: 0.5830078125\n",
      "Batch: 135, Loss: 1.2320797443389893, Accuracy: 0.615234375\n",
      "Batch: 136, Loss: 1.2849452495574951, Accuracy: 0.5849609375\n",
      "Batch: 137, Loss: 1.2266206741333008, Accuracy: 0.58984375\n",
      "Batch: 138, Loss: 1.1197056770324707, Accuracy: 0.6259765625\n",
      "Batch: 139, Loss: 1.1581788063049316, Accuracy: 0.62109375\n",
      "Batch: 140, Loss: 1.3106179237365723, Accuracy: 0.5751953125\n",
      "Batch: 141, Loss: 1.3590607643127441, Accuracy: 0.5732421875\n",
      "Batch: 142, Loss: 1.3196167945861816, Accuracy: 0.587890625\n",
      "Batch: 143, Loss: 1.339231252670288, Accuracy: 0.587890625\n",
      "Batch: 144, Loss: 1.3006013631820679, Accuracy: 0.59375\n",
      "Batch: 145, Loss: 1.227742314338684, Accuracy: 0.603515625\n",
      "Batch: 146, Loss: 1.3785163164138794, Accuracy: 0.5546875\n",
      "Batch: 147, Loss: 1.3005187511444092, Accuracy: 0.5859375\n",
      "Batch: 148, Loss: 1.4948867559432983, Accuracy: 0.5244140625\n",
      "Batch: 149, Loss: 1.352364420890808, Accuracy: 0.5556640625\n",
      "Batch: 150, Loss: 1.2367339134216309, Accuracy: 0.60546875\n",
      "Batch: 151, Loss: 1.2020187377929688, Accuracy: 0.619140625\n",
      "Epoch 9/80\n",
      "Batch: 1, Loss: 1.5211845636367798, Accuracy: 0.50390625\n",
      "Batch: 2, Loss: 1.3024299144744873, Accuracy: 0.568359375\n",
      "Batch: 3, Loss: 1.2236430644989014, Accuracy: 0.5908203125\n",
      "Batch: 4, Loss: 1.154269814491272, Accuracy: 0.63671875\n",
      "Batch: 5, Loss: 1.1889979839324951, Accuracy: 0.6298828125\n",
      "Batch: 6, Loss: 1.3071374893188477, Accuracy: 0.5615234375\n",
      "Batch: 7, Loss: 1.2411020994186401, Accuracy: 0.5927734375\n",
      "Batch: 8, Loss: 1.1889429092407227, Accuracy: 0.6123046875\n",
      "Batch: 9, Loss: 1.1464018821716309, Accuracy: 0.6357421875\n",
      "Batch: 10, Loss: 1.1974445581436157, Accuracy: 0.6220703125\n",
      "Batch: 11, Loss: 1.3789384365081787, Accuracy: 0.5302734375\n",
      "Batch: 12, Loss: 1.3976812362670898, Accuracy: 0.56640625\n",
      "Batch: 13, Loss: 1.0960338115692139, Accuracy: 0.654296875\n",
      "Batch: 14, Loss: 1.3889490365982056, Accuracy: 0.5517578125\n",
      "Batch: 15, Loss: 1.2342115640640259, Accuracy: 0.6171875\n",
      "Batch: 16, Loss: 1.2231062650680542, Accuracy: 0.607421875\n",
      "Batch: 17, Loss: 1.3237366676330566, Accuracy: 0.5810546875\n",
      "Batch: 18, Loss: 1.3172729015350342, Accuracy: 0.5712890625\n",
      "Batch: 19, Loss: 1.3576338291168213, Accuracy: 0.5830078125\n",
      "Batch: 20, Loss: 1.2474541664123535, Accuracy: 0.62109375\n",
      "Batch: 21, Loss: 1.2080888748168945, Accuracy: 0.6064453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 22, Loss: 1.3551702499389648, Accuracy: 0.603515625\n",
      "Batch: 23, Loss: 1.2454930543899536, Accuracy: 0.607421875\n",
      "Batch: 24, Loss: 1.2816081047058105, Accuracy: 0.5849609375\n",
      "Batch: 25, Loss: 1.2760562896728516, Accuracy: 0.603515625\n",
      "Batch: 26, Loss: 1.16938316822052, Accuracy: 0.6279296875\n",
      "Batch: 27, Loss: 1.2340760231018066, Accuracy: 0.599609375\n",
      "Batch: 28, Loss: 1.3178739547729492, Accuracy: 0.5693359375\n",
      "Batch: 29, Loss: 1.297839879989624, Accuracy: 0.5625\n",
      "Batch: 30, Loss: 1.2506232261657715, Accuracy: 0.61328125\n",
      "Batch: 31, Loss: 1.2250034809112549, Accuracy: 0.630859375\n",
      "Batch: 32, Loss: 1.2001385688781738, Accuracy: 0.6025390625\n",
      "Batch: 33, Loss: 1.4097669124603271, Accuracy: 0.5517578125\n",
      "Batch: 34, Loss: 1.4703538417816162, Accuracy: 0.5458984375\n",
      "Batch: 35, Loss: 1.3310997486114502, Accuracy: 0.56640625\n",
      "Batch: 36, Loss: 1.308809518814087, Accuracy: 0.603515625\n",
      "Batch: 37, Loss: 1.3563024997711182, Accuracy: 0.580078125\n",
      "Batch: 38, Loss: 1.3101859092712402, Accuracy: 0.5654296875\n",
      "Batch: 39, Loss: 1.3243991136550903, Accuracy: 0.5869140625\n",
      "Batch: 40, Loss: 1.3752427101135254, Accuracy: 0.59375\n",
      "Batch: 41, Loss: 1.364850640296936, Accuracy: 0.5771484375\n",
      "Batch: 42, Loss: 1.0868215560913086, Accuracy: 0.6533203125\n",
      "Batch: 43, Loss: 1.2927207946777344, Accuracy: 0.568359375\n",
      "Batch: 44, Loss: 1.2520158290863037, Accuracy: 0.591796875\n",
      "Batch: 45, Loss: 1.1259896755218506, Accuracy: 0.6240234375\n",
      "Batch: 46, Loss: 1.2670139074325562, Accuracy: 0.607421875\n",
      "Batch: 47, Loss: 1.2632403373718262, Accuracy: 0.607421875\n",
      "Batch: 48, Loss: 1.2415335178375244, Accuracy: 0.607421875\n",
      "Batch: 49, Loss: 1.4182766675949097, Accuracy: 0.546875\n",
      "Batch: 50, Loss: 1.3702551126480103, Accuracy: 0.5693359375\n",
      "Batch: 51, Loss: 1.4486973285675049, Accuracy: 0.546875\n",
      "Batch: 52, Loss: 1.4189634323120117, Accuracy: 0.5927734375\n",
      "Batch: 53, Loss: 1.1702730655670166, Accuracy: 0.6376953125\n",
      "Batch: 54, Loss: 1.274550199508667, Accuracy: 0.6201171875\n",
      "Batch: 55, Loss: 1.3120148181915283, Accuracy: 0.57421875\n",
      "Batch: 56, Loss: 1.3426644802093506, Accuracy: 0.58203125\n",
      "Batch: 57, Loss: 1.2807527780532837, Accuracy: 0.60546875\n",
      "Batch: 58, Loss: 1.399524211883545, Accuracy: 0.5830078125\n",
      "Batch: 59, Loss: 1.1738779544830322, Accuracy: 0.650390625\n",
      "Batch: 60, Loss: 1.1781086921691895, Accuracy: 0.6376953125\n",
      "Batch: 61, Loss: 1.315838098526001, Accuracy: 0.5810546875\n",
      "Batch: 62, Loss: 1.258042812347412, Accuracy: 0.61328125\n",
      "Batch: 63, Loss: 1.2888679504394531, Accuracy: 0.591796875\n",
      "Batch: 64, Loss: 1.2460801601409912, Accuracy: 0.6064453125\n",
      "Batch: 65, Loss: 1.3087899684906006, Accuracy: 0.5869140625\n",
      "Batch: 66, Loss: 1.219704270362854, Accuracy: 0.6171875\n",
      "Batch: 67, Loss: 1.3806958198547363, Accuracy: 0.5888671875\n",
      "Batch: 68, Loss: 1.3700265884399414, Accuracy: 0.6005859375\n",
      "Batch: 69, Loss: 1.2974562644958496, Accuracy: 0.6083984375\n",
      "Batch: 70, Loss: 1.2921693325042725, Accuracy: 0.6005859375\n",
      "Batch: 71, Loss: 1.3178462982177734, Accuracy: 0.5859375\n",
      "Batch: 72, Loss: 1.1935555934906006, Accuracy: 0.62890625\n",
      "Batch: 73, Loss: 1.2501461505889893, Accuracy: 0.634765625\n",
      "Batch: 74, Loss: 1.2081427574157715, Accuracy: 0.615234375\n",
      "Batch: 75, Loss: 1.1767778396606445, Accuracy: 0.638671875\n",
      "Batch: 76, Loss: 1.3363243341445923, Accuracy: 0.56640625\n",
      "Batch: 77, Loss: 1.2863402366638184, Accuracy: 0.5859375\n",
      "Batch: 78, Loss: 1.2641947269439697, Accuracy: 0.6240234375\n",
      "Batch: 79, Loss: 1.1407769918441772, Accuracy: 0.669921875\n",
      "Batch: 80, Loss: 1.2012794017791748, Accuracy: 0.5947265625\n",
      "Batch: 81, Loss: 1.3517687320709229, Accuracy: 0.55078125\n",
      "Batch: 82, Loss: 1.3226460218429565, Accuracy: 0.5830078125\n",
      "Batch: 83, Loss: 1.1272532939910889, Accuracy: 0.6533203125\n",
      "Batch: 84, Loss: 1.1901628971099854, Accuracy: 0.6376953125\n",
      "Batch: 85, Loss: 1.1551580429077148, Accuracy: 0.6474609375\n",
      "Batch: 86, Loss: 1.417703628540039, Accuracy: 0.5625\n",
      "Batch: 87, Loss: 1.2123348712921143, Accuracy: 0.6318359375\n",
      "Batch: 88, Loss: 1.3159078359603882, Accuracy: 0.603515625\n",
      "Batch: 89, Loss: 1.3264663219451904, Accuracy: 0.5986328125\n",
      "Batch: 90, Loss: 1.2040884494781494, Accuracy: 0.6103515625\n",
      "Batch: 91, Loss: 1.2388838529586792, Accuracy: 0.6181640625\n",
      "Batch: 92, Loss: 1.3129243850708008, Accuracy: 0.6015625\n",
      "Batch: 93, Loss: 1.193427324295044, Accuracy: 0.634765625\n",
      "Batch: 94, Loss: 1.2186391353607178, Accuracy: 0.611328125\n",
      "Batch: 95, Loss: 1.267086386680603, Accuracy: 0.5849609375\n",
      "Batch: 96, Loss: 1.2423518896102905, Accuracy: 0.6181640625\n",
      "Batch: 97, Loss: 1.101946234703064, Accuracy: 0.654296875\n",
      "Batch: 98, Loss: 1.1528007984161377, Accuracy: 0.6474609375\n",
      "Batch: 99, Loss: 1.1276835203170776, Accuracy: 0.646484375\n",
      "Batch: 100, Loss: 1.2459852695465088, Accuracy: 0.6181640625\n",
      "Batch: 101, Loss: 1.2987287044525146, Accuracy: 0.59375\n",
      "Batch: 102, Loss: 1.1951953172683716, Accuracy: 0.6181640625\n",
      "Batch: 103, Loss: 1.3129451274871826, Accuracy: 0.6142578125\n",
      "Batch: 104, Loss: 1.1743190288543701, Accuracy: 0.63671875\n",
      "Batch: 105, Loss: 1.311492919921875, Accuracy: 0.578125\n",
      "Batch: 106, Loss: 1.2835345268249512, Accuracy: 0.6044921875\n",
      "Batch: 107, Loss: 1.4342981576919556, Accuracy: 0.5625\n",
      "Batch: 108, Loss: 1.3715298175811768, Accuracy: 0.576171875\n",
      "Batch: 109, Loss: 1.4094737768173218, Accuracy: 0.5439453125\n",
      "Batch: 110, Loss: 1.1106640100479126, Accuracy: 0.6396484375\n",
      "Batch: 111, Loss: 1.296140432357788, Accuracy: 0.5625\n",
      "Batch: 112, Loss: 1.2421127557754517, Accuracy: 0.607421875\n",
      "Batch: 113, Loss: 1.3051443099975586, Accuracy: 0.609375\n",
      "Batch: 114, Loss: 1.4243007898330688, Accuracy: 0.55859375\n",
      "Batch: 115, Loss: 1.435924768447876, Accuracy: 0.580078125\n",
      "Batch: 116, Loss: 1.3762835264205933, Accuracy: 0.560546875\n",
      "Batch: 117, Loss: 1.3673131465911865, Accuracy: 0.580078125\n",
      "Batch: 118, Loss: 1.1282124519348145, Accuracy: 0.65234375\n",
      "Batch: 119, Loss: 1.2032139301300049, Accuracy: 0.6337890625\n",
      "Batch: 120, Loss: 1.3261967897415161, Accuracy: 0.5732421875\n",
      "Batch: 121, Loss: 1.3782882690429688, Accuracy: 0.5732421875\n",
      "Batch: 122, Loss: 1.2201547622680664, Accuracy: 0.6240234375\n",
      "Batch: 123, Loss: 1.2448527812957764, Accuracy: 0.6171875\n",
      "Batch: 124, Loss: 1.284322738647461, Accuracy: 0.5986328125\n",
      "Batch: 125, Loss: 1.3156574964523315, Accuracy: 0.58203125\n",
      "Batch: 126, Loss: 1.3175392150878906, Accuracy: 0.5673828125\n",
      "Batch: 127, Loss: 1.165416955947876, Accuracy: 0.662109375\n",
      "Batch: 128, Loss: 1.4283063411712646, Accuracy: 0.5654296875\n",
      "Batch: 129, Loss: 1.2551487684249878, Accuracy: 0.5908203125\n",
      "Batch: 130, Loss: 1.5404434204101562, Accuracy: 0.5361328125\n",
      "Batch: 131, Loss: 1.3315725326538086, Accuracy: 0.5751953125\n",
      "Batch: 132, Loss: 1.3530709743499756, Accuracy: 0.5859375\n",
      "Batch: 133, Loss: 1.1928462982177734, Accuracy: 0.6220703125\n",
      "Batch: 134, Loss: 1.2671130895614624, Accuracy: 0.583984375\n",
      "Batch: 135, Loss: 1.2093431949615479, Accuracy: 0.62109375\n",
      "Batch: 136, Loss: 1.2431485652923584, Accuracy: 0.6044921875\n",
      "Batch: 137, Loss: 1.2044563293457031, Accuracy: 0.583984375\n",
      "Batch: 138, Loss: 1.0729163885116577, Accuracy: 0.6572265625\n",
      "Batch: 139, Loss: 1.1321158409118652, Accuracy: 0.607421875\n",
      "Batch: 140, Loss: 1.284267544746399, Accuracy: 0.58984375\n",
      "Batch: 141, Loss: 1.2961266040802002, Accuracy: 0.591796875\n",
      "Batch: 142, Loss: 1.3030157089233398, Accuracy: 0.5791015625\n",
      "Batch: 143, Loss: 1.3066903352737427, Accuracy: 0.578125\n",
      "Batch: 144, Loss: 1.2450298070907593, Accuracy: 0.5986328125\n",
      "Batch: 145, Loss: 1.1942059993743896, Accuracy: 0.6083984375\n",
      "Batch: 146, Loss: 1.3420342206954956, Accuracy: 0.57421875\n",
      "Batch: 147, Loss: 1.2711399793624878, Accuracy: 0.59765625\n",
      "Batch: 148, Loss: 1.4332433938980103, Accuracy: 0.5244140625\n",
      "Batch: 149, Loss: 1.3080170154571533, Accuracy: 0.5625\n",
      "Batch: 150, Loss: 1.2062721252441406, Accuracy: 0.603515625\n",
      "Batch: 151, Loss: 1.1673355102539062, Accuracy: 0.6455078125\n",
      "Epoch 10/80\n",
      "Batch: 1, Loss: 1.5052950382232666, Accuracy: 0.51171875\n",
      "Batch: 2, Loss: 1.2950222492218018, Accuracy: 0.556640625\n",
      "Batch: 3, Loss: 1.1923174858093262, Accuracy: 0.6025390625\n",
      "Batch: 4, Loss: 1.1021013259887695, Accuracy: 0.6552734375\n",
      "Batch: 5, Loss: 1.1317963600158691, Accuracy: 0.65234375\n",
      "Batch: 6, Loss: 1.2671825885772705, Accuracy: 0.57421875\n",
      "Batch: 7, Loss: 1.211327075958252, Accuracy: 0.599609375\n",
      "Batch: 8, Loss: 1.1762454509735107, Accuracy: 0.609375\n",
      "Batch: 9, Loss: 1.1375315189361572, Accuracy: 0.626953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 10, Loss: 1.1454112529754639, Accuracy: 0.6318359375\n",
      "Batch: 11, Loss: 1.3509061336517334, Accuracy: 0.5439453125\n",
      "Batch: 12, Loss: 1.357168436050415, Accuracy: 0.576171875\n",
      "Batch: 13, Loss: 1.0650112628936768, Accuracy: 0.6630859375\n",
      "Batch: 14, Loss: 1.3439356088638306, Accuracy: 0.5732421875\n",
      "Batch: 15, Loss: 1.2093862295150757, Accuracy: 0.638671875\n",
      "Batch: 16, Loss: 1.195010781288147, Accuracy: 0.6298828125\n",
      "Batch: 17, Loss: 1.3069579601287842, Accuracy: 0.578125\n",
      "Batch: 18, Loss: 1.2905809879302979, Accuracy: 0.5830078125\n",
      "Batch: 19, Loss: 1.305964708328247, Accuracy: 0.5830078125\n",
      "Batch: 20, Loss: 1.2104299068450928, Accuracy: 0.626953125\n",
      "Batch: 21, Loss: 1.1796166896820068, Accuracy: 0.619140625\n",
      "Batch: 22, Loss: 1.305997610092163, Accuracy: 0.5966796875\n",
      "Batch: 23, Loss: 1.2022058963775635, Accuracy: 0.6201171875\n",
      "Batch: 24, Loss: 1.2664161920547485, Accuracy: 0.587890625\n",
      "Batch: 25, Loss: 1.239469289779663, Accuracy: 0.6015625\n",
      "Batch: 26, Loss: 1.1294019222259521, Accuracy: 0.6396484375\n",
      "Batch: 27, Loss: 1.2046904563903809, Accuracy: 0.6015625\n",
      "Batch: 28, Loss: 1.291968822479248, Accuracy: 0.576171875\n",
      "Batch: 29, Loss: 1.269728183746338, Accuracy: 0.5966796875\n",
      "Batch: 30, Loss: 1.2385435104370117, Accuracy: 0.623046875\n",
      "Batch: 31, Loss: 1.171328067779541, Accuracy: 0.6376953125\n",
      "Batch: 32, Loss: 1.1608153581619263, Accuracy: 0.6142578125\n",
      "Batch: 33, Loss: 1.3908432722091675, Accuracy: 0.556640625\n",
      "Batch: 34, Loss: 1.4540293216705322, Accuracy: 0.541015625\n",
      "Batch: 35, Loss: 1.2836142778396606, Accuracy: 0.58203125\n",
      "Batch: 36, Loss: 1.2982990741729736, Accuracy: 0.5947265625\n",
      "Batch: 37, Loss: 1.3026195764541626, Accuracy: 0.5810546875\n",
      "Batch: 38, Loss: 1.2797173261642456, Accuracy: 0.5810546875\n",
      "Batch: 39, Loss: 1.3204076290130615, Accuracy: 0.6015625\n",
      "Batch: 40, Loss: 1.3280413150787354, Accuracy: 0.6025390625\n",
      "Batch: 41, Loss: 1.3179399967193604, Accuracy: 0.5947265625\n",
      "Batch: 42, Loss: 1.0851279497146606, Accuracy: 0.6455078125\n",
      "Batch: 43, Loss: 1.2574613094329834, Accuracy: 0.578125\n",
      "Batch: 44, Loss: 1.2432641983032227, Accuracy: 0.5849609375\n",
      "Batch: 45, Loss: 1.0921025276184082, Accuracy: 0.6396484375\n",
      "Batch: 46, Loss: 1.2278547286987305, Accuracy: 0.611328125\n",
      "Batch: 47, Loss: 1.252350926399231, Accuracy: 0.61328125\n",
      "Batch: 48, Loss: 1.205415964126587, Accuracy: 0.625\n",
      "Batch: 49, Loss: 1.3925716876983643, Accuracy: 0.568359375\n",
      "Batch: 50, Loss: 1.3540738821029663, Accuracy: 0.5703125\n",
      "Batch: 51, Loss: 1.4387105703353882, Accuracy: 0.552734375\n",
      "Batch: 52, Loss: 1.3835211992263794, Accuracy: 0.58984375\n",
      "Batch: 53, Loss: 1.1389284133911133, Accuracy: 0.6416015625\n",
      "Batch: 54, Loss: 1.2479002475738525, Accuracy: 0.625\n",
      "Batch: 55, Loss: 1.2748080492019653, Accuracy: 0.6025390625\n",
      "Batch: 56, Loss: 1.3190255165100098, Accuracy: 0.591796875\n",
      "Batch: 57, Loss: 1.2503820657730103, Accuracy: 0.6103515625\n",
      "Batch: 58, Loss: 1.3698707818984985, Accuracy: 0.5693359375\n",
      "Batch: 59, Loss: 1.1320252418518066, Accuracy: 0.6650390625\n",
      "Batch: 60, Loss: 1.109063744544983, Accuracy: 0.666015625\n",
      "Batch: 61, Loss: 1.2870492935180664, Accuracy: 0.5947265625\n",
      "Batch: 62, Loss: 1.2506771087646484, Accuracy: 0.619140625\n",
      "Batch: 63, Loss: 1.2573606967926025, Accuracy: 0.5888671875\n",
      "Batch: 64, Loss: 1.2098305225372314, Accuracy: 0.62109375\n",
      "Batch: 65, Loss: 1.2784497737884521, Accuracy: 0.5986328125\n",
      "Batch: 66, Loss: 1.186772346496582, Accuracy: 0.619140625\n",
      "Batch: 67, Loss: 1.340087652206421, Accuracy: 0.59765625\n",
      "Batch: 68, Loss: 1.334559679031372, Accuracy: 0.5947265625\n",
      "Batch: 69, Loss: 1.2536547183990479, Accuracy: 0.6025390625\n",
      "Batch: 70, Loss: 1.248816728591919, Accuracy: 0.625\n",
      "Batch: 71, Loss: 1.303781270980835, Accuracy: 0.58203125\n",
      "Batch: 72, Loss: 1.1749317646026611, Accuracy: 0.625\n",
      "Batch: 73, Loss: 1.233656406402588, Accuracy: 0.634765625\n",
      "Batch: 74, Loss: 1.166441798210144, Accuracy: 0.62109375\n",
      "Batch: 75, Loss: 1.153386116027832, Accuracy: 0.6201171875\n",
      "Batch: 76, Loss: 1.3002479076385498, Accuracy: 0.5791015625\n",
      "Batch: 77, Loss: 1.283482313156128, Accuracy: 0.5849609375\n",
      "Batch: 78, Loss: 1.2199033498764038, Accuracy: 0.626953125\n",
      "Batch: 79, Loss: 1.1455143690109253, Accuracy: 0.66796875\n",
      "Batch: 80, Loss: 1.175295114517212, Accuracy: 0.6005859375\n",
      "Batch: 81, Loss: 1.3039002418518066, Accuracy: 0.5498046875\n",
      "Batch: 82, Loss: 1.2662580013275146, Accuracy: 0.5927734375\n",
      "Batch: 83, Loss: 1.109769344329834, Accuracy: 0.642578125\n",
      "Batch: 84, Loss: 1.17878258228302, Accuracy: 0.6494140625\n",
      "Batch: 85, Loss: 1.116541862487793, Accuracy: 0.64453125\n",
      "Batch: 86, Loss: 1.4066736698150635, Accuracy: 0.572265625\n",
      "Batch: 87, Loss: 1.2106096744537354, Accuracy: 0.6337890625\n",
      "Batch: 88, Loss: 1.303476095199585, Accuracy: 0.6083984375\n",
      "Batch: 89, Loss: 1.2855497598648071, Accuracy: 0.599609375\n",
      "Batch: 90, Loss: 1.1654272079467773, Accuracy: 0.6318359375\n",
      "Batch: 91, Loss: 1.221278429031372, Accuracy: 0.6083984375\n",
      "Batch: 92, Loss: 1.311530351638794, Accuracy: 0.5966796875\n",
      "Batch: 93, Loss: 1.247065544128418, Accuracy: 0.619140625\n",
      "Batch: 94, Loss: 1.249363660812378, Accuracy: 0.595703125\n",
      "Batch: 95, Loss: 1.2447080612182617, Accuracy: 0.587890625\n",
      "Batch: 96, Loss: 1.2415263652801514, Accuracy: 0.607421875\n",
      "Batch: 97, Loss: 1.082059383392334, Accuracy: 0.6572265625\n",
      "Batch: 98, Loss: 1.1327905654907227, Accuracy: 0.6474609375\n",
      "Batch: 99, Loss: 1.1411328315734863, Accuracy: 0.640625\n",
      "Batch: 100, Loss: 1.2341654300689697, Accuracy: 0.61328125\n",
      "Batch: 101, Loss: 1.2723217010498047, Accuracy: 0.6005859375\n",
      "Batch: 102, Loss: 1.1680980920791626, Accuracy: 0.626953125\n",
      "Batch: 103, Loss: 1.2812215089797974, Accuracy: 0.6171875\n",
      "Batch: 104, Loss: 1.1474955081939697, Accuracy: 0.6396484375\n",
      "Batch: 105, Loss: 1.280522108078003, Accuracy: 0.6142578125\n",
      "Batch: 106, Loss: 1.2645580768585205, Accuracy: 0.59375\n",
      "Batch: 107, Loss: 1.3979527950286865, Accuracy: 0.5576171875\n",
      "Batch: 108, Loss: 1.3375135660171509, Accuracy: 0.5654296875\n",
      "Batch: 109, Loss: 1.4111090898513794, Accuracy: 0.5546875\n",
      "Batch: 110, Loss: 1.0845818519592285, Accuracy: 0.6474609375\n",
      "Batch: 111, Loss: 1.271789789199829, Accuracy: 0.57421875\n",
      "Batch: 112, Loss: 1.2263975143432617, Accuracy: 0.6259765625\n",
      "Batch: 113, Loss: 1.2683329582214355, Accuracy: 0.6279296875\n",
      "Batch: 114, Loss: 1.3930528163909912, Accuracy: 0.5703125\n",
      "Batch: 115, Loss: 1.4042693376541138, Accuracy: 0.5703125\n",
      "Batch: 116, Loss: 1.3235268592834473, Accuracy: 0.5869140625\n",
      "Batch: 117, Loss: 1.345360279083252, Accuracy: 0.5908203125\n",
      "Batch: 118, Loss: 1.1075376272201538, Accuracy: 0.6611328125\n",
      "Batch: 119, Loss: 1.1563788652420044, Accuracy: 0.6533203125\n",
      "Batch: 120, Loss: 1.3224561214447021, Accuracy: 0.583984375\n",
      "Batch: 121, Loss: 1.3368960618972778, Accuracy: 0.578125\n",
      "Batch: 122, Loss: 1.2074609994888306, Accuracy: 0.6240234375\n",
      "Batch: 123, Loss: 1.209423542022705, Accuracy: 0.6220703125\n",
      "Batch: 124, Loss: 1.2498445510864258, Accuracy: 0.625\n",
      "Batch: 125, Loss: 1.2810893058776855, Accuracy: 0.595703125\n",
      "Batch: 126, Loss: 1.2748315334320068, Accuracy: 0.59375\n",
      "Batch: 127, Loss: 1.1452982425689697, Accuracy: 0.662109375\n",
      "Batch: 128, Loss: 1.3980845212936401, Accuracy: 0.5908203125\n",
      "Batch: 129, Loss: 1.2097749710083008, Accuracy: 0.6181640625\n",
      "Batch: 130, Loss: 1.4755626916885376, Accuracy: 0.5546875\n",
      "Batch: 131, Loss: 1.30901038646698, Accuracy: 0.578125\n",
      "Batch: 132, Loss: 1.2984367609024048, Accuracy: 0.5966796875\n",
      "Batch: 133, Loss: 1.196664810180664, Accuracy: 0.6142578125\n",
      "Batch: 134, Loss: 1.242079734802246, Accuracy: 0.599609375\n",
      "Batch: 135, Loss: 1.161792516708374, Accuracy: 0.640625\n",
      "Batch: 136, Loss: 1.2323013544082642, Accuracy: 0.6142578125\n",
      "Batch: 137, Loss: 1.1812180280685425, Accuracy: 0.5966796875\n",
      "Batch: 138, Loss: 1.036896824836731, Accuracy: 0.6513671875\n",
      "Batch: 139, Loss: 1.1049011945724487, Accuracy: 0.6328125\n",
      "Batch: 140, Loss: 1.2405505180358887, Accuracy: 0.5888671875\n",
      "Batch: 141, Loss: 1.2455476522445679, Accuracy: 0.609375\n",
      "Batch: 142, Loss: 1.2774817943572998, Accuracy: 0.5810546875\n",
      "Batch: 143, Loss: 1.2689738273620605, Accuracy: 0.5908203125\n",
      "Batch: 144, Loss: 1.2356184720993042, Accuracy: 0.6083984375\n",
      "Batch: 145, Loss: 1.170912265777588, Accuracy: 0.6123046875\n",
      "Batch: 146, Loss: 1.3200111389160156, Accuracy: 0.56640625\n",
      "Batch: 147, Loss: 1.2453888654708862, Accuracy: 0.599609375\n",
      "Batch: 148, Loss: 1.3875346183776855, Accuracy: 0.5498046875\n",
      "Batch: 149, Loss: 1.2914965152740479, Accuracy: 0.5859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 150, Loss: 1.1633656024932861, Accuracy: 0.6220703125\n",
      "Batch: 151, Loss: 1.1156525611877441, Accuracy: 0.6572265625\n",
      "Saved Weights at epoch 10 to file Weights_10.h5\n",
      "Epoch 11/80\n",
      "Batch: 1, Loss: 1.4902888536453247, Accuracy: 0.5341796875\n",
      "Batch: 2, Loss: 1.2600661516189575, Accuracy: 0.560546875\n",
      "Batch: 3, Loss: 1.1733938455581665, Accuracy: 0.625\n",
      "Batch: 4, Loss: 1.1044306755065918, Accuracy: 0.654296875\n",
      "Batch: 5, Loss: 1.1456876993179321, Accuracy: 0.6396484375\n",
      "Batch: 6, Loss: 1.2539665699005127, Accuracy: 0.5859375\n",
      "Batch: 7, Loss: 1.163512945175171, Accuracy: 0.6171875\n",
      "Batch: 8, Loss: 1.133833408355713, Accuracy: 0.6240234375\n",
      "Batch: 9, Loss: 1.0846327543258667, Accuracy: 0.6611328125\n",
      "Batch: 10, Loss: 1.1440633535385132, Accuracy: 0.6318359375\n",
      "Batch: 11, Loss: 1.3327243328094482, Accuracy: 0.5732421875\n",
      "Batch: 12, Loss: 1.3292078971862793, Accuracy: 0.580078125\n",
      "Batch: 13, Loss: 1.05006742477417, Accuracy: 0.662109375\n",
      "Batch: 14, Loss: 1.327958583831787, Accuracy: 0.56640625\n",
      "Batch: 15, Loss: 1.1799440383911133, Accuracy: 0.6357421875\n",
      "Batch: 16, Loss: 1.1565628051757812, Accuracy: 0.646484375\n",
      "Batch: 17, Loss: 1.243988037109375, Accuracy: 0.6142578125\n",
      "Batch: 18, Loss: 1.2543621063232422, Accuracy: 0.5966796875\n",
      "Batch: 19, Loss: 1.301132082939148, Accuracy: 0.5888671875\n",
      "Batch: 20, Loss: 1.181190013885498, Accuracy: 0.6279296875\n",
      "Batch: 21, Loss: 1.1487818956375122, Accuracy: 0.626953125\n",
      "Batch: 22, Loss: 1.2689024209976196, Accuracy: 0.6044921875\n",
      "Batch: 23, Loss: 1.189481258392334, Accuracy: 0.6162109375\n",
      "Batch: 24, Loss: 1.220099687576294, Accuracy: 0.6181640625\n",
      "Batch: 25, Loss: 1.2220560312271118, Accuracy: 0.6142578125\n",
      "Batch: 26, Loss: 1.1253514289855957, Accuracy: 0.6201171875\n",
      "Batch: 27, Loss: 1.1832618713378906, Accuracy: 0.59765625\n",
      "Batch: 28, Loss: 1.2504736185073853, Accuracy: 0.591796875\n",
      "Batch: 29, Loss: 1.2487081289291382, Accuracy: 0.5986328125\n",
      "Batch: 30, Loss: 1.1584049463272095, Accuracy: 0.650390625\n",
      "Batch: 31, Loss: 1.1703850030899048, Accuracy: 0.64453125\n",
      "Batch: 32, Loss: 1.1467199325561523, Accuracy: 0.6181640625\n",
      "Batch: 33, Loss: 1.3469343185424805, Accuracy: 0.5634765625\n",
      "Batch: 34, Loss: 1.3897850513458252, Accuracy: 0.564453125\n",
      "Batch: 35, Loss: 1.2684168815612793, Accuracy: 0.5791015625\n",
      "Batch: 36, Loss: 1.2535772323608398, Accuracy: 0.6142578125\n",
      "Batch: 37, Loss: 1.268911361694336, Accuracy: 0.607421875\n",
      "Batch: 38, Loss: 1.2648448944091797, Accuracy: 0.5859375\n",
      "Batch: 39, Loss: 1.298006534576416, Accuracy: 0.5966796875\n",
      "Batch: 40, Loss: 1.2873928546905518, Accuracy: 0.6064453125\n",
      "Batch: 41, Loss: 1.2873187065124512, Accuracy: 0.591796875\n",
      "Batch: 42, Loss: 1.034928798675537, Accuracy: 0.6640625\n",
      "Batch: 43, Loss: 1.232550024986267, Accuracy: 0.5771484375\n",
      "Batch: 44, Loss: 1.2137541770935059, Accuracy: 0.6015625\n",
      "Batch: 45, Loss: 1.0588107109069824, Accuracy: 0.6513671875\n",
      "Batch: 46, Loss: 1.2291076183319092, Accuracy: 0.6181640625\n",
      "Batch: 47, Loss: 1.197538137435913, Accuracy: 0.6318359375\n",
      "Batch: 48, Loss: 1.186402440071106, Accuracy: 0.6357421875\n",
      "Batch: 49, Loss: 1.3627935647964478, Accuracy: 0.576171875\n",
      "Batch: 50, Loss: 1.3334474563598633, Accuracy: 0.578125\n",
      "Batch: 51, Loss: 1.3968743085861206, Accuracy: 0.5625\n",
      "Batch: 52, Loss: 1.3492236137390137, Accuracy: 0.6064453125\n",
      "Batch: 53, Loss: 1.145207166671753, Accuracy: 0.6396484375\n",
      "Batch: 54, Loss: 1.2234444618225098, Accuracy: 0.6328125\n",
      "Batch: 55, Loss: 1.2702107429504395, Accuracy: 0.5888671875\n",
      "Batch: 56, Loss: 1.2993195056915283, Accuracy: 0.5849609375\n",
      "Batch: 57, Loss: 1.2099123001098633, Accuracy: 0.6259765625\n",
      "Batch: 58, Loss: 1.3290486335754395, Accuracy: 0.607421875\n",
      "Batch: 59, Loss: 1.101503610610962, Accuracy: 0.66015625\n",
      "Batch: 60, Loss: 1.1091268062591553, Accuracy: 0.654296875\n",
      "Batch: 61, Loss: 1.2711033821105957, Accuracy: 0.5986328125\n",
      "Batch: 62, Loss: 1.2138371467590332, Accuracy: 0.6279296875\n",
      "Batch: 63, Loss: 1.222877860069275, Accuracy: 0.6083984375\n",
      "Batch: 64, Loss: 1.1881203651428223, Accuracy: 0.625\n",
      "Batch: 65, Loss: 1.2504284381866455, Accuracy: 0.60546875\n",
      "Batch: 66, Loss: 1.151768684387207, Accuracy: 0.6396484375\n",
      "Batch: 67, Loss: 1.3171907663345337, Accuracy: 0.5927734375\n",
      "Batch: 68, Loss: 1.2854806184768677, Accuracy: 0.6083984375\n",
      "Batch: 69, Loss: 1.234668493270874, Accuracy: 0.6025390625\n",
      "Batch: 70, Loss: 1.2315253019332886, Accuracy: 0.62890625\n",
      "Batch: 71, Loss: 1.2814815044403076, Accuracy: 0.5986328125\n",
      "Batch: 72, Loss: 1.1325793266296387, Accuracy: 0.640625\n",
      "Batch: 73, Loss: 1.201962947845459, Accuracy: 0.6376953125\n",
      "Batch: 74, Loss: 1.1278685331344604, Accuracy: 0.642578125\n",
      "Batch: 75, Loss: 1.117512583732605, Accuracy: 0.6416015625\n",
      "Batch: 76, Loss: 1.2643814086914062, Accuracy: 0.5830078125\n",
      "Batch: 77, Loss: 1.257678508758545, Accuracy: 0.5927734375\n",
      "Batch: 78, Loss: 1.1819801330566406, Accuracy: 0.642578125\n",
      "Batch: 79, Loss: 1.083737850189209, Accuracy: 0.6865234375\n",
      "Batch: 80, Loss: 1.1406636238098145, Accuracy: 0.6162109375\n",
      "Batch: 81, Loss: 1.3075478076934814, Accuracy: 0.546875\n",
      "Batch: 82, Loss: 1.252915620803833, Accuracy: 0.6064453125\n",
      "Batch: 83, Loss: 1.0998809337615967, Accuracy: 0.650390625\n",
      "Batch: 84, Loss: 1.1233725547790527, Accuracy: 0.6552734375\n",
      "Batch: 85, Loss: 1.0846858024597168, Accuracy: 0.662109375\n",
      "Batch: 86, Loss: 1.3608111143112183, Accuracy: 0.5771484375\n",
      "Batch: 87, Loss: 1.1524162292480469, Accuracy: 0.640625\n",
      "Batch: 88, Loss: 1.2902112007141113, Accuracy: 0.615234375\n",
      "Batch: 89, Loss: 1.2591723203659058, Accuracy: 0.609375\n",
      "Batch: 90, Loss: 1.1147737503051758, Accuracy: 0.6396484375\n",
      "Batch: 91, Loss: 1.1709016561508179, Accuracy: 0.6162109375\n",
      "Batch: 92, Loss: 1.2567946910858154, Accuracy: 0.6064453125\n",
      "Batch: 93, Loss: 1.149299144744873, Accuracy: 0.625\n",
      "Batch: 94, Loss: 1.174303650856018, Accuracy: 0.623046875\n",
      "Batch: 95, Loss: 1.211614727973938, Accuracy: 0.58984375\n",
      "Batch: 96, Loss: 1.2082934379577637, Accuracy: 0.6298828125\n",
      "Batch: 97, Loss: 1.0562691688537598, Accuracy: 0.662109375\n",
      "Batch: 98, Loss: 1.1072837114334106, Accuracy: 0.6552734375\n",
      "Batch: 99, Loss: 1.0895154476165771, Accuracy: 0.6630859375\n",
      "Batch: 100, Loss: 1.199310064315796, Accuracy: 0.6181640625\n",
      "Batch: 101, Loss: 1.2614983320236206, Accuracy: 0.5986328125\n",
      "Batch: 102, Loss: 1.1298654079437256, Accuracy: 0.6396484375\n",
      "Batch: 103, Loss: 1.2513145208358765, Accuracy: 0.615234375\n",
      "Batch: 104, Loss: 1.1078498363494873, Accuracy: 0.65234375\n",
      "Batch: 105, Loss: 1.2356972694396973, Accuracy: 0.599609375\n",
      "Batch: 106, Loss: 1.222485065460205, Accuracy: 0.607421875\n",
      "Batch: 107, Loss: 1.3419086933135986, Accuracy: 0.6015625\n",
      "Batch: 108, Loss: 1.3024755716323853, Accuracy: 0.5751953125\n",
      "Batch: 109, Loss: 1.379089593887329, Accuracy: 0.560546875\n",
      "Batch: 110, Loss: 1.0525211095809937, Accuracy: 0.6513671875\n",
      "Batch: 111, Loss: 1.2446815967559814, Accuracy: 0.572265625\n",
      "Batch: 112, Loss: 1.1967180967330933, Accuracy: 0.6171875\n",
      "Batch: 113, Loss: 1.2349021434783936, Accuracy: 0.6181640625\n",
      "Batch: 114, Loss: 1.3406696319580078, Accuracy: 0.5849609375\n",
      "Batch: 115, Loss: 1.3583450317382812, Accuracy: 0.5849609375\n",
      "Batch: 116, Loss: 1.281636118888855, Accuracy: 0.5732421875\n",
      "Batch: 117, Loss: 1.2819759845733643, Accuracy: 0.5908203125\n",
      "Batch: 118, Loss: 1.0735825300216675, Accuracy: 0.6513671875\n",
      "Batch: 119, Loss: 1.1496387720108032, Accuracy: 0.650390625\n",
      "Batch: 120, Loss: 1.2709529399871826, Accuracy: 0.5966796875\n",
      "Batch: 121, Loss: 1.3104255199432373, Accuracy: 0.58203125\n",
      "Batch: 122, Loss: 1.1694732904434204, Accuracy: 0.6318359375\n",
      "Batch: 123, Loss: 1.185845136642456, Accuracy: 0.62890625\n",
      "Batch: 124, Loss: 1.2351068258285522, Accuracy: 0.6123046875\n",
      "Batch: 125, Loss: 1.271097183227539, Accuracy: 0.5888671875\n",
      "Batch: 126, Loss: 1.229559063911438, Accuracy: 0.6015625\n",
      "Batch: 127, Loss: 1.1147301197052002, Accuracy: 0.6630859375\n",
      "Batch: 128, Loss: 1.3595795631408691, Accuracy: 0.5908203125\n",
      "Batch: 129, Loss: 1.163297414779663, Accuracy: 0.61328125\n",
      "Batch: 130, Loss: 1.4432129859924316, Accuracy: 0.5595703125\n",
      "Batch: 131, Loss: 1.2777248620986938, Accuracy: 0.59375\n",
      "Batch: 132, Loss: 1.3032505512237549, Accuracy: 0.5908203125\n",
      "Batch: 133, Loss: 1.149300456047058, Accuracy: 0.625\n",
      "Batch: 134, Loss: 1.1999459266662598, Accuracy: 0.595703125\n",
      "Batch: 135, Loss: 1.1410390138626099, Accuracy: 0.6474609375\n",
      "Batch: 136, Loss: 1.2060134410858154, Accuracy: 0.6220703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 137, Loss: 1.1483030319213867, Accuracy: 0.599609375\n",
      "Batch: 138, Loss: 1.0278444290161133, Accuracy: 0.65234375\n",
      "Batch: 139, Loss: 1.0497441291809082, Accuracy: 0.642578125\n",
      "Batch: 140, Loss: 1.2230162620544434, Accuracy: 0.6025390625\n",
      "Batch: 141, Loss: 1.2565529346466064, Accuracy: 0.591796875\n",
      "Batch: 142, Loss: 1.2482457160949707, Accuracy: 0.6044921875\n",
      "Batch: 143, Loss: 1.256117820739746, Accuracy: 0.595703125\n",
      "Batch: 144, Loss: 1.2045658826828003, Accuracy: 0.6064453125\n",
      "Batch: 145, Loss: 1.1476253271102905, Accuracy: 0.6142578125\n",
      "Batch: 146, Loss: 1.2923178672790527, Accuracy: 0.5712890625\n",
      "Batch: 147, Loss: 1.2246906757354736, Accuracy: 0.6025390625\n",
      "Batch: 148, Loss: 1.371938705444336, Accuracy: 0.5205078125\n",
      "Batch: 149, Loss: 1.250983476638794, Accuracy: 0.583984375\n",
      "Batch: 150, Loss: 1.1358898878097534, Accuracy: 0.6181640625\n",
      "Batch: 151, Loss: 1.082251787185669, Accuracy: 0.650390625\n",
      "Epoch 12/80\n",
      "Batch: 1, Loss: 1.4570939540863037, Accuracy: 0.5205078125\n",
      "Batch: 2, Loss: 1.223130464553833, Accuracy: 0.5810546875\n",
      "Batch: 3, Loss: 1.1511465311050415, Accuracy: 0.6181640625\n",
      "Batch: 4, Loss: 1.060516119003296, Accuracy: 0.6708984375\n",
      "Batch: 5, Loss: 1.111226201057434, Accuracy: 0.6298828125\n",
      "Batch: 6, Loss: 1.2236462831497192, Accuracy: 0.572265625\n",
      "Batch: 7, Loss: 1.1534343957901, Accuracy: 0.6181640625\n",
      "Batch: 8, Loss: 1.1090142726898193, Accuracy: 0.6318359375\n",
      "Batch: 9, Loss: 1.0622284412384033, Accuracy: 0.6640625\n",
      "Batch: 10, Loss: 1.1236392259597778, Accuracy: 0.619140625\n",
      "Batch: 11, Loss: 1.3164769411087036, Accuracy: 0.560546875\n",
      "Batch: 12, Loss: 1.2940163612365723, Accuracy: 0.5849609375\n",
      "Batch: 13, Loss: 1.0181336402893066, Accuracy: 0.6796875\n",
      "Batch: 14, Loss: 1.3214468955993652, Accuracy: 0.5703125\n",
      "Batch: 15, Loss: 1.140371322631836, Accuracy: 0.6337890625\n",
      "Batch: 16, Loss: 1.160524606704712, Accuracy: 0.619140625\n",
      "Batch: 17, Loss: 1.2254482507705688, Accuracy: 0.615234375\n",
      "Batch: 18, Loss: 1.2512853145599365, Accuracy: 0.6015625\n",
      "Batch: 19, Loss: 1.263267993927002, Accuracy: 0.591796875\n",
      "Batch: 20, Loss: 1.1664535999298096, Accuracy: 0.6494140625\n",
      "Batch: 21, Loss: 1.1440014839172363, Accuracy: 0.62890625\n",
      "Batch: 22, Loss: 1.255910873413086, Accuracy: 0.5986328125\n",
      "Batch: 23, Loss: 1.1841381788253784, Accuracy: 0.6123046875\n",
      "Batch: 24, Loss: 1.2038377523422241, Accuracy: 0.607421875\n",
      "Batch: 25, Loss: 1.2072043418884277, Accuracy: 0.61328125\n",
      "Batch: 26, Loss: 1.0953187942504883, Accuracy: 0.666015625\n",
      "Batch: 27, Loss: 1.146021842956543, Accuracy: 0.6201171875\n",
      "Batch: 28, Loss: 1.2278308868408203, Accuracy: 0.587890625\n",
      "Batch: 29, Loss: 1.2193909883499146, Accuracy: 0.6015625\n",
      "Batch: 30, Loss: 1.1194957494735718, Accuracy: 0.66015625\n",
      "Batch: 31, Loss: 1.1406844854354858, Accuracy: 0.646484375\n",
      "Batch: 32, Loss: 1.1136207580566406, Accuracy: 0.63671875\n",
      "Batch: 33, Loss: 1.3135981559753418, Accuracy: 0.5732421875\n",
      "Batch: 34, Loss: 1.3693784475326538, Accuracy: 0.5654296875\n",
      "Batch: 35, Loss: 1.2332853078842163, Accuracy: 0.5888671875\n",
      "Batch: 36, Loss: 1.2297632694244385, Accuracy: 0.611328125\n",
      "Batch: 37, Loss: 1.2330260276794434, Accuracy: 0.6025390625\n",
      "Batch: 38, Loss: 1.225034236907959, Accuracy: 0.5888671875\n",
      "Batch: 39, Loss: 1.261357069015503, Accuracy: 0.6181640625\n",
      "Batch: 40, Loss: 1.22709059715271, Accuracy: 0.62109375\n",
      "Batch: 41, Loss: 1.2514362335205078, Accuracy: 0.6142578125\n",
      "Batch: 42, Loss: 1.016239881515503, Accuracy: 0.671875\n",
      "Batch: 43, Loss: 1.218780755996704, Accuracy: 0.5791015625\n",
      "Batch: 44, Loss: 1.1935193538665771, Accuracy: 0.5869140625\n",
      "Batch: 45, Loss: 1.0434157848358154, Accuracy: 0.6396484375\n",
      "Batch: 46, Loss: 1.1792957782745361, Accuracy: 0.62890625\n",
      "Batch: 47, Loss: 1.193770408630371, Accuracy: 0.625\n",
      "Batch: 48, Loss: 1.1330747604370117, Accuracy: 0.63671875\n",
      "Batch: 49, Loss: 1.3237793445587158, Accuracy: 0.5869140625\n",
      "Batch: 50, Loss: 1.2905722856521606, Accuracy: 0.5927734375\n",
      "Batch: 51, Loss: 1.3404853343963623, Accuracy: 0.5791015625\n",
      "Batch: 52, Loss: 1.3056446313858032, Accuracy: 0.587890625\n",
      "Batch: 53, Loss: 1.0896354913711548, Accuracy: 0.6552734375\n",
      "Batch: 54, Loss: 1.207538366317749, Accuracy: 0.62890625\n",
      "Batch: 55, Loss: 1.2271413803100586, Accuracy: 0.599609375\n",
      "Batch: 56, Loss: 1.2638691663742065, Accuracy: 0.59375\n",
      "Batch: 57, Loss: 1.1628966331481934, Accuracy: 0.6455078125\n",
      "Batch: 58, Loss: 1.2875375747680664, Accuracy: 0.61328125\n",
      "Batch: 59, Loss: 1.0861485004425049, Accuracy: 0.66796875\n",
      "Batch: 60, Loss: 1.087034821510315, Accuracy: 0.6669921875\n",
      "Batch: 61, Loss: 1.2459312677383423, Accuracy: 0.615234375\n",
      "Batch: 62, Loss: 1.2079201936721802, Accuracy: 0.6201171875\n",
      "Batch: 63, Loss: 1.216883897781372, Accuracy: 0.6142578125\n",
      "Batch: 64, Loss: 1.1800236701965332, Accuracy: 0.62109375\n",
      "Batch: 65, Loss: 1.2225980758666992, Accuracy: 0.61328125\n",
      "Batch: 66, Loss: 1.130718469619751, Accuracy: 0.6279296875\n",
      "Batch: 67, Loss: 1.3043625354766846, Accuracy: 0.6015625\n",
      "Batch: 68, Loss: 1.2585363388061523, Accuracy: 0.619140625\n",
      "Batch: 69, Loss: 1.2061519622802734, Accuracy: 0.619140625\n",
      "Batch: 70, Loss: 1.2058194875717163, Accuracy: 0.6376953125\n",
      "Batch: 71, Loss: 1.2315278053283691, Accuracy: 0.6259765625\n",
      "Batch: 72, Loss: 1.0960581302642822, Accuracy: 0.6513671875\n",
      "Batch: 73, Loss: 1.171123743057251, Accuracy: 0.6328125\n",
      "Batch: 74, Loss: 1.1369984149932861, Accuracy: 0.63671875\n",
      "Batch: 75, Loss: 1.0923906564712524, Accuracy: 0.6533203125\n",
      "Batch: 76, Loss: 1.2156317234039307, Accuracy: 0.5947265625\n",
      "Batch: 77, Loss: 1.218289852142334, Accuracy: 0.61328125\n",
      "Batch: 78, Loss: 1.1674768924713135, Accuracy: 0.640625\n",
      "Batch: 79, Loss: 1.0607669353485107, Accuracy: 0.6826171875\n",
      "Batch: 80, Loss: 1.110791802406311, Accuracy: 0.6162109375\n",
      "Batch: 81, Loss: 1.2634706497192383, Accuracy: 0.560546875\n",
      "Batch: 82, Loss: 1.2012470960617065, Accuracy: 0.60546875\n",
      "Batch: 83, Loss: 1.087483525276184, Accuracy: 0.642578125\n",
      "Batch: 84, Loss: 1.1277120113372803, Accuracy: 0.654296875\n",
      "Batch: 85, Loss: 1.0589239597320557, Accuracy: 0.6640625\n",
      "Batch: 86, Loss: 1.3453655242919922, Accuracy: 0.583984375\n",
      "Batch: 87, Loss: 1.1175814867019653, Accuracy: 0.6552734375\n",
      "Batch: 88, Loss: 1.2260451316833496, Accuracy: 0.6279296875\n",
      "Batch: 89, Loss: 1.2411810159683228, Accuracy: 0.6162109375\n",
      "Batch: 90, Loss: 1.1018617153167725, Accuracy: 0.6513671875\n",
      "Batch: 91, Loss: 1.1569442749023438, Accuracy: 0.634765625\n",
      "Batch: 92, Loss: 1.2078337669372559, Accuracy: 0.6240234375\n",
      "Batch: 93, Loss: 1.1274663209915161, Accuracy: 0.6455078125\n",
      "Batch: 94, Loss: 1.1423828601837158, Accuracy: 0.642578125\n",
      "Batch: 95, Loss: 1.1911993026733398, Accuracy: 0.5947265625\n",
      "Batch: 96, Loss: 1.178769588470459, Accuracy: 0.615234375\n",
      "Batch: 97, Loss: 1.0227534770965576, Accuracy: 0.6728515625\n",
      "Batch: 98, Loss: 1.065546989440918, Accuracy: 0.673828125\n",
      "Batch: 99, Loss: 1.0538966655731201, Accuracy: 0.6591796875\n",
      "Batch: 100, Loss: 1.151796579360962, Accuracy: 0.6376953125\n",
      "Batch: 101, Loss: 1.2365567684173584, Accuracy: 0.611328125\n",
      "Batch: 102, Loss: 1.119301199913025, Accuracy: 0.63671875\n",
      "Batch: 103, Loss: 1.21234130859375, Accuracy: 0.640625\n",
      "Batch: 104, Loss: 1.0888429880142212, Accuracy: 0.638671875\n",
      "Batch: 105, Loss: 1.2134180068969727, Accuracy: 0.6103515625\n",
      "Batch: 106, Loss: 1.1999582052230835, Accuracy: 0.6142578125\n",
      "Batch: 107, Loss: 1.31393301486969, Accuracy: 0.599609375\n",
      "Batch: 108, Loss: 1.255188226699829, Accuracy: 0.5810546875\n",
      "Batch: 109, Loss: 1.3479117155075073, Accuracy: 0.57421875\n",
      "Batch: 110, Loss: 1.024674654006958, Accuracy: 0.6689453125\n",
      "Batch: 111, Loss: 1.198694109916687, Accuracy: 0.6025390625\n",
      "Batch: 112, Loss: 1.1667087078094482, Accuracy: 0.6396484375\n",
      "Batch: 113, Loss: 1.1869254112243652, Accuracy: 0.6298828125\n",
      "Batch: 114, Loss: 1.3259708881378174, Accuracy: 0.5712890625\n",
      "Batch: 115, Loss: 1.3455479145050049, Accuracy: 0.5830078125\n",
      "Batch: 116, Loss: 1.2417004108428955, Accuracy: 0.6064453125\n",
      "Batch: 117, Loss: 1.2818474769592285, Accuracy: 0.603515625\n",
      "Batch: 118, Loss: 1.0576956272125244, Accuracy: 0.662109375\n",
      "Batch: 119, Loss: 1.1098352670669556, Accuracy: 0.6669921875\n",
      "Batch: 120, Loss: 1.2368028163909912, Accuracy: 0.599609375\n",
      "Batch: 121, Loss: 1.2762422561645508, Accuracy: 0.6015625\n",
      "Batch: 122, Loss: 1.1374143362045288, Accuracy: 0.634765625\n",
      "Batch: 123, Loss: 1.142284870147705, Accuracy: 0.6455078125\n",
      "Batch: 124, Loss: 1.1806023120880127, Accuracy: 0.6376953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 125, Loss: 1.2463425397872925, Accuracy: 0.599609375\n",
      "Batch: 126, Loss: 1.1966540813446045, Accuracy: 0.6005859375\n",
      "Batch: 127, Loss: 1.095402717590332, Accuracy: 0.66015625\n",
      "Batch: 128, Loss: 1.348340392112732, Accuracy: 0.60546875\n",
      "Batch: 129, Loss: 1.167367935180664, Accuracy: 0.6123046875\n",
      "Batch: 130, Loss: 1.410807490348816, Accuracy: 0.5654296875\n",
      "Batch: 131, Loss: 1.2471842765808105, Accuracy: 0.5966796875\n",
      "Batch: 132, Loss: 1.2620041370391846, Accuracy: 0.599609375\n",
      "Batch: 133, Loss: 1.1120152473449707, Accuracy: 0.626953125\n",
      "Batch: 134, Loss: 1.1684131622314453, Accuracy: 0.6171875\n",
      "Batch: 135, Loss: 1.1135361194610596, Accuracy: 0.642578125\n",
      "Batch: 136, Loss: 1.1763081550598145, Accuracy: 0.6240234375\n",
      "Batch: 137, Loss: 1.099885106086731, Accuracy: 0.61328125\n",
      "Batch: 138, Loss: 0.999506950378418, Accuracy: 0.6611328125\n",
      "Batch: 139, Loss: 1.052231788635254, Accuracy: 0.650390625\n",
      "Batch: 140, Loss: 1.1907621622085571, Accuracy: 0.599609375\n",
      "Batch: 141, Loss: 1.2140390872955322, Accuracy: 0.626953125\n",
      "Batch: 142, Loss: 1.209220290184021, Accuracy: 0.61328125\n",
      "Batch: 143, Loss: 1.2224757671356201, Accuracy: 0.5986328125\n",
      "Batch: 144, Loss: 1.18174409866333, Accuracy: 0.611328125\n",
      "Batch: 145, Loss: 1.1099271774291992, Accuracy: 0.6240234375\n",
      "Batch: 146, Loss: 1.2598342895507812, Accuracy: 0.568359375\n",
      "Batch: 147, Loss: 1.2129491567611694, Accuracy: 0.5986328125\n",
      "Batch: 148, Loss: 1.3693772554397583, Accuracy: 0.55078125\n",
      "Batch: 149, Loss: 1.202345848083496, Accuracy: 0.6142578125\n",
      "Batch: 150, Loss: 1.1312377452850342, Accuracy: 0.6318359375\n",
      "Batch: 151, Loss: 1.055321455001831, Accuracy: 0.6708984375\n",
      "Epoch 13/80\n",
      "Batch: 1, Loss: 1.419559359550476, Accuracy: 0.541015625\n",
      "Batch: 2, Loss: 1.193831443786621, Accuracy: 0.5966796875\n",
      "Batch: 3, Loss: 1.108303189277649, Accuracy: 0.6376953125\n",
      "Batch: 4, Loss: 1.0597882270812988, Accuracy: 0.6689453125\n",
      "Batch: 5, Loss: 1.0804615020751953, Accuracy: 0.6474609375\n",
      "Batch: 6, Loss: 1.1721473932266235, Accuracy: 0.5908203125\n",
      "Batch: 7, Loss: 1.128539800643921, Accuracy: 0.607421875\n",
      "Batch: 8, Loss: 1.0803437232971191, Accuracy: 0.6416015625\n",
      "Batch: 9, Loss: 1.032847285270691, Accuracy: 0.6640625\n",
      "Batch: 10, Loss: 1.1020829677581787, Accuracy: 0.6484375\n",
      "Batch: 11, Loss: 1.257520079612732, Accuracy: 0.5703125\n",
      "Batch: 12, Loss: 1.2696901559829712, Accuracy: 0.5849609375\n",
      "Batch: 13, Loss: 0.9945698976516724, Accuracy: 0.681640625\n",
      "Batch: 14, Loss: 1.2833797931671143, Accuracy: 0.591796875\n",
      "Batch: 15, Loss: 1.099792718887329, Accuracy: 0.6728515625\n",
      "Batch: 16, Loss: 1.1124131679534912, Accuracy: 0.6533203125\n",
      "Batch: 17, Loss: 1.2201120853424072, Accuracy: 0.603515625\n",
      "Batch: 18, Loss: 1.2097113132476807, Accuracy: 0.62109375\n",
      "Batch: 19, Loss: 1.2456239461898804, Accuracy: 0.6083984375\n",
      "Batch: 20, Loss: 1.1512519121170044, Accuracy: 0.658203125\n",
      "Batch: 21, Loss: 1.1009938716888428, Accuracy: 0.650390625\n",
      "Batch: 22, Loss: 1.2314918041229248, Accuracy: 0.609375\n",
      "Batch: 23, Loss: 1.1659882068634033, Accuracy: 0.611328125\n",
      "Batch: 24, Loss: 1.1654317378997803, Accuracy: 0.619140625\n",
      "Batch: 25, Loss: 1.1534302234649658, Accuracy: 0.6162109375\n",
      "Batch: 26, Loss: 1.0609699487686157, Accuracy: 0.66015625\n",
      "Batch: 27, Loss: 1.1330680847167969, Accuracy: 0.62109375\n",
      "Batch: 28, Loss: 1.2119543552398682, Accuracy: 0.58984375\n",
      "Batch: 29, Loss: 1.1822131872177124, Accuracy: 0.611328125\n",
      "Batch: 30, Loss: 1.1218031644821167, Accuracy: 0.65234375\n",
      "Batch: 31, Loss: 1.121814489364624, Accuracy: 0.6533203125\n",
      "Batch: 32, Loss: 1.090536117553711, Accuracy: 0.6318359375\n",
      "Batch: 33, Loss: 1.2766447067260742, Accuracy: 0.5849609375\n",
      "Batch: 34, Loss: 1.3259598016738892, Accuracy: 0.578125\n",
      "Batch: 35, Loss: 1.2244601249694824, Accuracy: 0.5927734375\n",
      "Batch: 36, Loss: 1.203437328338623, Accuracy: 0.6318359375\n",
      "Batch: 37, Loss: 1.2080693244934082, Accuracy: 0.623046875\n",
      "Batch: 38, Loss: 1.1867101192474365, Accuracy: 0.6083984375\n",
      "Batch: 39, Loss: 1.2162216901779175, Accuracy: 0.623046875\n",
      "Batch: 40, Loss: 1.2403342723846436, Accuracy: 0.607421875\n",
      "Batch: 41, Loss: 1.2135462760925293, Accuracy: 0.638671875\n",
      "Batch: 42, Loss: 0.9806339740753174, Accuracy: 0.6630859375\n",
      "Batch: 43, Loss: 1.1997857093811035, Accuracy: 0.58984375\n",
      "Batch: 44, Loss: 1.1882400512695312, Accuracy: 0.59765625\n",
      "Batch: 45, Loss: 1.0306894779205322, Accuracy: 0.650390625\n",
      "Batch: 46, Loss: 1.1657335758209229, Accuracy: 0.62109375\n",
      "Batch: 47, Loss: 1.153564214706421, Accuracy: 0.62109375\n",
      "Batch: 48, Loss: 1.1336233615875244, Accuracy: 0.6435546875\n",
      "Batch: 49, Loss: 1.3282549381256104, Accuracy: 0.5751953125\n",
      "Batch: 50, Loss: 1.278319239616394, Accuracy: 0.5791015625\n",
      "Batch: 51, Loss: 1.3466742038726807, Accuracy: 0.5732421875\n",
      "Batch: 52, Loss: 1.2661199569702148, Accuracy: 0.623046875\n",
      "Batch: 53, Loss: 1.0791451930999756, Accuracy: 0.650390625\n",
      "Batch: 54, Loss: 1.1688621044158936, Accuracy: 0.6318359375\n",
      "Batch: 55, Loss: 1.2134146690368652, Accuracy: 0.59375\n",
      "Batch: 56, Loss: 1.2247965335845947, Accuracy: 0.609375\n",
      "Batch: 57, Loss: 1.1714661121368408, Accuracy: 0.64453125\n",
      "Batch: 58, Loss: 1.2707217931747437, Accuracy: 0.6181640625\n",
      "Batch: 59, Loss: 1.0621343851089478, Accuracy: 0.6728515625\n",
      "Batch: 60, Loss: 1.0518053770065308, Accuracy: 0.6650390625\n",
      "Batch: 61, Loss: 1.2277116775512695, Accuracy: 0.6259765625\n",
      "Batch: 62, Loss: 1.178456425666809, Accuracy: 0.6298828125\n",
      "Batch: 63, Loss: 1.1812806129455566, Accuracy: 0.623046875\n",
      "Batch: 64, Loss: 1.1370079517364502, Accuracy: 0.6337890625\n",
      "Batch: 65, Loss: 1.1839311122894287, Accuracy: 0.615234375\n",
      "Batch: 66, Loss: 1.1180031299591064, Accuracy: 0.6484375\n",
      "Batch: 67, Loss: 1.2508991956710815, Accuracy: 0.61328125\n",
      "Batch: 68, Loss: 1.2637319564819336, Accuracy: 0.611328125\n",
      "Batch: 69, Loss: 1.1953201293945312, Accuracy: 0.62109375\n",
      "Batch: 70, Loss: 1.1807491779327393, Accuracy: 0.6337890625\n",
      "Batch: 71, Loss: 1.2121211290359497, Accuracy: 0.623046875\n",
      "Batch: 72, Loss: 1.0876367092132568, Accuracy: 0.6591796875\n",
      "Batch: 73, Loss: 1.1223645210266113, Accuracy: 0.6630859375\n",
      "Batch: 74, Loss: 1.1046040058135986, Accuracy: 0.6484375\n",
      "Batch: 75, Loss: 1.073265552520752, Accuracy: 0.642578125\n",
      "Batch: 76, Loss: 1.1995608806610107, Accuracy: 0.6064453125\n",
      "Batch: 77, Loss: 1.209362268447876, Accuracy: 0.6015625\n",
      "Batch: 78, Loss: 1.148095726966858, Accuracy: 0.6484375\n",
      "Batch: 79, Loss: 1.0426318645477295, Accuracy: 0.6845703125\n",
      "Batch: 80, Loss: 1.073254108428955, Accuracy: 0.6220703125\n",
      "Batch: 81, Loss: 1.233418345451355, Accuracy: 0.578125\n",
      "Batch: 82, Loss: 1.198936939239502, Accuracy: 0.6123046875\n",
      "Batch: 83, Loss: 1.0393468141555786, Accuracy: 0.6689453125\n",
      "Batch: 84, Loss: 1.1222801208496094, Accuracy: 0.6708984375\n",
      "Batch: 85, Loss: 1.0383543968200684, Accuracy: 0.6787109375\n",
      "Batch: 86, Loss: 1.3190221786499023, Accuracy: 0.578125\n",
      "Batch: 87, Loss: 1.0951800346374512, Accuracy: 0.65234375\n",
      "Batch: 88, Loss: 1.2356364727020264, Accuracy: 0.611328125\n",
      "Batch: 89, Loss: 1.2021477222442627, Accuracy: 0.623046875\n",
      "Batch: 90, Loss: 1.0817430019378662, Accuracy: 0.6591796875\n",
      "Batch: 91, Loss: 1.138597011566162, Accuracy: 0.630859375\n",
      "Batch: 92, Loss: 1.2031700611114502, Accuracy: 0.619140625\n",
      "Batch: 93, Loss: 1.115257740020752, Accuracy: 0.6474609375\n",
      "Batch: 94, Loss: 1.1261544227600098, Accuracy: 0.623046875\n",
      "Batch: 95, Loss: 1.162184476852417, Accuracy: 0.5986328125\n",
      "Batch: 96, Loss: 1.1453399658203125, Accuracy: 0.6416015625\n",
      "Batch: 97, Loss: 1.0006442070007324, Accuracy: 0.6826171875\n",
      "Batch: 98, Loss: 1.0490520000457764, Accuracy: 0.6728515625\n",
      "Batch: 99, Loss: 1.0303845405578613, Accuracy: 0.666015625\n",
      "Batch: 100, Loss: 1.1368634700775146, Accuracy: 0.642578125\n",
      "Batch: 101, Loss: 1.202606201171875, Accuracy: 0.615234375\n",
      "Batch: 102, Loss: 1.0902454853057861, Accuracy: 0.642578125\n",
      "Batch: 103, Loss: 1.2065792083740234, Accuracy: 0.625\n",
      "Batch: 104, Loss: 1.0645456314086914, Accuracy: 0.658203125\n",
      "Batch: 105, Loss: 1.202972412109375, Accuracy: 0.6142578125\n",
      "Batch: 106, Loss: 1.1482784748077393, Accuracy: 0.6328125\n",
      "Batch: 107, Loss: 1.2648024559020996, Accuracy: 0.6220703125\n",
      "Batch: 108, Loss: 1.2345519065856934, Accuracy: 0.591796875\n",
      "Batch: 109, Loss: 1.3177921772003174, Accuracy: 0.5732421875\n",
      "Batch: 110, Loss: 1.0004169940948486, Accuracy: 0.6708984375\n",
      "Batch: 111, Loss: 1.1838067770004272, Accuracy: 0.6103515625\n",
      "Batch: 112, Loss: 1.1610374450683594, Accuracy: 0.634765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 113, Loss: 1.1655285358428955, Accuracy: 0.6259765625\n",
      "Batch: 114, Loss: 1.2845628261566162, Accuracy: 0.5888671875\n",
      "Batch: 115, Loss: 1.3486909866333008, Accuracy: 0.5947265625\n",
      "Batch: 116, Loss: 1.220632791519165, Accuracy: 0.6044921875\n",
      "Batch: 117, Loss: 1.2551655769348145, Accuracy: 0.6103515625\n",
      "Batch: 118, Loss: 1.0245733261108398, Accuracy: 0.6728515625\n",
      "Batch: 119, Loss: 1.1062917709350586, Accuracy: 0.6669921875\n",
      "Batch: 120, Loss: 1.222010612487793, Accuracy: 0.6201171875\n",
      "Batch: 121, Loss: 1.2532109022140503, Accuracy: 0.599609375\n",
      "Batch: 122, Loss: 1.1186076402664185, Accuracy: 0.6474609375\n",
      "Batch: 123, Loss: 1.1372978687286377, Accuracy: 0.638671875\n",
      "Batch: 124, Loss: 1.1833009719848633, Accuracy: 0.61328125\n",
      "Batch: 125, Loss: 1.222123622894287, Accuracy: 0.609375\n",
      "Batch: 126, Loss: 1.2143100500106812, Accuracy: 0.5966796875\n",
      "Batch: 127, Loss: 1.0744428634643555, Accuracy: 0.6640625\n",
      "Batch: 128, Loss: 1.3189959526062012, Accuracy: 0.5986328125\n",
      "Batch: 129, Loss: 1.1193060874938965, Accuracy: 0.640625\n",
      "Batch: 130, Loss: 1.3884309530258179, Accuracy: 0.564453125\n",
      "Batch: 131, Loss: 1.214003562927246, Accuracy: 0.611328125\n",
      "Batch: 132, Loss: 1.244154453277588, Accuracy: 0.6181640625\n",
      "Batch: 133, Loss: 1.0810294151306152, Accuracy: 0.63671875\n",
      "Batch: 134, Loss: 1.1528633832931519, Accuracy: 0.619140625\n",
      "Batch: 135, Loss: 1.0823180675506592, Accuracy: 0.6513671875\n",
      "Batch: 136, Loss: 1.160811185836792, Accuracy: 0.6220703125\n",
      "Batch: 137, Loss: 1.0951886177062988, Accuracy: 0.6181640625\n",
      "Batch: 138, Loss: 0.9836529493331909, Accuracy: 0.6708984375\n",
      "Batch: 139, Loss: 1.0480295419692993, Accuracy: 0.642578125\n",
      "Batch: 140, Loss: 1.1683681011199951, Accuracy: 0.6025390625\n",
      "Batch: 141, Loss: 1.1851692199707031, Accuracy: 0.6201171875\n",
      "Batch: 142, Loss: 1.2012887001037598, Accuracy: 0.6015625\n",
      "Batch: 143, Loss: 1.2155859470367432, Accuracy: 0.6025390625\n",
      "Batch: 144, Loss: 1.1357393264770508, Accuracy: 0.63671875\n",
      "Batch: 145, Loss: 1.1244688034057617, Accuracy: 0.6103515625\n",
      "Batch: 146, Loss: 1.2486028671264648, Accuracy: 0.59765625\n",
      "Batch: 147, Loss: 1.1912641525268555, Accuracy: 0.6142578125\n",
      "Batch: 148, Loss: 1.3161717653274536, Accuracy: 0.5556640625\n",
      "Batch: 149, Loss: 1.183720588684082, Accuracy: 0.609375\n",
      "Batch: 150, Loss: 1.1191976070404053, Accuracy: 0.6328125\n",
      "Batch: 151, Loss: 1.0375034809112549, Accuracy: 0.673828125\n",
      "Epoch 14/80\n",
      "Batch: 1, Loss: 1.3837677240371704, Accuracy: 0.548828125\n",
      "Batch: 2, Loss: 1.193065881729126, Accuracy: 0.580078125\n",
      "Batch: 3, Loss: 1.093703031539917, Accuracy: 0.6240234375\n",
      "Batch: 4, Loss: 1.0067477226257324, Accuracy: 0.6904296875\n",
      "Batch: 5, Loss: 1.0958690643310547, Accuracy: 0.64453125\n",
      "Batch: 6, Loss: 1.1726709604263306, Accuracy: 0.5966796875\n",
      "Batch: 7, Loss: 1.1188111305236816, Accuracy: 0.619140625\n",
      "Batch: 8, Loss: 1.0713410377502441, Accuracy: 0.6455078125\n",
      "Batch: 9, Loss: 1.0237164497375488, Accuracy: 0.6708984375\n",
      "Batch: 10, Loss: 1.0588195323944092, Accuracy: 0.654296875\n",
      "Batch: 11, Loss: 1.2423005104064941, Accuracy: 0.5810546875\n",
      "Batch: 12, Loss: 1.2218749523162842, Accuracy: 0.5859375\n",
      "Batch: 13, Loss: 0.9745041728019714, Accuracy: 0.677734375\n",
      "Batch: 14, Loss: 1.24161696434021, Accuracy: 0.5966796875\n",
      "Batch: 15, Loss: 1.0659663677215576, Accuracy: 0.66015625\n",
      "Batch: 16, Loss: 1.0830426216125488, Accuracy: 0.654296875\n",
      "Batch: 17, Loss: 1.1875293254852295, Accuracy: 0.6044921875\n",
      "Batch: 18, Loss: 1.2045142650604248, Accuracy: 0.619140625\n",
      "Batch: 19, Loss: 1.223628282546997, Accuracy: 0.6142578125\n",
      "Batch: 20, Loss: 1.1074519157409668, Accuracy: 0.6669921875\n",
      "Batch: 21, Loss: 1.066227674484253, Accuracy: 0.650390625\n",
      "Batch: 22, Loss: 1.2057099342346191, Accuracy: 0.623046875\n",
      "Batch: 23, Loss: 1.1352412700653076, Accuracy: 0.630859375\n",
      "Batch: 24, Loss: 1.1554834842681885, Accuracy: 0.6171875\n",
      "Batch: 25, Loss: 1.1468172073364258, Accuracy: 0.6279296875\n",
      "Batch: 26, Loss: 1.0438294410705566, Accuracy: 0.6572265625\n",
      "Batch: 27, Loss: 1.0990922451019287, Accuracy: 0.625\n",
      "Batch: 28, Loss: 1.1830116510391235, Accuracy: 0.6103515625\n",
      "Batch: 29, Loss: 1.1428191661834717, Accuracy: 0.6201171875\n",
      "Batch: 30, Loss: 1.0653903484344482, Accuracy: 0.6748046875\n",
      "Batch: 31, Loss: 1.1240640878677368, Accuracy: 0.6435546875\n",
      "Batch: 32, Loss: 1.050537109375, Accuracy: 0.6494140625\n",
      "Batch: 33, Loss: 1.2738434076309204, Accuracy: 0.583984375\n",
      "Batch: 34, Loss: 1.3311158418655396, Accuracy: 0.58203125\n",
      "Batch: 35, Loss: 1.2048530578613281, Accuracy: 0.609375\n",
      "Batch: 36, Loss: 1.158378005027771, Accuracy: 0.630859375\n",
      "Batch: 37, Loss: 1.1629081964492798, Accuracy: 0.6328125\n",
      "Batch: 38, Loss: 1.1730016469955444, Accuracy: 0.623046875\n",
      "Batch: 39, Loss: 1.2103471755981445, Accuracy: 0.6279296875\n",
      "Batch: 40, Loss: 1.2087039947509766, Accuracy: 0.6328125\n",
      "Batch: 41, Loss: 1.1899023056030273, Accuracy: 0.6181640625\n",
      "Batch: 42, Loss: 0.9576143026351929, Accuracy: 0.6806640625\n",
      "Batch: 43, Loss: 1.1820181608200073, Accuracy: 0.5888671875\n",
      "Batch: 44, Loss: 1.161245346069336, Accuracy: 0.6123046875\n",
      "Batch: 45, Loss: 1.0138787031173706, Accuracy: 0.65625\n",
      "Batch: 46, Loss: 1.1257367134094238, Accuracy: 0.6572265625\n",
      "Batch: 47, Loss: 1.1168482303619385, Accuracy: 0.6552734375\n",
      "Batch: 48, Loss: 1.083929181098938, Accuracy: 0.6484375\n",
      "Batch: 49, Loss: 1.3128058910369873, Accuracy: 0.58203125\n",
      "Batch: 50, Loss: 1.2563493251800537, Accuracy: 0.58984375\n",
      "Batch: 51, Loss: 1.3175129890441895, Accuracy: 0.5751953125\n",
      "Batch: 52, Loss: 1.2719433307647705, Accuracy: 0.6083984375\n",
      "Batch: 53, Loss: 1.0710766315460205, Accuracy: 0.66796875\n",
      "Batch: 54, Loss: 1.161799669265747, Accuracy: 0.6455078125\n",
      "Batch: 55, Loss: 1.195716381072998, Accuracy: 0.6044921875\n",
      "Batch: 56, Loss: 1.2157845497131348, Accuracy: 0.623046875\n",
      "Batch: 57, Loss: 1.1451442241668701, Accuracy: 0.6328125\n",
      "Batch: 58, Loss: 1.2477025985717773, Accuracy: 0.625\n",
      "Batch: 59, Loss: 1.0399398803710938, Accuracy: 0.6767578125\n",
      "Batch: 60, Loss: 1.0369820594787598, Accuracy: 0.666015625\n",
      "Batch: 61, Loss: 1.1925313472747803, Accuracy: 0.6142578125\n",
      "Batch: 62, Loss: 1.1564304828643799, Accuracy: 0.6376953125\n",
      "Batch: 63, Loss: 1.1622296571731567, Accuracy: 0.623046875\n",
      "Batch: 64, Loss: 1.1440200805664062, Accuracy: 0.6337890625\n",
      "Batch: 65, Loss: 1.1776857376098633, Accuracy: 0.625\n",
      "Batch: 66, Loss: 1.099611759185791, Accuracy: 0.6396484375\n",
      "Batch: 67, Loss: 1.2470675706863403, Accuracy: 0.6142578125\n",
      "Batch: 68, Loss: 1.2380262613296509, Accuracy: 0.6201171875\n",
      "Batch: 69, Loss: 1.1532646417617798, Accuracy: 0.638671875\n",
      "Batch: 70, Loss: 1.129690170288086, Accuracy: 0.6572265625\n",
      "Batch: 71, Loss: 1.1878920793533325, Accuracy: 0.619140625\n",
      "Batch: 72, Loss: 1.0597175359725952, Accuracy: 0.65625\n",
      "Batch: 73, Loss: 1.141921043395996, Accuracy: 0.64453125\n",
      "Batch: 74, Loss: 1.0734869241714478, Accuracy: 0.6533203125\n",
      "Batch: 75, Loss: 1.0452401638031006, Accuracy: 0.662109375\n",
      "Batch: 76, Loss: 1.1715588569641113, Accuracy: 0.6083984375\n",
      "Batch: 77, Loss: 1.1714365482330322, Accuracy: 0.609375\n",
      "Batch: 78, Loss: 1.1174578666687012, Accuracy: 0.6435546875\n",
      "Batch: 79, Loss: 1.0085742473602295, Accuracy: 0.703125\n",
      "Batch: 80, Loss: 1.0678718090057373, Accuracy: 0.6328125\n",
      "Batch: 81, Loss: 1.2239540815353394, Accuracy: 0.578125\n",
      "Batch: 82, Loss: 1.1796045303344727, Accuracy: 0.611328125\n",
      "Batch: 83, Loss: 1.0151948928833008, Accuracy: 0.6748046875\n",
      "Batch: 84, Loss: 1.093226432800293, Accuracy: 0.6708984375\n",
      "Batch: 85, Loss: 1.040387511253357, Accuracy: 0.669921875\n",
      "Batch: 86, Loss: 1.2931510210037231, Accuracy: 0.5947265625\n",
      "Batch: 87, Loss: 1.079208493232727, Accuracy: 0.6572265625\n",
      "Batch: 88, Loss: 1.2152031660079956, Accuracy: 0.6240234375\n",
      "Batch: 89, Loss: 1.2014930248260498, Accuracy: 0.6162109375\n",
      "Batch: 90, Loss: 1.076077938079834, Accuracy: 0.642578125\n",
      "Batch: 91, Loss: 1.121281623840332, Accuracy: 0.6474609375\n",
      "Batch: 92, Loss: 1.1712671518325806, Accuracy: 0.6220703125\n",
      "Batch: 93, Loss: 1.1014384031295776, Accuracy: 0.638671875\n",
      "Batch: 94, Loss: 1.0926021337509155, Accuracy: 0.62890625\n",
      "Batch: 95, Loss: 1.1565780639648438, Accuracy: 0.603515625\n",
      "Batch: 96, Loss: 1.1330146789550781, Accuracy: 0.6357421875\n",
      "Batch: 97, Loss: 0.9948924779891968, Accuracy: 0.6806640625\n",
      "Batch: 98, Loss: 1.0312583446502686, Accuracy: 0.6767578125\n",
      "Batch: 99, Loss: 1.0386011600494385, Accuracy: 0.654296875\n",
      "Batch: 100, Loss: 1.1226526498794556, Accuracy: 0.640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 101, Loss: 1.1697287559509277, Accuracy: 0.6171875\n",
      "Batch: 102, Loss: 1.0893504619598389, Accuracy: 0.6416015625\n",
      "Batch: 103, Loss: 1.1879425048828125, Accuracy: 0.6376953125\n",
      "Batch: 104, Loss: 1.0561494827270508, Accuracy: 0.654296875\n",
      "Batch: 105, Loss: 1.1800094842910767, Accuracy: 0.5986328125\n",
      "Batch: 106, Loss: 1.1434481143951416, Accuracy: 0.6357421875\n",
      "Batch: 107, Loss: 1.25714910030365, Accuracy: 0.6123046875\n",
      "Batch: 108, Loss: 1.2105063199996948, Accuracy: 0.5966796875\n",
      "Batch: 109, Loss: 1.3028088808059692, Accuracy: 0.5712890625\n",
      "Batch: 110, Loss: 0.9954455494880676, Accuracy: 0.6572265625\n",
      "Batch: 111, Loss: 1.1779792308807373, Accuracy: 0.5947265625\n",
      "Batch: 112, Loss: 1.1297240257263184, Accuracy: 0.6376953125\n",
      "Batch: 113, Loss: 1.1407262086868286, Accuracy: 0.6455078125\n",
      "Batch: 114, Loss: 1.2775444984436035, Accuracy: 0.59765625\n",
      "Batch: 115, Loss: 1.2869211435317993, Accuracy: 0.599609375\n",
      "Batch: 116, Loss: 1.2009888887405396, Accuracy: 0.6025390625\n",
      "Batch: 117, Loss: 1.2270739078521729, Accuracy: 0.61328125\n",
      "Batch: 118, Loss: 1.0275328159332275, Accuracy: 0.6708984375\n",
      "Batch: 119, Loss: 1.0680688619613647, Accuracy: 0.669921875\n",
      "Batch: 120, Loss: 1.1929970979690552, Accuracy: 0.6142578125\n",
      "Batch: 121, Loss: 1.2247068881988525, Accuracy: 0.6181640625\n",
      "Batch: 122, Loss: 1.1121976375579834, Accuracy: 0.6494140625\n",
      "Batch: 123, Loss: 1.1113945245742798, Accuracy: 0.650390625\n",
      "Batch: 124, Loss: 1.1444913148880005, Accuracy: 0.638671875\n",
      "Batch: 125, Loss: 1.1941161155700684, Accuracy: 0.6025390625\n",
      "Batch: 126, Loss: 1.1692509651184082, Accuracy: 0.6181640625\n",
      "Batch: 127, Loss: 1.052545189857483, Accuracy: 0.6806640625\n",
      "Batch: 128, Loss: 1.284678339958191, Accuracy: 0.609375\n",
      "Batch: 129, Loss: 1.0977847576141357, Accuracy: 0.6376953125\n",
      "Batch: 130, Loss: 1.3483686447143555, Accuracy: 0.568359375\n",
      "Batch: 131, Loss: 1.1937230825424194, Accuracy: 0.607421875\n",
      "Batch: 132, Loss: 1.2142153978347778, Accuracy: 0.6201171875\n",
      "Batch: 133, Loss: 1.06821870803833, Accuracy: 0.6494140625\n",
      "Batch: 134, Loss: 1.1467912197113037, Accuracy: 0.6201171875\n",
      "Batch: 135, Loss: 1.0442652702331543, Accuracy: 0.671875\n",
      "Batch: 136, Loss: 1.1331133842468262, Accuracy: 0.6484375\n",
      "Batch: 137, Loss: 1.0695250034332275, Accuracy: 0.642578125\n",
      "Batch: 138, Loss: 0.9687939882278442, Accuracy: 0.6640625\n",
      "Batch: 139, Loss: 1.0048749446868896, Accuracy: 0.662109375\n",
      "Batch: 140, Loss: 1.1543092727661133, Accuracy: 0.6103515625\n",
      "Batch: 141, Loss: 1.1808323860168457, Accuracy: 0.62890625\n",
      "Batch: 142, Loss: 1.1754076480865479, Accuracy: 0.6181640625\n",
      "Batch: 143, Loss: 1.1594841480255127, Accuracy: 0.6259765625\n",
      "Batch: 144, Loss: 1.1381407976150513, Accuracy: 0.6328125\n",
      "Batch: 145, Loss: 1.0986077785491943, Accuracy: 0.6083984375\n",
      "Batch: 146, Loss: 1.1928009986877441, Accuracy: 0.5859375\n",
      "Batch: 147, Loss: 1.1726280450820923, Accuracy: 0.5986328125\n",
      "Batch: 148, Loss: 1.30753493309021, Accuracy: 0.5537109375\n",
      "Batch: 149, Loss: 1.1808477640151978, Accuracy: 0.6025390625\n",
      "Batch: 150, Loss: 1.0637409687042236, Accuracy: 0.646484375\n",
      "Batch: 151, Loss: 1.001244306564331, Accuracy: 0.671875\n",
      "Epoch 15/80\n",
      "Batch: 1, Loss: 1.3719109296798706, Accuracy: 0.560546875\n",
      "Batch: 2, Loss: 1.1598219871520996, Accuracy: 0.607421875\n",
      "Batch: 3, Loss: 1.0640811920166016, Accuracy: 0.6484375\n",
      "Batch: 4, Loss: 1.0254621505737305, Accuracy: 0.6748046875\n",
      "Batch: 5, Loss: 1.07097327709198, Accuracy: 0.65625\n",
      "Batch: 6, Loss: 1.1601576805114746, Accuracy: 0.609375\n",
      "Batch: 7, Loss: 1.0935860872268677, Accuracy: 0.6298828125\n",
      "Batch: 8, Loss: 1.0441291332244873, Accuracy: 0.6455078125\n",
      "Batch: 9, Loss: 1.009285569190979, Accuracy: 0.6630859375\n",
      "Batch: 10, Loss: 1.0560489892959595, Accuracy: 0.6455078125\n",
      "Batch: 11, Loss: 1.1978113651275635, Accuracy: 0.58984375\n",
      "Batch: 12, Loss: 1.208042860031128, Accuracy: 0.61328125\n",
      "Batch: 13, Loss: 0.9773744344711304, Accuracy: 0.6943359375\n",
      "Batch: 14, Loss: 1.2309327125549316, Accuracy: 0.59765625\n",
      "Batch: 15, Loss: 1.0792601108551025, Accuracy: 0.6728515625\n",
      "Batch: 16, Loss: 1.0903700590133667, Accuracy: 0.6611328125\n",
      "Batch: 17, Loss: 1.1752967834472656, Accuracy: 0.615234375\n",
      "Batch: 18, Loss: 1.1973965167999268, Accuracy: 0.6123046875\n",
      "Batch: 19, Loss: 1.206151008605957, Accuracy: 0.6162109375\n",
      "Batch: 20, Loss: 1.079148769378662, Accuracy: 0.65625\n",
      "Batch: 21, Loss: 1.0707670450210571, Accuracy: 0.640625\n",
      "Batch: 22, Loss: 1.1882492303848267, Accuracy: 0.6201171875\n",
      "Batch: 23, Loss: 1.0955314636230469, Accuracy: 0.6259765625\n",
      "Batch: 24, Loss: 1.138639211654663, Accuracy: 0.6279296875\n",
      "Batch: 25, Loss: 1.1182397603988647, Accuracy: 0.6318359375\n",
      "Batch: 26, Loss: 1.021432876586914, Accuracy: 0.669921875\n",
      "Batch: 27, Loss: 1.0888633728027344, Accuracy: 0.62890625\n",
      "Batch: 28, Loss: 1.166815161705017, Accuracy: 0.60546875\n",
      "Batch: 29, Loss: 1.1360254287719727, Accuracy: 0.6259765625\n",
      "Batch: 30, Loss: 1.060768723487854, Accuracy: 0.673828125\n",
      "Batch: 31, Loss: 1.0762513875961304, Accuracy: 0.662109375\n",
      "Batch: 32, Loss: 1.0558503866195679, Accuracy: 0.65234375\n",
      "Batch: 33, Loss: 1.251656413078308, Accuracy: 0.5986328125\n",
      "Batch: 34, Loss: 1.2954206466674805, Accuracy: 0.5869140625\n",
      "Batch: 35, Loss: 1.1598587036132812, Accuracy: 0.6083984375\n",
      "Batch: 36, Loss: 1.1253368854522705, Accuracy: 0.63671875\n",
      "Batch: 37, Loss: 1.15635347366333, Accuracy: 0.6455078125\n",
      "Batch: 38, Loss: 1.1788816452026367, Accuracy: 0.6044921875\n",
      "Batch: 39, Loss: 1.1925725936889648, Accuracy: 0.62890625\n",
      "Batch: 40, Loss: 1.1991114616394043, Accuracy: 0.623046875\n",
      "Batch: 41, Loss: 1.1596033573150635, Accuracy: 0.6318359375\n",
      "Batch: 42, Loss: 0.9513556957244873, Accuracy: 0.6787109375\n",
      "Batch: 43, Loss: 1.1651612520217896, Accuracy: 0.6015625\n",
      "Batch: 44, Loss: 1.1358023881912231, Accuracy: 0.603515625\n",
      "Batch: 45, Loss: 1.0199780464172363, Accuracy: 0.64453125\n",
      "Batch: 46, Loss: 1.110263466835022, Accuracy: 0.6552734375\n",
      "Batch: 47, Loss: 1.120693325996399, Accuracy: 0.650390625\n",
      "Batch: 48, Loss: 1.052903175354004, Accuracy: 0.6572265625\n",
      "Batch: 49, Loss: 1.277057409286499, Accuracy: 0.5859375\n",
      "Batch: 50, Loss: 1.2558281421661377, Accuracy: 0.5927734375\n",
      "Batch: 51, Loss: 1.2797315120697021, Accuracy: 0.5986328125\n",
      "Batch: 52, Loss: 1.2528272867202759, Accuracy: 0.6298828125\n",
      "Batch: 53, Loss: 1.0499184131622314, Accuracy: 0.6455078125\n",
      "Batch: 54, Loss: 1.1368669271469116, Accuracy: 0.6357421875\n",
      "Batch: 55, Loss: 1.209568738937378, Accuracy: 0.6044921875\n",
      "Batch: 56, Loss: 1.191094160079956, Accuracy: 0.623046875\n",
      "Batch: 57, Loss: 1.1108086109161377, Accuracy: 0.654296875\n",
      "Batch: 58, Loss: 1.2464141845703125, Accuracy: 0.6181640625\n",
      "Batch: 59, Loss: 1.0286401510238647, Accuracy: 0.6845703125\n",
      "Batch: 60, Loss: 1.0111935138702393, Accuracy: 0.689453125\n",
      "Batch: 61, Loss: 1.1650139093399048, Accuracy: 0.6357421875\n",
      "Batch: 62, Loss: 1.1194396018981934, Accuracy: 0.642578125\n",
      "Batch: 63, Loss: 1.148580551147461, Accuracy: 0.6357421875\n",
      "Batch: 64, Loss: 1.1098675727844238, Accuracy: 0.63671875\n",
      "Batch: 65, Loss: 1.1677656173706055, Accuracy: 0.62890625\n",
      "Batch: 66, Loss: 1.076615810394287, Accuracy: 0.6591796875\n",
      "Batch: 67, Loss: 1.2350785732269287, Accuracy: 0.607421875\n",
      "Batch: 68, Loss: 1.221656084060669, Accuracy: 0.6298828125\n",
      "Batch: 69, Loss: 1.1305292844772339, Accuracy: 0.6279296875\n",
      "Batch: 70, Loss: 1.1528849601745605, Accuracy: 0.6455078125\n",
      "Batch: 71, Loss: 1.1534850597381592, Accuracy: 0.619140625\n",
      "Batch: 72, Loss: 1.0453203916549683, Accuracy: 0.6494140625\n",
      "Batch: 73, Loss: 1.0878013372421265, Accuracy: 0.669921875\n",
      "Batch: 74, Loss: 1.064786672592163, Accuracy: 0.6513671875\n",
      "Batch: 75, Loss: 1.0189906358718872, Accuracy: 0.666015625\n",
      "Batch: 76, Loss: 1.152252197265625, Accuracy: 0.603515625\n",
      "Batch: 77, Loss: 1.1391785144805908, Accuracy: 0.630859375\n",
      "Batch: 78, Loss: 1.0847135782241821, Accuracy: 0.66796875\n",
      "Batch: 79, Loss: 0.997583270072937, Accuracy: 0.6884765625\n",
      "Batch: 80, Loss: 1.0334523916244507, Accuracy: 0.6328125\n",
      "Batch: 81, Loss: 1.205045223236084, Accuracy: 0.583984375\n",
      "Batch: 82, Loss: 1.1824809312820435, Accuracy: 0.595703125\n",
      "Batch: 83, Loss: 0.9989962577819824, Accuracy: 0.6923828125\n",
      "Batch: 84, Loss: 1.0720789432525635, Accuracy: 0.677734375\n",
      "Batch: 85, Loss: 1.0129613876342773, Accuracy: 0.6748046875\n",
      "Batch: 86, Loss: 1.2624520063400269, Accuracy: 0.599609375\n",
      "Batch: 87, Loss: 1.0465441942214966, Accuracy: 0.67578125\n",
      "Batch: 88, Loss: 1.1833934783935547, Accuracy: 0.6328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 89, Loss: 1.1579248905181885, Accuracy: 0.6337890625\n",
      "Batch: 90, Loss: 1.0525718927383423, Accuracy: 0.6494140625\n",
      "Batch: 91, Loss: 1.0805630683898926, Accuracy: 0.640625\n",
      "Batch: 92, Loss: 1.1637537479400635, Accuracy: 0.6142578125\n",
      "Batch: 93, Loss: 1.0931296348571777, Accuracy: 0.6474609375\n",
      "Batch: 94, Loss: 1.1009756326675415, Accuracy: 0.634765625\n",
      "Batch: 95, Loss: 1.1497714519500732, Accuracy: 0.607421875\n",
      "Batch: 96, Loss: 1.118659257888794, Accuracy: 0.642578125\n",
      "Batch: 97, Loss: 0.9568065404891968, Accuracy: 0.6806640625\n",
      "Batch: 98, Loss: 1.0254067182540894, Accuracy: 0.6806640625\n",
      "Batch: 99, Loss: 1.0161370038986206, Accuracy: 0.6708984375\n",
      "Batch: 100, Loss: 1.1023799180984497, Accuracy: 0.66015625\n",
      "Batch: 101, Loss: 1.1656732559204102, Accuracy: 0.626953125\n",
      "Batch: 102, Loss: 1.0729236602783203, Accuracy: 0.66015625\n",
      "Batch: 103, Loss: 1.166802167892456, Accuracy: 0.6416015625\n",
      "Batch: 104, Loss: 1.0450242757797241, Accuracy: 0.6533203125\n",
      "Batch: 105, Loss: 1.1556355953216553, Accuracy: 0.623046875\n",
      "Batch: 106, Loss: 1.105331301689148, Accuracy: 0.63671875\n",
      "Batch: 107, Loss: 1.2181925773620605, Accuracy: 0.609375\n",
      "Batch: 108, Loss: 1.1728363037109375, Accuracy: 0.607421875\n",
      "Batch: 109, Loss: 1.293888807296753, Accuracy: 0.57421875\n",
      "Batch: 110, Loss: 0.9773839116096497, Accuracy: 0.6826171875\n",
      "Batch: 111, Loss: 1.1655982732772827, Accuracy: 0.59765625\n",
      "Batch: 112, Loss: 1.1094975471496582, Accuracy: 0.6572265625\n",
      "Batch: 113, Loss: 1.1115639209747314, Accuracy: 0.6513671875\n",
      "Batch: 114, Loss: 1.2331504821777344, Accuracy: 0.59375\n",
      "Batch: 115, Loss: 1.2719107866287231, Accuracy: 0.6025390625\n",
      "Batch: 116, Loss: 1.1691343784332275, Accuracy: 0.6279296875\n",
      "Batch: 117, Loss: 1.2190747261047363, Accuracy: 0.6181640625\n",
      "Batch: 118, Loss: 0.9857820868492126, Accuracy: 0.669921875\n",
      "Batch: 119, Loss: 1.0302696228027344, Accuracy: 0.671875\n",
      "Batch: 120, Loss: 1.172687292098999, Accuracy: 0.607421875\n",
      "Batch: 121, Loss: 1.2256906032562256, Accuracy: 0.6064453125\n",
      "Batch: 122, Loss: 1.0545843839645386, Accuracy: 0.671875\n",
      "Batch: 123, Loss: 1.113163948059082, Accuracy: 0.6484375\n",
      "Batch: 124, Loss: 1.1396421194076538, Accuracy: 0.642578125\n",
      "Batch: 125, Loss: 1.20615553855896, Accuracy: 0.6162109375\n",
      "Batch: 126, Loss: 1.1415646076202393, Accuracy: 0.6201171875\n",
      "Batch: 127, Loss: 1.0389418601989746, Accuracy: 0.685546875\n",
      "Batch: 128, Loss: 1.2585315704345703, Accuracy: 0.6142578125\n",
      "Batch: 129, Loss: 1.103860855102539, Accuracy: 0.6298828125\n",
      "Batch: 130, Loss: 1.3189703226089478, Accuracy: 0.5966796875\n",
      "Batch: 131, Loss: 1.170576572418213, Accuracy: 0.6240234375\n",
      "Batch: 132, Loss: 1.1687099933624268, Accuracy: 0.623046875\n",
      "Batch: 133, Loss: 1.0300769805908203, Accuracy: 0.64453125\n",
      "Batch: 134, Loss: 1.1024456024169922, Accuracy: 0.6298828125\n",
      "Batch: 135, Loss: 1.0324971675872803, Accuracy: 0.6806640625\n",
      "Batch: 136, Loss: 1.1261329650878906, Accuracy: 0.6572265625\n",
      "Batch: 137, Loss: 1.0493290424346924, Accuracy: 0.640625\n",
      "Batch: 138, Loss: 0.9462569952011108, Accuracy: 0.6767578125\n",
      "Batch: 139, Loss: 1.018855094909668, Accuracy: 0.6513671875\n",
      "Batch: 140, Loss: 1.1270123720169067, Accuracy: 0.62109375\n",
      "Batch: 141, Loss: 1.1520475149154663, Accuracy: 0.625\n",
      "Batch: 142, Loss: 1.1483385562896729, Accuracy: 0.6240234375\n",
      "Batch: 143, Loss: 1.1546332836151123, Accuracy: 0.6328125\n",
      "Batch: 144, Loss: 1.1155363321304321, Accuracy: 0.640625\n",
      "Batch: 145, Loss: 1.0739721059799194, Accuracy: 0.6259765625\n",
      "Batch: 146, Loss: 1.1759033203125, Accuracy: 0.61328125\n",
      "Batch: 147, Loss: 1.17206609249115, Accuracy: 0.62109375\n",
      "Batch: 148, Loss: 1.2562158107757568, Accuracy: 0.5791015625\n",
      "Batch: 149, Loss: 1.124070644378662, Accuracy: 0.607421875\n",
      "Batch: 150, Loss: 1.099992036819458, Accuracy: 0.6455078125\n",
      "Batch: 151, Loss: 0.9840903878211975, Accuracy: 0.681640625\n",
      "Epoch 16/80\n",
      "Batch: 1, Loss: 1.3846381902694702, Accuracy: 0.564453125\n",
      "Batch: 2, Loss: 1.1811304092407227, Accuracy: 0.607421875\n",
      "Batch: 3, Loss: 1.0781102180480957, Accuracy: 0.634765625\n",
      "Batch: 4, Loss: 0.9889269471168518, Accuracy: 0.69140625\n",
      "Batch: 5, Loss: 1.0333895683288574, Accuracy: 0.6728515625\n",
      "Batch: 6, Loss: 1.1298589706420898, Accuracy: 0.6123046875\n",
      "Batch: 7, Loss: 1.0619070529937744, Accuracy: 0.6318359375\n",
      "Batch: 8, Loss: 1.0315909385681152, Accuracy: 0.6494140625\n",
      "Batch: 9, Loss: 1.0137088298797607, Accuracy: 0.6630859375\n",
      "Batch: 10, Loss: 1.0306823253631592, Accuracy: 0.6689453125\n",
      "Batch: 11, Loss: 1.2194366455078125, Accuracy: 0.5810546875\n",
      "Batch: 12, Loss: 1.204014778137207, Accuracy: 0.595703125\n",
      "Batch: 13, Loss: 0.9390488862991333, Accuracy: 0.705078125\n",
      "Batch: 14, Loss: 1.221994400024414, Accuracy: 0.6015625\n",
      "Batch: 15, Loss: 1.0396161079406738, Accuracy: 0.6767578125\n",
      "Batch: 16, Loss: 1.068415641784668, Accuracy: 0.66796875\n",
      "Batch: 17, Loss: 1.1512248516082764, Accuracy: 0.630859375\n",
      "Batch: 18, Loss: 1.1280217170715332, Accuracy: 0.640625\n",
      "Batch: 19, Loss: 1.1728291511535645, Accuracy: 0.62890625\n",
      "Batch: 20, Loss: 1.080121397972107, Accuracy: 0.6787109375\n",
      "Batch: 21, Loss: 1.0445384979248047, Accuracy: 0.666015625\n",
      "Batch: 22, Loss: 1.168088674545288, Accuracy: 0.630859375\n",
      "Batch: 23, Loss: 1.0881829261779785, Accuracy: 0.6279296875\n",
      "Batch: 24, Loss: 1.1186660528182983, Accuracy: 0.6337890625\n",
      "Batch: 25, Loss: 1.1115386486053467, Accuracy: 0.642578125\n",
      "Batch: 26, Loss: 1.0173323154449463, Accuracy: 0.6630859375\n",
      "Batch: 27, Loss: 1.0861294269561768, Accuracy: 0.6376953125\n",
      "Batch: 28, Loss: 1.1662218570709229, Accuracy: 0.60546875\n",
      "Batch: 29, Loss: 1.1104938983917236, Accuracy: 0.62890625\n",
      "Batch: 30, Loss: 1.0565125942230225, Accuracy: 0.6826171875\n",
      "Batch: 31, Loss: 1.0453521013259888, Accuracy: 0.662109375\n",
      "Batch: 32, Loss: 1.0155147314071655, Accuracy: 0.666015625\n",
      "Batch: 33, Loss: 1.2305697202682495, Accuracy: 0.6015625\n",
      "Batch: 34, Loss: 1.2680457830429077, Accuracy: 0.5966796875\n",
      "Batch: 35, Loss: 1.162558674812317, Accuracy: 0.619140625\n",
      "Batch: 36, Loss: 1.1695932149887085, Accuracy: 0.63671875\n",
      "Batch: 37, Loss: 1.1237432956695557, Accuracy: 0.626953125\n",
      "Batch: 38, Loss: 1.1410903930664062, Accuracy: 0.6142578125\n",
      "Batch: 39, Loss: 1.1564680337905884, Accuracy: 0.6337890625\n",
      "Batch: 40, Loss: 1.1852694749832153, Accuracy: 0.62109375\n",
      "Batch: 41, Loss: 1.1523091793060303, Accuracy: 0.6240234375\n",
      "Batch: 42, Loss: 0.9308984279632568, Accuracy: 0.6904296875\n",
      "Batch: 43, Loss: 1.1486777067184448, Accuracy: 0.615234375\n",
      "Batch: 44, Loss: 1.119436264038086, Accuracy: 0.6201171875\n",
      "Batch: 45, Loss: 0.9929732084274292, Accuracy: 0.654296875\n",
      "Batch: 46, Loss: 1.0988030433654785, Accuracy: 0.6484375\n",
      "Batch: 47, Loss: 1.0974223613739014, Accuracy: 0.6650390625\n",
      "Batch: 48, Loss: 1.0374113321304321, Accuracy: 0.6689453125\n",
      "Batch: 49, Loss: 1.2688854932785034, Accuracy: 0.5869140625\n",
      "Batch: 50, Loss: 1.2355339527130127, Accuracy: 0.5888671875\n",
      "Batch: 51, Loss: 1.2675669193267822, Accuracy: 0.6005859375\n",
      "Batch: 52, Loss: 1.215004324913025, Accuracy: 0.6337890625\n",
      "Batch: 53, Loss: 1.0535715818405151, Accuracy: 0.6533203125\n",
      "Batch: 54, Loss: 1.1163746118545532, Accuracy: 0.6533203125\n",
      "Batch: 55, Loss: 1.1679704189300537, Accuracy: 0.6171875\n",
      "Batch: 56, Loss: 1.182092547416687, Accuracy: 0.6142578125\n",
      "Batch: 57, Loss: 1.1042934656143188, Accuracy: 0.6474609375\n",
      "Batch: 58, Loss: 1.2089797258377075, Accuracy: 0.6376953125\n",
      "Batch: 59, Loss: 1.003674030303955, Accuracy: 0.68359375\n",
      "Batch: 60, Loss: 1.0013947486877441, Accuracy: 0.6787109375\n",
      "Batch: 61, Loss: 1.1492440700531006, Accuracy: 0.6396484375\n",
      "Batch: 62, Loss: 1.1067191362380981, Accuracy: 0.634765625\n",
      "Batch: 63, Loss: 1.1293284893035889, Accuracy: 0.6318359375\n",
      "Batch: 64, Loss: 1.091846227645874, Accuracy: 0.6494140625\n",
      "Batch: 65, Loss: 1.1281696557998657, Accuracy: 0.6474609375\n",
      "Batch: 66, Loss: 1.08028244972229, Accuracy: 0.63671875\n",
      "Batch: 67, Loss: 1.186166763305664, Accuracy: 0.630859375\n",
      "Batch: 68, Loss: 1.2015726566314697, Accuracy: 0.626953125\n",
      "Batch: 69, Loss: 1.1538501977920532, Accuracy: 0.62890625\n",
      "Batch: 70, Loss: 1.1357285976409912, Accuracy: 0.64453125\n",
      "Batch: 71, Loss: 1.1663480997085571, Accuracy: 0.623046875\n",
      "Batch: 72, Loss: 1.0194100141525269, Accuracy: 0.6708984375\n",
      "Batch: 73, Loss: 1.0856541395187378, Accuracy: 0.6611328125\n",
      "Batch: 74, Loss: 1.061905860900879, Accuracy: 0.6728515625\n",
      "Batch: 75, Loss: 1.0494582653045654, Accuracy: 0.65625\n",
      "Batch: 76, Loss: 1.1519325971603394, Accuracy: 0.609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 77, Loss: 1.1487635374069214, Accuracy: 0.62109375\n",
      "Batch: 78, Loss: 1.0689730644226074, Accuracy: 0.662109375\n",
      "Batch: 79, Loss: 0.9932284951210022, Accuracy: 0.6943359375\n",
      "Batch: 80, Loss: 1.0909881591796875, Accuracy: 0.630859375\n",
      "Batch: 81, Loss: 1.339073896408081, Accuracy: 0.564453125\n",
      "Batch: 82, Loss: 1.2230195999145508, Accuracy: 0.5966796875\n",
      "Batch: 83, Loss: 1.0055248737335205, Accuracy: 0.6904296875\n",
      "Batch: 84, Loss: 1.0700292587280273, Accuracy: 0.67578125\n",
      "Batch: 85, Loss: 1.015647530555725, Accuracy: 0.6708984375\n",
      "Batch: 86, Loss: 1.3031558990478516, Accuracy: 0.5947265625\n",
      "Batch: 87, Loss: 1.0860192775726318, Accuracy: 0.6494140625\n",
      "Batch: 88, Loss: 1.1843105554580688, Accuracy: 0.6328125\n",
      "Batch: 89, Loss: 1.197724461555481, Accuracy: 0.6298828125\n",
      "Batch: 90, Loss: 1.0713316202163696, Accuracy: 0.6484375\n",
      "Batch: 91, Loss: 1.1061367988586426, Accuracy: 0.642578125\n",
      "Batch: 92, Loss: 1.1893043518066406, Accuracy: 0.609375\n",
      "Batch: 93, Loss: 1.1204619407653809, Accuracy: 0.6328125\n",
      "Batch: 94, Loss: 1.109933614730835, Accuracy: 0.6240234375\n",
      "Batch: 95, Loss: 1.1425561904907227, Accuracy: 0.6259765625\n",
      "Batch: 96, Loss: 1.1554408073425293, Accuracy: 0.634765625\n",
      "Batch: 97, Loss: 0.9693933725357056, Accuracy: 0.685546875\n",
      "Batch: 98, Loss: 1.024162769317627, Accuracy: 0.677734375\n",
      "Batch: 99, Loss: 1.0167592763900757, Accuracy: 0.66015625\n",
      "Batch: 100, Loss: 1.0957088470458984, Accuracy: 0.6494140625\n",
      "Batch: 101, Loss: 1.1593692302703857, Accuracy: 0.6181640625\n",
      "Batch: 102, Loss: 1.0624384880065918, Accuracy: 0.6650390625\n",
      "Batch: 103, Loss: 1.1446181535720825, Accuracy: 0.6572265625\n",
      "Batch: 104, Loss: 1.0416252613067627, Accuracy: 0.6572265625\n",
      "Batch: 105, Loss: 1.1333054304122925, Accuracy: 0.625\n",
      "Batch: 106, Loss: 1.1154875755310059, Accuracy: 0.650390625\n",
      "Batch: 107, Loss: 1.2070121765136719, Accuracy: 0.6181640625\n",
      "Batch: 108, Loss: 1.145990252494812, Accuracy: 0.6279296875\n",
      "Batch: 109, Loss: 1.2823126316070557, Accuracy: 0.5927734375\n",
      "Batch: 110, Loss: 0.9666723012924194, Accuracy: 0.677734375\n",
      "Batch: 111, Loss: 1.1505568027496338, Accuracy: 0.6025390625\n",
      "Batch: 112, Loss: 1.098095417022705, Accuracy: 0.666015625\n",
      "Batch: 113, Loss: 1.1143324375152588, Accuracy: 0.6572265625\n",
      "Batch: 114, Loss: 1.2678091526031494, Accuracy: 0.5947265625\n",
      "Batch: 115, Loss: 1.2520203590393066, Accuracy: 0.6181640625\n",
      "Batch: 116, Loss: 1.1807005405426025, Accuracy: 0.634765625\n",
      "Batch: 117, Loss: 1.1855127811431885, Accuracy: 0.625\n",
      "Batch: 118, Loss: 0.9720470905303955, Accuracy: 0.6845703125\n",
      "Batch: 119, Loss: 1.0105421543121338, Accuracy: 0.6826171875\n",
      "Batch: 120, Loss: 1.1632473468780518, Accuracy: 0.6240234375\n",
      "Batch: 121, Loss: 1.2023118734359741, Accuracy: 0.599609375\n",
      "Batch: 122, Loss: 1.0541150569915771, Accuracy: 0.6728515625\n",
      "Batch: 123, Loss: 1.069356918334961, Accuracy: 0.6591796875\n",
      "Batch: 124, Loss: 1.118433952331543, Accuracy: 0.6376953125\n",
      "Batch: 125, Loss: 1.1560941934585571, Accuracy: 0.6357421875\n",
      "Batch: 126, Loss: 1.126375675201416, Accuracy: 0.638671875\n",
      "Batch: 127, Loss: 1.025411605834961, Accuracy: 0.6806640625\n",
      "Batch: 128, Loss: 1.2405027151107788, Accuracy: 0.6171875\n",
      "Batch: 129, Loss: 1.0670788288116455, Accuracy: 0.6494140625\n",
      "Batch: 130, Loss: 1.3159862756729126, Accuracy: 0.5869140625\n",
      "Batch: 131, Loss: 1.1481680870056152, Accuracy: 0.634765625\n",
      "Batch: 132, Loss: 1.1596834659576416, Accuracy: 0.6240234375\n",
      "Batch: 133, Loss: 1.0383380651474, Accuracy: 0.662109375\n",
      "Batch: 134, Loss: 1.1346579790115356, Accuracy: 0.6064453125\n",
      "Batch: 135, Loss: 1.0409040451049805, Accuracy: 0.6787109375\n",
      "Batch: 136, Loss: 1.1126532554626465, Accuracy: 0.64453125\n",
      "Batch: 137, Loss: 1.0473296642303467, Accuracy: 0.626953125\n",
      "Batch: 138, Loss: 0.9400050640106201, Accuracy: 0.681640625\n",
      "Batch: 139, Loss: 0.9951516389846802, Accuracy: 0.662109375\n",
      "Batch: 140, Loss: 1.106372594833374, Accuracy: 0.625\n",
      "Batch: 141, Loss: 1.1179897785186768, Accuracy: 0.6328125\n",
      "Batch: 142, Loss: 1.1579248905181885, Accuracy: 0.6181640625\n",
      "Batch: 143, Loss: 1.1238908767700195, Accuracy: 0.6279296875\n",
      "Batch: 144, Loss: 1.0942118167877197, Accuracy: 0.646484375\n",
      "Batch: 145, Loss: 1.073512077331543, Accuracy: 0.6279296875\n",
      "Batch: 146, Loss: 1.1659153699874878, Accuracy: 0.6181640625\n",
      "Batch: 147, Loss: 1.151787519454956, Accuracy: 0.6357421875\n",
      "Batch: 148, Loss: 1.2721803188323975, Accuracy: 0.5625\n",
      "Batch: 149, Loss: 1.134034276008606, Accuracy: 0.6103515625\n",
      "Batch: 150, Loss: 1.062819480895996, Accuracy: 0.654296875\n",
      "Batch: 151, Loss: 0.9725319147109985, Accuracy: 0.685546875\n",
      "Epoch 17/80\n",
      "Batch: 1, Loss: 1.3709559440612793, Accuracy: 0.5703125\n",
      "Batch: 2, Loss: 1.137681484222412, Accuracy: 0.6005859375\n",
      "Batch: 3, Loss: 1.054543375968933, Accuracy: 0.6416015625\n",
      "Batch: 4, Loss: 0.9613664746284485, Accuracy: 0.6982421875\n",
      "Batch: 5, Loss: 1.0234084129333496, Accuracy: 0.673828125\n",
      "Batch: 6, Loss: 1.1075786352157593, Accuracy: 0.6279296875\n",
      "Batch: 7, Loss: 1.0516036748886108, Accuracy: 0.65234375\n",
      "Batch: 8, Loss: 1.0175511837005615, Accuracy: 0.650390625\n",
      "Batch: 9, Loss: 0.9827561974525452, Accuracy: 0.6787109375\n",
      "Batch: 10, Loss: 1.0041130781173706, Accuracy: 0.654296875\n",
      "Batch: 11, Loss: 1.1932039260864258, Accuracy: 0.5888671875\n",
      "Batch: 12, Loss: 1.1685270071029663, Accuracy: 0.6318359375\n",
      "Batch: 13, Loss: 0.9417412281036377, Accuracy: 0.705078125\n",
      "Batch: 14, Loss: 1.2039475440979004, Accuracy: 0.6015625\n",
      "Batch: 15, Loss: 1.0471241474151611, Accuracy: 0.6767578125\n",
      "Batch: 16, Loss: 1.0718472003936768, Accuracy: 0.666015625\n",
      "Batch: 17, Loss: 1.1548316478729248, Accuracy: 0.6337890625\n",
      "Batch: 18, Loss: 1.1471469402313232, Accuracy: 0.630859375\n",
      "Batch: 19, Loss: 1.1717522144317627, Accuracy: 0.625\n",
      "Batch: 20, Loss: 1.0669583082199097, Accuracy: 0.666015625\n",
      "Batch: 21, Loss: 1.0515353679656982, Accuracy: 0.6552734375\n",
      "Batch: 22, Loss: 1.1655144691467285, Accuracy: 0.6318359375\n",
      "Batch: 23, Loss: 1.093712329864502, Accuracy: 0.646484375\n",
      "Batch: 24, Loss: 1.124990701675415, Accuracy: 0.6328125\n",
      "Batch: 25, Loss: 1.0949280261993408, Accuracy: 0.6416015625\n",
      "Batch: 26, Loss: 1.0002002716064453, Accuracy: 0.6650390625\n",
      "Batch: 27, Loss: 1.0504059791564941, Accuracy: 0.646484375\n",
      "Batch: 28, Loss: 1.1378587484359741, Accuracy: 0.6279296875\n",
      "Batch: 29, Loss: 1.0844002962112427, Accuracy: 0.634765625\n",
      "Batch: 30, Loss: 1.0410144329071045, Accuracy: 0.673828125\n",
      "Batch: 31, Loss: 1.019228458404541, Accuracy: 0.677734375\n",
      "Batch: 32, Loss: 1.02508544921875, Accuracy: 0.6552734375\n",
      "Batch: 33, Loss: 1.2215046882629395, Accuracy: 0.6015625\n",
      "Batch: 34, Loss: 1.2300467491149902, Accuracy: 0.6064453125\n",
      "Batch: 35, Loss: 1.1412758827209473, Accuracy: 0.623046875\n",
      "Batch: 36, Loss: 1.1368327140808105, Accuracy: 0.650390625\n",
      "Batch: 37, Loss: 1.1148003339767456, Accuracy: 0.6357421875\n",
      "Batch: 38, Loss: 1.1516162157058716, Accuracy: 0.611328125\n",
      "Batch: 39, Loss: 1.1499805450439453, Accuracy: 0.6201171875\n",
      "Batch: 40, Loss: 1.1248358488082886, Accuracy: 0.6455078125\n",
      "Batch: 41, Loss: 1.1288700103759766, Accuracy: 0.6328125\n",
      "Batch: 42, Loss: 0.9089529514312744, Accuracy: 0.703125\n",
      "Batch: 43, Loss: 1.1095911264419556, Accuracy: 0.623046875\n",
      "Batch: 44, Loss: 1.1161046028137207, Accuracy: 0.61328125\n",
      "Batch: 45, Loss: 1.0163215398788452, Accuracy: 0.65234375\n",
      "Batch: 46, Loss: 1.0749292373657227, Accuracy: 0.658203125\n",
      "Batch: 47, Loss: 1.072540521621704, Accuracy: 0.669921875\n",
      "Batch: 48, Loss: 1.0347176790237427, Accuracy: 0.671875\n",
      "Batch: 49, Loss: 1.2317591905593872, Accuracy: 0.603515625\n",
      "Batch: 50, Loss: 1.2016184329986572, Accuracy: 0.6083984375\n",
      "Batch: 51, Loss: 1.257171630859375, Accuracy: 0.58984375\n",
      "Batch: 52, Loss: 1.2242839336395264, Accuracy: 0.6240234375\n",
      "Batch: 53, Loss: 1.0339701175689697, Accuracy: 0.65625\n",
      "Batch: 54, Loss: 1.091587781906128, Accuracy: 0.6630859375\n",
      "Batch: 55, Loss: 1.1808130741119385, Accuracy: 0.61328125\n",
      "Batch: 56, Loss: 1.1747273206710815, Accuracy: 0.6337890625\n",
      "Batch: 57, Loss: 1.0967223644256592, Accuracy: 0.650390625\n",
      "Batch: 58, Loss: 1.1959612369537354, Accuracy: 0.6328125\n",
      "Batch: 59, Loss: 0.9889484643936157, Accuracy: 0.6962890625\n",
      "Batch: 60, Loss: 0.973151445388794, Accuracy: 0.68359375\n",
      "Batch: 61, Loss: 1.1302520036697388, Accuracy: 0.63671875\n",
      "Batch: 62, Loss: 1.0928981304168701, Accuracy: 0.650390625\n",
      "Batch: 63, Loss: 1.0878461599349976, Accuracy: 0.6533203125\n",
      "Batch: 64, Loss: 1.093249797821045, Accuracy: 0.65625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 65, Loss: 1.122728705406189, Accuracy: 0.638671875\n",
      "Batch: 66, Loss: 1.0595526695251465, Accuracy: 0.6630859375\n",
      "Batch: 67, Loss: 1.1860249042510986, Accuracy: 0.626953125\n",
      "Batch: 68, Loss: 1.1874802112579346, Accuracy: 0.630859375\n",
      "Batch: 69, Loss: 1.1096633672714233, Accuracy: 0.6474609375\n",
      "Batch: 70, Loss: 1.114583969116211, Accuracy: 0.6591796875\n",
      "Batch: 71, Loss: 1.1400930881500244, Accuracy: 0.6396484375\n",
      "Batch: 72, Loss: 1.01535964012146, Accuracy: 0.6767578125\n",
      "Batch: 73, Loss: 1.065699815750122, Accuracy: 0.6689453125\n",
      "Batch: 74, Loss: 1.037750482559204, Accuracy: 0.6591796875\n",
      "Batch: 75, Loss: 1.0092213153839111, Accuracy: 0.6806640625\n",
      "Batch: 76, Loss: 1.1153223514556885, Accuracy: 0.619140625\n",
      "Batch: 77, Loss: 1.1065372228622437, Accuracy: 0.640625\n",
      "Batch: 78, Loss: 1.0698364973068237, Accuracy: 0.6689453125\n",
      "Batch: 79, Loss: 0.9645657539367676, Accuracy: 0.7001953125\n",
      "Batch: 80, Loss: 1.0387805700302124, Accuracy: 0.642578125\n",
      "Batch: 81, Loss: 1.187305212020874, Accuracy: 0.5859375\n",
      "Batch: 82, Loss: 1.1201393604278564, Accuracy: 0.6259765625\n",
      "Batch: 83, Loss: 0.9770559668540955, Accuracy: 0.685546875\n",
      "Batch: 84, Loss: 1.0643415451049805, Accuracy: 0.66796875\n",
      "Batch: 85, Loss: 0.9856877326965332, Accuracy: 0.6826171875\n",
      "Batch: 86, Loss: 1.2504326105117798, Accuracy: 0.619140625\n",
      "Batch: 87, Loss: 1.0304991006851196, Accuracy: 0.681640625\n",
      "Batch: 88, Loss: 1.1745357513427734, Accuracy: 0.62109375\n",
      "Batch: 89, Loss: 1.1559817790985107, Accuracy: 0.6337890625\n",
      "Batch: 90, Loss: 1.0449899435043335, Accuracy: 0.6591796875\n",
      "Batch: 91, Loss: 1.0666565895080566, Accuracy: 0.654296875\n",
      "Batch: 92, Loss: 1.1335331201553345, Accuracy: 0.6279296875\n",
      "Batch: 93, Loss: 1.0709596872329712, Accuracy: 0.666015625\n",
      "Batch: 94, Loss: 1.0496222972869873, Accuracy: 0.6591796875\n",
      "Batch: 95, Loss: 1.125164270401001, Accuracy: 0.6220703125\n",
      "Batch: 96, Loss: 1.100230097770691, Accuracy: 0.6494140625\n",
      "Batch: 97, Loss: 0.9419788718223572, Accuracy: 0.689453125\n",
      "Batch: 98, Loss: 0.9984233379364014, Accuracy: 0.6826171875\n",
      "Batch: 99, Loss: 0.9779183268547058, Accuracy: 0.6982421875\n",
      "Batch: 100, Loss: 1.0667407512664795, Accuracy: 0.67578125\n",
      "Batch: 101, Loss: 1.1308114528656006, Accuracy: 0.6357421875\n",
      "Batch: 102, Loss: 1.069274663925171, Accuracy: 0.654296875\n",
      "Batch: 103, Loss: 1.1305782794952393, Accuracy: 0.6533203125\n",
      "Batch: 104, Loss: 1.0166780948638916, Accuracy: 0.6689453125\n",
      "Batch: 105, Loss: 1.1253368854522705, Accuracy: 0.6337890625\n",
      "Batch: 106, Loss: 1.10863196849823, Accuracy: 0.642578125\n",
      "Batch: 107, Loss: 1.1810297966003418, Accuracy: 0.6328125\n",
      "Batch: 108, Loss: 1.1357835531234741, Accuracy: 0.623046875\n",
      "Batch: 109, Loss: 1.2350382804870605, Accuracy: 0.5869140625\n",
      "Batch: 110, Loss: 0.9459808468818665, Accuracy: 0.66796875\n",
      "Batch: 111, Loss: 1.126105546951294, Accuracy: 0.630859375\n",
      "Batch: 112, Loss: 1.0786113739013672, Accuracy: 0.654296875\n",
      "Batch: 113, Loss: 1.0856897830963135, Accuracy: 0.662109375\n",
      "Batch: 114, Loss: 1.2138278484344482, Accuracy: 0.6025390625\n",
      "Batch: 115, Loss: 1.2578461170196533, Accuracy: 0.619140625\n",
      "Batch: 116, Loss: 1.1502082347869873, Accuracy: 0.6240234375\n",
      "Batch: 117, Loss: 1.1672827005386353, Accuracy: 0.640625\n",
      "Batch: 118, Loss: 0.9492536783218384, Accuracy: 0.6884765625\n",
      "Batch: 119, Loss: 1.0120402574539185, Accuracy: 0.6806640625\n",
      "Batch: 120, Loss: 1.1419531106948853, Accuracy: 0.626953125\n",
      "Batch: 121, Loss: 1.173903465270996, Accuracy: 0.6201171875\n",
      "Batch: 122, Loss: 1.0492274761199951, Accuracy: 0.6884765625\n",
      "Batch: 123, Loss: 1.0580298900604248, Accuracy: 0.6708984375\n",
      "Batch: 124, Loss: 1.1051356792449951, Accuracy: 0.6416015625\n",
      "Batch: 125, Loss: 1.1483601331710815, Accuracy: 0.6220703125\n",
      "Batch: 126, Loss: 1.1034884452819824, Accuracy: 0.6376953125\n",
      "Batch: 127, Loss: 1.0069167613983154, Accuracy: 0.68359375\n",
      "Batch: 128, Loss: 1.2317306995391846, Accuracy: 0.623046875\n",
      "Batch: 129, Loss: 1.049795389175415, Accuracy: 0.65625\n",
      "Batch: 130, Loss: 1.2630321979522705, Accuracy: 0.59765625\n",
      "Batch: 131, Loss: 1.1543378829956055, Accuracy: 0.625\n",
      "Batch: 132, Loss: 1.1462855339050293, Accuracy: 0.6328125\n",
      "Batch: 133, Loss: 1.0133156776428223, Accuracy: 0.64453125\n",
      "Batch: 134, Loss: 1.1279106140136719, Accuracy: 0.634765625\n",
      "Batch: 135, Loss: 1.0037411451339722, Accuracy: 0.681640625\n",
      "Batch: 136, Loss: 1.102958083152771, Accuracy: 0.6328125\n",
      "Batch: 137, Loss: 1.0340394973754883, Accuracy: 0.63671875\n",
      "Batch: 138, Loss: 0.9188902378082275, Accuracy: 0.6943359375\n",
      "Batch: 139, Loss: 0.9902682304382324, Accuracy: 0.662109375\n",
      "Batch: 140, Loss: 1.0883164405822754, Accuracy: 0.6484375\n",
      "Batch: 141, Loss: 1.1231931447982788, Accuracy: 0.638671875\n",
      "Batch: 142, Loss: 1.145118236541748, Accuracy: 0.6201171875\n",
      "Batch: 143, Loss: 1.1255725622177124, Accuracy: 0.6318359375\n",
      "Batch: 144, Loss: 1.0814595222473145, Accuracy: 0.6376953125\n",
      "Batch: 145, Loss: 1.0582022666931152, Accuracy: 0.626953125\n",
      "Batch: 146, Loss: 1.1230758428573608, Accuracy: 0.623046875\n",
      "Batch: 147, Loss: 1.1368048191070557, Accuracy: 0.626953125\n",
      "Batch: 148, Loss: 1.2620978355407715, Accuracy: 0.568359375\n",
      "Batch: 149, Loss: 1.13032865524292, Accuracy: 0.615234375\n",
      "Batch: 150, Loss: 1.072014331817627, Accuracy: 0.6552734375\n",
      "Batch: 151, Loss: 0.9934872984886169, Accuracy: 0.6904296875\n",
      "Epoch 18/80\n",
      "Batch: 1, Loss: 1.3721177577972412, Accuracy: 0.5537109375\n",
      "Batch: 2, Loss: 1.1708908081054688, Accuracy: 0.60546875\n",
      "Batch: 3, Loss: 1.0567384958267212, Accuracy: 0.638671875\n",
      "Batch: 4, Loss: 0.9826779961585999, Accuracy: 0.6884765625\n",
      "Batch: 5, Loss: 1.0308419466018677, Accuracy: 0.654296875\n",
      "Batch: 6, Loss: 1.1474395990371704, Accuracy: 0.5986328125\n",
      "Batch: 7, Loss: 1.0587742328643799, Accuracy: 0.6298828125\n",
      "Batch: 8, Loss: 1.0222711563110352, Accuracy: 0.64453125\n",
      "Batch: 9, Loss: 0.9536914825439453, Accuracy: 0.6982421875\n",
      "Batch: 10, Loss: 1.0087209939956665, Accuracy: 0.6611328125\n",
      "Batch: 11, Loss: 1.1894817352294922, Accuracy: 0.6025390625\n",
      "Batch: 12, Loss: 1.1895818710327148, Accuracy: 0.6162109375\n",
      "Batch: 13, Loss: 0.938755452632904, Accuracy: 0.69921875\n",
      "Batch: 14, Loss: 1.2038487195968628, Accuracy: 0.599609375\n",
      "Batch: 15, Loss: 1.0184015035629272, Accuracy: 0.6787109375\n",
      "Batch: 16, Loss: 1.0491478443145752, Accuracy: 0.6640625\n",
      "Batch: 17, Loss: 1.1405214071273804, Accuracy: 0.63671875\n",
      "Batch: 18, Loss: 1.1398943662643433, Accuracy: 0.634765625\n",
      "Batch: 19, Loss: 1.1536897420883179, Accuracy: 0.6279296875\n",
      "Batch: 20, Loss: 1.0456416606903076, Accuracy: 0.6796875\n",
      "Batch: 21, Loss: 1.0211668014526367, Accuracy: 0.65625\n",
      "Batch: 22, Loss: 1.1412888765335083, Accuracy: 0.640625\n",
      "Batch: 23, Loss: 1.0672295093536377, Accuracy: 0.662109375\n",
      "Batch: 24, Loss: 1.099389910697937, Accuracy: 0.6396484375\n",
      "Batch: 25, Loss: 1.0985196828842163, Accuracy: 0.64453125\n",
      "Batch: 26, Loss: 0.9733715653419495, Accuracy: 0.6787109375\n",
      "Batch: 27, Loss: 1.0359182357788086, Accuracy: 0.638671875\n",
      "Batch: 28, Loss: 1.14972722530365, Accuracy: 0.6201171875\n",
      "Batch: 29, Loss: 1.0577443838119507, Accuracy: 0.63671875\n",
      "Batch: 30, Loss: 0.9974220395088196, Accuracy: 0.6953125\n",
      "Batch: 31, Loss: 1.0223116874694824, Accuracy: 0.6796875\n",
      "Batch: 32, Loss: 0.9793537855148315, Accuracy: 0.6767578125\n",
      "Batch: 33, Loss: 1.1740365028381348, Accuracy: 0.6142578125\n",
      "Batch: 34, Loss: 1.2190990447998047, Accuracy: 0.607421875\n",
      "Batch: 35, Loss: 1.1382348537445068, Accuracy: 0.611328125\n",
      "Batch: 36, Loss: 1.1235257387161255, Accuracy: 0.6259765625\n",
      "Batch: 37, Loss: 1.0824512243270874, Accuracy: 0.6337890625\n",
      "Batch: 38, Loss: 1.1366245746612549, Accuracy: 0.626953125\n",
      "Batch: 39, Loss: 1.1462262868881226, Accuracy: 0.638671875\n",
      "Batch: 40, Loss: 1.1343046426773071, Accuracy: 0.6376953125\n",
      "Batch: 41, Loss: 1.12184476852417, Accuracy: 0.630859375\n",
      "Batch: 42, Loss: 0.9071736335754395, Accuracy: 0.689453125\n",
      "Batch: 43, Loss: 1.1275293827056885, Accuracy: 0.6201171875\n",
      "Batch: 44, Loss: 1.114858865737915, Accuracy: 0.623046875\n",
      "Batch: 45, Loss: 0.9794007539749146, Accuracy: 0.671875\n",
      "Batch: 46, Loss: 1.0478801727294922, Accuracy: 0.6796875\n",
      "Batch: 47, Loss: 1.0536692142486572, Accuracy: 0.6640625\n",
      "Batch: 48, Loss: 1.0122109651565552, Accuracy: 0.673828125\n",
      "Batch: 49, Loss: 1.1858410835266113, Accuracy: 0.6171875\n",
      "Batch: 50, Loss: 1.1890873908996582, Accuracy: 0.6044921875\n",
      "Batch: 51, Loss: 1.2377469539642334, Accuracy: 0.5888671875\n",
      "Batch: 52, Loss: 1.1852747201919556, Accuracy: 0.6328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 53, Loss: 1.0156347751617432, Accuracy: 0.654296875\n",
      "Batch: 54, Loss: 1.1093392372131348, Accuracy: 0.6484375\n",
      "Batch: 55, Loss: 1.1643198728561401, Accuracy: 0.6181640625\n",
      "Batch: 56, Loss: 1.1415278911590576, Accuracy: 0.65234375\n",
      "Batch: 57, Loss: 1.0563793182373047, Accuracy: 0.662109375\n",
      "Batch: 58, Loss: 1.1931891441345215, Accuracy: 0.63671875\n",
      "Batch: 59, Loss: 0.995037317276001, Accuracy: 0.689453125\n",
      "Batch: 60, Loss: 0.964292585849762, Accuracy: 0.6845703125\n",
      "Batch: 61, Loss: 1.1191942691802979, Accuracy: 0.6357421875\n",
      "Batch: 62, Loss: 1.0789588689804077, Accuracy: 0.666015625\n",
      "Batch: 63, Loss: 1.0880310535430908, Accuracy: 0.6513671875\n",
      "Batch: 64, Loss: 1.0630136728286743, Accuracy: 0.6533203125\n",
      "Batch: 65, Loss: 1.1088502407073975, Accuracy: 0.6376953125\n",
      "Batch: 66, Loss: 1.0394458770751953, Accuracy: 0.65625\n",
      "Batch: 67, Loss: 1.1715410947799683, Accuracy: 0.62890625\n",
      "Batch: 68, Loss: 1.1767303943634033, Accuracy: 0.638671875\n",
      "Batch: 69, Loss: 1.1076886653900146, Accuracy: 0.6484375\n",
      "Batch: 70, Loss: 1.0943650007247925, Accuracy: 0.671875\n",
      "Batch: 71, Loss: 1.1398980617523193, Accuracy: 0.6328125\n",
      "Batch: 72, Loss: 0.974787712097168, Accuracy: 0.671875\n",
      "Batch: 73, Loss: 1.038781762123108, Accuracy: 0.6728515625\n",
      "Batch: 74, Loss: 1.0074265003204346, Accuracy: 0.67578125\n",
      "Batch: 75, Loss: 0.9950149059295654, Accuracy: 0.677734375\n",
      "Batch: 76, Loss: 1.0957989692687988, Accuracy: 0.619140625\n",
      "Batch: 77, Loss: 1.0926530361175537, Accuracy: 0.640625\n",
      "Batch: 78, Loss: 1.038694143295288, Accuracy: 0.6796875\n",
      "Batch: 79, Loss: 0.9483339190483093, Accuracy: 0.712890625\n",
      "Batch: 80, Loss: 1.0179717540740967, Accuracy: 0.6455078125\n",
      "Batch: 81, Loss: 1.164763331413269, Accuracy: 0.6015625\n",
      "Batch: 82, Loss: 1.112974762916565, Accuracy: 0.640625\n",
      "Batch: 83, Loss: 0.9634805917739868, Accuracy: 0.6962890625\n",
      "Batch: 84, Loss: 1.0241955518722534, Accuracy: 0.685546875\n",
      "Batch: 85, Loss: 0.981474757194519, Accuracy: 0.6845703125\n",
      "Batch: 86, Loss: 1.2405028343200684, Accuracy: 0.62109375\n",
      "Batch: 87, Loss: 1.0230755805969238, Accuracy: 0.6591796875\n",
      "Batch: 88, Loss: 1.1199727058410645, Accuracy: 0.66015625\n",
      "Batch: 89, Loss: 1.13685142993927, Accuracy: 0.63671875\n",
      "Batch: 90, Loss: 1.0253201723098755, Accuracy: 0.67578125\n",
      "Batch: 91, Loss: 1.041158676147461, Accuracy: 0.6494140625\n",
      "Batch: 92, Loss: 1.1105386018753052, Accuracy: 0.64453125\n",
      "Batch: 93, Loss: 1.066512107849121, Accuracy: 0.646484375\n",
      "Batch: 94, Loss: 1.012613296508789, Accuracy: 0.673828125\n",
      "Batch: 95, Loss: 1.1006709337234497, Accuracy: 0.6171875\n",
      "Batch: 96, Loss: 1.07741117477417, Accuracy: 0.646484375\n",
      "Batch: 97, Loss: 0.9247023463249207, Accuracy: 0.6953125\n",
      "Batch: 98, Loss: 0.9893828630447388, Accuracy: 0.6728515625\n",
      "Batch: 99, Loss: 0.9842261075973511, Accuracy: 0.669921875\n",
      "Batch: 100, Loss: 1.0431358814239502, Accuracy: 0.654296875\n",
      "Batch: 101, Loss: 1.1011123657226562, Accuracy: 0.650390625\n",
      "Batch: 102, Loss: 1.0555145740509033, Accuracy: 0.646484375\n",
      "Batch: 103, Loss: 1.1064082384109497, Accuracy: 0.6572265625\n",
      "Batch: 104, Loss: 1.0142247676849365, Accuracy: 0.6591796875\n",
      "Batch: 105, Loss: 1.1090269088745117, Accuracy: 0.630859375\n",
      "Batch: 106, Loss: 1.0682324171066284, Accuracy: 0.65625\n",
      "Batch: 107, Loss: 1.1621687412261963, Accuracy: 0.6328125\n",
      "Batch: 108, Loss: 1.1285337209701538, Accuracy: 0.623046875\n",
      "Batch: 109, Loss: 1.2181686162948608, Accuracy: 0.60546875\n",
      "Batch: 110, Loss: 0.9379672408103943, Accuracy: 0.677734375\n",
      "Batch: 111, Loss: 1.1148478984832764, Accuracy: 0.638671875\n",
      "Batch: 112, Loss: 1.0524216890335083, Accuracy: 0.6474609375\n",
      "Batch: 113, Loss: 1.0723955631256104, Accuracy: 0.6650390625\n",
      "Batch: 114, Loss: 1.1730668544769287, Accuracy: 0.611328125\n",
      "Batch: 115, Loss: 1.2278350591659546, Accuracy: 0.62890625\n",
      "Batch: 116, Loss: 1.1545970439910889, Accuracy: 0.63671875\n",
      "Batch: 117, Loss: 1.1476460695266724, Accuracy: 0.6396484375\n",
      "Batch: 118, Loss: 0.9575797319412231, Accuracy: 0.68359375\n",
      "Batch: 119, Loss: 0.9943944215774536, Accuracy: 0.6728515625\n",
      "Batch: 120, Loss: 1.150888204574585, Accuracy: 0.6171875\n",
      "Batch: 121, Loss: 1.1947782039642334, Accuracy: 0.5986328125\n",
      "Batch: 122, Loss: 1.0295302867889404, Accuracy: 0.6796875\n",
      "Batch: 123, Loss: 1.0440325736999512, Accuracy: 0.6689453125\n",
      "Batch: 124, Loss: 1.1006866693496704, Accuracy: 0.654296875\n",
      "Batch: 125, Loss: 1.1513829231262207, Accuracy: 0.626953125\n",
      "Batch: 126, Loss: 1.0941135883331299, Accuracy: 0.6484375\n",
      "Batch: 127, Loss: 0.9769247174263, Accuracy: 0.6943359375\n",
      "Batch: 128, Loss: 1.2270007133483887, Accuracy: 0.615234375\n",
      "Batch: 129, Loss: 1.044968843460083, Accuracy: 0.6513671875\n",
      "Batch: 130, Loss: 1.2653924226760864, Accuracy: 0.60546875\n",
      "Batch: 131, Loss: 1.103240728378296, Accuracy: 0.640625\n",
      "Batch: 132, Loss: 1.1186473369598389, Accuracy: 0.6484375\n",
      "Batch: 133, Loss: 1.0235553979873657, Accuracy: 0.6650390625\n",
      "Batch: 134, Loss: 1.1188071966171265, Accuracy: 0.6279296875\n",
      "Batch: 135, Loss: 1.0247962474822998, Accuracy: 0.6728515625\n",
      "Batch: 136, Loss: 1.0867854356765747, Accuracy: 0.6572265625\n",
      "Batch: 137, Loss: 1.0086427927017212, Accuracy: 0.6416015625\n",
      "Batch: 138, Loss: 0.9004136323928833, Accuracy: 0.6865234375\n",
      "Batch: 139, Loss: 0.9631538391113281, Accuracy: 0.6748046875\n",
      "Batch: 140, Loss: 1.0672016143798828, Accuracy: 0.6435546875\n",
      "Batch: 141, Loss: 1.09803307056427, Accuracy: 0.6240234375\n",
      "Batch: 142, Loss: 1.1302745342254639, Accuracy: 0.6162109375\n",
      "Batch: 143, Loss: 1.0937845706939697, Accuracy: 0.640625\n",
      "Batch: 144, Loss: 1.0892302989959717, Accuracy: 0.64453125\n",
      "Batch: 145, Loss: 1.0707035064697266, Accuracy: 0.603515625\n",
      "Batch: 146, Loss: 1.1451835632324219, Accuracy: 0.623046875\n",
      "Batch: 147, Loss: 1.1374759674072266, Accuracy: 0.6259765625\n",
      "Batch: 148, Loss: 1.2660951614379883, Accuracy: 0.5703125\n",
      "Batch: 149, Loss: 1.1047499179840088, Accuracy: 0.623046875\n",
      "Batch: 150, Loss: 1.0343784093856812, Accuracy: 0.6640625\n",
      "Batch: 151, Loss: 0.9383748769760132, Accuracy: 0.6962890625\n",
      "Epoch 19/80\n",
      "Batch: 1, Loss: 1.3531991243362427, Accuracy: 0.5615234375\n",
      "Batch: 2, Loss: 1.1356816291809082, Accuracy: 0.6162109375\n",
      "Batch: 3, Loss: 1.0363491773605347, Accuracy: 0.6572265625\n",
      "Batch: 4, Loss: 0.9549641609191895, Accuracy: 0.697265625\n",
      "Batch: 5, Loss: 1.0153636932373047, Accuracy: 0.6650390625\n",
      "Batch: 6, Loss: 1.0713064670562744, Accuracy: 0.6337890625\n",
      "Batch: 7, Loss: 1.0372061729431152, Accuracy: 0.640625\n",
      "Batch: 8, Loss: 1.0073744058609009, Accuracy: 0.658203125\n",
      "Batch: 9, Loss: 0.9589089751243591, Accuracy: 0.6875\n",
      "Batch: 10, Loss: 0.993077278137207, Accuracy: 0.671875\n",
      "Batch: 11, Loss: 1.1832785606384277, Accuracy: 0.6015625\n",
      "Batch: 12, Loss: 1.1448640823364258, Accuracy: 0.6220703125\n",
      "Batch: 13, Loss: 0.9002299308776855, Accuracy: 0.7109375\n",
      "Batch: 14, Loss: 1.1940603256225586, Accuracy: 0.61328125\n",
      "Batch: 15, Loss: 0.9752143025398254, Accuracy: 0.6826171875\n",
      "Batch: 16, Loss: 1.0317487716674805, Accuracy: 0.6708984375\n",
      "Batch: 17, Loss: 1.1001927852630615, Accuracy: 0.638671875\n",
      "Batch: 18, Loss: 1.1023920774459839, Accuracy: 0.623046875\n",
      "Batch: 19, Loss: 1.1286990642547607, Accuracy: 0.634765625\n",
      "Batch: 20, Loss: 1.0294716358184814, Accuracy: 0.673828125\n",
      "Batch: 21, Loss: 1.0081803798675537, Accuracy: 0.6650390625\n",
      "Batch: 22, Loss: 1.1188048124313354, Accuracy: 0.6376953125\n",
      "Batch: 23, Loss: 1.0626229047775269, Accuracy: 0.642578125\n",
      "Batch: 24, Loss: 1.1098707914352417, Accuracy: 0.634765625\n",
      "Batch: 25, Loss: 1.068434476852417, Accuracy: 0.650390625\n",
      "Batch: 26, Loss: 0.9761524796485901, Accuracy: 0.68359375\n",
      "Batch: 27, Loss: 1.0286271572113037, Accuracy: 0.6494140625\n",
      "Batch: 28, Loss: 1.1230930089950562, Accuracy: 0.6279296875\n",
      "Batch: 29, Loss: 1.0496333837509155, Accuracy: 0.6474609375\n",
      "Batch: 30, Loss: 1.0099636316299438, Accuracy: 0.6943359375\n",
      "Batch: 31, Loss: 1.003226399421692, Accuracy: 0.693359375\n",
      "Batch: 32, Loss: 1.0108680725097656, Accuracy: 0.6611328125\n",
      "Batch: 33, Loss: 1.202709436416626, Accuracy: 0.615234375\n",
      "Batch: 34, Loss: 1.29526948928833, Accuracy: 0.5966796875\n",
      "Batch: 35, Loss: 1.1073832511901855, Accuracy: 0.6279296875\n",
      "Batch: 36, Loss: 1.1307237148284912, Accuracy: 0.642578125\n",
      "Batch: 37, Loss: 1.0856468677520752, Accuracy: 0.65625\n",
      "Batch: 38, Loss: 1.1205801963806152, Accuracy: 0.6337890625\n",
      "Batch: 39, Loss: 1.110440731048584, Accuracy: 0.638671875\n",
      "Batch: 40, Loss: 1.091994047164917, Accuracy: 0.6474609375\n",
      "Batch: 41, Loss: 1.0736862421035767, Accuracy: 0.6611328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 42, Loss: 0.8928189277648926, Accuracy: 0.708984375\n",
      "Batch: 43, Loss: 1.1038732528686523, Accuracy: 0.6328125\n",
      "Batch: 44, Loss: 1.0866315364837646, Accuracy: 0.615234375\n",
      "Batch: 45, Loss: 0.958408772945404, Accuracy: 0.66796875\n",
      "Batch: 46, Loss: 1.0148043632507324, Accuracy: 0.6748046875\n",
      "Batch: 47, Loss: 1.0459145307540894, Accuracy: 0.6689453125\n",
      "Batch: 48, Loss: 0.9971374869346619, Accuracy: 0.66796875\n",
      "Batch: 49, Loss: 1.2093067169189453, Accuracy: 0.6044921875\n",
      "Batch: 50, Loss: 1.156235933303833, Accuracy: 0.6142578125\n",
      "Batch: 51, Loss: 1.230541467666626, Accuracy: 0.603515625\n",
      "Batch: 52, Loss: 1.1959528923034668, Accuracy: 0.619140625\n",
      "Batch: 53, Loss: 1.0076323747634888, Accuracy: 0.662109375\n",
      "Batch: 54, Loss: 1.0778650045394897, Accuracy: 0.6513671875\n",
      "Batch: 55, Loss: 1.1179265975952148, Accuracy: 0.6396484375\n",
      "Batch: 56, Loss: 1.139670729637146, Accuracy: 0.6298828125\n",
      "Batch: 57, Loss: 1.0637439489364624, Accuracy: 0.6640625\n",
      "Batch: 58, Loss: 1.1891934871673584, Accuracy: 0.63671875\n",
      "Batch: 59, Loss: 0.9565277695655823, Accuracy: 0.6982421875\n",
      "Batch: 60, Loss: 0.9625338912010193, Accuracy: 0.6875\n",
      "Batch: 61, Loss: 1.0984513759613037, Accuracy: 0.6494140625\n",
      "Batch: 62, Loss: 1.0633723735809326, Accuracy: 0.642578125\n",
      "Batch: 63, Loss: 1.0873212814331055, Accuracy: 0.6484375\n",
      "Batch: 64, Loss: 1.0642446279525757, Accuracy: 0.6494140625\n",
      "Batch: 65, Loss: 1.0956552028656006, Accuracy: 0.65234375\n",
      "Batch: 66, Loss: 1.0170537233352661, Accuracy: 0.671875\n",
      "Batch: 67, Loss: 1.173201084136963, Accuracy: 0.6220703125\n",
      "Batch: 68, Loss: 1.1387403011322021, Accuracy: 0.6455078125\n",
      "Batch: 69, Loss: 1.0817700624465942, Accuracy: 0.662109375\n",
      "Batch: 70, Loss: 1.0868933200836182, Accuracy: 0.6533203125\n",
      "Batch: 71, Loss: 1.1080060005187988, Accuracy: 0.64453125\n",
      "Batch: 72, Loss: 0.9713469743728638, Accuracy: 0.6767578125\n",
      "Batch: 73, Loss: 1.025815486907959, Accuracy: 0.666015625\n",
      "Batch: 74, Loss: 0.9916812181472778, Accuracy: 0.6748046875\n",
      "Batch: 75, Loss: 0.9878247976303101, Accuracy: 0.6787109375\n",
      "Batch: 76, Loss: 1.0807476043701172, Accuracy: 0.6240234375\n",
      "Batch: 77, Loss: 1.0869536399841309, Accuracy: 0.6376953125\n",
      "Batch: 78, Loss: 1.0159900188446045, Accuracy: 0.6787109375\n",
      "Batch: 79, Loss: 0.9384040832519531, Accuracy: 0.7138671875\n",
      "Batch: 80, Loss: 0.9855613112449646, Accuracy: 0.662109375\n",
      "Batch: 81, Loss: 1.1684949398040771, Accuracy: 0.599609375\n",
      "Batch: 82, Loss: 1.1013485193252563, Accuracy: 0.640625\n",
      "Batch: 83, Loss: 0.941138744354248, Accuracy: 0.7099609375\n",
      "Batch: 84, Loss: 1.0231902599334717, Accuracy: 0.6884765625\n",
      "Batch: 85, Loss: 0.9790407419204712, Accuracy: 0.6982421875\n",
      "Batch: 86, Loss: 1.2113945484161377, Accuracy: 0.6259765625\n",
      "Batch: 87, Loss: 0.9844489097595215, Accuracy: 0.6845703125\n",
      "Batch: 88, Loss: 1.1429040431976318, Accuracy: 0.634765625\n",
      "Batch: 89, Loss: 1.120764970779419, Accuracy: 0.6484375\n",
      "Batch: 90, Loss: 1.0153083801269531, Accuracy: 0.671875\n",
      "Batch: 91, Loss: 1.0708551406860352, Accuracy: 0.6494140625\n",
      "Batch: 92, Loss: 1.09422767162323, Accuracy: 0.6328125\n",
      "Batch: 93, Loss: 1.0513684749603271, Accuracy: 0.6650390625\n",
      "Batch: 94, Loss: 1.0307472944259644, Accuracy: 0.65234375\n",
      "Batch: 95, Loss: 1.0780727863311768, Accuracy: 0.634765625\n",
      "Batch: 96, Loss: 1.070631504058838, Accuracy: 0.650390625\n",
      "Batch: 97, Loss: 0.9147032499313354, Accuracy: 0.703125\n",
      "Batch: 98, Loss: 0.9726920127868652, Accuracy: 0.685546875\n",
      "Batch: 99, Loss: 0.9800847172737122, Accuracy: 0.6748046875\n",
      "Batch: 100, Loss: 1.0430039167404175, Accuracy: 0.654296875\n",
      "Batch: 101, Loss: 1.1098614931106567, Accuracy: 0.6357421875\n",
      "Batch: 102, Loss: 1.012183666229248, Accuracy: 0.67578125\n",
      "Batch: 103, Loss: 1.1040990352630615, Accuracy: 0.654296875\n",
      "Batch: 104, Loss: 0.997011125087738, Accuracy: 0.669921875\n",
      "Batch: 105, Loss: 1.1027778387069702, Accuracy: 0.640625\n",
      "Batch: 106, Loss: 1.0760157108306885, Accuracy: 0.6572265625\n",
      "Batch: 107, Loss: 1.1323528289794922, Accuracy: 0.640625\n",
      "Batch: 108, Loss: 1.1257143020629883, Accuracy: 0.6181640625\n",
      "Batch: 109, Loss: 1.2133102416992188, Accuracy: 0.6005859375\n",
      "Batch: 110, Loss: 0.9270471334457397, Accuracy: 0.6884765625\n",
      "Batch: 111, Loss: 1.092395544052124, Accuracy: 0.63671875\n",
      "Batch: 112, Loss: 1.0420235395431519, Accuracy: 0.6591796875\n",
      "Batch: 113, Loss: 1.061501145362854, Accuracy: 0.6630859375\n",
      "Batch: 114, Loss: 1.1541125774383545, Accuracy: 0.6337890625\n",
      "Batch: 115, Loss: 1.2015948295593262, Accuracy: 0.630859375\n",
      "Batch: 116, Loss: 1.129386067390442, Accuracy: 0.630859375\n",
      "Batch: 117, Loss: 1.13057279586792, Accuracy: 0.640625\n",
      "Batch: 118, Loss: 0.9481642842292786, Accuracy: 0.7021484375\n",
      "Batch: 119, Loss: 0.9777017831802368, Accuracy: 0.685546875\n",
      "Batch: 120, Loss: 1.1255271434783936, Accuracy: 0.6259765625\n",
      "Batch: 121, Loss: 1.1780319213867188, Accuracy: 0.62109375\n",
      "Batch: 122, Loss: 1.0146138668060303, Accuracy: 0.6787109375\n",
      "Batch: 123, Loss: 1.0417659282684326, Accuracy: 0.677734375\n",
      "Batch: 124, Loss: 1.0740783214569092, Accuracy: 0.6591796875\n",
      "Batch: 125, Loss: 1.1010764837265015, Accuracy: 0.6435546875\n",
      "Batch: 126, Loss: 1.0859414339065552, Accuracy: 0.640625\n",
      "Batch: 127, Loss: 0.9756927490234375, Accuracy: 0.697265625\n",
      "Batch: 128, Loss: 1.1980323791503906, Accuracy: 0.6279296875\n",
      "Batch: 129, Loss: 1.0213277339935303, Accuracy: 0.666015625\n",
      "Batch: 130, Loss: 1.2448447942733765, Accuracy: 0.611328125\n",
      "Batch: 131, Loss: 1.101374626159668, Accuracy: 0.638671875\n",
      "Batch: 132, Loss: 1.1193526983261108, Accuracy: 0.6376953125\n",
      "Batch: 133, Loss: 0.9684220552444458, Accuracy: 0.671875\n",
      "Batch: 134, Loss: 1.0602681636810303, Accuracy: 0.642578125\n",
      "Batch: 135, Loss: 0.9843689203262329, Accuracy: 0.69140625\n",
      "Batch: 136, Loss: 1.0915930271148682, Accuracy: 0.63671875\n",
      "Batch: 137, Loss: 1.0150625705718994, Accuracy: 0.63671875\n",
      "Batch: 138, Loss: 0.8872367143630981, Accuracy: 0.697265625\n",
      "Batch: 139, Loss: 0.9639238715171814, Accuracy: 0.669921875\n",
      "Batch: 140, Loss: 1.0545188188552856, Accuracy: 0.6357421875\n",
      "Batch: 141, Loss: 1.0760034322738647, Accuracy: 0.6435546875\n",
      "Batch: 142, Loss: 1.1178045272827148, Accuracy: 0.6337890625\n",
      "Batch: 143, Loss: 1.0889768600463867, Accuracy: 0.6435546875\n",
      "Batch: 144, Loss: 1.0613014698028564, Accuracy: 0.6513671875\n",
      "Batch: 145, Loss: 1.044799566268921, Accuracy: 0.6298828125\n",
      "Batch: 146, Loss: 1.1227227449417114, Accuracy: 0.626953125\n",
      "Batch: 147, Loss: 1.1229650974273682, Accuracy: 0.6279296875\n",
      "Batch: 148, Loss: 1.217414379119873, Accuracy: 0.578125\n",
      "Batch: 149, Loss: 1.083075761795044, Accuracy: 0.6474609375\n",
      "Batch: 150, Loss: 1.0440735816955566, Accuracy: 0.650390625\n",
      "Batch: 151, Loss: 0.9516583681106567, Accuracy: 0.6923828125\n",
      "Epoch 20/80\n",
      "Batch: 1, Loss: 1.3064302206039429, Accuracy: 0.5888671875\n",
      "Batch: 2, Loss: 1.1156584024429321, Accuracy: 0.630859375\n",
      "Batch: 3, Loss: 1.0054526329040527, Accuracy: 0.6630859375\n",
      "Batch: 4, Loss: 0.9253134727478027, Accuracy: 0.703125\n",
      "Batch: 5, Loss: 0.9927123785018921, Accuracy: 0.6767578125\n",
      "Batch: 6, Loss: 1.0755202770233154, Accuracy: 0.6435546875\n",
      "Batch: 7, Loss: 1.024381160736084, Accuracy: 0.6474609375\n",
      "Batch: 8, Loss: 0.9642647504806519, Accuracy: 0.6708984375\n",
      "Batch: 9, Loss: 0.9821505546569824, Accuracy: 0.685546875\n",
      "Batch: 10, Loss: 0.9835331439971924, Accuracy: 0.6689453125\n",
      "Batch: 11, Loss: 1.158653974533081, Accuracy: 0.61328125\n",
      "Batch: 12, Loss: 1.1324427127838135, Accuracy: 0.646484375\n",
      "Batch: 13, Loss: 0.8952524065971375, Accuracy: 0.7021484375\n",
      "Batch: 14, Loss: 1.1709949970245361, Accuracy: 0.6083984375\n",
      "Batch: 15, Loss: 0.9820200204849243, Accuracy: 0.6875\n",
      "Batch: 16, Loss: 1.024812936782837, Accuracy: 0.6708984375\n",
      "Batch: 17, Loss: 1.0926060676574707, Accuracy: 0.6376953125\n",
      "Batch: 18, Loss: 1.1037094593048096, Accuracy: 0.626953125\n",
      "Batch: 19, Loss: 1.13052237033844, Accuracy: 0.6318359375\n",
      "Batch: 20, Loss: 1.0010693073272705, Accuracy: 0.6884765625\n",
      "Batch: 21, Loss: 0.9988608956336975, Accuracy: 0.6572265625\n",
      "Batch: 22, Loss: 1.1147814989089966, Accuracy: 0.6640625\n",
      "Batch: 23, Loss: 1.0325678586959839, Accuracy: 0.662109375\n",
      "Batch: 24, Loss: 1.0769693851470947, Accuracy: 0.64453125\n",
      "Batch: 25, Loss: 1.0663607120513916, Accuracy: 0.65234375\n",
      "Batch: 26, Loss: 0.9572913646697998, Accuracy: 0.69140625\n",
      "Batch: 27, Loss: 1.0245033502578735, Accuracy: 0.646484375\n",
      "Batch: 28, Loss: 1.1060997247695923, Accuracy: 0.62890625\n",
      "Batch: 29, Loss: 1.032087802886963, Accuracy: 0.6455078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 30, Loss: 0.9737954139709473, Accuracy: 0.7060546875\n",
      "Batch: 31, Loss: 0.9817596077919006, Accuracy: 0.701171875\n",
      "Batch: 32, Loss: 0.9749199748039246, Accuracy: 0.6875\n",
      "Batch: 33, Loss: 1.1479558944702148, Accuracy: 0.62890625\n",
      "Batch: 34, Loss: 1.1872135400772095, Accuracy: 0.626953125\n",
      "Batch: 35, Loss: 1.0917541980743408, Accuracy: 0.6376953125\n",
      "Batch: 36, Loss: 1.0881627798080444, Accuracy: 0.6611328125\n",
      "Batch: 37, Loss: 1.0740206241607666, Accuracy: 0.6513671875\n",
      "Batch: 38, Loss: 1.1159813404083252, Accuracy: 0.623046875\n",
      "Batch: 39, Loss: 1.0808953046798706, Accuracy: 0.654296875\n",
      "Batch: 40, Loss: 1.0967193841934204, Accuracy: 0.6484375\n",
      "Batch: 41, Loss: 1.0542285442352295, Accuracy: 0.6591796875\n",
      "Batch: 42, Loss: 0.8769322633743286, Accuracy: 0.701171875\n",
      "Batch: 43, Loss: 1.0929145812988281, Accuracy: 0.6298828125\n",
      "Batch: 44, Loss: 1.088515043258667, Accuracy: 0.63671875\n",
      "Batch: 45, Loss: 0.9593451023101807, Accuracy: 0.669921875\n",
      "Batch: 46, Loss: 1.0120210647583008, Accuracy: 0.6865234375\n",
      "Batch: 47, Loss: 1.0197980403900146, Accuracy: 0.6884765625\n",
      "Batch: 48, Loss: 0.9745235443115234, Accuracy: 0.6796875\n",
      "Batch: 49, Loss: 1.2140560150146484, Accuracy: 0.607421875\n",
      "Batch: 50, Loss: 1.1712231636047363, Accuracy: 0.609375\n",
      "Batch: 51, Loss: 1.2102110385894775, Accuracy: 0.6044921875\n",
      "Batch: 52, Loss: 1.162341594696045, Accuracy: 0.6328125\n",
      "Batch: 53, Loss: 0.9729750156402588, Accuracy: 0.6748046875\n",
      "Batch: 54, Loss: 1.0812124013900757, Accuracy: 0.66796875\n",
      "Batch: 55, Loss: 1.112015724182129, Accuracy: 0.64453125\n",
      "Batch: 56, Loss: 1.1165895462036133, Accuracy: 0.6337890625\n",
      "Batch: 57, Loss: 1.0389723777770996, Accuracy: 0.681640625\n",
      "Batch: 58, Loss: 1.1599467992782593, Accuracy: 0.6396484375\n",
      "Batch: 59, Loss: 0.9741254448890686, Accuracy: 0.703125\n",
      "Batch: 60, Loss: 0.9480767846107483, Accuracy: 0.6884765625\n",
      "Batch: 61, Loss: 1.0830671787261963, Accuracy: 0.66015625\n",
      "Batch: 62, Loss: 1.0392820835113525, Accuracy: 0.658203125\n",
      "Batch: 63, Loss: 1.054865837097168, Accuracy: 0.6796875\n",
      "Batch: 64, Loss: 1.0674222707748413, Accuracy: 0.65625\n",
      "Batch: 65, Loss: 1.0837712287902832, Accuracy: 0.6494140625\n",
      "Batch: 66, Loss: 1.0102007389068604, Accuracy: 0.6669921875\n",
      "Batch: 67, Loss: 1.1394480466842651, Accuracy: 0.6396484375\n",
      "Batch: 68, Loss: 1.137297511100769, Accuracy: 0.6435546875\n",
      "Batch: 69, Loss: 1.0819958448410034, Accuracy: 0.6484375\n",
      "Batch: 70, Loss: 1.051243782043457, Accuracy: 0.677734375\n",
      "Batch: 71, Loss: 1.1051597595214844, Accuracy: 0.6494140625\n",
      "Batch: 72, Loss: 0.9418301582336426, Accuracy: 0.697265625\n",
      "Batch: 73, Loss: 0.982816219329834, Accuracy: 0.6953125\n",
      "Batch: 74, Loss: 1.0036464929580688, Accuracy: 0.669921875\n",
      "Batch: 75, Loss: 0.9525054693222046, Accuracy: 0.6904296875\n",
      "Batch: 76, Loss: 1.0712677240371704, Accuracy: 0.642578125\n",
      "Batch: 77, Loss: 1.062307596206665, Accuracy: 0.6494140625\n",
      "Batch: 78, Loss: 1.0210269689559937, Accuracy: 0.6748046875\n",
      "Batch: 79, Loss: 0.9112921357154846, Accuracy: 0.7314453125\n",
      "Batch: 80, Loss: 0.9894980192184448, Accuracy: 0.6533203125\n",
      "Batch: 81, Loss: 1.1391689777374268, Accuracy: 0.609375\n",
      "Batch: 82, Loss: 1.0781910419464111, Accuracy: 0.63671875\n",
      "Batch: 83, Loss: 0.9498590230941772, Accuracy: 0.70703125\n",
      "Batch: 84, Loss: 1.0005929470062256, Accuracy: 0.6826171875\n",
      "Batch: 85, Loss: 0.9485939145088196, Accuracy: 0.6845703125\n",
      "Batch: 86, Loss: 1.1897153854370117, Accuracy: 0.6240234375\n",
      "Batch: 87, Loss: 0.9869660139083862, Accuracy: 0.68359375\n",
      "Batch: 88, Loss: 1.1012256145477295, Accuracy: 0.654296875\n",
      "Batch: 89, Loss: 1.0945898294448853, Accuracy: 0.640625\n",
      "Batch: 90, Loss: 0.9832496643066406, Accuracy: 0.6708984375\n",
      "Batch: 91, Loss: 1.0361692905426025, Accuracy: 0.66796875\n",
      "Batch: 92, Loss: 1.086961030960083, Accuracy: 0.658203125\n",
      "Batch: 93, Loss: 1.0104494094848633, Accuracy: 0.6708984375\n",
      "Batch: 94, Loss: 1.0059939622879028, Accuracy: 0.6708984375\n",
      "Batch: 95, Loss: 1.0962756872177124, Accuracy: 0.62890625\n",
      "Batch: 96, Loss: 1.0681989192962646, Accuracy: 0.6640625\n",
      "Batch: 97, Loss: 0.8805839419364929, Accuracy: 0.7109375\n",
      "Batch: 98, Loss: 0.9744337797164917, Accuracy: 0.689453125\n",
      "Batch: 99, Loss: 0.9479030966758728, Accuracy: 0.6904296875\n",
      "Batch: 100, Loss: 1.0325440168380737, Accuracy: 0.66015625\n",
      "Batch: 101, Loss: 1.0869611501693726, Accuracy: 0.638671875\n",
      "Batch: 102, Loss: 1.0091171264648438, Accuracy: 0.681640625\n",
      "Batch: 103, Loss: 1.0865731239318848, Accuracy: 0.658203125\n",
      "Batch: 104, Loss: 0.9811584949493408, Accuracy: 0.6728515625\n",
      "Batch: 105, Loss: 1.1020530462265015, Accuracy: 0.634765625\n",
      "Batch: 106, Loss: 1.0363316535949707, Accuracy: 0.6630859375\n",
      "Batch: 107, Loss: 1.1384639739990234, Accuracy: 0.6416015625\n",
      "Batch: 108, Loss: 1.1014621257781982, Accuracy: 0.6318359375\n",
      "Batch: 109, Loss: 1.1794629096984863, Accuracy: 0.6123046875\n",
      "Batch: 110, Loss: 0.9005945920944214, Accuracy: 0.7001953125\n",
      "Batch: 111, Loss: 1.0658397674560547, Accuracy: 0.6357421875\n",
      "Batch: 112, Loss: 1.0436029434204102, Accuracy: 0.671875\n",
      "Batch: 113, Loss: 1.038480520248413, Accuracy: 0.6708984375\n",
      "Batch: 114, Loss: 1.1443209648132324, Accuracy: 0.6220703125\n",
      "Batch: 115, Loss: 1.190716028213501, Accuracy: 0.62890625\n",
      "Batch: 116, Loss: 1.109114170074463, Accuracy: 0.630859375\n",
      "Batch: 117, Loss: 1.1135566234588623, Accuracy: 0.642578125\n",
      "Batch: 118, Loss: 0.9257544875144958, Accuracy: 0.6962890625\n",
      "Batch: 119, Loss: 0.9803688526153564, Accuracy: 0.669921875\n",
      "Batch: 120, Loss: 1.1091328859329224, Accuracy: 0.634765625\n",
      "Batch: 121, Loss: 1.168533444404602, Accuracy: 0.6279296875\n",
      "Batch: 122, Loss: 1.004051923751831, Accuracy: 0.6826171875\n",
      "Batch: 123, Loss: 1.0375759601593018, Accuracy: 0.6689453125\n",
      "Batch: 124, Loss: 1.0635695457458496, Accuracy: 0.65234375\n",
      "Batch: 125, Loss: 1.0923304557800293, Accuracy: 0.6435546875\n",
      "Batch: 126, Loss: 1.083901286125183, Accuracy: 0.65234375\n",
      "Batch: 127, Loss: 0.949062705039978, Accuracy: 0.701171875\n",
      "Batch: 128, Loss: 1.1879469156265259, Accuracy: 0.6328125\n",
      "Batch: 129, Loss: 1.006066083908081, Accuracy: 0.6650390625\n",
      "Batch: 130, Loss: 1.2551894187927246, Accuracy: 0.6123046875\n",
      "Batch: 131, Loss: 1.0697200298309326, Accuracy: 0.650390625\n",
      "Batch: 132, Loss: 1.096681833267212, Accuracy: 0.6552734375\n",
      "Batch: 133, Loss: 0.9674937725067139, Accuracy: 0.6806640625\n",
      "Batch: 134, Loss: 1.0813262462615967, Accuracy: 0.6416015625\n",
      "Batch: 135, Loss: 0.9529716968536377, Accuracy: 0.705078125\n",
      "Batch: 136, Loss: 1.0762839317321777, Accuracy: 0.6640625\n",
      "Batch: 137, Loss: 1.002140998840332, Accuracy: 0.646484375\n",
      "Batch: 138, Loss: 0.8888514041900635, Accuracy: 0.685546875\n",
      "Batch: 139, Loss: 0.9511392712593079, Accuracy: 0.6728515625\n",
      "Batch: 140, Loss: 1.050842523574829, Accuracy: 0.654296875\n",
      "Batch: 141, Loss: 1.0552047491073608, Accuracy: 0.650390625\n",
      "Batch: 142, Loss: 1.1112228631973267, Accuracy: 0.623046875\n",
      "Batch: 143, Loss: 1.0696568489074707, Accuracy: 0.6611328125\n",
      "Batch: 144, Loss: 1.039350986480713, Accuracy: 0.6552734375\n",
      "Batch: 145, Loss: 1.0153701305389404, Accuracy: 0.6484375\n",
      "Batch: 146, Loss: 1.1093332767486572, Accuracy: 0.6357421875\n",
      "Batch: 147, Loss: 1.1039159297943115, Accuracy: 0.62890625\n",
      "Batch: 148, Loss: 1.1826493740081787, Accuracy: 0.5859375\n",
      "Batch: 149, Loss: 1.044136643409729, Accuracy: 0.638671875\n",
      "Batch: 150, Loss: 1.0252983570098877, Accuracy: 0.6650390625\n",
      "Batch: 151, Loss: 0.9293675422668457, Accuracy: 0.7099609375\n",
      "Saved Weights at epoch 20 to file Weights_20.h5\n",
      "Epoch 21/80\n",
      "Batch: 1, Loss: 1.3221352100372314, Accuracy: 0.580078125\n",
      "Batch: 2, Loss: 1.1207771301269531, Accuracy: 0.6201171875\n",
      "Batch: 3, Loss: 1.0063402652740479, Accuracy: 0.6513671875\n",
      "Batch: 4, Loss: 0.8963271379470825, Accuracy: 0.708984375\n",
      "Batch: 5, Loss: 0.9931445121765137, Accuracy: 0.69140625\n",
      "Batch: 6, Loss: 1.0406582355499268, Accuracy: 0.646484375\n",
      "Batch: 7, Loss: 1.0011277198791504, Accuracy: 0.662109375\n",
      "Batch: 8, Loss: 0.9812266230583191, Accuracy: 0.6689453125\n",
      "Batch: 9, Loss: 0.9361032247543335, Accuracy: 0.68359375\n",
      "Batch: 10, Loss: 0.96783447265625, Accuracy: 0.6826171875\n",
      "Batch: 11, Loss: 1.1545054912567139, Accuracy: 0.62109375\n",
      "Batch: 12, Loss: 1.1332578659057617, Accuracy: 0.630859375\n",
      "Batch: 13, Loss: 0.8680373430252075, Accuracy: 0.73046875\n",
      "Batch: 14, Loss: 1.1474167108535767, Accuracy: 0.623046875\n",
      "Batch: 15, Loss: 0.976834774017334, Accuracy: 0.7080078125\n",
      "Batch: 16, Loss: 1.0317881107330322, Accuracy: 0.67578125\n",
      "Batch: 17, Loss: 1.0937819480895996, Accuracy: 0.650390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 18, Loss: 1.1032512187957764, Accuracy: 0.6552734375\n",
      "Batch: 19, Loss: 1.1014951467514038, Accuracy: 0.646484375\n",
      "Batch: 20, Loss: 1.0386571884155273, Accuracy: 0.6806640625\n",
      "Batch: 21, Loss: 0.9853888750076294, Accuracy: 0.6845703125\n",
      "Batch: 22, Loss: 1.1148960590362549, Accuracy: 0.65625\n",
      "Batch: 23, Loss: 1.0405676364898682, Accuracy: 0.662109375\n",
      "Batch: 24, Loss: 1.0711661577224731, Accuracy: 0.6494140625\n",
      "Batch: 25, Loss: 1.0327988862991333, Accuracy: 0.66796875\n",
      "Batch: 26, Loss: 0.9291243553161621, Accuracy: 0.7060546875\n",
      "Batch: 27, Loss: 0.9835045337677002, Accuracy: 0.6630859375\n",
      "Batch: 28, Loss: 1.0848579406738281, Accuracy: 0.6318359375\n",
      "Batch: 29, Loss: 1.0434691905975342, Accuracy: 0.64453125\n",
      "Batch: 30, Loss: 0.9589366912841797, Accuracy: 0.7060546875\n",
      "Batch: 31, Loss: 0.949458658695221, Accuracy: 0.6923828125\n",
      "Batch: 32, Loss: 0.9722560048103333, Accuracy: 0.677734375\n",
      "Batch: 33, Loss: 1.1450169086456299, Accuracy: 0.6318359375\n",
      "Batch: 34, Loss: 1.1963095664978027, Accuracy: 0.6025390625\n",
      "Batch: 35, Loss: 1.0873932838439941, Accuracy: 0.6357421875\n",
      "Batch: 36, Loss: 1.080949068069458, Accuracy: 0.6474609375\n",
      "Batch: 37, Loss: 1.0536139011383057, Accuracy: 0.666015625\n",
      "Batch: 38, Loss: 1.081038475036621, Accuracy: 0.634765625\n",
      "Batch: 39, Loss: 1.0733824968338013, Accuracy: 0.650390625\n",
      "Batch: 40, Loss: 1.0893723964691162, Accuracy: 0.6630859375\n",
      "Batch: 41, Loss: 1.0395548343658447, Accuracy: 0.65625\n",
      "Batch: 42, Loss: 0.8471397757530212, Accuracy: 0.7177734375\n",
      "Batch: 43, Loss: 1.0939204692840576, Accuracy: 0.6240234375\n",
      "Batch: 44, Loss: 1.0676474571228027, Accuracy: 0.64453125\n",
      "Batch: 45, Loss: 0.9627331495285034, Accuracy: 0.6650390625\n",
      "Batch: 46, Loss: 0.9789896607398987, Accuracy: 0.6875\n",
      "Batch: 47, Loss: 1.0006213188171387, Accuracy: 0.685546875\n",
      "Batch: 48, Loss: 0.9641650915145874, Accuracy: 0.6806640625\n",
      "Batch: 49, Loss: 1.1862655878067017, Accuracy: 0.603515625\n",
      "Batch: 50, Loss: 1.1561908721923828, Accuracy: 0.6103515625\n",
      "Batch: 51, Loss: 1.1896772384643555, Accuracy: 0.6064453125\n",
      "Batch: 52, Loss: 1.1359777450561523, Accuracy: 0.6494140625\n",
      "Batch: 53, Loss: 0.9839702248573303, Accuracy: 0.6650390625\n",
      "Batch: 54, Loss: 1.0437052249908447, Accuracy: 0.677734375\n",
      "Batch: 55, Loss: 1.089329719543457, Accuracy: 0.640625\n",
      "Batch: 56, Loss: 1.1170164346694946, Accuracy: 0.6435546875\n",
      "Batch: 57, Loss: 1.0391461849212646, Accuracy: 0.6650390625\n",
      "Batch: 58, Loss: 1.143165111541748, Accuracy: 0.66015625\n",
      "Batch: 59, Loss: 0.9450348615646362, Accuracy: 0.7099609375\n",
      "Batch: 60, Loss: 0.9321935772895813, Accuracy: 0.6826171875\n",
      "Batch: 61, Loss: 1.0722813606262207, Accuracy: 0.650390625\n",
      "Batch: 62, Loss: 1.0460236072540283, Accuracy: 0.66796875\n",
      "Batch: 63, Loss: 1.0646134614944458, Accuracy: 0.6513671875\n",
      "Batch: 64, Loss: 1.0437041521072388, Accuracy: 0.666015625\n",
      "Batch: 65, Loss: 1.0680958032608032, Accuracy: 0.642578125\n",
      "Batch: 66, Loss: 1.0127366781234741, Accuracy: 0.673828125\n",
      "Batch: 67, Loss: 1.1246912479400635, Accuracy: 0.662109375\n",
      "Batch: 68, Loss: 1.1022394895553589, Accuracy: 0.650390625\n",
      "Batch: 69, Loss: 1.073329210281372, Accuracy: 0.65234375\n",
      "Batch: 70, Loss: 1.0475469827651978, Accuracy: 0.681640625\n",
      "Batch: 71, Loss: 1.0826663970947266, Accuracy: 0.66015625\n",
      "Batch: 72, Loss: 0.9577394723892212, Accuracy: 0.6962890625\n",
      "Batch: 73, Loss: 1.004959225654602, Accuracy: 0.6943359375\n",
      "Batch: 74, Loss: 0.9771103262901306, Accuracy: 0.68359375\n",
      "Batch: 75, Loss: 0.9227004647254944, Accuracy: 0.68359375\n",
      "Batch: 76, Loss: 1.0705020427703857, Accuracy: 0.6396484375\n",
      "Batch: 77, Loss: 1.0601733922958374, Accuracy: 0.646484375\n",
      "Batch: 78, Loss: 0.9931643009185791, Accuracy: 0.7041015625\n",
      "Batch: 79, Loss: 0.9150161743164062, Accuracy: 0.72265625\n",
      "Batch: 80, Loss: 0.9761924743652344, Accuracy: 0.662109375\n",
      "Batch: 81, Loss: 1.1305032968521118, Accuracy: 0.6025390625\n",
      "Batch: 82, Loss: 1.0845086574554443, Accuracy: 0.6298828125\n",
      "Batch: 83, Loss: 0.9161158800125122, Accuracy: 0.71875\n",
      "Batch: 84, Loss: 0.988821268081665, Accuracy: 0.685546875\n",
      "Batch: 85, Loss: 0.9608997106552124, Accuracy: 0.6845703125\n",
      "Batch: 86, Loss: 1.2077956199645996, Accuracy: 0.62109375\n",
      "Batch: 87, Loss: 0.9732694029808044, Accuracy: 0.689453125\n",
      "Batch: 88, Loss: 1.0864484310150146, Accuracy: 0.6494140625\n",
      "Batch: 89, Loss: 1.1003077030181885, Accuracy: 0.63671875\n",
      "Batch: 90, Loss: 0.9905042052268982, Accuracy: 0.6630859375\n",
      "Batch: 91, Loss: 1.0244176387786865, Accuracy: 0.6796875\n",
      "Batch: 92, Loss: 1.0607151985168457, Accuracy: 0.658203125\n",
      "Batch: 93, Loss: 1.0013633966445923, Accuracy: 0.671875\n",
      "Batch: 94, Loss: 1.026422142982483, Accuracy: 0.66015625\n",
      "Batch: 95, Loss: 1.075635552406311, Accuracy: 0.642578125\n",
      "Batch: 96, Loss: 1.0387213230133057, Accuracy: 0.677734375\n",
      "Batch: 97, Loss: 0.8955246210098267, Accuracy: 0.7138671875\n",
      "Batch: 98, Loss: 0.9597623944282532, Accuracy: 0.69921875\n",
      "Batch: 99, Loss: 0.9607932567596436, Accuracy: 0.693359375\n",
      "Batch: 100, Loss: 1.0044546127319336, Accuracy: 0.67578125\n",
      "Batch: 101, Loss: 1.0723176002502441, Accuracy: 0.65234375\n",
      "Batch: 102, Loss: 1.0123341083526611, Accuracy: 0.67578125\n",
      "Batch: 103, Loss: 1.0704818964004517, Accuracy: 0.6708984375\n",
      "Batch: 104, Loss: 0.9769330024719238, Accuracy: 0.693359375\n",
      "Batch: 105, Loss: 1.086545705795288, Accuracy: 0.6474609375\n",
      "Batch: 106, Loss: 1.0499181747436523, Accuracy: 0.658203125\n",
      "Batch: 107, Loss: 1.1044318675994873, Accuracy: 0.6416015625\n",
      "Batch: 108, Loss: 1.0590662956237793, Accuracy: 0.640625\n",
      "Batch: 109, Loss: 1.164259433746338, Accuracy: 0.6083984375\n",
      "Batch: 110, Loss: 0.8864859342575073, Accuracy: 0.69921875\n",
      "Batch: 111, Loss: 1.078296184539795, Accuracy: 0.625\n",
      "Batch: 112, Loss: 1.030984878540039, Accuracy: 0.6708984375\n",
      "Batch: 113, Loss: 1.0201796293258667, Accuracy: 0.68359375\n",
      "Batch: 114, Loss: 1.119216799736023, Accuracy: 0.642578125\n",
      "Batch: 115, Loss: 1.181496262550354, Accuracy: 0.642578125\n",
      "Batch: 116, Loss: 1.0820248126983643, Accuracy: 0.650390625\n",
      "Batch: 117, Loss: 1.1000996828079224, Accuracy: 0.6455078125\n",
      "Batch: 118, Loss: 0.9235565662384033, Accuracy: 0.6953125\n",
      "Batch: 119, Loss: 0.9514115452766418, Accuracy: 0.6875\n",
      "Batch: 120, Loss: 1.084775447845459, Accuracy: 0.6435546875\n",
      "Batch: 121, Loss: 1.1346765756607056, Accuracy: 0.6396484375\n",
      "Batch: 122, Loss: 0.9769091606140137, Accuracy: 0.6865234375\n",
      "Batch: 123, Loss: 1.0266464948654175, Accuracy: 0.66796875\n",
      "Batch: 124, Loss: 1.0437325239181519, Accuracy: 0.6630859375\n",
      "Batch: 125, Loss: 1.0967906713485718, Accuracy: 0.6513671875\n",
      "Batch: 126, Loss: 1.0417330265045166, Accuracy: 0.66796875\n",
      "Batch: 127, Loss: 0.9666160345077515, Accuracy: 0.689453125\n",
      "Batch: 128, Loss: 1.1796109676361084, Accuracy: 0.638671875\n",
      "Batch: 129, Loss: 0.9877885580062866, Accuracy: 0.6826171875\n",
      "Batch: 130, Loss: 1.207840085029602, Accuracy: 0.6171875\n",
      "Batch: 131, Loss: 1.062467336654663, Accuracy: 0.669921875\n",
      "Batch: 132, Loss: 1.0843772888183594, Accuracy: 0.64453125\n",
      "Batch: 133, Loss: 0.9733322262763977, Accuracy: 0.67578125\n",
      "Batch: 134, Loss: 1.0520024299621582, Accuracy: 0.6552734375\n",
      "Batch: 135, Loss: 0.974295973777771, Accuracy: 0.6943359375\n",
      "Batch: 136, Loss: 1.0493535995483398, Accuracy: 0.6572265625\n",
      "Batch: 137, Loss: 1.0032414197921753, Accuracy: 0.65234375\n",
      "Batch: 138, Loss: 0.8702606558799744, Accuracy: 0.7021484375\n",
      "Batch: 139, Loss: 0.9507673382759094, Accuracy: 0.6787109375\n",
      "Batch: 140, Loss: 1.0366853475570679, Accuracy: 0.646484375\n",
      "Batch: 141, Loss: 1.052503228187561, Accuracy: 0.65234375\n",
      "Batch: 142, Loss: 1.0571389198303223, Accuracy: 0.6650390625\n",
      "Batch: 143, Loss: 1.0641145706176758, Accuracy: 0.65234375\n",
      "Batch: 144, Loss: 1.035941243171692, Accuracy: 0.6513671875\n",
      "Batch: 145, Loss: 1.0041718482971191, Accuracy: 0.640625\n",
      "Batch: 146, Loss: 1.0805554389953613, Accuracy: 0.6337890625\n",
      "Batch: 147, Loss: 1.0698583126068115, Accuracy: 0.6474609375\n",
      "Batch: 148, Loss: 1.1911996603012085, Accuracy: 0.59375\n",
      "Batch: 149, Loss: 1.058720588684082, Accuracy: 0.6298828125\n",
      "Batch: 150, Loss: 1.0099750757217407, Accuracy: 0.6640625\n",
      "Batch: 151, Loss: 0.8997623324394226, Accuracy: 0.70703125\n",
      "Epoch 22/80\n",
      "Batch: 1, Loss: 1.3342480659484863, Accuracy: 0.5615234375\n",
      "Batch: 2, Loss: 1.1185721158981323, Accuracy: 0.6220703125\n",
      "Batch: 3, Loss: 0.9727892875671387, Accuracy: 0.6826171875\n",
      "Batch: 4, Loss: 0.8953793048858643, Accuracy: 0.705078125\n",
      "Batch: 5, Loss: 0.9632793068885803, Accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 6, Loss: 1.034645676612854, Accuracy: 0.6513671875\n",
      "Batch: 7, Loss: 0.9934595227241516, Accuracy: 0.662109375\n",
      "Batch: 8, Loss: 0.9538352489471436, Accuracy: 0.677734375\n",
      "Batch: 9, Loss: 0.9278457164764404, Accuracy: 0.7099609375\n",
      "Batch: 10, Loss: 0.9365729689598083, Accuracy: 0.68359375\n",
      "Batch: 11, Loss: 1.1126909255981445, Accuracy: 0.61328125\n",
      "Batch: 12, Loss: 1.0942165851593018, Accuracy: 0.6494140625\n",
      "Batch: 13, Loss: 0.8713404536247253, Accuracy: 0.7216796875\n",
      "Batch: 14, Loss: 1.1590503454208374, Accuracy: 0.6181640625\n",
      "Batch: 15, Loss: 0.938169002532959, Accuracy: 0.703125\n",
      "Batch: 16, Loss: 1.0198770761489868, Accuracy: 0.6865234375\n",
      "Batch: 17, Loss: 1.0692683458328247, Accuracy: 0.654296875\n",
      "Batch: 18, Loss: 1.0771658420562744, Accuracy: 0.6494140625\n",
      "Batch: 19, Loss: 1.1016404628753662, Accuracy: 0.650390625\n",
      "Batch: 20, Loss: 0.9982483386993408, Accuracy: 0.6865234375\n",
      "Batch: 21, Loss: 0.96478670835495, Accuracy: 0.6806640625\n",
      "Batch: 22, Loss: 1.1103339195251465, Accuracy: 0.6513671875\n",
      "Batch: 23, Loss: 1.019063949584961, Accuracy: 0.6591796875\n",
      "Batch: 24, Loss: 1.0563621520996094, Accuracy: 0.6611328125\n",
      "Batch: 25, Loss: 1.0239075422286987, Accuracy: 0.654296875\n",
      "Batch: 26, Loss: 0.927096962928772, Accuracy: 0.6923828125\n",
      "Batch: 27, Loss: 0.9843407869338989, Accuracy: 0.6689453125\n",
      "Batch: 28, Loss: 1.0642242431640625, Accuracy: 0.6455078125\n",
      "Batch: 29, Loss: 1.0252695083618164, Accuracy: 0.654296875\n",
      "Batch: 30, Loss: 0.9272074103355408, Accuracy: 0.708984375\n",
      "Batch: 31, Loss: 0.9636445641517639, Accuracy: 0.7021484375\n",
      "Batch: 32, Loss: 0.9459073543548584, Accuracy: 0.673828125\n",
      "Batch: 33, Loss: 1.1445304155349731, Accuracy: 0.62890625\n",
      "Batch: 34, Loss: 1.168688416481018, Accuracy: 0.6220703125\n",
      "Batch: 35, Loss: 1.0730476379394531, Accuracy: 0.650390625\n",
      "Batch: 36, Loss: 1.0703051090240479, Accuracy: 0.65234375\n",
      "Batch: 37, Loss: 1.061585783958435, Accuracy: 0.6455078125\n",
      "Batch: 38, Loss: 1.0890252590179443, Accuracy: 0.646484375\n",
      "Batch: 39, Loss: 1.0671170949935913, Accuracy: 0.650390625\n",
      "Batch: 40, Loss: 1.0527008771896362, Accuracy: 0.662109375\n",
      "Batch: 41, Loss: 1.0357239246368408, Accuracy: 0.666015625\n",
      "Batch: 42, Loss: 0.8578066825866699, Accuracy: 0.7060546875\n",
      "Batch: 43, Loss: 1.0734751224517822, Accuracy: 0.634765625\n",
      "Batch: 44, Loss: 1.058670997619629, Accuracy: 0.6376953125\n",
      "Batch: 45, Loss: 0.9460107088088989, Accuracy: 0.6748046875\n",
      "Batch: 46, Loss: 0.9736251831054688, Accuracy: 0.697265625\n",
      "Batch: 47, Loss: 0.9776358604431152, Accuracy: 0.6875\n",
      "Batch: 48, Loss: 0.9519376754760742, Accuracy: 0.6884765625\n",
      "Batch: 49, Loss: 1.1647956371307373, Accuracy: 0.6181640625\n",
      "Batch: 50, Loss: 1.1285178661346436, Accuracy: 0.62109375\n",
      "Batch: 51, Loss: 1.1664650440216064, Accuracy: 0.6162109375\n",
      "Batch: 52, Loss: 1.1255300045013428, Accuracy: 0.6279296875\n",
      "Batch: 53, Loss: 0.9720194339752197, Accuracy: 0.6708984375\n",
      "Batch: 54, Loss: 1.032801866531372, Accuracy: 0.6748046875\n",
      "Batch: 55, Loss: 1.1026980876922607, Accuracy: 0.6416015625\n",
      "Batch: 56, Loss: 1.1087660789489746, Accuracy: 0.64453125\n",
      "Batch: 57, Loss: 1.0346570014953613, Accuracy: 0.650390625\n",
      "Batch: 58, Loss: 1.1404247283935547, Accuracy: 0.650390625\n",
      "Batch: 59, Loss: 0.9522418975830078, Accuracy: 0.7001953125\n",
      "Batch: 60, Loss: 0.9281675815582275, Accuracy: 0.7060546875\n",
      "Batch: 61, Loss: 1.0714020729064941, Accuracy: 0.6513671875\n",
      "Batch: 62, Loss: 1.0073647499084473, Accuracy: 0.685546875\n",
      "Batch: 63, Loss: 1.0445740222930908, Accuracy: 0.6591796875\n",
      "Batch: 64, Loss: 1.0367534160614014, Accuracy: 0.666015625\n",
      "Batch: 65, Loss: 1.0533497333526611, Accuracy: 0.6630859375\n",
      "Batch: 66, Loss: 0.9577054977416992, Accuracy: 0.6943359375\n",
      "Batch: 67, Loss: 1.1236134767532349, Accuracy: 0.64453125\n",
      "Batch: 68, Loss: 1.1020939350128174, Accuracy: 0.6650390625\n",
      "Batch: 69, Loss: 1.0455105304718018, Accuracy: 0.6591796875\n",
      "Batch: 70, Loss: 1.0336769819259644, Accuracy: 0.67578125\n",
      "Batch: 71, Loss: 1.0586353540420532, Accuracy: 0.662109375\n",
      "Batch: 72, Loss: 0.9257293939590454, Accuracy: 0.69140625\n",
      "Batch: 73, Loss: 0.965653121471405, Accuracy: 0.7099609375\n",
      "Batch: 74, Loss: 0.9602454900741577, Accuracy: 0.68359375\n",
      "Batch: 75, Loss: 0.9428789019584656, Accuracy: 0.6943359375\n",
      "Batch: 76, Loss: 1.0733261108398438, Accuracy: 0.64453125\n",
      "Batch: 77, Loss: 1.0193291902542114, Accuracy: 0.6572265625\n",
      "Batch: 78, Loss: 0.9892189502716064, Accuracy: 0.69921875\n",
      "Batch: 79, Loss: 0.8890469074249268, Accuracy: 0.7265625\n",
      "Batch: 80, Loss: 0.9583426713943481, Accuracy: 0.6630859375\n",
      "Batch: 81, Loss: 1.1051703691482544, Accuracy: 0.6201171875\n",
      "Batch: 82, Loss: 1.0599145889282227, Accuracy: 0.6630859375\n",
      "Batch: 83, Loss: 0.9041626453399658, Accuracy: 0.7138671875\n",
      "Batch: 84, Loss: 0.9538124203681946, Accuracy: 0.705078125\n",
      "Batch: 85, Loss: 0.9256982207298279, Accuracy: 0.69921875\n",
      "Batch: 86, Loss: 1.1663572788238525, Accuracy: 0.638671875\n",
      "Batch: 87, Loss: 0.962944507598877, Accuracy: 0.6982421875\n",
      "Batch: 88, Loss: 1.0725369453430176, Accuracy: 0.6630859375\n",
      "Batch: 89, Loss: 1.056801676750183, Accuracy: 0.6591796875\n",
      "Batch: 90, Loss: 0.9815831780433655, Accuracy: 0.685546875\n",
      "Batch: 91, Loss: 0.9979342222213745, Accuracy: 0.6728515625\n",
      "Batch: 92, Loss: 1.0592732429504395, Accuracy: 0.6630859375\n",
      "Batch: 93, Loss: 1.0219203233718872, Accuracy: 0.6669921875\n",
      "Batch: 94, Loss: 0.9951375722885132, Accuracy: 0.6689453125\n",
      "Batch: 95, Loss: 1.051416277885437, Accuracy: 0.638671875\n",
      "Batch: 96, Loss: 1.0077686309814453, Accuracy: 0.6806640625\n",
      "Batch: 97, Loss: 0.8611420392990112, Accuracy: 0.7158203125\n",
      "Batch: 98, Loss: 0.9314373731613159, Accuracy: 0.7060546875\n",
      "Batch: 99, Loss: 0.9399224519729614, Accuracy: 0.701171875\n",
      "Batch: 100, Loss: 0.9748370051383972, Accuracy: 0.6748046875\n",
      "Batch: 101, Loss: 1.055213212966919, Accuracy: 0.6591796875\n",
      "Batch: 102, Loss: 0.9941500425338745, Accuracy: 0.677734375\n",
      "Batch: 103, Loss: 1.0559937953948975, Accuracy: 0.6767578125\n",
      "Batch: 104, Loss: 0.9373692870140076, Accuracy: 0.693359375\n",
      "Batch: 105, Loss: 1.059940218925476, Accuracy: 0.6435546875\n",
      "Batch: 106, Loss: 1.0116279125213623, Accuracy: 0.673828125\n",
      "Batch: 107, Loss: 1.0836302042007446, Accuracy: 0.65234375\n",
      "Batch: 108, Loss: 1.0209729671478271, Accuracy: 0.650390625\n",
      "Batch: 109, Loss: 1.1557073593139648, Accuracy: 0.6298828125\n",
      "Batch: 110, Loss: 0.9073612093925476, Accuracy: 0.6884765625\n",
      "Batch: 111, Loss: 1.0550165176391602, Accuracy: 0.6572265625\n",
      "Batch: 112, Loss: 1.0046582221984863, Accuracy: 0.68359375\n",
      "Batch: 113, Loss: 1.02458918094635, Accuracy: 0.6845703125\n",
      "Batch: 114, Loss: 1.0980110168457031, Accuracy: 0.6455078125\n",
      "Batch: 115, Loss: 1.1683920621871948, Accuracy: 0.630859375\n",
      "Batch: 116, Loss: 1.0655328035354614, Accuracy: 0.650390625\n",
      "Batch: 117, Loss: 1.0780584812164307, Accuracy: 0.6455078125\n",
      "Batch: 118, Loss: 0.9389879703521729, Accuracy: 0.69921875\n",
      "Batch: 119, Loss: 0.9334515333175659, Accuracy: 0.6904296875\n",
      "Batch: 120, Loss: 1.0945351123809814, Accuracy: 0.6455078125\n",
      "Batch: 121, Loss: 1.119767665863037, Accuracy: 0.638671875\n",
      "Batch: 122, Loss: 0.9623813629150391, Accuracy: 0.6826171875\n",
      "Batch: 123, Loss: 0.99690181016922, Accuracy: 0.6923828125\n",
      "Batch: 124, Loss: 1.0397858619689941, Accuracy: 0.6689453125\n",
      "Batch: 125, Loss: 1.0832816362380981, Accuracy: 0.623046875\n",
      "Batch: 126, Loss: 1.0412962436676025, Accuracy: 0.666015625\n",
      "Batch: 127, Loss: 0.9377518892288208, Accuracy: 0.6884765625\n",
      "Batch: 128, Loss: 1.1434376239776611, Accuracy: 0.6376953125\n",
      "Batch: 129, Loss: 0.9901292324066162, Accuracy: 0.6826171875\n",
      "Batch: 130, Loss: 1.223686695098877, Accuracy: 0.6064453125\n",
      "Batch: 131, Loss: 1.0564396381378174, Accuracy: 0.6552734375\n",
      "Batch: 132, Loss: 1.069594144821167, Accuracy: 0.6640625\n",
      "Batch: 133, Loss: 0.9419170618057251, Accuracy: 0.681640625\n",
      "Batch: 134, Loss: 1.0492404699325562, Accuracy: 0.638671875\n",
      "Batch: 135, Loss: 0.9552416205406189, Accuracy: 0.69140625\n",
      "Batch: 136, Loss: 1.0243806838989258, Accuracy: 0.6708984375\n",
      "Batch: 137, Loss: 0.9996435642242432, Accuracy: 0.6357421875\n",
      "Batch: 138, Loss: 0.8781274557113647, Accuracy: 0.69140625\n",
      "Batch: 139, Loss: 0.9248629808425903, Accuracy: 0.6953125\n",
      "Batch: 140, Loss: 1.0233337879180908, Accuracy: 0.6552734375\n",
      "Batch: 141, Loss: 1.0560855865478516, Accuracy: 0.64453125\n",
      "Batch: 142, Loss: 1.0548840761184692, Accuracy: 0.65625\n",
      "Batch: 143, Loss: 1.027872085571289, Accuracy: 0.6650390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 144, Loss: 1.0076483488082886, Accuracy: 0.669921875\n",
      "Batch: 145, Loss: 1.007489800453186, Accuracy: 0.638671875\n",
      "Batch: 146, Loss: 1.0703959465026855, Accuracy: 0.6494140625\n",
      "Batch: 147, Loss: 1.080020785331726, Accuracy: 0.6552734375\n",
      "Batch: 148, Loss: 1.184956431388855, Accuracy: 0.6025390625\n",
      "Batch: 149, Loss: 1.020227313041687, Accuracy: 0.650390625\n",
      "Batch: 150, Loss: 0.9735569953918457, Accuracy: 0.6669921875\n",
      "Batch: 151, Loss: 0.8822774887084961, Accuracy: 0.7138671875\n",
      "Epoch 23/80\n",
      "Batch: 1, Loss: 1.2595586776733398, Accuracy: 0.6044921875\n",
      "Batch: 2, Loss: 1.0925346612930298, Accuracy: 0.6279296875\n",
      "Batch: 3, Loss: 0.9887369275093079, Accuracy: 0.666015625\n",
      "Batch: 4, Loss: 0.8800409436225891, Accuracy: 0.7236328125\n",
      "Batch: 5, Loss: 0.9592324495315552, Accuracy: 0.689453125\n",
      "Batch: 6, Loss: 1.0373187065124512, Accuracy: 0.66015625\n",
      "Batch: 7, Loss: 0.9857399463653564, Accuracy: 0.66015625\n",
      "Batch: 8, Loss: 0.9220386743545532, Accuracy: 0.6904296875\n",
      "Batch: 9, Loss: 0.9299271106719971, Accuracy: 0.69921875\n",
      "Batch: 10, Loss: 0.9293736815452576, Accuracy: 0.6923828125\n",
      "Batch: 11, Loss: 1.1181626319885254, Accuracy: 0.6142578125\n",
      "Batch: 12, Loss: 1.0882833003997803, Accuracy: 0.6591796875\n",
      "Batch: 13, Loss: 0.8664257526397705, Accuracy: 0.7236328125\n",
      "Batch: 14, Loss: 1.1231489181518555, Accuracy: 0.6162109375\n",
      "Batch: 15, Loss: 0.9581537842750549, Accuracy: 0.703125\n",
      "Batch: 16, Loss: 0.9761625528335571, Accuracy: 0.6904296875\n",
      "Batch: 17, Loss: 1.058217167854309, Accuracy: 0.658203125\n",
      "Batch: 18, Loss: 1.0729031562805176, Accuracy: 0.646484375\n",
      "Batch: 19, Loss: 1.0752391815185547, Accuracy: 0.6591796875\n",
      "Batch: 20, Loss: 0.9715934991836548, Accuracy: 0.693359375\n",
      "Batch: 21, Loss: 0.9569807052612305, Accuracy: 0.6826171875\n",
      "Batch: 22, Loss: 1.076153039932251, Accuracy: 0.654296875\n",
      "Batch: 23, Loss: 1.004954218864441, Accuracy: 0.6708984375\n",
      "Batch: 24, Loss: 1.008315086364746, Accuracy: 0.654296875\n",
      "Batch: 25, Loss: 1.0083494186401367, Accuracy: 0.6591796875\n",
      "Batch: 26, Loss: 0.9139704704284668, Accuracy: 0.6796875\n",
      "Batch: 27, Loss: 0.9647293090820312, Accuracy: 0.669921875\n",
      "Batch: 28, Loss: 1.0710525512695312, Accuracy: 0.630859375\n",
      "Batch: 29, Loss: 0.9938936233520508, Accuracy: 0.66796875\n",
      "Batch: 30, Loss: 0.9402415156364441, Accuracy: 0.7216796875\n",
      "Batch: 31, Loss: 0.9290691018104553, Accuracy: 0.7021484375\n",
      "Batch: 32, Loss: 0.9123191833496094, Accuracy: 0.6923828125\n",
      "Batch: 33, Loss: 1.1175510883331299, Accuracy: 0.64453125\n",
      "Batch: 34, Loss: 1.1510366201400757, Accuracy: 0.6298828125\n",
      "Batch: 35, Loss: 1.0580577850341797, Accuracy: 0.6455078125\n",
      "Batch: 36, Loss: 1.0454092025756836, Accuracy: 0.6640625\n",
      "Batch: 37, Loss: 1.0257842540740967, Accuracy: 0.6494140625\n",
      "Batch: 38, Loss: 1.0477403402328491, Accuracy: 0.6513671875\n",
      "Batch: 39, Loss: 1.045985460281372, Accuracy: 0.662109375\n",
      "Batch: 40, Loss: 1.042154312133789, Accuracy: 0.669921875\n",
      "Batch: 41, Loss: 0.997688353061676, Accuracy: 0.6748046875\n",
      "Batch: 42, Loss: 0.8236366510391235, Accuracy: 0.72265625\n",
      "Batch: 43, Loss: 1.0718262195587158, Accuracy: 0.6416015625\n",
      "Batch: 44, Loss: 1.0458146333694458, Accuracy: 0.6337890625\n",
      "Batch: 45, Loss: 0.9109666347503662, Accuracy: 0.681640625\n",
      "Batch: 46, Loss: 0.9649007320404053, Accuracy: 0.6875\n",
      "Batch: 47, Loss: 0.9729818105697632, Accuracy: 0.6923828125\n",
      "Batch: 48, Loss: 0.9237213134765625, Accuracy: 0.701171875\n",
      "Batch: 49, Loss: 1.1281304359436035, Accuracy: 0.6337890625\n",
      "Batch: 50, Loss: 1.1114791631698608, Accuracy: 0.625\n",
      "Batch: 51, Loss: 1.1653985977172852, Accuracy: 0.6240234375\n",
      "Batch: 52, Loss: 1.1062026023864746, Accuracy: 0.669921875\n",
      "Batch: 53, Loss: 0.9545612335205078, Accuracy: 0.6845703125\n",
      "Batch: 54, Loss: 1.0332627296447754, Accuracy: 0.6728515625\n",
      "Batch: 55, Loss: 1.1122536659240723, Accuracy: 0.6318359375\n",
      "Batch: 56, Loss: 1.1007294654846191, Accuracy: 0.6455078125\n",
      "Batch: 57, Loss: 1.0277756452560425, Accuracy: 0.669921875\n",
      "Batch: 58, Loss: 1.1232925653457642, Accuracy: 0.6484375\n",
      "Batch: 59, Loss: 0.9296157360076904, Accuracy: 0.7001953125\n",
      "Batch: 60, Loss: 0.9248368144035339, Accuracy: 0.6904296875\n",
      "Batch: 61, Loss: 1.055686354637146, Accuracy: 0.671875\n",
      "Batch: 62, Loss: 1.0001006126403809, Accuracy: 0.6689453125\n",
      "Batch: 63, Loss: 1.0304038524627686, Accuracy: 0.669921875\n",
      "Batch: 64, Loss: 1.0224623680114746, Accuracy: 0.6689453125\n",
      "Batch: 65, Loss: 1.0311355590820312, Accuracy: 0.685546875\n",
      "Batch: 66, Loss: 0.9687588214874268, Accuracy: 0.7080078125\n",
      "Batch: 67, Loss: 1.0968633890151978, Accuracy: 0.6513671875\n",
      "Batch: 68, Loss: 1.109359622001648, Accuracy: 0.654296875\n",
      "Batch: 69, Loss: 1.0343234539031982, Accuracy: 0.6572265625\n",
      "Batch: 70, Loss: 1.007838487625122, Accuracy: 0.685546875\n",
      "Batch: 71, Loss: 1.075470209121704, Accuracy: 0.6494140625\n",
      "Batch: 72, Loss: 0.9017319083213806, Accuracy: 0.703125\n",
      "Batch: 73, Loss: 0.9372090101242065, Accuracy: 0.6962890625\n",
      "Batch: 74, Loss: 0.9430845379829407, Accuracy: 0.6923828125\n",
      "Batch: 75, Loss: 0.9270196557044983, Accuracy: 0.6904296875\n",
      "Batch: 76, Loss: 1.0463519096374512, Accuracy: 0.6337890625\n",
      "Batch: 77, Loss: 1.0158939361572266, Accuracy: 0.658203125\n",
      "Batch: 78, Loss: 0.9444724321365356, Accuracy: 0.7060546875\n",
      "Batch: 79, Loss: 0.886271595954895, Accuracy: 0.7265625\n",
      "Batch: 80, Loss: 0.9751120805740356, Accuracy: 0.6591796875\n",
      "Batch: 81, Loss: 1.097949743270874, Accuracy: 0.626953125\n",
      "Batch: 82, Loss: 1.0473957061767578, Accuracy: 0.65234375\n",
      "Batch: 83, Loss: 0.8715366125106812, Accuracy: 0.7119140625\n",
      "Batch: 84, Loss: 0.9783427715301514, Accuracy: 0.7021484375\n",
      "Batch: 85, Loss: 0.9196383357048035, Accuracy: 0.6884765625\n",
      "Batch: 86, Loss: 1.1646027565002441, Accuracy: 0.626953125\n",
      "Batch: 87, Loss: 0.9207956790924072, Accuracy: 0.697265625\n",
      "Batch: 88, Loss: 1.0579102039337158, Accuracy: 0.66015625\n",
      "Batch: 89, Loss: 1.0323761701583862, Accuracy: 0.6796875\n",
      "Batch: 90, Loss: 0.9729633927345276, Accuracy: 0.6806640625\n",
      "Batch: 91, Loss: 0.9756184816360474, Accuracy: 0.6884765625\n",
      "Batch: 92, Loss: 1.06184983253479, Accuracy: 0.6650390625\n",
      "Batch: 93, Loss: 0.9969577193260193, Accuracy: 0.669921875\n",
      "Batch: 94, Loss: 0.9886975884437561, Accuracy: 0.6767578125\n",
      "Batch: 95, Loss: 1.0439996719360352, Accuracy: 0.6552734375\n",
      "Batch: 96, Loss: 1.0193867683410645, Accuracy: 0.677734375\n",
      "Batch: 97, Loss: 0.8676853775978088, Accuracy: 0.7197265625\n",
      "Batch: 98, Loss: 0.924729585647583, Accuracy: 0.6904296875\n",
      "Batch: 99, Loss: 0.9462268352508545, Accuracy: 0.6904296875\n",
      "Batch: 100, Loss: 0.9709962606430054, Accuracy: 0.68359375\n",
      "Batch: 101, Loss: 1.0447649955749512, Accuracy: 0.6650390625\n",
      "Batch: 102, Loss: 0.985798716545105, Accuracy: 0.689453125\n",
      "Batch: 103, Loss: 1.050586462020874, Accuracy: 0.6708984375\n",
      "Batch: 104, Loss: 0.9321345686912537, Accuracy: 0.693359375\n",
      "Batch: 105, Loss: 1.0499238967895508, Accuracy: 0.66796875\n",
      "Batch: 106, Loss: 1.0111379623413086, Accuracy: 0.6787109375\n",
      "Batch: 107, Loss: 1.0585834980010986, Accuracy: 0.6494140625\n",
      "Batch: 108, Loss: 1.0412943363189697, Accuracy: 0.6572265625\n",
      "Batch: 109, Loss: 1.1296277046203613, Accuracy: 0.6171875\n",
      "Batch: 110, Loss: 0.8817204236984253, Accuracy: 0.705078125\n",
      "Batch: 111, Loss: 1.0478992462158203, Accuracy: 0.6484375\n",
      "Batch: 112, Loss: 0.9831126928329468, Accuracy: 0.6845703125\n",
      "Batch: 113, Loss: 1.0150556564331055, Accuracy: 0.6806640625\n",
      "Batch: 114, Loss: 1.0741500854492188, Accuracy: 0.6474609375\n",
      "Batch: 115, Loss: 1.1343690156936646, Accuracy: 0.6484375\n",
      "Batch: 116, Loss: 1.0622687339782715, Accuracy: 0.6552734375\n",
      "Batch: 117, Loss: 1.0842220783233643, Accuracy: 0.646484375\n",
      "Batch: 118, Loss: 0.9222223162651062, Accuracy: 0.7138671875\n",
      "Batch: 119, Loss: 0.903975248336792, Accuracy: 0.7041015625\n",
      "Batch: 120, Loss: 1.0578683614730835, Accuracy: 0.6591796875\n",
      "Batch: 121, Loss: 1.104346513748169, Accuracy: 0.6474609375\n",
      "Batch: 122, Loss: 0.9591332077980042, Accuracy: 0.6962890625\n",
      "Batch: 123, Loss: 1.0100319385528564, Accuracy: 0.6904296875\n",
      "Batch: 124, Loss: 0.9943500757217407, Accuracy: 0.6669921875\n",
      "Batch: 125, Loss: 1.057837724685669, Accuracy: 0.66015625\n",
      "Batch: 126, Loss: 1.0128517150878906, Accuracy: 0.66015625\n",
      "Batch: 127, Loss: 0.9216890931129456, Accuracy: 0.7041015625\n",
      "Batch: 128, Loss: 1.1279935836791992, Accuracy: 0.6533203125\n",
      "Batch: 129, Loss: 0.9738249778747559, Accuracy: 0.69140625\n",
      "Batch: 130, Loss: 1.2141218185424805, Accuracy: 0.623046875\n",
      "Batch: 131, Loss: 1.0665749311447144, Accuracy: 0.650390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 132, Loss: 1.0804202556610107, Accuracy: 0.65625\n",
      "Batch: 133, Loss: 0.9426887035369873, Accuracy: 0.6806640625\n",
      "Batch: 134, Loss: 1.0065011978149414, Accuracy: 0.6796875\n",
      "Batch: 135, Loss: 0.9360828995704651, Accuracy: 0.701171875\n",
      "Batch: 136, Loss: 1.016808032989502, Accuracy: 0.6630859375\n",
      "Batch: 137, Loss: 0.9608233571052551, Accuracy: 0.6748046875\n",
      "Batch: 138, Loss: 0.8569488525390625, Accuracy: 0.7080078125\n",
      "Batch: 139, Loss: 0.9357790946960449, Accuracy: 0.6884765625\n",
      "Batch: 140, Loss: 1.003067135810852, Accuracy: 0.6611328125\n",
      "Batch: 141, Loss: 1.0217739343643188, Accuracy: 0.662109375\n",
      "Batch: 142, Loss: 1.0362612009048462, Accuracy: 0.6572265625\n",
      "Batch: 143, Loss: 1.022818684577942, Accuracy: 0.6533203125\n",
      "Batch: 144, Loss: 1.0238993167877197, Accuracy: 0.669921875\n",
      "Batch: 145, Loss: 0.9786198139190674, Accuracy: 0.6455078125\n",
      "Batch: 146, Loss: 1.060408353805542, Accuracy: 0.6513671875\n",
      "Batch: 147, Loss: 1.0495414733886719, Accuracy: 0.6650390625\n",
      "Batch: 148, Loss: 1.1620323657989502, Accuracy: 0.5986328125\n",
      "Batch: 149, Loss: 1.0087554454803467, Accuracy: 0.671875\n",
      "Batch: 150, Loss: 1.0003597736358643, Accuracy: 0.67578125\n",
      "Batch: 151, Loss: 0.886393129825592, Accuracy: 0.712890625\n",
      "Epoch 24/80\n",
      "Batch: 1, Loss: 1.259615421295166, Accuracy: 0.587890625\n",
      "Batch: 2, Loss: 1.075368881225586, Accuracy: 0.63671875\n",
      "Batch: 3, Loss: 0.97159343957901, Accuracy: 0.6826171875\n",
      "Batch: 4, Loss: 0.8814496994018555, Accuracy: 0.70703125\n",
      "Batch: 5, Loss: 0.9364774227142334, Accuracy: 0.7021484375\n",
      "Batch: 6, Loss: 1.002591848373413, Accuracy: 0.6591796875\n",
      "Batch: 7, Loss: 0.9907848834991455, Accuracy: 0.66796875\n",
      "Batch: 8, Loss: 0.9259682297706604, Accuracy: 0.701171875\n",
      "Batch: 9, Loss: 0.8923090696334839, Accuracy: 0.72265625\n",
      "Batch: 10, Loss: 0.9299952387809753, Accuracy: 0.681640625\n",
      "Batch: 11, Loss: 1.10589599609375, Accuracy: 0.62109375\n",
      "Batch: 12, Loss: 1.0712344646453857, Accuracy: 0.654296875\n",
      "Batch: 13, Loss: 0.8436894416809082, Accuracy: 0.7197265625\n",
      "Batch: 14, Loss: 1.0978100299835205, Accuracy: 0.625\n",
      "Batch: 15, Loss: 0.9413415193557739, Accuracy: 0.703125\n",
      "Batch: 16, Loss: 0.9921460151672363, Accuracy: 0.673828125\n",
      "Batch: 17, Loss: 1.0311517715454102, Accuracy: 0.67578125\n",
      "Batch: 18, Loss: 1.0484275817871094, Accuracy: 0.673828125\n",
      "Batch: 19, Loss: 1.0622687339782715, Accuracy: 0.6611328125\n",
      "Batch: 20, Loss: 0.9689521193504333, Accuracy: 0.69140625\n",
      "Batch: 21, Loss: 0.9579833745956421, Accuracy: 0.681640625\n",
      "Batch: 22, Loss: 1.053593397140503, Accuracy: 0.66015625\n",
      "Batch: 23, Loss: 0.9936931133270264, Accuracy: 0.669921875\n",
      "Batch: 24, Loss: 1.0127097368240356, Accuracy: 0.66796875\n",
      "Batch: 25, Loss: 1.0170750617980957, Accuracy: 0.669921875\n",
      "Batch: 26, Loss: 0.9124313592910767, Accuracy: 0.6962890625\n",
      "Batch: 27, Loss: 0.9630880355834961, Accuracy: 0.66796875\n",
      "Batch: 28, Loss: 1.034599781036377, Accuracy: 0.6533203125\n",
      "Batch: 29, Loss: 0.9989527463912964, Accuracy: 0.6572265625\n",
      "Batch: 30, Loss: 0.9204201698303223, Accuracy: 0.712890625\n",
      "Batch: 31, Loss: 0.9345479011535645, Accuracy: 0.6962890625\n",
      "Batch: 32, Loss: 0.9377524256706238, Accuracy: 0.6904296875\n",
      "Batch: 33, Loss: 1.0745599269866943, Accuracy: 0.638671875\n",
      "Batch: 34, Loss: 1.1548583507537842, Accuracy: 0.6337890625\n",
      "Batch: 35, Loss: 1.056419014930725, Accuracy: 0.646484375\n",
      "Batch: 36, Loss: 1.0671265125274658, Accuracy: 0.6513671875\n",
      "Batch: 37, Loss: 1.0323481559753418, Accuracy: 0.6552734375\n",
      "Batch: 38, Loss: 1.0501620769500732, Accuracy: 0.6416015625\n",
      "Batch: 39, Loss: 1.0164707899093628, Accuracy: 0.6708984375\n",
      "Batch: 40, Loss: 1.004127025604248, Accuracy: 0.681640625\n",
      "Batch: 41, Loss: 0.9898905754089355, Accuracy: 0.68359375\n",
      "Batch: 42, Loss: 0.8246235847473145, Accuracy: 0.71875\n",
      "Batch: 43, Loss: 1.0363317728042603, Accuracy: 0.6591796875\n",
      "Batch: 44, Loss: 1.0410188436508179, Accuracy: 0.6416015625\n",
      "Batch: 45, Loss: 0.9217867255210876, Accuracy: 0.697265625\n",
      "Batch: 46, Loss: 0.9574475884437561, Accuracy: 0.685546875\n",
      "Batch: 47, Loss: 0.9459284543991089, Accuracy: 0.69921875\n",
      "Batch: 48, Loss: 0.9267444610595703, Accuracy: 0.6904296875\n",
      "Batch: 49, Loss: 1.0976701974868774, Accuracy: 0.642578125\n",
      "Batch: 50, Loss: 1.0885612964630127, Accuracy: 0.630859375\n",
      "Batch: 51, Loss: 1.1353521347045898, Accuracy: 0.6328125\n",
      "Batch: 52, Loss: 1.074699878692627, Accuracy: 0.654296875\n",
      "Batch: 53, Loss: 0.9472593069076538, Accuracy: 0.6865234375\n",
      "Batch: 54, Loss: 1.0232274532318115, Accuracy: 0.6767578125\n",
      "Batch: 55, Loss: 1.069016695022583, Accuracy: 0.6455078125\n",
      "Batch: 56, Loss: 1.0735414028167725, Accuracy: 0.6474609375\n",
      "Batch: 57, Loss: 1.0193085670471191, Accuracy: 0.6630859375\n",
      "Batch: 58, Loss: 1.123024821281433, Accuracy: 0.66015625\n",
      "Batch: 59, Loss: 0.9147244691848755, Accuracy: 0.70703125\n",
      "Batch: 60, Loss: 0.9061976671218872, Accuracy: 0.7021484375\n",
      "Batch: 61, Loss: 1.0511658191680908, Accuracy: 0.65625\n",
      "Batch: 62, Loss: 0.9871282577514648, Accuracy: 0.6826171875\n",
      "Batch: 63, Loss: 1.0138152837753296, Accuracy: 0.6806640625\n",
      "Batch: 64, Loss: 1.0160419940948486, Accuracy: 0.6708984375\n",
      "Batch: 65, Loss: 1.0255048274993896, Accuracy: 0.681640625\n",
      "Batch: 66, Loss: 0.9492226839065552, Accuracy: 0.6904296875\n",
      "Batch: 67, Loss: 1.0682812929153442, Accuracy: 0.65234375\n",
      "Batch: 68, Loss: 1.1009018421173096, Accuracy: 0.6728515625\n",
      "Batch: 69, Loss: 1.0121941566467285, Accuracy: 0.67578125\n",
      "Batch: 70, Loss: 1.0090668201446533, Accuracy: 0.6982421875\n",
      "Batch: 71, Loss: 1.0579122304916382, Accuracy: 0.65625\n",
      "Batch: 72, Loss: 0.8984050750732422, Accuracy: 0.69921875\n",
      "Batch: 73, Loss: 0.9301356077194214, Accuracy: 0.7001953125\n",
      "Batch: 74, Loss: 0.9338529109954834, Accuracy: 0.6982421875\n",
      "Batch: 75, Loss: 0.9184435606002808, Accuracy: 0.693359375\n",
      "Batch: 76, Loss: 1.0186314582824707, Accuracy: 0.6630859375\n",
      "Batch: 77, Loss: 0.9974433183670044, Accuracy: 0.6787109375\n",
      "Batch: 78, Loss: 0.9649877548217773, Accuracy: 0.6923828125\n",
      "Batch: 79, Loss: 0.8710377216339111, Accuracy: 0.720703125\n",
      "Batch: 80, Loss: 0.9297751784324646, Accuracy: 0.6748046875\n",
      "Batch: 81, Loss: 1.088672161102295, Accuracy: 0.6201171875\n",
      "Batch: 82, Loss: 1.0373761653900146, Accuracy: 0.658203125\n",
      "Batch: 83, Loss: 0.8763582110404968, Accuracy: 0.71484375\n",
      "Batch: 84, Loss: 0.9663485884666443, Accuracy: 0.693359375\n",
      "Batch: 85, Loss: 0.9119359254837036, Accuracy: 0.7080078125\n",
      "Batch: 86, Loss: 1.1342582702636719, Accuracy: 0.6416015625\n",
      "Batch: 87, Loss: 0.9325106143951416, Accuracy: 0.703125\n",
      "Batch: 88, Loss: 1.0622284412384033, Accuracy: 0.669921875\n",
      "Batch: 89, Loss: 1.038893699645996, Accuracy: 0.6669921875\n",
      "Batch: 90, Loss: 0.9392173290252686, Accuracy: 0.6884765625\n",
      "Batch: 91, Loss: 0.9756569266319275, Accuracy: 0.68359375\n",
      "Batch: 92, Loss: 1.0356947183609009, Accuracy: 0.6630859375\n",
      "Batch: 93, Loss: 0.9743384122848511, Accuracy: 0.662109375\n",
      "Batch: 94, Loss: 0.9688510894775391, Accuracy: 0.6826171875\n",
      "Batch: 95, Loss: 1.0164082050323486, Accuracy: 0.650390625\n",
      "Batch: 96, Loss: 1.0194320678710938, Accuracy: 0.6728515625\n",
      "Batch: 97, Loss: 0.8614693284034729, Accuracy: 0.712890625\n",
      "Batch: 98, Loss: 0.9209522008895874, Accuracy: 0.7001953125\n",
      "Batch: 99, Loss: 0.9181255102157593, Accuracy: 0.7138671875\n",
      "Batch: 100, Loss: 0.9738659858703613, Accuracy: 0.6943359375\n",
      "Batch: 101, Loss: 1.040130376815796, Accuracy: 0.6630859375\n",
      "Batch: 102, Loss: 0.97607421875, Accuracy: 0.6826171875\n",
      "Batch: 103, Loss: 1.034731149673462, Accuracy: 0.69140625\n",
      "Batch: 104, Loss: 0.9298418760299683, Accuracy: 0.6962890625\n",
      "Batch: 105, Loss: 1.0220565795898438, Accuracy: 0.662109375\n",
      "Batch: 106, Loss: 0.982646107673645, Accuracy: 0.6787109375\n",
      "Batch: 107, Loss: 1.0433775186538696, Accuracy: 0.6708984375\n",
      "Batch: 108, Loss: 1.0308053493499756, Accuracy: 0.658203125\n",
      "Batch: 109, Loss: 1.1248672008514404, Accuracy: 0.634765625\n",
      "Batch: 110, Loss: 0.8846694827079773, Accuracy: 0.708984375\n",
      "Batch: 111, Loss: 1.0490903854370117, Accuracy: 0.6669921875\n",
      "Batch: 112, Loss: 0.9762814044952393, Accuracy: 0.708984375\n",
      "Batch: 113, Loss: 0.9892922639846802, Accuracy: 0.6748046875\n",
      "Batch: 114, Loss: 1.0845458507537842, Accuracy: 0.654296875\n",
      "Batch: 115, Loss: 1.1357730627059937, Accuracy: 0.642578125\n",
      "Batch: 116, Loss: 1.056956171989441, Accuracy: 0.65234375\n",
      "Batch: 117, Loss: 1.0673868656158447, Accuracy: 0.646484375\n",
      "Batch: 118, Loss: 0.9022844433784485, Accuracy: 0.70703125\n",
      "Batch: 119, Loss: 0.9293456673622131, Accuracy: 0.701171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 120, Loss: 1.0575170516967773, Accuracy: 0.6630859375\n",
      "Batch: 121, Loss: 1.0807628631591797, Accuracy: 0.642578125\n",
      "Batch: 122, Loss: 0.9589552879333496, Accuracy: 0.7001953125\n",
      "Batch: 123, Loss: 0.9487264156341553, Accuracy: 0.703125\n",
      "Batch: 124, Loss: 0.9812936782836914, Accuracy: 0.677734375\n",
      "Batch: 125, Loss: 1.0575928688049316, Accuracy: 0.6513671875\n",
      "Batch: 126, Loss: 1.020251989364624, Accuracy: 0.669921875\n",
      "Batch: 127, Loss: 0.8954195976257324, Accuracy: 0.720703125\n",
      "Batch: 128, Loss: 1.0926215648651123, Accuracy: 0.6572265625\n",
      "Batch: 129, Loss: 0.9481710195541382, Accuracy: 0.6787109375\n",
      "Batch: 130, Loss: 1.173905372619629, Accuracy: 0.62890625\n",
      "Batch: 131, Loss: 1.0332934856414795, Accuracy: 0.6552734375\n",
      "Batch: 132, Loss: 1.052329659461975, Accuracy: 0.6689453125\n",
      "Batch: 133, Loss: 0.9294002056121826, Accuracy: 0.7060546875\n",
      "Batch: 134, Loss: 1.0345087051391602, Accuracy: 0.65234375\n",
      "Batch: 135, Loss: 0.9346516728401184, Accuracy: 0.7109375\n",
      "Batch: 136, Loss: 1.034218192100525, Accuracy: 0.6669921875\n",
      "Batch: 137, Loss: 0.9683103561401367, Accuracy: 0.6708984375\n",
      "Batch: 138, Loss: 0.8494718074798584, Accuracy: 0.69921875\n",
      "Batch: 139, Loss: 0.9312469363212585, Accuracy: 0.6865234375\n",
      "Batch: 140, Loss: 0.9833203554153442, Accuracy: 0.6728515625\n",
      "Batch: 141, Loss: 0.9939413666725159, Accuracy: 0.6767578125\n",
      "Batch: 142, Loss: 1.0605175495147705, Accuracy: 0.6650390625\n",
      "Batch: 143, Loss: 1.0237864255905151, Accuracy: 0.662109375\n",
      "Batch: 144, Loss: 1.0093193054199219, Accuracy: 0.697265625\n",
      "Batch: 145, Loss: 0.9871849417686462, Accuracy: 0.654296875\n",
      "Batch: 146, Loss: 1.0780253410339355, Accuracy: 0.6435546875\n",
      "Batch: 147, Loss: 1.0760118961334229, Accuracy: 0.640625\n",
      "Batch: 148, Loss: 1.1706461906433105, Accuracy: 0.603515625\n",
      "Batch: 149, Loss: 0.9829195141792297, Accuracy: 0.66796875\n",
      "Batch: 150, Loss: 0.9657692909240723, Accuracy: 0.6875\n",
      "Batch: 151, Loss: 0.8780319094657898, Accuracy: 0.7119140625\n",
      "Epoch 25/80\n",
      "Batch: 1, Loss: 1.2585480213165283, Accuracy: 0.591796875\n",
      "Batch: 2, Loss: 1.0879079103469849, Accuracy: 0.625\n",
      "Batch: 3, Loss: 0.9573227167129517, Accuracy: 0.6826171875\n",
      "Batch: 4, Loss: 0.8603166341781616, Accuracy: 0.7216796875\n",
      "Batch: 5, Loss: 0.9372838735580444, Accuracy: 0.703125\n",
      "Batch: 6, Loss: 0.9923792481422424, Accuracy: 0.6572265625\n",
      "Batch: 7, Loss: 0.9437605738639832, Accuracy: 0.6787109375\n",
      "Batch: 8, Loss: 0.9183908104896545, Accuracy: 0.7080078125\n",
      "Batch: 9, Loss: 0.8968689441680908, Accuracy: 0.7138671875\n",
      "Batch: 10, Loss: 0.930984616279602, Accuracy: 0.6904296875\n",
      "Batch: 11, Loss: 1.097090244293213, Accuracy: 0.6220703125\n",
      "Batch: 12, Loss: 1.0481219291687012, Accuracy: 0.6640625\n",
      "Batch: 13, Loss: 0.8219091892242432, Accuracy: 0.7294921875\n",
      "Batch: 14, Loss: 1.0953248739242554, Accuracy: 0.6435546875\n",
      "Batch: 15, Loss: 0.9141228795051575, Accuracy: 0.712890625\n",
      "Batch: 16, Loss: 0.9878383874893188, Accuracy: 0.6787109375\n",
      "Batch: 17, Loss: 1.030648112297058, Accuracy: 0.6650390625\n",
      "Batch: 18, Loss: 1.0305956602096558, Accuracy: 0.66796875\n",
      "Batch: 19, Loss: 1.0533177852630615, Accuracy: 0.658203125\n",
      "Batch: 20, Loss: 0.9354889392852783, Accuracy: 0.7080078125\n",
      "Batch: 21, Loss: 0.9346761703491211, Accuracy: 0.6923828125\n",
      "Batch: 22, Loss: 1.0664881467819214, Accuracy: 0.658203125\n",
      "Batch: 23, Loss: 0.9942238330841064, Accuracy: 0.6669921875\n",
      "Batch: 24, Loss: 0.9959921836853027, Accuracy: 0.662109375\n",
      "Batch: 25, Loss: 0.9952178001403809, Accuracy: 0.671875\n",
      "Batch: 26, Loss: 0.8781330585479736, Accuracy: 0.705078125\n",
      "Batch: 27, Loss: 0.9505131244659424, Accuracy: 0.66796875\n",
      "Batch: 28, Loss: 1.035475730895996, Accuracy: 0.65234375\n",
      "Batch: 29, Loss: 0.9524248838424683, Accuracy: 0.677734375\n",
      "Batch: 30, Loss: 0.9112997651100159, Accuracy: 0.7119140625\n",
      "Batch: 31, Loss: 0.8963701725006104, Accuracy: 0.71875\n",
      "Batch: 32, Loss: 0.9326286315917969, Accuracy: 0.69140625\n",
      "Batch: 33, Loss: 1.0631592273712158, Accuracy: 0.6650390625\n",
      "Batch: 34, Loss: 1.1117103099822998, Accuracy: 0.6416015625\n",
      "Batch: 35, Loss: 1.0292749404907227, Accuracy: 0.6484375\n",
      "Batch: 36, Loss: 1.0462570190429688, Accuracy: 0.669921875\n",
      "Batch: 37, Loss: 1.0099365711212158, Accuracy: 0.6767578125\n",
      "Batch: 38, Loss: 1.0284554958343506, Accuracy: 0.6572265625\n",
      "Batch: 39, Loss: 1.0231599807739258, Accuracy: 0.6787109375\n",
      "Batch: 40, Loss: 1.0222734212875366, Accuracy: 0.6630859375\n",
      "Batch: 41, Loss: 0.9972038269042969, Accuracy: 0.6796875\n",
      "Batch: 42, Loss: 0.803325891494751, Accuracy: 0.7255859375\n",
      "Batch: 43, Loss: 1.036517858505249, Accuracy: 0.6572265625\n",
      "Batch: 44, Loss: 1.0309746265411377, Accuracy: 0.6591796875\n",
      "Batch: 45, Loss: 0.9079878926277161, Accuracy: 0.685546875\n",
      "Batch: 46, Loss: 0.9538294076919556, Accuracy: 0.6884765625\n",
      "Batch: 47, Loss: 0.9358350038528442, Accuracy: 0.7109375\n",
      "Batch: 48, Loss: 0.879041314125061, Accuracy: 0.7060546875\n",
      "Batch: 49, Loss: 1.120585322380066, Accuracy: 0.6357421875\n",
      "Batch: 50, Loss: 1.0815060138702393, Accuracy: 0.640625\n",
      "Batch: 51, Loss: 1.0992064476013184, Accuracy: 0.640625\n",
      "Batch: 52, Loss: 1.0604565143585205, Accuracy: 0.6611328125\n",
      "Batch: 53, Loss: 0.9336774349212646, Accuracy: 0.689453125\n",
      "Batch: 54, Loss: 1.029988408088684, Accuracy: 0.6806640625\n",
      "Batch: 55, Loss: 1.0773851871490479, Accuracy: 0.6435546875\n",
      "Batch: 56, Loss: 1.0368115901947021, Accuracy: 0.66796875\n",
      "Batch: 57, Loss: 1.0081301927566528, Accuracy: 0.6767578125\n",
      "Batch: 58, Loss: 1.1002792119979858, Accuracy: 0.6728515625\n",
      "Batch: 59, Loss: 0.9284654259681702, Accuracy: 0.7060546875\n",
      "Batch: 60, Loss: 0.8879789710044861, Accuracy: 0.716796875\n",
      "Batch: 61, Loss: 1.00520920753479, Accuracy: 0.66015625\n",
      "Batch: 62, Loss: 0.9730831384658813, Accuracy: 0.6806640625\n",
      "Batch: 63, Loss: 1.0213773250579834, Accuracy: 0.6767578125\n",
      "Batch: 64, Loss: 0.9871717095375061, Accuracy: 0.681640625\n",
      "Batch: 65, Loss: 1.0267012119293213, Accuracy: 0.66796875\n",
      "Batch: 66, Loss: 0.9452559947967529, Accuracy: 0.7109375\n",
      "Batch: 67, Loss: 1.0518878698349, Accuracy: 0.654296875\n",
      "Batch: 68, Loss: 1.0524882078170776, Accuracy: 0.6796875\n",
      "Batch: 69, Loss: 1.0223782062530518, Accuracy: 0.66796875\n",
      "Batch: 70, Loss: 0.979686975479126, Accuracy: 0.705078125\n",
      "Batch: 71, Loss: 1.0310908555984497, Accuracy: 0.650390625\n",
      "Batch: 72, Loss: 0.8759612441062927, Accuracy: 0.712890625\n",
      "Batch: 73, Loss: 0.9209547638893127, Accuracy: 0.701171875\n",
      "Batch: 74, Loss: 0.9237351417541504, Accuracy: 0.7060546875\n",
      "Batch: 75, Loss: 0.9112949371337891, Accuracy: 0.705078125\n",
      "Batch: 76, Loss: 1.008611798286438, Accuracy: 0.671875\n",
      "Batch: 77, Loss: 0.967475414276123, Accuracy: 0.669921875\n",
      "Batch: 78, Loss: 0.9364997744560242, Accuracy: 0.6953125\n",
      "Batch: 79, Loss: 0.8624036312103271, Accuracy: 0.7314453125\n",
      "Batch: 80, Loss: 0.9298617839813232, Accuracy: 0.689453125\n",
      "Batch: 81, Loss: 1.0889403820037842, Accuracy: 0.6220703125\n",
      "Batch: 82, Loss: 1.0035955905914307, Accuracy: 0.66796875\n",
      "Batch: 83, Loss: 0.8803081512451172, Accuracy: 0.71875\n",
      "Batch: 84, Loss: 0.9515488743782043, Accuracy: 0.7080078125\n",
      "Batch: 85, Loss: 0.9057279825210571, Accuracy: 0.7001953125\n",
      "Batch: 86, Loss: 1.1374409198760986, Accuracy: 0.6474609375\n",
      "Batch: 87, Loss: 0.9133686423301697, Accuracy: 0.7109375\n",
      "Batch: 88, Loss: 1.058699607849121, Accuracy: 0.662109375\n",
      "Batch: 89, Loss: 1.0446300506591797, Accuracy: 0.666015625\n",
      "Batch: 90, Loss: 0.9455054998397827, Accuracy: 0.697265625\n",
      "Batch: 91, Loss: 0.9752957820892334, Accuracy: 0.6884765625\n",
      "Batch: 92, Loss: 1.0332119464874268, Accuracy: 0.677734375\n",
      "Batch: 93, Loss: 1.003961205482483, Accuracy: 0.673828125\n",
      "Batch: 94, Loss: 0.9516812562942505, Accuracy: 0.677734375\n",
      "Batch: 95, Loss: 0.9977822303771973, Accuracy: 0.6640625\n",
      "Batch: 96, Loss: 1.0033098459243774, Accuracy: 0.6669921875\n",
      "Batch: 97, Loss: 0.8287248611450195, Accuracy: 0.720703125\n",
      "Batch: 98, Loss: 0.9135725498199463, Accuracy: 0.7109375\n",
      "Batch: 99, Loss: 0.9113936424255371, Accuracy: 0.69921875\n",
      "Batch: 100, Loss: 0.9557947516441345, Accuracy: 0.689453125\n",
      "Batch: 101, Loss: 1.0046398639678955, Accuracy: 0.66796875\n",
      "Batch: 102, Loss: 0.9666818380355835, Accuracy: 0.697265625\n",
      "Batch: 103, Loss: 1.031637191772461, Accuracy: 0.671875\n",
      "Batch: 104, Loss: 0.9064167737960815, Accuracy: 0.7001953125\n",
      "Batch: 105, Loss: 1.023870825767517, Accuracy: 0.673828125\n",
      "Batch: 106, Loss: 1.0049784183502197, Accuracy: 0.693359375\n",
      "Batch: 107, Loss: 1.0401043891906738, Accuracy: 0.6591796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 108, Loss: 0.9947059154510498, Accuracy: 0.6708984375\n",
      "Batch: 109, Loss: 1.1165038347244263, Accuracy: 0.6328125\n",
      "Batch: 110, Loss: 0.869246244430542, Accuracy: 0.7021484375\n",
      "Batch: 111, Loss: 1.0043597221374512, Accuracy: 0.6630859375\n",
      "Batch: 112, Loss: 0.9767358303070068, Accuracy: 0.68359375\n",
      "Batch: 113, Loss: 1.002662181854248, Accuracy: 0.689453125\n",
      "Batch: 114, Loss: 1.0716971158981323, Accuracy: 0.6630859375\n",
      "Batch: 115, Loss: 1.1371142864227295, Accuracy: 0.6552734375\n",
      "Batch: 116, Loss: 1.0330514907836914, Accuracy: 0.669921875\n",
      "Batch: 117, Loss: 1.0621806383132935, Accuracy: 0.650390625\n",
      "Batch: 118, Loss: 0.855496883392334, Accuracy: 0.71484375\n",
      "Batch: 119, Loss: 0.9040346145629883, Accuracy: 0.705078125\n",
      "Batch: 120, Loss: 1.0391377210617065, Accuracy: 0.6533203125\n",
      "Batch: 121, Loss: 1.0757702589035034, Accuracy: 0.6494140625\n",
      "Batch: 122, Loss: 0.946108341217041, Accuracy: 0.705078125\n",
      "Batch: 123, Loss: 0.9838817119598389, Accuracy: 0.6953125\n",
      "Batch: 124, Loss: 0.9943143725395203, Accuracy: 0.6640625\n",
      "Batch: 125, Loss: 1.0311081409454346, Accuracy: 0.64453125\n",
      "Batch: 126, Loss: 1.0000193119049072, Accuracy: 0.666015625\n",
      "Batch: 127, Loss: 0.8876331448554993, Accuracy: 0.724609375\n",
      "Batch: 128, Loss: 1.0999300479888916, Accuracy: 0.6572265625\n",
      "Batch: 129, Loss: 0.9225480556488037, Accuracy: 0.6923828125\n",
      "Batch: 130, Loss: 1.1450421810150146, Accuracy: 0.6357421875\n",
      "Batch: 131, Loss: 1.019299030303955, Accuracy: 0.6650390625\n",
      "Batch: 132, Loss: 1.0316811800003052, Accuracy: 0.6650390625\n",
      "Batch: 133, Loss: 0.9030330181121826, Accuracy: 0.6923828125\n",
      "Batch: 134, Loss: 0.989072322845459, Accuracy: 0.673828125\n",
      "Batch: 135, Loss: 0.9149594902992249, Accuracy: 0.697265625\n",
      "Batch: 136, Loss: 0.9969435930252075, Accuracy: 0.673828125\n",
      "Batch: 137, Loss: 0.9481576681137085, Accuracy: 0.677734375\n",
      "Batch: 138, Loss: 0.833587646484375, Accuracy: 0.7109375\n",
      "Batch: 139, Loss: 0.9182000160217285, Accuracy: 0.7001953125\n",
      "Batch: 140, Loss: 0.9962995648384094, Accuracy: 0.6650390625\n",
      "Batch: 141, Loss: 1.0160332918167114, Accuracy: 0.6630859375\n",
      "Batch: 142, Loss: 1.0276355743408203, Accuracy: 0.658203125\n",
      "Batch: 143, Loss: 1.0124515295028687, Accuracy: 0.6611328125\n",
      "Batch: 144, Loss: 0.9900590181350708, Accuracy: 0.6748046875\n",
      "Batch: 145, Loss: 0.9449968338012695, Accuracy: 0.6591796875\n",
      "Batch: 146, Loss: 1.0338549613952637, Accuracy: 0.654296875\n",
      "Batch: 147, Loss: 1.053898572921753, Accuracy: 0.6552734375\n",
      "Batch: 148, Loss: 1.1401326656341553, Accuracy: 0.609375\n",
      "Batch: 149, Loss: 0.9960028529167175, Accuracy: 0.6611328125\n",
      "Batch: 150, Loss: 0.9573743343353271, Accuracy: 0.6923828125\n",
      "Batch: 151, Loss: 0.8775017261505127, Accuracy: 0.6943359375\n",
      "Epoch 26/80\n",
      "Batch: 1, Loss: 1.233872652053833, Accuracy: 0.6181640625\n",
      "Batch: 2, Loss: 1.0532093048095703, Accuracy: 0.6435546875\n",
      "Batch: 3, Loss: 0.933072566986084, Accuracy: 0.6787109375\n",
      "Batch: 4, Loss: 0.8658577799797058, Accuracy: 0.7197265625\n",
      "Batch: 5, Loss: 0.939370334148407, Accuracy: 0.6884765625\n",
      "Batch: 6, Loss: 1.0000804662704468, Accuracy: 0.67578125\n",
      "Batch: 7, Loss: 0.9497817754745483, Accuracy: 0.677734375\n",
      "Batch: 8, Loss: 0.918523907661438, Accuracy: 0.69140625\n",
      "Batch: 9, Loss: 0.8653545379638672, Accuracy: 0.7255859375\n",
      "Batch: 10, Loss: 0.9051781892776489, Accuracy: 0.6826171875\n",
      "Batch: 11, Loss: 1.0942230224609375, Accuracy: 0.64453125\n",
      "Batch: 12, Loss: 1.0397977828979492, Accuracy: 0.65234375\n",
      "Batch: 13, Loss: 0.8252208232879639, Accuracy: 0.7421875\n",
      "Batch: 14, Loss: 1.102956771850586, Accuracy: 0.6328125\n",
      "Batch: 15, Loss: 0.8726491928100586, Accuracy: 0.7236328125\n",
      "Batch: 16, Loss: 0.978493869304657, Accuracy: 0.6767578125\n",
      "Batch: 17, Loss: 1.028481364250183, Accuracy: 0.6630859375\n",
      "Batch: 18, Loss: 1.0184667110443115, Accuracy: 0.6728515625\n",
      "Batch: 19, Loss: 1.044511079788208, Accuracy: 0.65625\n",
      "Batch: 20, Loss: 0.9202390909194946, Accuracy: 0.7060546875\n",
      "Batch: 21, Loss: 0.9330205321311951, Accuracy: 0.6806640625\n",
      "Batch: 22, Loss: 1.086349606513977, Accuracy: 0.65625\n",
      "Batch: 23, Loss: 0.987512469291687, Accuracy: 0.666015625\n",
      "Batch: 24, Loss: 1.0261213779449463, Accuracy: 0.654296875\n",
      "Batch: 25, Loss: 0.9902404546737671, Accuracy: 0.6826171875\n",
      "Batch: 26, Loss: 0.8711577653884888, Accuracy: 0.708984375\n",
      "Batch: 27, Loss: 0.9239416122436523, Accuracy: 0.693359375\n",
      "Batch: 28, Loss: 1.0285215377807617, Accuracy: 0.650390625\n",
      "Batch: 29, Loss: 0.9476280808448792, Accuracy: 0.6845703125\n",
      "Batch: 30, Loss: 0.8833073377609253, Accuracy: 0.736328125\n",
      "Batch: 31, Loss: 0.8735014200210571, Accuracy: 0.71484375\n",
      "Batch: 32, Loss: 0.8848687410354614, Accuracy: 0.7021484375\n",
      "Batch: 33, Loss: 1.0806355476379395, Accuracy: 0.6533203125\n",
      "Batch: 34, Loss: 1.116608738899231, Accuracy: 0.638671875\n",
      "Batch: 35, Loss: 1.016782522201538, Accuracy: 0.6572265625\n",
      "Batch: 36, Loss: 1.0455529689788818, Accuracy: 0.658203125\n",
      "Batch: 37, Loss: 1.0015453100204468, Accuracy: 0.666015625\n",
      "Batch: 38, Loss: 1.0320817232131958, Accuracy: 0.6591796875\n",
      "Batch: 39, Loss: 1.0070000886917114, Accuracy: 0.67578125\n",
      "Batch: 40, Loss: 1.0039573907852173, Accuracy: 0.6845703125\n",
      "Batch: 41, Loss: 0.9702100157737732, Accuracy: 0.701171875\n",
      "Batch: 42, Loss: 0.7809579372406006, Accuracy: 0.7314453125\n",
      "Batch: 43, Loss: 1.016768217086792, Accuracy: 0.6650390625\n",
      "Batch: 44, Loss: 0.9985994696617126, Accuracy: 0.671875\n",
      "Batch: 45, Loss: 0.910009503364563, Accuracy: 0.69921875\n",
      "Batch: 46, Loss: 0.9228193163871765, Accuracy: 0.685546875\n",
      "Batch: 47, Loss: 0.9513018727302551, Accuracy: 0.7099609375\n",
      "Batch: 48, Loss: 0.8769122958183289, Accuracy: 0.7177734375\n",
      "Batch: 49, Loss: 1.0768928527832031, Accuracy: 0.64453125\n",
      "Batch: 50, Loss: 1.0634288787841797, Accuracy: 0.654296875\n",
      "Batch: 51, Loss: 1.0821176767349243, Accuracy: 0.642578125\n",
      "Batch: 52, Loss: 1.0432547330856323, Accuracy: 0.6708984375\n",
      "Batch: 53, Loss: 0.9161247611045837, Accuracy: 0.6806640625\n",
      "Batch: 54, Loss: 1.008687973022461, Accuracy: 0.6806640625\n",
      "Batch: 55, Loss: 1.049529790878296, Accuracy: 0.6513671875\n",
      "Batch: 56, Loss: 1.0613794326782227, Accuracy: 0.6533203125\n",
      "Batch: 57, Loss: 0.9788618087768555, Accuracy: 0.673828125\n",
      "Batch: 58, Loss: 1.1107059717178345, Accuracy: 0.673828125\n",
      "Batch: 59, Loss: 0.892247200012207, Accuracy: 0.7099609375\n",
      "Batch: 60, Loss: 0.8977652788162231, Accuracy: 0.697265625\n",
      "Batch: 61, Loss: 1.0041959285736084, Accuracy: 0.6875\n",
      "Batch: 62, Loss: 0.9460752606391907, Accuracy: 0.69921875\n",
      "Batch: 63, Loss: 0.9955169558525085, Accuracy: 0.6962890625\n",
      "Batch: 64, Loss: 0.9759216904640198, Accuracy: 0.685546875\n",
      "Batch: 65, Loss: 1.0199158191680908, Accuracy: 0.67578125\n",
      "Batch: 66, Loss: 0.9777342081069946, Accuracy: 0.6826171875\n",
      "Batch: 67, Loss: 1.0548789501190186, Accuracy: 0.66796875\n",
      "Batch: 68, Loss: 1.0884078741073608, Accuracy: 0.6728515625\n",
      "Batch: 69, Loss: 1.0036793947219849, Accuracy: 0.658203125\n",
      "Batch: 70, Loss: 0.9823005199432373, Accuracy: 0.697265625\n",
      "Batch: 71, Loss: 1.032822847366333, Accuracy: 0.6689453125\n",
      "Batch: 72, Loss: 0.8720012903213501, Accuracy: 0.712890625\n",
      "Batch: 73, Loss: 0.9375114440917969, Accuracy: 0.703125\n",
      "Batch: 74, Loss: 0.8988329768180847, Accuracy: 0.705078125\n",
      "Batch: 75, Loss: 0.8765044212341309, Accuracy: 0.7119140625\n",
      "Batch: 76, Loss: 1.013085126876831, Accuracy: 0.6513671875\n",
      "Batch: 77, Loss: 0.9790346622467041, Accuracy: 0.669921875\n",
      "Batch: 78, Loss: 0.89845210313797, Accuracy: 0.7041015625\n",
      "Batch: 79, Loss: 0.860770583152771, Accuracy: 0.732421875\n",
      "Batch: 80, Loss: 0.917948842048645, Accuracy: 0.693359375\n",
      "Batch: 81, Loss: 1.0467748641967773, Accuracy: 0.62890625\n",
      "Batch: 82, Loss: 1.0092005729675293, Accuracy: 0.66015625\n",
      "Batch: 83, Loss: 0.875507116317749, Accuracy: 0.72265625\n",
      "Batch: 84, Loss: 0.9559279680252075, Accuracy: 0.6904296875\n",
      "Batch: 85, Loss: 0.8640981316566467, Accuracy: 0.71484375\n",
      "Batch: 86, Loss: 1.1131412982940674, Accuracy: 0.654296875\n",
      "Batch: 87, Loss: 0.9137684106826782, Accuracy: 0.7021484375\n",
      "Batch: 88, Loss: 1.028001308441162, Accuracy: 0.6884765625\n",
      "Batch: 89, Loss: 1.042064905166626, Accuracy: 0.6669921875\n",
      "Batch: 90, Loss: 0.9142141342163086, Accuracy: 0.708984375\n",
      "Batch: 91, Loss: 0.95525723695755, Accuracy: 0.6865234375\n",
      "Batch: 92, Loss: 1.028069257736206, Accuracy: 0.6748046875\n",
      "Batch: 93, Loss: 0.94609534740448, Accuracy: 0.6943359375\n",
      "Batch: 94, Loss: 0.9385331273078918, Accuracy: 0.69140625\n",
      "Batch: 95, Loss: 0.9962407946586609, Accuracy: 0.666015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 96, Loss: 0.9747283458709717, Accuracy: 0.6953125\n",
      "Batch: 97, Loss: 0.8253727555274963, Accuracy: 0.716796875\n",
      "Batch: 98, Loss: 0.9008606672286987, Accuracy: 0.70703125\n",
      "Batch: 99, Loss: 0.8998667597770691, Accuracy: 0.712890625\n",
      "Batch: 100, Loss: 0.922482967376709, Accuracy: 0.705078125\n",
      "Batch: 101, Loss: 1.0110788345336914, Accuracy: 0.6689453125\n",
      "Batch: 102, Loss: 0.9590616822242737, Accuracy: 0.69140625\n",
      "Batch: 103, Loss: 0.9875829815864563, Accuracy: 0.6865234375\n",
      "Batch: 104, Loss: 0.8972762227058411, Accuracy: 0.6962890625\n",
      "Batch: 105, Loss: 1.0015201568603516, Accuracy: 0.6875\n",
      "Batch: 106, Loss: 0.973802924156189, Accuracy: 0.689453125\n",
      "Batch: 107, Loss: 1.0303280353546143, Accuracy: 0.68359375\n",
      "Batch: 108, Loss: 1.0007479190826416, Accuracy: 0.669921875\n",
      "Batch: 109, Loss: 1.1120623350143433, Accuracy: 0.6337890625\n",
      "Batch: 110, Loss: 0.8469593524932861, Accuracy: 0.716796875\n",
      "Batch: 111, Loss: 0.9916910529136658, Accuracy: 0.669921875\n",
      "Batch: 112, Loss: 0.9335405826568604, Accuracy: 0.716796875\n",
      "Batch: 113, Loss: 0.9648239016532898, Accuracy: 0.6953125\n",
      "Batch: 114, Loss: 1.0439159870147705, Accuracy: 0.6611328125\n",
      "Batch: 115, Loss: 1.0957748889923096, Accuracy: 0.65234375\n",
      "Batch: 116, Loss: 1.0568461418151855, Accuracy: 0.6494140625\n",
      "Batch: 117, Loss: 1.038445234298706, Accuracy: 0.66015625\n",
      "Batch: 118, Loss: 0.8522824048995972, Accuracy: 0.724609375\n",
      "Batch: 119, Loss: 0.8756116628646851, Accuracy: 0.7138671875\n",
      "Batch: 120, Loss: 1.0161879062652588, Accuracy: 0.6708984375\n",
      "Batch: 121, Loss: 1.029637098312378, Accuracy: 0.6630859375\n",
      "Batch: 122, Loss: 0.9073677062988281, Accuracy: 0.7041015625\n",
      "Batch: 123, Loss: 0.9486884474754333, Accuracy: 0.712890625\n",
      "Batch: 124, Loss: 0.9838007092475891, Accuracy: 0.6640625\n",
      "Batch: 125, Loss: 1.0387370586395264, Accuracy: 0.6552734375\n",
      "Batch: 126, Loss: 0.9961977005004883, Accuracy: 0.677734375\n",
      "Batch: 127, Loss: 0.8915800452232361, Accuracy: 0.7060546875\n",
      "Batch: 128, Loss: 1.1020770072937012, Accuracy: 0.65234375\n",
      "Batch: 129, Loss: 0.9182283282279968, Accuracy: 0.6982421875\n",
      "Batch: 130, Loss: 1.1530957221984863, Accuracy: 0.6357421875\n",
      "Batch: 131, Loss: 1.006486415863037, Accuracy: 0.6748046875\n",
      "Batch: 132, Loss: 1.0077379941940308, Accuracy: 0.673828125\n",
      "Batch: 133, Loss: 0.9148164987564087, Accuracy: 0.6904296875\n",
      "Batch: 134, Loss: 0.9872614145278931, Accuracy: 0.65234375\n",
      "Batch: 135, Loss: 0.9082111120223999, Accuracy: 0.716796875\n",
      "Batch: 136, Loss: 0.9826787114143372, Accuracy: 0.681640625\n",
      "Batch: 137, Loss: 0.9447411298751831, Accuracy: 0.67578125\n",
      "Batch: 138, Loss: 0.8299362659454346, Accuracy: 0.7265625\n",
      "Batch: 139, Loss: 0.9035558700561523, Accuracy: 0.6962890625\n",
      "Batch: 140, Loss: 0.9876538515090942, Accuracy: 0.6669921875\n",
      "Batch: 141, Loss: 1.0157769918441772, Accuracy: 0.66015625\n",
      "Batch: 142, Loss: 1.0351669788360596, Accuracy: 0.658203125\n",
      "Batch: 143, Loss: 1.0067815780639648, Accuracy: 0.6708984375\n",
      "Batch: 144, Loss: 0.978485107421875, Accuracy: 0.6875\n",
      "Batch: 145, Loss: 0.9551024436950684, Accuracy: 0.666015625\n",
      "Batch: 146, Loss: 1.0075178146362305, Accuracy: 0.6650390625\n",
      "Batch: 147, Loss: 1.034308671951294, Accuracy: 0.65625\n",
      "Batch: 148, Loss: 1.1216216087341309, Accuracy: 0.62890625\n",
      "Batch: 149, Loss: 0.9870145320892334, Accuracy: 0.6611328125\n",
      "Batch: 150, Loss: 0.9615055322647095, Accuracy: 0.69140625\n",
      "Batch: 151, Loss: 0.8672369718551636, Accuracy: 0.70703125\n",
      "Epoch 27/80\n",
      "Batch: 1, Loss: 1.2111647129058838, Accuracy: 0.6064453125\n",
      "Batch: 2, Loss: 1.0654678344726562, Accuracy: 0.6318359375\n",
      "Batch: 3, Loss: 0.9301610589027405, Accuracy: 0.6923828125\n",
      "Batch: 4, Loss: 0.8813632726669312, Accuracy: 0.7197265625\n",
      "Batch: 5, Loss: 0.9286748170852661, Accuracy: 0.70703125\n",
      "Batch: 6, Loss: 1.0002100467681885, Accuracy: 0.669921875\n",
      "Batch: 7, Loss: 0.9729381203651428, Accuracy: 0.6630859375\n",
      "Batch: 8, Loss: 0.9206568002700806, Accuracy: 0.7041015625\n",
      "Batch: 9, Loss: 0.8676655292510986, Accuracy: 0.712890625\n",
      "Batch: 10, Loss: 0.894828200340271, Accuracy: 0.6943359375\n",
      "Batch: 11, Loss: 1.0702637434005737, Accuracy: 0.6328125\n",
      "Batch: 12, Loss: 1.0355488061904907, Accuracy: 0.6708984375\n",
      "Batch: 13, Loss: 0.7949076890945435, Accuracy: 0.7431640625\n",
      "Batch: 14, Loss: 1.0596593618392944, Accuracy: 0.6572265625\n",
      "Batch: 15, Loss: 0.8848046660423279, Accuracy: 0.7099609375\n",
      "Batch: 16, Loss: 0.9518160223960876, Accuracy: 0.6845703125\n",
      "Batch: 17, Loss: 1.0169429779052734, Accuracy: 0.6806640625\n",
      "Batch: 18, Loss: 1.0197697877883911, Accuracy: 0.66015625\n",
      "Batch: 19, Loss: 1.031038761138916, Accuracy: 0.669921875\n",
      "Batch: 20, Loss: 0.8750070333480835, Accuracy: 0.71875\n",
      "Batch: 21, Loss: 0.9106724262237549, Accuracy: 0.7021484375\n",
      "Batch: 22, Loss: 1.0331737995147705, Accuracy: 0.669921875\n",
      "Batch: 23, Loss: 0.9902212619781494, Accuracy: 0.6767578125\n",
      "Batch: 24, Loss: 0.9749892950057983, Accuracy: 0.6669921875\n",
      "Batch: 25, Loss: 0.9674018621444702, Accuracy: 0.6708984375\n",
      "Batch: 26, Loss: 0.8754162788391113, Accuracy: 0.708984375\n",
      "Batch: 27, Loss: 0.9174371957778931, Accuracy: 0.6806640625\n",
      "Batch: 28, Loss: 1.0223197937011719, Accuracy: 0.6669921875\n",
      "Batch: 29, Loss: 0.9227675199508667, Accuracy: 0.697265625\n",
      "Batch: 30, Loss: 0.89976966381073, Accuracy: 0.71484375\n",
      "Batch: 31, Loss: 0.8719464540481567, Accuracy: 0.7216796875\n",
      "Batch: 32, Loss: 0.9017958641052246, Accuracy: 0.7001953125\n",
      "Batch: 33, Loss: 1.0462597608566284, Accuracy: 0.662109375\n",
      "Batch: 34, Loss: 1.089551568031311, Accuracy: 0.6474609375\n",
      "Batch: 35, Loss: 1.0179461240768433, Accuracy: 0.666015625\n",
      "Batch: 36, Loss: 1.0247998237609863, Accuracy: 0.6708984375\n",
      "Batch: 37, Loss: 0.9683789014816284, Accuracy: 0.6845703125\n",
      "Batch: 38, Loss: 1.0303521156311035, Accuracy: 0.654296875\n",
      "Batch: 39, Loss: 1.0199384689331055, Accuracy: 0.66015625\n",
      "Batch: 40, Loss: 0.966123104095459, Accuracy: 0.689453125\n",
      "Batch: 41, Loss: 0.9647324085235596, Accuracy: 0.6953125\n",
      "Batch: 42, Loss: 0.7933535575866699, Accuracy: 0.7333984375\n",
      "Batch: 43, Loss: 1.009196400642395, Accuracy: 0.6630859375\n",
      "Batch: 44, Loss: 0.9996259212493896, Accuracy: 0.6640625\n",
      "Batch: 45, Loss: 0.9008829593658447, Accuracy: 0.701171875\n",
      "Batch: 46, Loss: 0.9075593948364258, Accuracy: 0.7080078125\n",
      "Batch: 47, Loss: 0.9217796325683594, Accuracy: 0.71484375\n",
      "Batch: 48, Loss: 0.897896409034729, Accuracy: 0.69140625\n",
      "Batch: 49, Loss: 1.0797863006591797, Accuracy: 0.64453125\n",
      "Batch: 50, Loss: 1.0531014204025269, Accuracy: 0.6435546875\n",
      "Batch: 51, Loss: 1.1051764488220215, Accuracy: 0.6376953125\n",
      "Batch: 52, Loss: 1.0501430034637451, Accuracy: 0.65625\n",
      "Batch: 53, Loss: 0.9080816507339478, Accuracy: 0.685546875\n",
      "Batch: 54, Loss: 0.9721076488494873, Accuracy: 0.6806640625\n",
      "Batch: 55, Loss: 1.0511913299560547, Accuracy: 0.6494140625\n",
      "Batch: 56, Loss: 1.0379010438919067, Accuracy: 0.6708984375\n",
      "Batch: 57, Loss: 0.9981081485748291, Accuracy: 0.6767578125\n",
      "Batch: 58, Loss: 1.0605701208114624, Accuracy: 0.671875\n",
      "Batch: 59, Loss: 0.8796585202217102, Accuracy: 0.716796875\n",
      "Batch: 60, Loss: 0.8834066987037659, Accuracy: 0.708984375\n",
      "Batch: 61, Loss: 0.9763631820678711, Accuracy: 0.681640625\n",
      "Batch: 62, Loss: 0.9614163637161255, Accuracy: 0.689453125\n",
      "Batch: 63, Loss: 0.9986095428466797, Accuracy: 0.6796875\n",
      "Batch: 64, Loss: 0.9939870834350586, Accuracy: 0.6865234375\n",
      "Batch: 65, Loss: 1.0090022087097168, Accuracy: 0.68359375\n",
      "Batch: 66, Loss: 0.9497471451759338, Accuracy: 0.703125\n",
      "Batch: 67, Loss: 1.0276083946228027, Accuracy: 0.6640625\n",
      "Batch: 68, Loss: 1.040272831916809, Accuracy: 0.689453125\n",
      "Batch: 69, Loss: 0.9882788062095642, Accuracy: 0.671875\n",
      "Batch: 70, Loss: 0.9637550115585327, Accuracy: 0.697265625\n",
      "Batch: 71, Loss: 1.0220239162445068, Accuracy: 0.662109375\n",
      "Batch: 72, Loss: 0.8745608329772949, Accuracy: 0.7099609375\n",
      "Batch: 73, Loss: 0.9088810682296753, Accuracy: 0.716796875\n",
      "Batch: 74, Loss: 0.8955768346786499, Accuracy: 0.7109375\n",
      "Batch: 75, Loss: 0.8765287399291992, Accuracy: 0.7060546875\n",
      "Batch: 76, Loss: 1.001124620437622, Accuracy: 0.6640625\n",
      "Batch: 77, Loss: 0.9661381840705872, Accuracy: 0.6748046875\n",
      "Batch: 78, Loss: 0.9243468046188354, Accuracy: 0.6962890625\n",
      "Batch: 79, Loss: 0.8547073602676392, Accuracy: 0.7177734375\n",
      "Batch: 80, Loss: 0.9163943529129028, Accuracy: 0.6748046875\n",
      "Batch: 81, Loss: 1.0355018377304077, Accuracy: 0.6435546875\n",
      "Batch: 82, Loss: 0.9998849630355835, Accuracy: 0.6806640625\n",
      "Batch: 83, Loss: 0.8672242164611816, Accuracy: 0.720703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 84, Loss: 0.9176770448684692, Accuracy: 0.7041015625\n",
      "Batch: 85, Loss: 0.8730676174163818, Accuracy: 0.712890625\n",
      "Batch: 86, Loss: 1.107811689376831, Accuracy: 0.6630859375\n",
      "Batch: 87, Loss: 0.8888634443283081, Accuracy: 0.71484375\n",
      "Batch: 88, Loss: 1.0243864059448242, Accuracy: 0.681640625\n",
      "Batch: 89, Loss: 0.9907981157302856, Accuracy: 0.6923828125\n",
      "Batch: 90, Loss: 0.9418764710426331, Accuracy: 0.6806640625\n",
      "Batch: 91, Loss: 0.9480319023132324, Accuracy: 0.689453125\n",
      "Batch: 92, Loss: 0.9953486919403076, Accuracy: 0.6728515625\n",
      "Batch: 93, Loss: 0.9705172181129456, Accuracy: 0.68359375\n",
      "Batch: 94, Loss: 0.9428902864456177, Accuracy: 0.6943359375\n",
      "Batch: 95, Loss: 0.9833782911300659, Accuracy: 0.6611328125\n",
      "Batch: 96, Loss: 0.9714846014976501, Accuracy: 0.689453125\n",
      "Batch: 97, Loss: 0.8397877216339111, Accuracy: 0.7275390625\n",
      "Batch: 98, Loss: 0.8964868783950806, Accuracy: 0.7060546875\n",
      "Batch: 99, Loss: 0.8908793330192566, Accuracy: 0.7236328125\n",
      "Batch: 100, Loss: 0.9369220733642578, Accuracy: 0.7099609375\n",
      "Batch: 101, Loss: 0.9966952204704285, Accuracy: 0.6689453125\n",
      "Batch: 102, Loss: 0.9353885650634766, Accuracy: 0.6923828125\n",
      "Batch: 103, Loss: 0.9882832765579224, Accuracy: 0.681640625\n",
      "Batch: 104, Loss: 0.8861133456230164, Accuracy: 0.712890625\n",
      "Batch: 105, Loss: 0.9910308122634888, Accuracy: 0.673828125\n",
      "Batch: 106, Loss: 0.9490050077438354, Accuracy: 0.6982421875\n",
      "Batch: 107, Loss: 1.0179110765457153, Accuracy: 0.673828125\n",
      "Batch: 108, Loss: 0.99027419090271, Accuracy: 0.6572265625\n",
      "Batch: 109, Loss: 1.0691454410552979, Accuracy: 0.6494140625\n",
      "Batch: 110, Loss: 0.8482833504676819, Accuracy: 0.7177734375\n",
      "Batch: 111, Loss: 1.0203518867492676, Accuracy: 0.673828125\n",
      "Batch: 112, Loss: 0.942057192325592, Accuracy: 0.701171875\n",
      "Batch: 113, Loss: 0.9591219425201416, Accuracy: 0.7041015625\n",
      "Batch: 114, Loss: 1.0430200099945068, Accuracy: 0.6552734375\n",
      "Batch: 115, Loss: 1.0937341451644897, Accuracy: 0.662109375\n",
      "Batch: 116, Loss: 1.0283489227294922, Accuracy: 0.673828125\n",
      "Batch: 117, Loss: 1.0336699485778809, Accuracy: 0.6689453125\n",
      "Batch: 118, Loss: 0.8650855422019958, Accuracy: 0.71875\n",
      "Batch: 119, Loss: 0.8679682016372681, Accuracy: 0.7099609375\n",
      "Batch: 120, Loss: 0.9989016056060791, Accuracy: 0.6806640625\n",
      "Batch: 121, Loss: 1.0371026992797852, Accuracy: 0.6513671875\n",
      "Batch: 122, Loss: 0.9063630700111389, Accuracy: 0.708984375\n",
      "Batch: 123, Loss: 0.9524145126342773, Accuracy: 0.6904296875\n",
      "Batch: 124, Loss: 0.9579490423202515, Accuracy: 0.681640625\n",
      "Batch: 125, Loss: 1.0137803554534912, Accuracy: 0.6513671875\n",
      "Batch: 126, Loss: 0.9657264947891235, Accuracy: 0.671875\n",
      "Batch: 127, Loss: 0.8593037128448486, Accuracy: 0.740234375\n",
      "Batch: 128, Loss: 1.0622484683990479, Accuracy: 0.6611328125\n",
      "Batch: 129, Loss: 0.9428971409797668, Accuracy: 0.697265625\n",
      "Batch: 130, Loss: 1.1238994598388672, Accuracy: 0.6494140625\n",
      "Batch: 131, Loss: 0.9890046119689941, Accuracy: 0.6630859375\n",
      "Batch: 132, Loss: 1.0220423936843872, Accuracy: 0.6708984375\n",
      "Batch: 133, Loss: 0.9104536771774292, Accuracy: 0.6953125\n",
      "Batch: 134, Loss: 0.9793707132339478, Accuracy: 0.6689453125\n",
      "Batch: 135, Loss: 0.8794995546340942, Accuracy: 0.720703125\n",
      "Batch: 136, Loss: 0.9794700145721436, Accuracy: 0.685546875\n",
      "Batch: 137, Loss: 0.9443638920783997, Accuracy: 0.67578125\n",
      "Batch: 138, Loss: 0.8427213430404663, Accuracy: 0.703125\n",
      "Batch: 139, Loss: 0.9039697051048279, Accuracy: 0.6865234375\n",
      "Batch: 140, Loss: 0.9565309882164001, Accuracy: 0.697265625\n",
      "Batch: 141, Loss: 0.990495502948761, Accuracy: 0.671875\n",
      "Batch: 142, Loss: 1.0139100551605225, Accuracy: 0.6640625\n",
      "Batch: 143, Loss: 1.0088368654251099, Accuracy: 0.66015625\n",
      "Batch: 144, Loss: 0.9573831558227539, Accuracy: 0.689453125\n",
      "Batch: 145, Loss: 0.9265725612640381, Accuracy: 0.666015625\n",
      "Batch: 146, Loss: 1.0178539752960205, Accuracy: 0.662109375\n",
      "Batch: 147, Loss: 1.0161105394363403, Accuracy: 0.6689453125\n",
      "Batch: 148, Loss: 1.1081678867340088, Accuracy: 0.62890625\n",
      "Batch: 149, Loss: 0.9855408072471619, Accuracy: 0.6728515625\n",
      "Batch: 150, Loss: 0.9506310820579529, Accuracy: 0.6875\n",
      "Batch: 151, Loss: 0.8409728407859802, Accuracy: 0.7275390625\n",
      "Epoch 28/80\n",
      "Batch: 1, Loss: 1.235527753829956, Accuracy: 0.609375\n",
      "Batch: 2, Loss: 1.0419001579284668, Accuracy: 0.638671875\n",
      "Batch: 3, Loss: 0.9313315153121948, Accuracy: 0.6845703125\n",
      "Batch: 4, Loss: 0.8617425560951233, Accuracy: 0.72265625\n",
      "Batch: 5, Loss: 0.9072837233543396, Accuracy: 0.708984375\n",
      "Batch: 6, Loss: 0.9707553386688232, Accuracy: 0.681640625\n",
      "Batch: 7, Loss: 0.9321890473365784, Accuracy: 0.689453125\n",
      "Batch: 8, Loss: 0.8856451511383057, Accuracy: 0.712890625\n",
      "Batch: 9, Loss: 0.8531365394592285, Accuracy: 0.7373046875\n",
      "Batch: 10, Loss: 0.8851541876792908, Accuracy: 0.705078125\n",
      "Batch: 11, Loss: 1.0809072256088257, Accuracy: 0.6298828125\n",
      "Batch: 12, Loss: 1.0509593486785889, Accuracy: 0.66015625\n",
      "Batch: 13, Loss: 0.8119666576385498, Accuracy: 0.74609375\n",
      "Batch: 14, Loss: 1.0613582134246826, Accuracy: 0.6513671875\n",
      "Batch: 15, Loss: 0.8725595474243164, Accuracy: 0.7255859375\n",
      "Batch: 16, Loss: 0.966016948223114, Accuracy: 0.6962890625\n",
      "Batch: 17, Loss: 1.009817123413086, Accuracy: 0.6748046875\n",
      "Batch: 18, Loss: 1.0141934156417847, Accuracy: 0.6650390625\n",
      "Batch: 19, Loss: 1.0424950122833252, Accuracy: 0.6806640625\n",
      "Batch: 20, Loss: 0.8776319026947021, Accuracy: 0.7216796875\n",
      "Batch: 21, Loss: 0.918166995048523, Accuracy: 0.6875\n",
      "Batch: 22, Loss: 1.0130484104156494, Accuracy: 0.6865234375\n",
      "Batch: 23, Loss: 0.9727474451065063, Accuracy: 0.669921875\n",
      "Batch: 24, Loss: 0.9870239496231079, Accuracy: 0.669921875\n",
      "Batch: 25, Loss: 0.9584879279136658, Accuracy: 0.681640625\n",
      "Batch: 26, Loss: 0.8755525946617126, Accuracy: 0.7060546875\n",
      "Batch: 27, Loss: 0.9370675683021545, Accuracy: 0.666015625\n",
      "Batch: 28, Loss: 0.9891965985298157, Accuracy: 0.6728515625\n",
      "Batch: 29, Loss: 0.92215895652771, Accuracy: 0.6845703125\n",
      "Batch: 30, Loss: 0.8654991388320923, Accuracy: 0.73046875\n",
      "Batch: 31, Loss: 0.8515994548797607, Accuracy: 0.7275390625\n",
      "Batch: 32, Loss: 0.8753973245620728, Accuracy: 0.708984375\n",
      "Batch: 33, Loss: 1.0383503437042236, Accuracy: 0.671875\n",
      "Batch: 34, Loss: 1.0924490690231323, Accuracy: 0.65234375\n",
      "Batch: 35, Loss: 0.9932805895805359, Accuracy: 0.66796875\n",
      "Batch: 36, Loss: 1.0283063650131226, Accuracy: 0.6669921875\n",
      "Batch: 37, Loss: 0.9789837002754211, Accuracy: 0.6748046875\n",
      "Batch: 38, Loss: 1.0209476947784424, Accuracy: 0.6533203125\n",
      "Batch: 39, Loss: 0.9926243424415588, Accuracy: 0.66015625\n",
      "Batch: 40, Loss: 0.9799516201019287, Accuracy: 0.6826171875\n",
      "Batch: 41, Loss: 0.9366470575332642, Accuracy: 0.701171875\n",
      "Batch: 42, Loss: 0.7724424600601196, Accuracy: 0.736328125\n",
      "Batch: 43, Loss: 1.0001931190490723, Accuracy: 0.658203125\n",
      "Batch: 44, Loss: 0.9737982749938965, Accuracy: 0.6640625\n",
      "Batch: 45, Loss: 0.8706252574920654, Accuracy: 0.708984375\n",
      "Batch: 46, Loss: 0.9182445406913757, Accuracy: 0.7138671875\n",
      "Batch: 47, Loss: 0.9034968614578247, Accuracy: 0.71484375\n",
      "Batch: 48, Loss: 0.8750880360603333, Accuracy: 0.70703125\n",
      "Batch: 49, Loss: 1.0523048639297485, Accuracy: 0.6640625\n",
      "Batch: 50, Loss: 1.0256657600402832, Accuracy: 0.6728515625\n",
      "Batch: 51, Loss: 1.0522041320800781, Accuracy: 0.6611328125\n",
      "Batch: 52, Loss: 1.0437681674957275, Accuracy: 0.654296875\n",
      "Batch: 53, Loss: 0.9094518423080444, Accuracy: 0.6953125\n",
      "Batch: 54, Loss: 0.975651741027832, Accuracy: 0.69921875\n",
      "Batch: 55, Loss: 1.0328333377838135, Accuracy: 0.66796875\n",
      "Batch: 56, Loss: 1.0151344537734985, Accuracy: 0.658203125\n",
      "Batch: 57, Loss: 0.9681737422943115, Accuracy: 0.685546875\n",
      "Batch: 58, Loss: 1.071152687072754, Accuracy: 0.6689453125\n",
      "Batch: 59, Loss: 0.8931604027748108, Accuracy: 0.712890625\n",
      "Batch: 60, Loss: 0.86141037940979, Accuracy: 0.7265625\n",
      "Batch: 61, Loss: 0.9780279994010925, Accuracy: 0.6787109375\n",
      "Batch: 62, Loss: 0.9369556307792664, Accuracy: 0.703125\n",
      "Batch: 63, Loss: 0.9713107347488403, Accuracy: 0.685546875\n",
      "Batch: 64, Loss: 0.9532803297042847, Accuracy: 0.6865234375\n",
      "Batch: 65, Loss: 0.9823408126831055, Accuracy: 0.685546875\n",
      "Batch: 66, Loss: 0.9215567708015442, Accuracy: 0.716796875\n",
      "Batch: 67, Loss: 1.0201606750488281, Accuracy: 0.66796875\n",
      "Batch: 68, Loss: 1.0585726499557495, Accuracy: 0.666015625\n",
      "Batch: 69, Loss: 0.9858315587043762, Accuracy: 0.6787109375\n",
      "Batch: 70, Loss: 0.9529303312301636, Accuracy: 0.69140625\n",
      "Batch: 71, Loss: 1.0007765293121338, Accuracy: 0.6611328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 72, Loss: 0.8616723418235779, Accuracy: 0.7060546875\n",
      "Batch: 73, Loss: 0.89464271068573, Accuracy: 0.720703125\n",
      "Batch: 74, Loss: 0.8820384740829468, Accuracy: 0.720703125\n",
      "Batch: 75, Loss: 0.8739866614341736, Accuracy: 0.720703125\n",
      "Batch: 76, Loss: 0.9929155707359314, Accuracy: 0.65625\n",
      "Batch: 77, Loss: 0.9618943929672241, Accuracy: 0.6943359375\n",
      "Batch: 78, Loss: 0.9121948480606079, Accuracy: 0.703125\n",
      "Batch: 79, Loss: 0.8288504481315613, Accuracy: 0.736328125\n",
      "Batch: 80, Loss: 0.9148797988891602, Accuracy: 0.6865234375\n",
      "Batch: 81, Loss: 1.0312323570251465, Accuracy: 0.638671875\n",
      "Batch: 82, Loss: 0.9725033044815063, Accuracy: 0.681640625\n",
      "Batch: 83, Loss: 0.8595086932182312, Accuracy: 0.720703125\n",
      "Batch: 84, Loss: 0.9098324179649353, Accuracy: 0.708984375\n",
      "Batch: 85, Loss: 0.8617367744445801, Accuracy: 0.7158203125\n",
      "Batch: 86, Loss: 1.079430341720581, Accuracy: 0.6640625\n",
      "Batch: 87, Loss: 0.8888302445411682, Accuracy: 0.7158203125\n",
      "Batch: 88, Loss: 1.024143934249878, Accuracy: 0.69921875\n",
      "Batch: 89, Loss: 0.9850091338157654, Accuracy: 0.6953125\n",
      "Batch: 90, Loss: 0.9109148979187012, Accuracy: 0.7060546875\n",
      "Batch: 91, Loss: 0.9441183805465698, Accuracy: 0.6904296875\n",
      "Batch: 92, Loss: 0.9774159789085388, Accuracy: 0.68359375\n",
      "Batch: 93, Loss: 0.9413244724273682, Accuracy: 0.6923828125\n",
      "Batch: 94, Loss: 0.9506517648696899, Accuracy: 0.6826171875\n",
      "Batch: 95, Loss: 1.0036171674728394, Accuracy: 0.666015625\n",
      "Batch: 96, Loss: 0.9393792152404785, Accuracy: 0.689453125\n",
      "Batch: 97, Loss: 0.7985004186630249, Accuracy: 0.732421875\n",
      "Batch: 98, Loss: 0.8977741003036499, Accuracy: 0.7158203125\n",
      "Batch: 99, Loss: 0.8789599537849426, Accuracy: 0.7119140625\n",
      "Batch: 100, Loss: 0.93271803855896, Accuracy: 0.697265625\n",
      "Batch: 101, Loss: 1.0011190176010132, Accuracy: 0.6669921875\n",
      "Batch: 102, Loss: 0.941736102104187, Accuracy: 0.697265625\n",
      "Batch: 103, Loss: 0.9837558269500732, Accuracy: 0.69921875\n",
      "Batch: 104, Loss: 0.9111330509185791, Accuracy: 0.705078125\n",
      "Batch: 105, Loss: 0.9733145236968994, Accuracy: 0.671875\n",
      "Batch: 106, Loss: 0.9613543152809143, Accuracy: 0.6904296875\n",
      "Batch: 107, Loss: 0.9995929598808289, Accuracy: 0.6884765625\n",
      "Batch: 108, Loss: 1.0064142942428589, Accuracy: 0.6611328125\n",
      "Batch: 109, Loss: 1.0836890935897827, Accuracy: 0.6396484375\n",
      "Batch: 110, Loss: 0.8257690668106079, Accuracy: 0.736328125\n",
      "Batch: 111, Loss: 1.0044231414794922, Accuracy: 0.6640625\n",
      "Batch: 112, Loss: 0.9467024803161621, Accuracy: 0.6962890625\n",
      "Batch: 113, Loss: 0.9554460048675537, Accuracy: 0.6982421875\n",
      "Batch: 114, Loss: 1.0141946077346802, Accuracy: 0.6796875\n",
      "Batch: 115, Loss: 1.0677850246429443, Accuracy: 0.666015625\n",
      "Batch: 116, Loss: 1.007118582725525, Accuracy: 0.68359375\n",
      "Batch: 117, Loss: 1.0382699966430664, Accuracy: 0.65625\n",
      "Batch: 118, Loss: 0.8499056100845337, Accuracy: 0.73046875\n",
      "Batch: 119, Loss: 0.8796971440315247, Accuracy: 0.716796875\n",
      "Batch: 120, Loss: 0.9947446584701538, Accuracy: 0.673828125\n",
      "Batch: 121, Loss: 1.046034336090088, Accuracy: 0.6513671875\n",
      "Batch: 122, Loss: 0.9105768203735352, Accuracy: 0.7099609375\n",
      "Batch: 123, Loss: 0.932421088218689, Accuracy: 0.7177734375\n",
      "Batch: 124, Loss: 0.944029688835144, Accuracy: 0.6865234375\n",
      "Batch: 125, Loss: 1.0312113761901855, Accuracy: 0.6494140625\n",
      "Batch: 126, Loss: 0.9812164902687073, Accuracy: 0.671875\n",
      "Batch: 127, Loss: 0.8775067329406738, Accuracy: 0.7392578125\n",
      "Batch: 128, Loss: 1.05354905128479, Accuracy: 0.669921875\n",
      "Batch: 129, Loss: 0.9342746734619141, Accuracy: 0.6953125\n",
      "Batch: 130, Loss: 1.1101858615875244, Accuracy: 0.6513671875\n",
      "Batch: 131, Loss: 0.9688498377799988, Accuracy: 0.68359375\n",
      "Batch: 132, Loss: 1.021801471710205, Accuracy: 0.6708984375\n",
      "Batch: 133, Loss: 0.9212741851806641, Accuracy: 0.69921875\n",
      "Batch: 134, Loss: 0.9782496690750122, Accuracy: 0.6728515625\n",
      "Batch: 135, Loss: 0.894465982913971, Accuracy: 0.708984375\n",
      "Batch: 136, Loss: 0.9667423963546753, Accuracy: 0.705078125\n",
      "Batch: 137, Loss: 0.9430564641952515, Accuracy: 0.6650390625\n",
      "Batch: 138, Loss: 0.8100051879882812, Accuracy: 0.732421875\n",
      "Batch: 139, Loss: 0.892329752445221, Accuracy: 0.6953125\n",
      "Batch: 140, Loss: 0.9465785622596741, Accuracy: 0.677734375\n",
      "Batch: 141, Loss: 0.9650778770446777, Accuracy: 0.67578125\n",
      "Batch: 142, Loss: 1.0040416717529297, Accuracy: 0.6640625\n",
      "Batch: 143, Loss: 0.9707001447677612, Accuracy: 0.677734375\n",
      "Batch: 144, Loss: 0.9592055678367615, Accuracy: 0.68359375\n",
      "Batch: 145, Loss: 0.9532850980758667, Accuracy: 0.681640625\n",
      "Batch: 146, Loss: 1.0222737789154053, Accuracy: 0.66796875\n",
      "Batch: 147, Loss: 1.01833975315094, Accuracy: 0.65625\n",
      "Batch: 148, Loss: 1.0922927856445312, Accuracy: 0.640625\n",
      "Batch: 149, Loss: 0.9225528836250305, Accuracy: 0.6865234375\n",
      "Batch: 150, Loss: 0.9360637068748474, Accuracy: 0.6865234375\n",
      "Batch: 151, Loss: 0.8502500057220459, Accuracy: 0.7275390625\n",
      "Epoch 29/80\n",
      "Batch: 1, Loss: 1.2161554098129272, Accuracy: 0.611328125\n",
      "Batch: 2, Loss: 1.0102500915527344, Accuracy: 0.6484375\n",
      "Batch: 3, Loss: 0.9226359724998474, Accuracy: 0.6923828125\n",
      "Batch: 4, Loss: 0.8417575359344482, Accuracy: 0.724609375\n",
      "Batch: 5, Loss: 0.9220899939537048, Accuracy: 0.712890625\n",
      "Batch: 6, Loss: 0.9687334895133972, Accuracy: 0.6767578125\n",
      "Batch: 7, Loss: 0.9498990178108215, Accuracy: 0.681640625\n",
      "Batch: 8, Loss: 0.8947134017944336, Accuracy: 0.7041015625\n",
      "Batch: 9, Loss: 0.847266674041748, Accuracy: 0.7255859375\n",
      "Batch: 10, Loss: 0.880681037902832, Accuracy: 0.7099609375\n",
      "Batch: 11, Loss: 1.051011085510254, Accuracy: 0.646484375\n",
      "Batch: 12, Loss: 1.0192320346832275, Accuracy: 0.6796875\n",
      "Batch: 13, Loss: 0.7855886220932007, Accuracy: 0.7509765625\n",
      "Batch: 14, Loss: 1.0422334671020508, Accuracy: 0.6513671875\n",
      "Batch: 15, Loss: 0.8796727061271667, Accuracy: 0.73828125\n",
      "Batch: 16, Loss: 0.9406864047050476, Accuracy: 0.6953125\n",
      "Batch: 17, Loss: 0.9988069534301758, Accuracy: 0.662109375\n",
      "Batch: 18, Loss: 1.0169901847839355, Accuracy: 0.66015625\n",
      "Batch: 19, Loss: 1.0147160291671753, Accuracy: 0.673828125\n",
      "Batch: 20, Loss: 0.8925741910934448, Accuracy: 0.712890625\n",
      "Batch: 21, Loss: 0.927929162979126, Accuracy: 0.6943359375\n",
      "Batch: 22, Loss: 1.0500010251998901, Accuracy: 0.6767578125\n",
      "Batch: 23, Loss: 0.9825945496559143, Accuracy: 0.681640625\n",
      "Batch: 24, Loss: 0.9842891693115234, Accuracy: 0.6591796875\n",
      "Batch: 25, Loss: 0.9653055667877197, Accuracy: 0.677734375\n",
      "Batch: 26, Loss: 0.8461310863494873, Accuracy: 0.7236328125\n",
      "Batch: 27, Loss: 0.9164308905601501, Accuracy: 0.6923828125\n",
      "Batch: 28, Loss: 1.0169644355773926, Accuracy: 0.6630859375\n",
      "Batch: 29, Loss: 0.9866325855255127, Accuracy: 0.6875\n",
      "Batch: 30, Loss: 0.8877947330474854, Accuracy: 0.7255859375\n",
      "Batch: 31, Loss: 0.9295095801353455, Accuracy: 0.705078125\n",
      "Batch: 32, Loss: 0.9375688433647156, Accuracy: 0.6875\n",
      "Batch: 33, Loss: 1.0778160095214844, Accuracy: 0.6533203125\n",
      "Batch: 34, Loss: 1.165223479270935, Accuracy: 0.630859375\n",
      "Batch: 35, Loss: 1.0207159519195557, Accuracy: 0.6708984375\n",
      "Batch: 36, Loss: 1.0654385089874268, Accuracy: 0.689453125\n",
      "Batch: 37, Loss: 1.0538794994354248, Accuracy: 0.662109375\n",
      "Batch: 38, Loss: 1.0670101642608643, Accuracy: 0.65234375\n",
      "Batch: 39, Loss: 1.0198187828063965, Accuracy: 0.6787109375\n",
      "Batch: 40, Loss: 0.9970983266830444, Accuracy: 0.6826171875\n",
      "Batch: 41, Loss: 0.9263229966163635, Accuracy: 0.6962890625\n",
      "Batch: 42, Loss: 0.7814578413963318, Accuracy: 0.73828125\n",
      "Batch: 43, Loss: 1.044594645500183, Accuracy: 0.6552734375\n",
      "Batch: 44, Loss: 1.0011401176452637, Accuracy: 0.65625\n",
      "Batch: 45, Loss: 0.9044783711433411, Accuracy: 0.6943359375\n",
      "Batch: 46, Loss: 0.9083584547042847, Accuracy: 0.7060546875\n",
      "Batch: 47, Loss: 0.8967453241348267, Accuracy: 0.724609375\n",
      "Batch: 48, Loss: 0.8629278540611267, Accuracy: 0.7158203125\n",
      "Batch: 49, Loss: 1.097802758216858, Accuracy: 0.646484375\n",
      "Batch: 50, Loss: 1.0463981628417969, Accuracy: 0.654296875\n",
      "Batch: 51, Loss: 1.0870296955108643, Accuracy: 0.65625\n",
      "Batch: 52, Loss: 1.0343776941299438, Accuracy: 0.6689453125\n",
      "Batch: 53, Loss: 0.9145386815071106, Accuracy: 0.6943359375\n",
      "Batch: 54, Loss: 0.9694446325302124, Accuracy: 0.6943359375\n",
      "Batch: 55, Loss: 1.0484496355056763, Accuracy: 0.66015625\n",
      "Batch: 56, Loss: 1.0548558235168457, Accuracy: 0.6640625\n",
      "Batch: 57, Loss: 0.9693547487258911, Accuracy: 0.693359375\n",
      "Batch: 58, Loss: 1.0756056308746338, Accuracy: 0.6669921875\n",
      "Batch: 59, Loss: 0.8801479339599609, Accuracy: 0.7255859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 60, Loss: 0.851127028465271, Accuracy: 0.7294921875\n",
      "Batch: 61, Loss: 0.9931745529174805, Accuracy: 0.671875\n",
      "Batch: 62, Loss: 0.9231329560279846, Accuracy: 0.701171875\n",
      "Batch: 63, Loss: 0.9750766158103943, Accuracy: 0.6904296875\n",
      "Batch: 64, Loss: 0.9554500579833984, Accuracy: 0.6884765625\n",
      "Batch: 65, Loss: 0.9699777364730835, Accuracy: 0.703125\n",
      "Batch: 66, Loss: 0.9217169284820557, Accuracy: 0.71484375\n",
      "Batch: 67, Loss: 1.0379619598388672, Accuracy: 0.6650390625\n",
      "Batch: 68, Loss: 1.058377742767334, Accuracy: 0.669921875\n",
      "Batch: 69, Loss: 0.9735813140869141, Accuracy: 0.6767578125\n",
      "Batch: 70, Loss: 0.9662289023399353, Accuracy: 0.69921875\n",
      "Batch: 71, Loss: 0.9911007881164551, Accuracy: 0.6796875\n",
      "Batch: 72, Loss: 0.8632546067237854, Accuracy: 0.71875\n",
      "Batch: 73, Loss: 0.8923167586326599, Accuracy: 0.7158203125\n",
      "Batch: 74, Loss: 0.8784639835357666, Accuracy: 0.7197265625\n",
      "Batch: 75, Loss: 0.8690853118896484, Accuracy: 0.7119140625\n",
      "Batch: 76, Loss: 0.9740376472473145, Accuracy: 0.6748046875\n",
      "Batch: 77, Loss: 0.9436193704605103, Accuracy: 0.6962890625\n",
      "Batch: 78, Loss: 0.88673335313797, Accuracy: 0.71875\n",
      "Batch: 79, Loss: 0.8244760036468506, Accuracy: 0.736328125\n",
      "Batch: 80, Loss: 0.8987210988998413, Accuracy: 0.6943359375\n",
      "Batch: 81, Loss: 1.0369303226470947, Accuracy: 0.6455078125\n",
      "Batch: 82, Loss: 0.9775658845901489, Accuracy: 0.671875\n",
      "Batch: 83, Loss: 0.8335669636726379, Accuracy: 0.7373046875\n",
      "Batch: 84, Loss: 0.9184439182281494, Accuracy: 0.7080078125\n",
      "Batch: 85, Loss: 0.8526856303215027, Accuracy: 0.716796875\n",
      "Batch: 86, Loss: 1.0845791101455688, Accuracy: 0.654296875\n",
      "Batch: 87, Loss: 0.8894121646881104, Accuracy: 0.71875\n",
      "Batch: 88, Loss: 1.0175285339355469, Accuracy: 0.6865234375\n",
      "Batch: 89, Loss: 0.9906097650527954, Accuracy: 0.69140625\n",
      "Batch: 90, Loss: 0.9037860631942749, Accuracy: 0.716796875\n",
      "Batch: 91, Loss: 0.9134637117385864, Accuracy: 0.6953125\n",
      "Batch: 92, Loss: 0.982898473739624, Accuracy: 0.6728515625\n",
      "Batch: 93, Loss: 0.9352262616157532, Accuracy: 0.6962890625\n",
      "Batch: 94, Loss: 0.9315979480743408, Accuracy: 0.6796875\n",
      "Batch: 95, Loss: 0.9659396409988403, Accuracy: 0.6669921875\n",
      "Batch: 96, Loss: 0.9613913297653198, Accuracy: 0.6904296875\n",
      "Batch: 97, Loss: 0.8056330680847168, Accuracy: 0.73046875\n",
      "Batch: 98, Loss: 0.8847997188568115, Accuracy: 0.7255859375\n",
      "Batch: 99, Loss: 0.9000729322433472, Accuracy: 0.7041015625\n",
      "Batch: 100, Loss: 0.9203544855117798, Accuracy: 0.7041015625\n",
      "Batch: 101, Loss: 0.9993221759796143, Accuracy: 0.68359375\n",
      "Batch: 102, Loss: 0.9213626384735107, Accuracy: 0.7021484375\n",
      "Batch: 103, Loss: 0.9343197345733643, Accuracy: 0.7060546875\n",
      "Batch: 104, Loss: 0.8759808540344238, Accuracy: 0.697265625\n",
      "Batch: 105, Loss: 0.9798314571380615, Accuracy: 0.6982421875\n",
      "Batch: 106, Loss: 0.9265197515487671, Accuracy: 0.69921875\n",
      "Batch: 107, Loss: 0.9646009206771851, Accuracy: 0.6826171875\n",
      "Batch: 108, Loss: 0.9623802900314331, Accuracy: 0.68359375\n",
      "Batch: 109, Loss: 1.0788358449935913, Accuracy: 0.6513671875\n",
      "Batch: 110, Loss: 0.8297321796417236, Accuracy: 0.732421875\n",
      "Batch: 111, Loss: 0.972192645072937, Accuracy: 0.681640625\n",
      "Batch: 112, Loss: 0.9208313226699829, Accuracy: 0.7138671875\n",
      "Batch: 113, Loss: 0.9645219445228577, Accuracy: 0.69921875\n",
      "Batch: 114, Loss: 1.0308749675750732, Accuracy: 0.6708984375\n",
      "Batch: 115, Loss: 1.0745916366577148, Accuracy: 0.6484375\n",
      "Batch: 116, Loss: 1.0008498430252075, Accuracy: 0.671875\n",
      "Batch: 117, Loss: 1.009775996208191, Accuracy: 0.6689453125\n",
      "Batch: 118, Loss: 0.8405495285987854, Accuracy: 0.7373046875\n",
      "Batch: 119, Loss: 0.8239900469779968, Accuracy: 0.73046875\n",
      "Batch: 120, Loss: 0.9939794540405273, Accuracy: 0.65625\n",
      "Batch: 121, Loss: 1.0411062240600586, Accuracy: 0.66015625\n",
      "Batch: 122, Loss: 0.9078628420829773, Accuracy: 0.7099609375\n",
      "Batch: 123, Loss: 0.8977479934692383, Accuracy: 0.716796875\n",
      "Batch: 124, Loss: 0.9697076082229614, Accuracy: 0.67578125\n",
      "Batch: 125, Loss: 1.0011407136917114, Accuracy: 0.654296875\n",
      "Batch: 126, Loss: 0.9548695087432861, Accuracy: 0.6943359375\n",
      "Batch: 127, Loss: 0.8630887269973755, Accuracy: 0.73046875\n",
      "Batch: 128, Loss: 1.0998289585113525, Accuracy: 0.66015625\n",
      "Batch: 129, Loss: 0.8989020586013794, Accuracy: 0.716796875\n",
      "Batch: 130, Loss: 1.0891666412353516, Accuracy: 0.6640625\n",
      "Batch: 131, Loss: 0.964198887348175, Accuracy: 0.669921875\n",
      "Batch: 132, Loss: 0.9767402410507202, Accuracy: 0.6884765625\n",
      "Batch: 133, Loss: 0.9014010429382324, Accuracy: 0.6953125\n",
      "Batch: 134, Loss: 0.9633231163024902, Accuracy: 0.69140625\n",
      "Batch: 135, Loss: 0.8801947832107544, Accuracy: 0.7255859375\n",
      "Batch: 136, Loss: 0.971799373626709, Accuracy: 0.677734375\n",
      "Batch: 137, Loss: 0.9110769033432007, Accuracy: 0.6865234375\n",
      "Batch: 138, Loss: 0.8356881141662598, Accuracy: 0.72265625\n",
      "Batch: 139, Loss: 0.8776074647903442, Accuracy: 0.6865234375\n",
      "Batch: 140, Loss: 0.944862961769104, Accuracy: 0.68359375\n",
      "Batch: 141, Loss: 0.9642636775970459, Accuracy: 0.6875\n",
      "Batch: 142, Loss: 0.9836249351501465, Accuracy: 0.68359375\n",
      "Batch: 143, Loss: 0.9449352025985718, Accuracy: 0.6962890625\n",
      "Batch: 144, Loss: 0.9317382574081421, Accuracy: 0.693359375\n",
      "Batch: 145, Loss: 0.9135845303535461, Accuracy: 0.677734375\n",
      "Batch: 146, Loss: 1.0041837692260742, Accuracy: 0.666015625\n",
      "Batch: 147, Loss: 0.9793996214866638, Accuracy: 0.68359375\n",
      "Batch: 148, Loss: 1.0881154537200928, Accuracy: 0.64453125\n",
      "Batch: 149, Loss: 0.9458813667297363, Accuracy: 0.6875\n",
      "Batch: 150, Loss: 0.933724582195282, Accuracy: 0.6962890625\n",
      "Batch: 151, Loss: 0.8578890562057495, Accuracy: 0.7197265625\n",
      "Epoch 30/80\n",
      "Batch: 1, Loss: 1.1891154050827026, Accuracy: 0.6142578125\n",
      "Batch: 2, Loss: 1.0183258056640625, Accuracy: 0.6494140625\n",
      "Batch: 3, Loss: 0.9051334857940674, Accuracy: 0.6904296875\n",
      "Batch: 4, Loss: 0.8199025988578796, Accuracy: 0.7421875\n",
      "Batch: 5, Loss: 0.891463041305542, Accuracy: 0.7021484375\n",
      "Batch: 6, Loss: 0.9622775912284851, Accuracy: 0.6884765625\n",
      "Batch: 7, Loss: 0.9209271669387817, Accuracy: 0.6904296875\n",
      "Batch: 8, Loss: 0.8788086175918579, Accuracy: 0.6923828125\n",
      "Batch: 9, Loss: 0.8381726741790771, Accuracy: 0.736328125\n",
      "Batch: 10, Loss: 0.8583900332450867, Accuracy: 0.6982421875\n",
      "Batch: 11, Loss: 1.0239454507827759, Accuracy: 0.64453125\n",
      "Batch: 12, Loss: 1.0167967081069946, Accuracy: 0.669921875\n",
      "Batch: 13, Loss: 0.7698150873184204, Accuracy: 0.74609375\n",
      "Batch: 14, Loss: 1.0671733617782593, Accuracy: 0.63671875\n",
      "Batch: 15, Loss: 0.8481404781341553, Accuracy: 0.7353515625\n",
      "Batch: 16, Loss: 0.9325593709945679, Accuracy: 0.6904296875\n",
      "Batch: 17, Loss: 0.9909756183624268, Accuracy: 0.6767578125\n",
      "Batch: 18, Loss: 0.9866609573364258, Accuracy: 0.6708984375\n",
      "Batch: 19, Loss: 0.9943739175796509, Accuracy: 0.6962890625\n",
      "Batch: 20, Loss: 0.8640687465667725, Accuracy: 0.7275390625\n",
      "Batch: 21, Loss: 0.9119703769683838, Accuracy: 0.6884765625\n",
      "Batch: 22, Loss: 0.9882732629776001, Accuracy: 0.6865234375\n",
      "Batch: 23, Loss: 0.9583176374435425, Accuracy: 0.68359375\n",
      "Batch: 24, Loss: 0.9550434350967407, Accuracy: 0.6865234375\n",
      "Batch: 25, Loss: 0.9268616437911987, Accuracy: 0.7001953125\n",
      "Batch: 26, Loss: 0.8308500647544861, Accuracy: 0.71875\n",
      "Batch: 27, Loss: 0.9105072021484375, Accuracy: 0.6943359375\n",
      "Batch: 28, Loss: 0.9642907381057739, Accuracy: 0.6689453125\n",
      "Batch: 29, Loss: 0.9085199236869812, Accuracy: 0.69140625\n",
      "Batch: 30, Loss: 0.8550997972488403, Accuracy: 0.732421875\n",
      "Batch: 31, Loss: 0.8690232038497925, Accuracy: 0.732421875\n",
      "Batch: 32, Loss: 0.8605554103851318, Accuracy: 0.7158203125\n",
      "Batch: 33, Loss: 1.0420503616333008, Accuracy: 0.669921875\n",
      "Batch: 34, Loss: 1.0479586124420166, Accuracy: 0.6533203125\n",
      "Batch: 35, Loss: 0.9826997518539429, Accuracy: 0.6689453125\n",
      "Batch: 36, Loss: 1.0069186687469482, Accuracy: 0.6845703125\n",
      "Batch: 37, Loss: 0.9620246291160583, Accuracy: 0.6923828125\n",
      "Batch: 38, Loss: 0.9799625873565674, Accuracy: 0.677734375\n",
      "Batch: 39, Loss: 0.9905943870544434, Accuracy: 0.6630859375\n",
      "Batch: 40, Loss: 0.9649606943130493, Accuracy: 0.6845703125\n",
      "Batch: 41, Loss: 0.9189250469207764, Accuracy: 0.7001953125\n",
      "Batch: 42, Loss: 0.7571398019790649, Accuracy: 0.7421875\n",
      "Batch: 43, Loss: 0.9595680236816406, Accuracy: 0.6923828125\n",
      "Batch: 44, Loss: 0.9557626247406006, Accuracy: 0.6728515625\n",
      "Batch: 45, Loss: 0.8731299042701721, Accuracy: 0.693359375\n",
      "Batch: 46, Loss: 0.9061212539672852, Accuracy: 0.6982421875\n",
      "Batch: 47, Loss: 0.8877935409545898, Accuracy: 0.734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 48, Loss: 0.8574850559234619, Accuracy: 0.7265625\n",
      "Batch: 49, Loss: 1.033968448638916, Accuracy: 0.6728515625\n",
      "Batch: 50, Loss: 1.0184928178787231, Accuracy: 0.6552734375\n",
      "Batch: 51, Loss: 1.0481563806533813, Accuracy: 0.666015625\n",
      "Batch: 52, Loss: 0.9866076707839966, Accuracy: 0.68359375\n",
      "Batch: 53, Loss: 0.8803320527076721, Accuracy: 0.6923828125\n",
      "Batch: 54, Loss: 0.9447574019432068, Accuracy: 0.7001953125\n",
      "Batch: 55, Loss: 1.008326530456543, Accuracy: 0.6748046875\n",
      "Batch: 56, Loss: 1.023057222366333, Accuracy: 0.6669921875\n",
      "Batch: 57, Loss: 0.9530913829803467, Accuracy: 0.6796875\n",
      "Batch: 58, Loss: 1.0664230585098267, Accuracy: 0.6767578125\n",
      "Batch: 59, Loss: 0.8550733923912048, Accuracy: 0.7265625\n",
      "Batch: 60, Loss: 0.8437693119049072, Accuracy: 0.7236328125\n",
      "Batch: 61, Loss: 0.9797607660293579, Accuracy: 0.6865234375\n",
      "Batch: 62, Loss: 0.9127224087715149, Accuracy: 0.7119140625\n",
      "Batch: 63, Loss: 0.9530054926872253, Accuracy: 0.6982421875\n",
      "Batch: 64, Loss: 0.940176248550415, Accuracy: 0.68359375\n",
      "Batch: 65, Loss: 0.9837259650230408, Accuracy: 0.6865234375\n",
      "Batch: 66, Loss: 0.9094468355178833, Accuracy: 0.7158203125\n",
      "Batch: 67, Loss: 1.0238008499145508, Accuracy: 0.681640625\n",
      "Batch: 68, Loss: 1.0048335790634155, Accuracy: 0.6884765625\n",
      "Batch: 69, Loss: 0.9808678030967712, Accuracy: 0.6806640625\n",
      "Batch: 70, Loss: 0.9434478878974915, Accuracy: 0.6904296875\n",
      "Batch: 71, Loss: 0.9647132158279419, Accuracy: 0.677734375\n",
      "Batch: 72, Loss: 0.8186577558517456, Accuracy: 0.7255859375\n",
      "Batch: 73, Loss: 0.8736782073974609, Accuracy: 0.7353515625\n",
      "Batch: 74, Loss: 0.8385567665100098, Accuracy: 0.7197265625\n",
      "Batch: 75, Loss: 0.8539263010025024, Accuracy: 0.7216796875\n",
      "Batch: 76, Loss: 0.9551019072532654, Accuracy: 0.666015625\n",
      "Batch: 77, Loss: 0.935785174369812, Accuracy: 0.689453125\n",
      "Batch: 78, Loss: 0.8726505041122437, Accuracy: 0.7255859375\n",
      "Batch: 79, Loss: 0.8364251852035522, Accuracy: 0.73046875\n",
      "Batch: 80, Loss: 0.894924521446228, Accuracy: 0.701171875\n",
      "Batch: 81, Loss: 1.0128761529922485, Accuracy: 0.6484375\n",
      "Batch: 82, Loss: 0.9718908071517944, Accuracy: 0.6875\n",
      "Batch: 83, Loss: 0.8288822174072266, Accuracy: 0.734375\n",
      "Batch: 84, Loss: 0.9122639894485474, Accuracy: 0.7001953125\n",
      "Batch: 85, Loss: 0.8398263454437256, Accuracy: 0.73046875\n",
      "Batch: 86, Loss: 1.078621506690979, Accuracy: 0.6708984375\n",
      "Batch: 87, Loss: 0.8662348985671997, Accuracy: 0.72265625\n",
      "Batch: 88, Loss: 0.980715274810791, Accuracy: 0.6962890625\n",
      "Batch: 89, Loss: 0.9691962599754333, Accuracy: 0.6884765625\n",
      "Batch: 90, Loss: 0.8752632141113281, Accuracy: 0.70703125\n",
      "Batch: 91, Loss: 0.9197111129760742, Accuracy: 0.7021484375\n",
      "Batch: 92, Loss: 0.9677359461784363, Accuracy: 0.6884765625\n",
      "Batch: 93, Loss: 0.9228328466415405, Accuracy: 0.7080078125\n",
      "Batch: 94, Loss: 0.9248515367507935, Accuracy: 0.6884765625\n",
      "Batch: 95, Loss: 0.9785639643669128, Accuracy: 0.689453125\n",
      "Batch: 96, Loss: 0.9263797998428345, Accuracy: 0.705078125\n",
      "Batch: 97, Loss: 0.7954695224761963, Accuracy: 0.75\n",
      "Batch: 98, Loss: 0.867572009563446, Accuracy: 0.736328125\n",
      "Batch: 99, Loss: 0.86338210105896, Accuracy: 0.716796875\n",
      "Batch: 100, Loss: 0.9156432747840881, Accuracy: 0.705078125\n",
      "Batch: 101, Loss: 0.9928682446479797, Accuracy: 0.681640625\n",
      "Batch: 102, Loss: 0.9371256828308105, Accuracy: 0.69921875\n",
      "Batch: 103, Loss: 0.9460365772247314, Accuracy: 0.697265625\n",
      "Batch: 104, Loss: 0.8530322313308716, Accuracy: 0.7177734375\n",
      "Batch: 105, Loss: 0.9640958905220032, Accuracy: 0.6953125\n",
      "Batch: 106, Loss: 0.9051110744476318, Accuracy: 0.7109375\n",
      "Batch: 107, Loss: 0.9624347686767578, Accuracy: 0.7001953125\n",
      "Batch: 108, Loss: 0.9232872724533081, Accuracy: 0.685546875\n",
      "Batch: 109, Loss: 1.0681836605072021, Accuracy: 0.66796875\n",
      "Batch: 110, Loss: 0.8211854696273804, Accuracy: 0.724609375\n",
      "Batch: 111, Loss: 0.95461106300354, Accuracy: 0.71484375\n",
      "Batch: 112, Loss: 0.9117789268493652, Accuracy: 0.712890625\n",
      "Batch: 113, Loss: 0.9469718337059021, Accuracy: 0.697265625\n",
      "Batch: 114, Loss: 1.0031423568725586, Accuracy: 0.6728515625\n",
      "Batch: 115, Loss: 1.065388798713684, Accuracy: 0.6630859375\n",
      "Batch: 116, Loss: 1.0041126012802124, Accuracy: 0.6787109375\n",
      "Batch: 117, Loss: 0.9988985657691956, Accuracy: 0.66796875\n",
      "Batch: 118, Loss: 0.8575408458709717, Accuracy: 0.7333984375\n",
      "Batch: 119, Loss: 0.8099043965339661, Accuracy: 0.732421875\n",
      "Batch: 120, Loss: 0.9803144931793213, Accuracy: 0.6884765625\n",
      "Batch: 121, Loss: 1.0000407695770264, Accuracy: 0.666015625\n",
      "Batch: 122, Loss: 0.884687066078186, Accuracy: 0.728515625\n",
      "Batch: 123, Loss: 0.8934676051139832, Accuracy: 0.7177734375\n",
      "Batch: 124, Loss: 0.9442540407180786, Accuracy: 0.685546875\n",
      "Batch: 125, Loss: 0.9864381551742554, Accuracy: 0.65625\n",
      "Batch: 126, Loss: 0.9435300230979919, Accuracy: 0.685546875\n",
      "Batch: 127, Loss: 0.8517194986343384, Accuracy: 0.7255859375\n",
      "Batch: 128, Loss: 1.0396572351455688, Accuracy: 0.669921875\n",
      "Batch: 129, Loss: 0.9016623497009277, Accuracy: 0.7099609375\n",
      "Batch: 130, Loss: 1.1010252237319946, Accuracy: 0.6533203125\n",
      "Batch: 131, Loss: 0.9554194808006287, Accuracy: 0.6875\n",
      "Batch: 132, Loss: 0.9895143508911133, Accuracy: 0.6806640625\n",
      "Batch: 133, Loss: 0.8600045442581177, Accuracy: 0.7138671875\n",
      "Batch: 134, Loss: 0.9536535143852234, Accuracy: 0.6884765625\n",
      "Batch: 135, Loss: 0.8460513353347778, Accuracy: 0.7294921875\n",
      "Batch: 136, Loss: 0.9366561770439148, Accuracy: 0.6875\n",
      "Batch: 137, Loss: 0.9022578001022339, Accuracy: 0.6962890625\n",
      "Batch: 138, Loss: 0.8065403699874878, Accuracy: 0.7431640625\n",
      "Batch: 139, Loss: 0.8635335564613342, Accuracy: 0.71484375\n",
      "Batch: 140, Loss: 0.9344052076339722, Accuracy: 0.6943359375\n",
      "Batch: 141, Loss: 0.9523527026176453, Accuracy: 0.689453125\n",
      "Batch: 142, Loss: 0.9848171472549438, Accuracy: 0.66796875\n",
      "Batch: 143, Loss: 0.9511803984642029, Accuracy: 0.6787109375\n",
      "Batch: 144, Loss: 0.925959050655365, Accuracy: 0.697265625\n",
      "Batch: 145, Loss: 0.9073982238769531, Accuracy: 0.685546875\n",
      "Batch: 146, Loss: 0.9817550182342529, Accuracy: 0.681640625\n",
      "Batch: 147, Loss: 0.9711588621139526, Accuracy: 0.681640625\n",
      "Batch: 148, Loss: 1.0678870677947998, Accuracy: 0.6396484375\n",
      "Batch: 149, Loss: 0.9378918409347534, Accuracy: 0.6787109375\n",
      "Batch: 150, Loss: 0.9140096306800842, Accuracy: 0.7060546875\n",
      "Batch: 151, Loss: 0.8228745460510254, Accuracy: 0.7353515625\n",
      "Saved Weights at epoch 30 to file Weights_30.h5\n",
      "Epoch 31/80\n",
      "Batch: 1, Loss: 1.152633786201477, Accuracy: 0.623046875\n",
      "Batch: 2, Loss: 1.0236549377441406, Accuracy: 0.65234375\n",
      "Batch: 3, Loss: 0.8741780519485474, Accuracy: 0.705078125\n",
      "Batch: 4, Loss: 0.8114877939224243, Accuracy: 0.744140625\n",
      "Batch: 5, Loss: 0.8741663694381714, Accuracy: 0.7138671875\n",
      "Batch: 6, Loss: 0.9251297116279602, Accuracy: 0.6953125\n",
      "Batch: 7, Loss: 0.8787164688110352, Accuracy: 0.7001953125\n",
      "Batch: 8, Loss: 0.855975866317749, Accuracy: 0.71484375\n",
      "Batch: 9, Loss: 0.8394023180007935, Accuracy: 0.720703125\n",
      "Batch: 10, Loss: 0.8629330992698669, Accuracy: 0.708984375\n",
      "Batch: 11, Loss: 1.038273572921753, Accuracy: 0.6572265625\n",
      "Batch: 12, Loss: 0.9994558095932007, Accuracy: 0.669921875\n",
      "Batch: 13, Loss: 0.7649255990982056, Accuracy: 0.7431640625\n",
      "Batch: 14, Loss: 1.0343165397644043, Accuracy: 0.662109375\n",
      "Batch: 15, Loss: 0.8289557695388794, Accuracy: 0.7373046875\n",
      "Batch: 16, Loss: 0.9309574365615845, Accuracy: 0.6806640625\n",
      "Batch: 17, Loss: 0.9582490921020508, Accuracy: 0.689453125\n",
      "Batch: 18, Loss: 0.9469112157821655, Accuracy: 0.693359375\n",
      "Batch: 19, Loss: 0.9896031618118286, Accuracy: 0.6806640625\n",
      "Batch: 20, Loss: 0.8519821763038635, Accuracy: 0.7294921875\n",
      "Batch: 21, Loss: 0.8996812105178833, Accuracy: 0.6923828125\n",
      "Batch: 22, Loss: 1.0064067840576172, Accuracy: 0.677734375\n",
      "Batch: 23, Loss: 0.9246120452880859, Accuracy: 0.681640625\n",
      "Batch: 24, Loss: 0.9245805144309998, Accuracy: 0.6884765625\n",
      "Batch: 25, Loss: 0.9222944974899292, Accuracy: 0.6875\n",
      "Batch: 26, Loss: 0.8118723630905151, Accuracy: 0.7177734375\n",
      "Batch: 27, Loss: 0.865226149559021, Accuracy: 0.6953125\n",
      "Batch: 28, Loss: 0.9670608043670654, Accuracy: 0.6806640625\n",
      "Batch: 29, Loss: 0.894630491733551, Accuracy: 0.701171875\n",
      "Batch: 30, Loss: 0.8177837133407593, Accuracy: 0.7470703125\n",
      "Batch: 31, Loss: 0.8404561877250671, Accuracy: 0.732421875\n",
      "Batch: 32, Loss: 0.8787420392036438, Accuracy: 0.69921875\n",
      "Batch: 33, Loss: 1.004089117050171, Accuracy: 0.6708984375\n",
      "Batch: 34, Loss: 1.0452076196670532, Accuracy: 0.65625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 35, Loss: 0.970488965511322, Accuracy: 0.69140625\n",
      "Batch: 36, Loss: 0.9704650640487671, Accuracy: 0.685546875\n",
      "Batch: 37, Loss: 0.9452277421951294, Accuracy: 0.693359375\n",
      "Batch: 38, Loss: 0.9849838614463806, Accuracy: 0.6630859375\n",
      "Batch: 39, Loss: 0.980362057685852, Accuracy: 0.68359375\n",
      "Batch: 40, Loss: 0.9067941904067993, Accuracy: 0.7080078125\n",
      "Batch: 41, Loss: 0.9100477695465088, Accuracy: 0.7099609375\n",
      "Batch: 42, Loss: 0.7407609224319458, Accuracy: 0.748046875\n",
      "Batch: 43, Loss: 0.9771761894226074, Accuracy: 0.6689453125\n",
      "Batch: 44, Loss: 0.9813656806945801, Accuracy: 0.666015625\n",
      "Batch: 45, Loss: 0.8803714513778687, Accuracy: 0.69921875\n",
      "Batch: 46, Loss: 0.8595880270004272, Accuracy: 0.716796875\n",
      "Batch: 47, Loss: 0.8966681957244873, Accuracy: 0.7138671875\n",
      "Batch: 48, Loss: 0.80926513671875, Accuracy: 0.7333984375\n",
      "Batch: 49, Loss: 1.0162129402160645, Accuracy: 0.654296875\n",
      "Batch: 50, Loss: 0.9934457540512085, Accuracy: 0.6708984375\n",
      "Batch: 51, Loss: 1.0407912731170654, Accuracy: 0.66796875\n",
      "Batch: 52, Loss: 0.9852650165557861, Accuracy: 0.6806640625\n",
      "Batch: 53, Loss: 0.8814113736152649, Accuracy: 0.7060546875\n",
      "Batch: 54, Loss: 0.9312912821769714, Accuracy: 0.705078125\n",
      "Batch: 55, Loss: 1.0045026540756226, Accuracy: 0.658203125\n",
      "Batch: 56, Loss: 1.0118329524993896, Accuracy: 0.6767578125\n",
      "Batch: 57, Loss: 0.9225125908851624, Accuracy: 0.697265625\n",
      "Batch: 58, Loss: 1.0640960931777954, Accuracy: 0.6845703125\n",
      "Batch: 59, Loss: 0.8660493493080139, Accuracy: 0.7333984375\n",
      "Batch: 60, Loss: 0.8435472249984741, Accuracy: 0.7255859375\n",
      "Batch: 61, Loss: 0.9501492977142334, Accuracy: 0.6806640625\n",
      "Batch: 62, Loss: 0.9092761278152466, Accuracy: 0.705078125\n",
      "Batch: 63, Loss: 0.9568939208984375, Accuracy: 0.689453125\n",
      "Batch: 64, Loss: 0.9356387853622437, Accuracy: 0.69140625\n",
      "Batch: 65, Loss: 0.9741725921630859, Accuracy: 0.693359375\n",
      "Batch: 66, Loss: 0.9045292139053345, Accuracy: 0.712890625\n",
      "Batch: 67, Loss: 0.9986734390258789, Accuracy: 0.681640625\n",
      "Batch: 68, Loss: 1.0094244480133057, Accuracy: 0.6845703125\n",
      "Batch: 69, Loss: 0.943412184715271, Accuracy: 0.70703125\n",
      "Batch: 70, Loss: 0.9337412714958191, Accuracy: 0.70703125\n",
      "Batch: 71, Loss: 0.9795768857002258, Accuracy: 0.68359375\n",
      "Batch: 72, Loss: 0.8284151554107666, Accuracy: 0.7255859375\n",
      "Batch: 73, Loss: 0.8646427392959595, Accuracy: 0.7236328125\n",
      "Batch: 74, Loss: 0.8454359769821167, Accuracy: 0.7314453125\n",
      "Batch: 75, Loss: 0.851386308670044, Accuracy: 0.7216796875\n",
      "Batch: 76, Loss: 0.9436609148979187, Accuracy: 0.6796875\n",
      "Batch: 77, Loss: 0.9226263761520386, Accuracy: 0.705078125\n",
      "Batch: 78, Loss: 0.8801625967025757, Accuracy: 0.7275390625\n",
      "Batch: 79, Loss: 0.7819868922233582, Accuracy: 0.76171875\n",
      "Batch: 80, Loss: 0.8703266382217407, Accuracy: 0.6865234375\n",
      "Batch: 81, Loss: 1.0039749145507812, Accuracy: 0.6494140625\n",
      "Batch: 82, Loss: 0.9511404037475586, Accuracy: 0.6982421875\n",
      "Batch: 83, Loss: 0.8195063471794128, Accuracy: 0.73046875\n",
      "Batch: 84, Loss: 0.8673744201660156, Accuracy: 0.736328125\n",
      "Batch: 85, Loss: 0.8343308568000793, Accuracy: 0.7275390625\n",
      "Batch: 86, Loss: 1.060576319694519, Accuracy: 0.677734375\n",
      "Batch: 87, Loss: 0.8560159802436829, Accuracy: 0.7333984375\n",
      "Batch: 88, Loss: 0.9780054688453674, Accuracy: 0.6953125\n",
      "Batch: 89, Loss: 0.9641966819763184, Accuracy: 0.689453125\n",
      "Batch: 90, Loss: 0.8769536018371582, Accuracy: 0.6982421875\n",
      "Batch: 91, Loss: 0.9008083343505859, Accuracy: 0.703125\n",
      "Batch: 92, Loss: 0.9509490132331848, Accuracy: 0.693359375\n",
      "Batch: 93, Loss: 0.9148359298706055, Accuracy: 0.7060546875\n",
      "Batch: 94, Loss: 0.9205304384231567, Accuracy: 0.7001953125\n",
      "Batch: 95, Loss: 0.9570773839950562, Accuracy: 0.6884765625\n",
      "Batch: 96, Loss: 0.8840997219085693, Accuracy: 0.7138671875\n",
      "Batch: 97, Loss: 0.7748687267303467, Accuracy: 0.7431640625\n",
      "Batch: 98, Loss: 0.8687516450881958, Accuracy: 0.72265625\n",
      "Batch: 99, Loss: 0.8633605241775513, Accuracy: 0.716796875\n",
      "Batch: 100, Loss: 0.9132870435714722, Accuracy: 0.708984375\n",
      "Batch: 101, Loss: 0.9592329859733582, Accuracy: 0.6943359375\n",
      "Batch: 102, Loss: 0.938522458076477, Accuracy: 0.6943359375\n",
      "Batch: 103, Loss: 0.9146708250045776, Accuracy: 0.7021484375\n",
      "Batch: 104, Loss: 0.848583459854126, Accuracy: 0.720703125\n",
      "Batch: 105, Loss: 0.9400731325149536, Accuracy: 0.68359375\n",
      "Batch: 106, Loss: 0.9165039658546448, Accuracy: 0.6943359375\n",
      "Batch: 107, Loss: 0.9426226615905762, Accuracy: 0.7060546875\n",
      "Batch: 108, Loss: 0.9434782266616821, Accuracy: 0.685546875\n",
      "Batch: 109, Loss: 1.0347943305969238, Accuracy: 0.66015625\n",
      "Batch: 110, Loss: 0.8296822905540466, Accuracy: 0.7255859375\n",
      "Batch: 111, Loss: 0.9525018930435181, Accuracy: 0.693359375\n",
      "Batch: 112, Loss: 0.9099449515342712, Accuracy: 0.6982421875\n",
      "Batch: 113, Loss: 0.9365477561950684, Accuracy: 0.7158203125\n",
      "Batch: 114, Loss: 0.9947966933250427, Accuracy: 0.68359375\n",
      "Batch: 115, Loss: 1.0614831447601318, Accuracy: 0.6591796875\n",
      "Batch: 116, Loss: 0.9764589071273804, Accuracy: 0.6806640625\n",
      "Batch: 117, Loss: 0.9827144145965576, Accuracy: 0.681640625\n",
      "Batch: 118, Loss: 0.8295390605926514, Accuracy: 0.734375\n",
      "Batch: 119, Loss: 0.8032255172729492, Accuracy: 0.7451171875\n",
      "Batch: 120, Loss: 0.9595083594322205, Accuracy: 0.68359375\n",
      "Batch: 121, Loss: 0.9791992902755737, Accuracy: 0.6748046875\n",
      "Batch: 122, Loss: 0.8798058032989502, Accuracy: 0.7109375\n",
      "Batch: 123, Loss: 0.862073540687561, Accuracy: 0.732421875\n",
      "Batch: 124, Loss: 0.9367830753326416, Accuracy: 0.689453125\n",
      "Batch: 125, Loss: 0.9714430570602417, Accuracy: 0.6787109375\n",
      "Batch: 126, Loss: 0.9537343978881836, Accuracy: 0.69140625\n",
      "Batch: 127, Loss: 0.8479456901550293, Accuracy: 0.7333984375\n",
      "Batch: 128, Loss: 1.0313403606414795, Accuracy: 0.6748046875\n",
      "Batch: 129, Loss: 0.8592155575752258, Accuracy: 0.7216796875\n",
      "Batch: 130, Loss: 1.064164638519287, Accuracy: 0.6552734375\n",
      "Batch: 131, Loss: 0.9483305215835571, Accuracy: 0.68359375\n",
      "Batch: 132, Loss: 0.9497625827789307, Accuracy: 0.693359375\n",
      "Batch: 133, Loss: 0.8737112283706665, Accuracy: 0.7119140625\n",
      "Batch: 134, Loss: 0.9423747062683105, Accuracy: 0.685546875\n",
      "Batch: 135, Loss: 0.861370325088501, Accuracy: 0.71875\n",
      "Batch: 136, Loss: 0.9284330010414124, Accuracy: 0.6982421875\n",
      "Batch: 137, Loss: 0.8975605368614197, Accuracy: 0.697265625\n",
      "Batch: 138, Loss: 0.7808946371078491, Accuracy: 0.740234375\n",
      "Batch: 139, Loss: 0.8878886103630066, Accuracy: 0.6923828125\n",
      "Batch: 140, Loss: 0.9167275428771973, Accuracy: 0.6982421875\n",
      "Batch: 141, Loss: 0.9400529861450195, Accuracy: 0.689453125\n",
      "Batch: 142, Loss: 0.9549630284309387, Accuracy: 0.6865234375\n",
      "Batch: 143, Loss: 0.9205655455589294, Accuracy: 0.701171875\n",
      "Batch: 144, Loss: 0.9224549531936646, Accuracy: 0.6982421875\n",
      "Batch: 145, Loss: 0.8971648216247559, Accuracy: 0.6796875\n",
      "Batch: 146, Loss: 0.9766575694084167, Accuracy: 0.6845703125\n",
      "Batch: 147, Loss: 0.9809258580207825, Accuracy: 0.6787109375\n",
      "Batch: 148, Loss: 1.077347755432129, Accuracy: 0.626953125\n",
      "Batch: 149, Loss: 0.9259554147720337, Accuracy: 0.69140625\n",
      "Batch: 150, Loss: 0.8987039923667908, Accuracy: 0.7060546875\n",
      "Batch: 151, Loss: 0.8236817121505737, Accuracy: 0.7353515625\n",
      "Epoch 32/80\n",
      "Batch: 1, Loss: 1.1553666591644287, Accuracy: 0.6396484375\n",
      "Batch: 2, Loss: 1.0171962976455688, Accuracy: 0.6474609375\n",
      "Batch: 3, Loss: 0.8684749603271484, Accuracy: 0.70703125\n",
      "Batch: 4, Loss: 0.8007169365882874, Accuracy: 0.732421875\n",
      "Batch: 5, Loss: 0.8949266672134399, Accuracy: 0.708984375\n",
      "Batch: 6, Loss: 0.9236640334129333, Accuracy: 0.697265625\n",
      "Batch: 7, Loss: 0.9151816964149475, Accuracy: 0.681640625\n",
      "Batch: 8, Loss: 0.8608381748199463, Accuracy: 0.736328125\n",
      "Batch: 9, Loss: 0.8390846252441406, Accuracy: 0.7255859375\n",
      "Batch: 10, Loss: 0.8611142635345459, Accuracy: 0.7158203125\n",
      "Batch: 11, Loss: 1.0047727823257446, Accuracy: 0.66015625\n",
      "Batch: 12, Loss: 0.9956653118133545, Accuracy: 0.6640625\n",
      "Batch: 13, Loss: 0.7585170865058899, Accuracy: 0.7548828125\n",
      "Batch: 14, Loss: 1.0458028316497803, Accuracy: 0.6552734375\n",
      "Batch: 15, Loss: 0.8239588737487793, Accuracy: 0.7431640625\n",
      "Batch: 16, Loss: 0.8911501169204712, Accuracy: 0.71484375\n",
      "Batch: 17, Loss: 0.9652137160301208, Accuracy: 0.6962890625\n",
      "Batch: 18, Loss: 0.9743176698684692, Accuracy: 0.6826171875\n",
      "Batch: 19, Loss: 0.9503297805786133, Accuracy: 0.69921875\n",
      "Batch: 20, Loss: 0.8373993039131165, Accuracy: 0.7275390625\n",
      "Batch: 21, Loss: 0.9003709554672241, Accuracy: 0.70703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 22, Loss: 0.971813976764679, Accuracy: 0.68359375\n",
      "Batch: 23, Loss: 0.945756196975708, Accuracy: 0.6767578125\n",
      "Batch: 24, Loss: 0.9561634063720703, Accuracy: 0.68359375\n",
      "Batch: 25, Loss: 0.916691780090332, Accuracy: 0.681640625\n",
      "Batch: 26, Loss: 0.7990812659263611, Accuracy: 0.7333984375\n",
      "Batch: 27, Loss: 0.881545901298523, Accuracy: 0.7109375\n",
      "Batch: 28, Loss: 0.9520056247711182, Accuracy: 0.6806640625\n",
      "Batch: 29, Loss: 0.8916756510734558, Accuracy: 0.703125\n",
      "Batch: 30, Loss: 0.8278268575668335, Accuracy: 0.73046875\n",
      "Batch: 31, Loss: 0.8360652923583984, Accuracy: 0.728515625\n",
      "Batch: 32, Loss: 0.8463253974914551, Accuracy: 0.7275390625\n",
      "Batch: 33, Loss: 0.9959006309509277, Accuracy: 0.689453125\n",
      "Batch: 34, Loss: 1.071588397026062, Accuracy: 0.6484375\n",
      "Batch: 35, Loss: 0.9607013463973999, Accuracy: 0.6787109375\n",
      "Batch: 36, Loss: 0.9877996444702148, Accuracy: 0.69140625\n",
      "Batch: 37, Loss: 0.9575812816619873, Accuracy: 0.68359375\n",
      "Batch: 38, Loss: 0.969657301902771, Accuracy: 0.67578125\n",
      "Batch: 39, Loss: 0.9398752450942993, Accuracy: 0.701171875\n",
      "Batch: 40, Loss: 0.9102867841720581, Accuracy: 0.70703125\n",
      "Batch: 41, Loss: 0.8977112770080566, Accuracy: 0.7138671875\n",
      "Batch: 42, Loss: 0.7517067193984985, Accuracy: 0.748046875\n",
      "Batch: 43, Loss: 0.9731700420379639, Accuracy: 0.67578125\n",
      "Batch: 44, Loss: 0.9486498832702637, Accuracy: 0.67578125\n",
      "Batch: 45, Loss: 0.8733222484588623, Accuracy: 0.70703125\n",
      "Batch: 46, Loss: 0.8802847266197205, Accuracy: 0.716796875\n",
      "Batch: 47, Loss: 0.8686133623123169, Accuracy: 0.7314453125\n",
      "Batch: 48, Loss: 0.8236061334609985, Accuracy: 0.720703125\n",
      "Batch: 49, Loss: 1.0026869773864746, Accuracy: 0.6806640625\n",
      "Batch: 50, Loss: 0.9891475439071655, Accuracy: 0.6630859375\n",
      "Batch: 51, Loss: 1.0323714017868042, Accuracy: 0.6630859375\n",
      "Batch: 52, Loss: 0.9824924468994141, Accuracy: 0.67578125\n",
      "Batch: 53, Loss: 0.8454899787902832, Accuracy: 0.7177734375\n",
      "Batch: 54, Loss: 0.916715681552887, Accuracy: 0.7080078125\n",
      "Batch: 55, Loss: 0.9682918787002563, Accuracy: 0.66796875\n",
      "Batch: 56, Loss: 0.9777858257293701, Accuracy: 0.6865234375\n",
      "Batch: 57, Loss: 0.920129656791687, Accuracy: 0.6943359375\n",
      "Batch: 58, Loss: 1.0082205533981323, Accuracy: 0.69140625\n",
      "Batch: 59, Loss: 0.8408194184303284, Accuracy: 0.7373046875\n",
      "Batch: 60, Loss: 0.8501677513122559, Accuracy: 0.7333984375\n",
      "Batch: 61, Loss: 0.942730724811554, Accuracy: 0.69140625\n",
      "Batch: 62, Loss: 0.894521176815033, Accuracy: 0.7158203125\n",
      "Batch: 63, Loss: 0.9389567971229553, Accuracy: 0.7021484375\n",
      "Batch: 64, Loss: 0.9266676902770996, Accuracy: 0.703125\n",
      "Batch: 65, Loss: 0.9595658779144287, Accuracy: 0.6962890625\n",
      "Batch: 66, Loss: 0.8847399353981018, Accuracy: 0.728515625\n",
      "Batch: 67, Loss: 0.994025468826294, Accuracy: 0.69140625\n",
      "Batch: 68, Loss: 0.969986081123352, Accuracy: 0.6865234375\n",
      "Batch: 69, Loss: 0.9557189345359802, Accuracy: 0.6884765625\n",
      "Batch: 70, Loss: 0.91318678855896, Accuracy: 0.7099609375\n",
      "Batch: 71, Loss: 0.9532921314239502, Accuracy: 0.681640625\n",
      "Batch: 72, Loss: 0.8013327121734619, Accuracy: 0.744140625\n",
      "Batch: 73, Loss: 0.8714276552200317, Accuracy: 0.724609375\n",
      "Batch: 74, Loss: 0.8561070561408997, Accuracy: 0.7265625\n",
      "Batch: 75, Loss: 0.8426142334938049, Accuracy: 0.720703125\n",
      "Batch: 76, Loss: 0.9565038681030273, Accuracy: 0.6630859375\n",
      "Batch: 77, Loss: 0.9185274243354797, Accuracy: 0.697265625\n",
      "Batch: 78, Loss: 0.853341817855835, Accuracy: 0.732421875\n",
      "Batch: 79, Loss: 0.8038339018821716, Accuracy: 0.7392578125\n",
      "Batch: 80, Loss: 0.8513678312301636, Accuracy: 0.705078125\n",
      "Batch: 81, Loss: 0.9888159036636353, Accuracy: 0.67578125\n",
      "Batch: 82, Loss: 0.945553183555603, Accuracy: 0.6943359375\n",
      "Batch: 83, Loss: 0.8007501363754272, Accuracy: 0.7353515625\n",
      "Batch: 84, Loss: 0.8897262215614319, Accuracy: 0.7109375\n",
      "Batch: 85, Loss: 0.827184796333313, Accuracy: 0.7294921875\n",
      "Batch: 86, Loss: 1.0597500801086426, Accuracy: 0.6689453125\n",
      "Batch: 87, Loss: 0.8514070510864258, Accuracy: 0.7431640625\n",
      "Batch: 88, Loss: 0.9625200629234314, Accuracy: 0.7060546875\n",
      "Batch: 89, Loss: 0.9645746946334839, Accuracy: 0.7001953125\n",
      "Batch: 90, Loss: 0.8772897720336914, Accuracy: 0.7138671875\n",
      "Batch: 91, Loss: 0.8755207657814026, Accuracy: 0.7060546875\n",
      "Batch: 92, Loss: 0.9456696510314941, Accuracy: 0.697265625\n",
      "Batch: 93, Loss: 0.9035793542861938, Accuracy: 0.7001953125\n",
      "Batch: 94, Loss: 0.8829267621040344, Accuracy: 0.7109375\n",
      "Batch: 95, Loss: 0.9434330463409424, Accuracy: 0.681640625\n",
      "Batch: 96, Loss: 0.8959294557571411, Accuracy: 0.71484375\n",
      "Batch: 97, Loss: 0.7647213935852051, Accuracy: 0.75\n",
      "Batch: 98, Loss: 0.8698825240135193, Accuracy: 0.734375\n",
      "Batch: 99, Loss: 0.857422411441803, Accuracy: 0.71875\n",
      "Batch: 100, Loss: 0.8834699392318726, Accuracy: 0.705078125\n",
      "Batch: 101, Loss: 0.9612970352172852, Accuracy: 0.693359375\n",
      "Batch: 102, Loss: 0.8785452842712402, Accuracy: 0.7216796875\n",
      "Batch: 103, Loss: 0.9219454526901245, Accuracy: 0.7001953125\n",
      "Batch: 104, Loss: 0.8700724244117737, Accuracy: 0.70703125\n",
      "Batch: 105, Loss: 0.9028434157371521, Accuracy: 0.7001953125\n",
      "Batch: 106, Loss: 0.8954354524612427, Accuracy: 0.712890625\n",
      "Batch: 107, Loss: 0.9437007904052734, Accuracy: 0.7138671875\n",
      "Batch: 108, Loss: 0.9269827008247375, Accuracy: 0.693359375\n",
      "Batch: 109, Loss: 1.0463945865631104, Accuracy: 0.658203125\n",
      "Batch: 110, Loss: 0.8219895362854004, Accuracy: 0.7314453125\n",
      "Batch: 111, Loss: 0.9526638984680176, Accuracy: 0.6962890625\n",
      "Batch: 112, Loss: 0.8950508832931519, Accuracy: 0.7119140625\n",
      "Batch: 113, Loss: 0.9297139644622803, Accuracy: 0.7119140625\n",
      "Batch: 114, Loss: 0.9958608150482178, Accuracy: 0.6748046875\n",
      "Batch: 115, Loss: 1.049100399017334, Accuracy: 0.673828125\n",
      "Batch: 116, Loss: 0.940319836139679, Accuracy: 0.7060546875\n",
      "Batch: 117, Loss: 0.9749004244804382, Accuracy: 0.6787109375\n",
      "Batch: 118, Loss: 0.8276474475860596, Accuracy: 0.73828125\n",
      "Batch: 119, Loss: 0.7891380786895752, Accuracy: 0.73828125\n",
      "Batch: 120, Loss: 0.95916748046875, Accuracy: 0.6884765625\n",
      "Batch: 121, Loss: 0.9607048034667969, Accuracy: 0.6806640625\n",
      "Batch: 122, Loss: 0.8578650951385498, Accuracy: 0.734375\n",
      "Batch: 123, Loss: 0.8493794202804565, Accuracy: 0.73046875\n",
      "Batch: 124, Loss: 0.9240046739578247, Accuracy: 0.703125\n",
      "Batch: 125, Loss: 0.9935268759727478, Accuracy: 0.6669921875\n",
      "Batch: 126, Loss: 0.9162381887435913, Accuracy: 0.697265625\n",
      "Batch: 127, Loss: 0.8252612948417664, Accuracy: 0.7314453125\n",
      "Batch: 128, Loss: 1.0306702852249146, Accuracy: 0.681640625\n",
      "Batch: 129, Loss: 0.8712199330329895, Accuracy: 0.728515625\n",
      "Batch: 130, Loss: 1.0559576749801636, Accuracy: 0.6669921875\n",
      "Batch: 131, Loss: 0.9724200367927551, Accuracy: 0.67578125\n",
      "Batch: 132, Loss: 0.9709420204162598, Accuracy: 0.6875\n",
      "Batch: 133, Loss: 0.8604342341423035, Accuracy: 0.7158203125\n",
      "Batch: 134, Loss: 0.9346657991409302, Accuracy: 0.6787109375\n",
      "Batch: 135, Loss: 0.8404956459999084, Accuracy: 0.7275390625\n",
      "Batch: 136, Loss: 0.9158827066421509, Accuracy: 0.7041015625\n",
      "Batch: 137, Loss: 0.892693281173706, Accuracy: 0.6875\n",
      "Batch: 138, Loss: 0.7871220707893372, Accuracy: 0.7314453125\n",
      "Batch: 139, Loss: 0.8489612340927124, Accuracy: 0.7001953125\n",
      "Batch: 140, Loss: 0.9278778433799744, Accuracy: 0.6923828125\n",
      "Batch: 141, Loss: 0.9381861686706543, Accuracy: 0.6884765625\n",
      "Batch: 142, Loss: 0.9693552255630493, Accuracy: 0.69140625\n",
      "Batch: 143, Loss: 0.9224287271499634, Accuracy: 0.6923828125\n",
      "Batch: 144, Loss: 0.9069048166275024, Accuracy: 0.712890625\n",
      "Batch: 145, Loss: 0.8852952718734741, Accuracy: 0.68359375\n",
      "Batch: 146, Loss: 0.9825072884559631, Accuracy: 0.6669921875\n",
      "Batch: 147, Loss: 0.9765356779098511, Accuracy: 0.666015625\n",
      "Batch: 148, Loss: 1.043745994567871, Accuracy: 0.65234375\n",
      "Batch: 149, Loss: 0.9020066261291504, Accuracy: 0.6962890625\n",
      "Batch: 150, Loss: 0.9076971411705017, Accuracy: 0.6982421875\n",
      "Batch: 151, Loss: 0.8224433660507202, Accuracy: 0.7265625\n",
      "Epoch 33/80\n",
      "Batch: 1, Loss: 1.164621114730835, Accuracy: 0.6201171875\n",
      "Batch: 2, Loss: 0.9677706360816956, Accuracy: 0.6708984375\n",
      "Batch: 3, Loss: 0.8499323129653931, Accuracy: 0.7138671875\n",
      "Batch: 4, Loss: 0.7936714887619019, Accuracy: 0.7607421875\n",
      "Batch: 5, Loss: 0.8665949106216431, Accuracy: 0.724609375\n",
      "Batch: 6, Loss: 0.9206852316856384, Accuracy: 0.6845703125\n",
      "Batch: 7, Loss: 0.8819253444671631, Accuracy: 0.6943359375\n",
      "Batch: 8, Loss: 0.8528399467468262, Accuracy: 0.7099609375\n",
      "Batch: 9, Loss: 0.8117561340332031, Accuracy: 0.7333984375\n",
      "Batch: 10, Loss: 0.8620539903640747, Accuracy: 0.71875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 11, Loss: 1.0054783821105957, Accuracy: 0.6669921875\n",
      "Batch: 12, Loss: 0.9776369333267212, Accuracy: 0.681640625\n",
      "Batch: 13, Loss: 0.7471671104431152, Accuracy: 0.7607421875\n",
      "Batch: 14, Loss: 0.9887984395027161, Accuracy: 0.658203125\n",
      "Batch: 15, Loss: 0.8151228427886963, Accuracy: 0.7509765625\n",
      "Batch: 16, Loss: 0.9051854610443115, Accuracy: 0.6982421875\n",
      "Batch: 17, Loss: 0.9552631378173828, Accuracy: 0.6875\n",
      "Batch: 18, Loss: 0.964374303817749, Accuracy: 0.6728515625\n",
      "Batch: 19, Loss: 0.9672360420227051, Accuracy: 0.685546875\n",
      "Batch: 20, Loss: 0.8500062227249146, Accuracy: 0.7255859375\n",
      "Batch: 21, Loss: 0.8565046787261963, Accuracy: 0.7275390625\n",
      "Batch: 22, Loss: 0.9901965856552124, Accuracy: 0.6875\n",
      "Batch: 23, Loss: 0.938544750213623, Accuracy: 0.6904296875\n",
      "Batch: 24, Loss: 0.9567734003067017, Accuracy: 0.677734375\n",
      "Batch: 25, Loss: 0.9393174052238464, Accuracy: 0.6884765625\n",
      "Batch: 26, Loss: 0.817444920539856, Accuracy: 0.7294921875\n",
      "Batch: 27, Loss: 0.850865364074707, Accuracy: 0.7177734375\n",
      "Batch: 28, Loss: 0.9528796076774597, Accuracy: 0.6845703125\n",
      "Batch: 29, Loss: 0.8872867822647095, Accuracy: 0.6923828125\n",
      "Batch: 30, Loss: 0.8278791904449463, Accuracy: 0.734375\n",
      "Batch: 31, Loss: 0.8180012702941895, Accuracy: 0.734375\n",
      "Batch: 32, Loss: 0.8201282620429993, Accuracy: 0.7314453125\n",
      "Batch: 33, Loss: 0.9809269905090332, Accuracy: 0.6904296875\n",
      "Batch: 34, Loss: 1.0208491086959839, Accuracy: 0.67578125\n",
      "Batch: 35, Loss: 0.9160417318344116, Accuracy: 0.6943359375\n",
      "Batch: 36, Loss: 0.9781308770179749, Accuracy: 0.6875\n",
      "Batch: 37, Loss: 0.9324855804443359, Accuracy: 0.685546875\n",
      "Batch: 38, Loss: 0.938709020614624, Accuracy: 0.677734375\n",
      "Batch: 39, Loss: 0.9652915000915527, Accuracy: 0.685546875\n",
      "Batch: 40, Loss: 0.8974013328552246, Accuracy: 0.7119140625\n",
      "Batch: 41, Loss: 0.8816936016082764, Accuracy: 0.716796875\n",
      "Batch: 42, Loss: 0.7343360781669617, Accuracy: 0.7587890625\n",
      "Batch: 43, Loss: 0.9177795648574829, Accuracy: 0.6943359375\n",
      "Batch: 44, Loss: 0.960561990737915, Accuracy: 0.6728515625\n",
      "Batch: 45, Loss: 0.8325985074043274, Accuracy: 0.7109375\n",
      "Batch: 46, Loss: 0.84630286693573, Accuracy: 0.7265625\n",
      "Batch: 47, Loss: 0.83250892162323, Accuracy: 0.728515625\n",
      "Batch: 48, Loss: 0.809235692024231, Accuracy: 0.7236328125\n",
      "Batch: 49, Loss: 1.0073316097259521, Accuracy: 0.6669921875\n",
      "Batch: 50, Loss: 0.9657995700836182, Accuracy: 0.6943359375\n",
      "Batch: 51, Loss: 1.0120611190795898, Accuracy: 0.6826171875\n",
      "Batch: 52, Loss: 0.9560678601264954, Accuracy: 0.6953125\n",
      "Batch: 53, Loss: 0.8637388944625854, Accuracy: 0.69921875\n",
      "Batch: 54, Loss: 0.9218889474868774, Accuracy: 0.6923828125\n",
      "Batch: 55, Loss: 0.9890148043632507, Accuracy: 0.6826171875\n",
      "Batch: 56, Loss: 0.9749555587768555, Accuracy: 0.6728515625\n",
      "Batch: 57, Loss: 0.9379871487617493, Accuracy: 0.6923828125\n",
      "Batch: 58, Loss: 1.033464789390564, Accuracy: 0.6650390625\n",
      "Batch: 59, Loss: 0.8649052381515503, Accuracy: 0.7294921875\n",
      "Batch: 60, Loss: 0.8103012442588806, Accuracy: 0.7392578125\n",
      "Batch: 61, Loss: 0.9360249042510986, Accuracy: 0.6875\n",
      "Batch: 62, Loss: 0.9052048325538635, Accuracy: 0.7109375\n",
      "Batch: 63, Loss: 0.9235957860946655, Accuracy: 0.7060546875\n",
      "Batch: 64, Loss: 0.9240683913230896, Accuracy: 0.6923828125\n",
      "Batch: 65, Loss: 0.9316240549087524, Accuracy: 0.6953125\n",
      "Batch: 66, Loss: 0.8841489553451538, Accuracy: 0.732421875\n",
      "Batch: 67, Loss: 0.9764148592948914, Accuracy: 0.69140625\n",
      "Batch: 68, Loss: 1.006486177444458, Accuracy: 0.6943359375\n",
      "Batch: 69, Loss: 0.9300935864448547, Accuracy: 0.7021484375\n",
      "Batch: 70, Loss: 0.8786661028862, Accuracy: 0.71875\n",
      "Batch: 71, Loss: 0.9335533380508423, Accuracy: 0.689453125\n",
      "Batch: 72, Loss: 0.8193002939224243, Accuracy: 0.71875\n",
      "Batch: 73, Loss: 0.8519179821014404, Accuracy: 0.7216796875\n",
      "Batch: 74, Loss: 0.8146417140960693, Accuracy: 0.748046875\n",
      "Batch: 75, Loss: 0.8203763961791992, Accuracy: 0.7314453125\n",
      "Batch: 76, Loss: 0.93292635679245, Accuracy: 0.68359375\n",
      "Batch: 77, Loss: 0.8922109007835388, Accuracy: 0.703125\n",
      "Batch: 78, Loss: 0.8310099244117737, Accuracy: 0.73828125\n",
      "Batch: 79, Loss: 0.8150596022605896, Accuracy: 0.7421875\n",
      "Batch: 80, Loss: 0.8424297571182251, Accuracy: 0.7041015625\n",
      "Batch: 81, Loss: 0.9819467067718506, Accuracy: 0.6669921875\n",
      "Batch: 82, Loss: 0.9603484869003296, Accuracy: 0.67578125\n",
      "Batch: 83, Loss: 0.7899450063705444, Accuracy: 0.75\n",
      "Batch: 84, Loss: 0.8647981286048889, Accuracy: 0.724609375\n",
      "Batch: 85, Loss: 0.8321659564971924, Accuracy: 0.7333984375\n",
      "Batch: 86, Loss: 1.0345077514648438, Accuracy: 0.689453125\n",
      "Batch: 87, Loss: 0.819399356842041, Accuracy: 0.74609375\n",
      "Batch: 88, Loss: 0.970555305480957, Accuracy: 0.6923828125\n",
      "Batch: 89, Loss: 0.9321861863136292, Accuracy: 0.7099609375\n",
      "Batch: 90, Loss: 0.8663867712020874, Accuracy: 0.724609375\n",
      "Batch: 91, Loss: 0.8714808225631714, Accuracy: 0.716796875\n",
      "Batch: 92, Loss: 0.9600173830986023, Accuracy: 0.6865234375\n",
      "Batch: 93, Loss: 0.8773961067199707, Accuracy: 0.70703125\n",
      "Batch: 94, Loss: 0.8784801959991455, Accuracy: 0.712890625\n",
      "Batch: 95, Loss: 0.9410974979400635, Accuracy: 0.6748046875\n",
      "Batch: 96, Loss: 0.8972163200378418, Accuracy: 0.70703125\n",
      "Batch: 97, Loss: 0.7783406972885132, Accuracy: 0.7392578125\n",
      "Batch: 98, Loss: 0.8266957998275757, Accuracy: 0.7353515625\n",
      "Batch: 99, Loss: 0.8688273429870605, Accuracy: 0.7177734375\n",
      "Batch: 100, Loss: 0.8820693492889404, Accuracy: 0.71484375\n",
      "Batch: 101, Loss: 0.9621745347976685, Accuracy: 0.693359375\n",
      "Batch: 102, Loss: 0.8962799906730652, Accuracy: 0.7060546875\n",
      "Batch: 103, Loss: 0.9107925891876221, Accuracy: 0.7041015625\n",
      "Batch: 104, Loss: 0.8528566360473633, Accuracy: 0.73046875\n",
      "Batch: 105, Loss: 0.9254391193389893, Accuracy: 0.712890625\n",
      "Batch: 106, Loss: 0.9023408889770508, Accuracy: 0.708984375\n",
      "Batch: 107, Loss: 0.9248225688934326, Accuracy: 0.7060546875\n",
      "Batch: 108, Loss: 0.9261540770530701, Accuracy: 0.701171875\n",
      "Batch: 109, Loss: 1.034432291984558, Accuracy: 0.669921875\n",
      "Batch: 110, Loss: 0.7955180406570435, Accuracy: 0.7373046875\n",
      "Batch: 111, Loss: 0.9477289319038391, Accuracy: 0.677734375\n",
      "Batch: 112, Loss: 0.8824431896209717, Accuracy: 0.7275390625\n",
      "Batch: 113, Loss: 0.9154534935951233, Accuracy: 0.69921875\n",
      "Batch: 114, Loss: 0.9960408210754395, Accuracy: 0.69140625\n",
      "Batch: 115, Loss: 1.0354763269424438, Accuracy: 0.6669921875\n",
      "Batch: 116, Loss: 0.9448912143707275, Accuracy: 0.6923828125\n",
      "Batch: 117, Loss: 0.9510655999183655, Accuracy: 0.6865234375\n",
      "Batch: 118, Loss: 0.819674015045166, Accuracy: 0.73828125\n",
      "Batch: 119, Loss: 0.7930447459220886, Accuracy: 0.7373046875\n",
      "Batch: 120, Loss: 0.9470483660697937, Accuracy: 0.6962890625\n",
      "Batch: 121, Loss: 0.9742825031280518, Accuracy: 0.677734375\n",
      "Batch: 122, Loss: 0.8639097213745117, Accuracy: 0.716796875\n",
      "Batch: 123, Loss: 0.8664080500602722, Accuracy: 0.7314453125\n",
      "Batch: 124, Loss: 0.8915786743164062, Accuracy: 0.7021484375\n",
      "Batch: 125, Loss: 0.9471144676208496, Accuracy: 0.6826171875\n",
      "Batch: 126, Loss: 0.9303474426269531, Accuracy: 0.7001953125\n",
      "Batch: 127, Loss: 0.8241903781890869, Accuracy: 0.734375\n",
      "Batch: 128, Loss: 1.009812593460083, Accuracy: 0.6826171875\n",
      "Batch: 129, Loss: 0.8560878038406372, Accuracy: 0.724609375\n",
      "Batch: 130, Loss: 1.0607926845550537, Accuracy: 0.654296875\n",
      "Batch: 131, Loss: 0.9034796953201294, Accuracy: 0.6806640625\n",
      "Batch: 132, Loss: 0.9052616357803345, Accuracy: 0.7109375\n",
      "Batch: 133, Loss: 0.8481132984161377, Accuracy: 0.7080078125\n",
      "Batch: 134, Loss: 0.936388373374939, Accuracy: 0.6767578125\n",
      "Batch: 135, Loss: 0.8435672521591187, Accuracy: 0.73828125\n",
      "Batch: 136, Loss: 0.9029878377914429, Accuracy: 0.6982421875\n",
      "Batch: 137, Loss: 0.8877026438713074, Accuracy: 0.7041015625\n",
      "Batch: 138, Loss: 0.7669422626495361, Accuracy: 0.748046875\n",
      "Batch: 139, Loss: 0.8502649068832397, Accuracy: 0.708984375\n",
      "Batch: 140, Loss: 0.8837001323699951, Accuracy: 0.72265625\n",
      "Batch: 141, Loss: 0.920824408531189, Accuracy: 0.6845703125\n",
      "Batch: 142, Loss: 0.945938229560852, Accuracy: 0.6962890625\n",
      "Batch: 143, Loss: 0.9193012118339539, Accuracy: 0.705078125\n",
      "Batch: 144, Loss: 0.914155125617981, Accuracy: 0.7001953125\n",
      "Batch: 145, Loss: 0.8772650957107544, Accuracy: 0.6865234375\n",
      "Batch: 146, Loss: 0.9676446914672852, Accuracy: 0.6787109375\n",
      "Batch: 147, Loss: 0.9647479057312012, Accuracy: 0.677734375\n",
      "Batch: 148, Loss: 1.0462088584899902, Accuracy: 0.6474609375\n",
      "Batch: 149, Loss: 0.8859249353408813, Accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 150, Loss: 0.9071078896522522, Accuracy: 0.6904296875\n",
      "Batch: 151, Loss: 0.7981757521629333, Accuracy: 0.734375\n",
      "Epoch 34/80\n",
      "Batch: 1, Loss: 1.16269850730896, Accuracy: 0.6259765625\n",
      "Batch: 2, Loss: 0.9832093715667725, Accuracy: 0.6591796875\n",
      "Batch: 3, Loss: 0.8771687746047974, Accuracy: 0.701171875\n",
      "Batch: 4, Loss: 0.7954654693603516, Accuracy: 0.7470703125\n",
      "Batch: 5, Loss: 0.8379703164100647, Accuracy: 0.7392578125\n",
      "Batch: 6, Loss: 0.9095391631126404, Accuracy: 0.693359375\n",
      "Batch: 7, Loss: 0.8814859390258789, Accuracy: 0.693359375\n",
      "Batch: 8, Loss: 0.8336775302886963, Accuracy: 0.7177734375\n",
      "Batch: 9, Loss: 0.8243381381034851, Accuracy: 0.7294921875\n",
      "Batch: 10, Loss: 0.8335247039794922, Accuracy: 0.7265625\n",
      "Batch: 11, Loss: 0.9936470985412598, Accuracy: 0.66015625\n",
      "Batch: 12, Loss: 0.9593871235847473, Accuracy: 0.68359375\n",
      "Batch: 13, Loss: 0.7547522783279419, Accuracy: 0.76953125\n",
      "Batch: 14, Loss: 1.0102109909057617, Accuracy: 0.6650390625\n",
      "Batch: 15, Loss: 0.8081603050231934, Accuracy: 0.748046875\n",
      "Batch: 16, Loss: 0.8780431747436523, Accuracy: 0.7119140625\n",
      "Batch: 17, Loss: 0.942742109298706, Accuracy: 0.68359375\n",
      "Batch: 18, Loss: 0.9351261854171753, Accuracy: 0.6865234375\n",
      "Batch: 19, Loss: 0.9407694339752197, Accuracy: 0.69140625\n",
      "Batch: 20, Loss: 0.8282616138458252, Accuracy: 0.736328125\n",
      "Batch: 21, Loss: 0.8699434995651245, Accuracy: 0.71875\n",
      "Batch: 22, Loss: 0.995107889175415, Accuracy: 0.6884765625\n",
      "Batch: 23, Loss: 0.9302656650543213, Accuracy: 0.689453125\n",
      "Batch: 24, Loss: 0.91873699426651, Accuracy: 0.68359375\n",
      "Batch: 25, Loss: 0.9267185926437378, Accuracy: 0.6904296875\n",
      "Batch: 26, Loss: 0.7927451133728027, Accuracy: 0.7314453125\n",
      "Batch: 27, Loss: 0.8546425104141235, Accuracy: 0.7099609375\n",
      "Batch: 28, Loss: 0.9308211207389832, Accuracy: 0.6884765625\n",
      "Batch: 29, Loss: 0.8657025098800659, Accuracy: 0.7119140625\n",
      "Batch: 30, Loss: 0.8051208257675171, Accuracy: 0.7548828125\n",
      "Batch: 31, Loss: 0.797832190990448, Accuracy: 0.74609375\n",
      "Batch: 32, Loss: 0.8006993532180786, Accuracy: 0.7373046875\n",
      "Batch: 33, Loss: 0.95040363073349, Accuracy: 0.69921875\n",
      "Batch: 34, Loss: 1.0241906642913818, Accuracy: 0.669921875\n",
      "Batch: 35, Loss: 0.9272675514221191, Accuracy: 0.693359375\n",
      "Batch: 36, Loss: 0.9527802467346191, Accuracy: 0.6923828125\n",
      "Batch: 37, Loss: 0.9179894924163818, Accuracy: 0.6962890625\n",
      "Batch: 38, Loss: 0.9327547550201416, Accuracy: 0.697265625\n",
      "Batch: 39, Loss: 0.9502866268157959, Accuracy: 0.673828125\n",
      "Batch: 40, Loss: 0.9038734436035156, Accuracy: 0.7021484375\n",
      "Batch: 41, Loss: 0.8260478973388672, Accuracy: 0.7275390625\n",
      "Batch: 42, Loss: 0.7116740942001343, Accuracy: 0.75\n",
      "Batch: 43, Loss: 0.9255608320236206, Accuracy: 0.6787109375\n",
      "Batch: 44, Loss: 0.9161415100097656, Accuracy: 0.6845703125\n",
      "Batch: 45, Loss: 0.8369874954223633, Accuracy: 0.7109375\n",
      "Batch: 46, Loss: 0.8365093469619751, Accuracy: 0.73046875\n",
      "Batch: 47, Loss: 0.8511019945144653, Accuracy: 0.740234375\n",
      "Batch: 48, Loss: 0.8291834592819214, Accuracy: 0.7236328125\n",
      "Batch: 49, Loss: 0.9846594333648682, Accuracy: 0.681640625\n",
      "Batch: 50, Loss: 0.9722859859466553, Accuracy: 0.669921875\n",
      "Batch: 51, Loss: 0.9697965383529663, Accuracy: 0.685546875\n",
      "Batch: 52, Loss: 0.9638184905052185, Accuracy: 0.6923828125\n",
      "Batch: 53, Loss: 0.8472319841384888, Accuracy: 0.7119140625\n",
      "Batch: 54, Loss: 0.8846886157989502, Accuracy: 0.7158203125\n",
      "Batch: 55, Loss: 0.9835135340690613, Accuracy: 0.6689453125\n",
      "Batch: 56, Loss: 0.9632601141929626, Accuracy: 0.701171875\n",
      "Batch: 57, Loss: 0.9089787602424622, Accuracy: 0.69140625\n",
      "Batch: 58, Loss: 1.0392091274261475, Accuracy: 0.681640625\n",
      "Batch: 59, Loss: 0.8368945121765137, Accuracy: 0.724609375\n",
      "Batch: 60, Loss: 0.8086601495742798, Accuracy: 0.7421875\n",
      "Batch: 61, Loss: 0.9342424273490906, Accuracy: 0.6904296875\n",
      "Batch: 62, Loss: 0.8860114812850952, Accuracy: 0.7099609375\n",
      "Batch: 63, Loss: 0.9224832057952881, Accuracy: 0.71875\n",
      "Batch: 64, Loss: 0.9139441251754761, Accuracy: 0.7041015625\n",
      "Batch: 65, Loss: 0.9269813299179077, Accuracy: 0.703125\n",
      "Batch: 66, Loss: 0.8744410276412964, Accuracy: 0.7236328125\n",
      "Batch: 67, Loss: 0.9764642715454102, Accuracy: 0.7080078125\n",
      "Batch: 68, Loss: 1.0155932903289795, Accuracy: 0.6982421875\n",
      "Batch: 69, Loss: 0.9242545366287231, Accuracy: 0.6953125\n",
      "Batch: 70, Loss: 0.879798412322998, Accuracy: 0.716796875\n",
      "Batch: 71, Loss: 0.9382686614990234, Accuracy: 0.6904296875\n",
      "Batch: 72, Loss: 0.823200523853302, Accuracy: 0.7158203125\n",
      "Batch: 73, Loss: 0.8412868976593018, Accuracy: 0.740234375\n",
      "Batch: 74, Loss: 0.823657751083374, Accuracy: 0.7451171875\n",
      "Batch: 75, Loss: 0.8078151941299438, Accuracy: 0.732421875\n",
      "Batch: 76, Loss: 0.9313416481018066, Accuracy: 0.693359375\n",
      "Batch: 77, Loss: 0.8974902033805847, Accuracy: 0.7099609375\n",
      "Batch: 78, Loss: 0.8154972791671753, Accuracy: 0.7509765625\n",
      "Batch: 79, Loss: 0.7662246227264404, Accuracy: 0.7568359375\n",
      "Batch: 80, Loss: 0.8580597043037415, Accuracy: 0.701171875\n",
      "Batch: 81, Loss: 0.9993424415588379, Accuracy: 0.65625\n",
      "Batch: 82, Loss: 0.9199234843254089, Accuracy: 0.705078125\n",
      "Batch: 83, Loss: 0.8034498691558838, Accuracy: 0.74609375\n",
      "Batch: 84, Loss: 0.84372878074646, Accuracy: 0.7294921875\n",
      "Batch: 85, Loss: 0.8317376375198364, Accuracy: 0.7294921875\n",
      "Batch: 86, Loss: 1.0225725173950195, Accuracy: 0.693359375\n",
      "Batch: 87, Loss: 0.8300502300262451, Accuracy: 0.748046875\n",
      "Batch: 88, Loss: 0.9461764693260193, Accuracy: 0.7021484375\n",
      "Batch: 89, Loss: 0.9234943389892578, Accuracy: 0.7177734375\n",
      "Batch: 90, Loss: 0.8571329712867737, Accuracy: 0.7158203125\n",
      "Batch: 91, Loss: 0.8628884553909302, Accuracy: 0.7119140625\n",
      "Batch: 92, Loss: 0.9149853587150574, Accuracy: 0.701171875\n",
      "Batch: 93, Loss: 0.856802225112915, Accuracy: 0.7236328125\n",
      "Batch: 94, Loss: 0.8984181880950928, Accuracy: 0.7060546875\n",
      "Batch: 95, Loss: 0.907436728477478, Accuracy: 0.7001953125\n",
      "Batch: 96, Loss: 0.8663761019706726, Accuracy: 0.7119140625\n",
      "Batch: 97, Loss: 0.7668241858482361, Accuracy: 0.7470703125\n",
      "Batch: 98, Loss: 0.8090627789497375, Accuracy: 0.7373046875\n",
      "Batch: 99, Loss: 0.8497633934020996, Accuracy: 0.73828125\n",
      "Batch: 100, Loss: 0.8854128122329712, Accuracy: 0.7021484375\n",
      "Batch: 101, Loss: 0.9544178247451782, Accuracy: 0.6953125\n",
      "Batch: 102, Loss: 0.8778899312019348, Accuracy: 0.720703125\n",
      "Batch: 103, Loss: 0.9019179344177246, Accuracy: 0.7158203125\n",
      "Batch: 104, Loss: 0.852584958076477, Accuracy: 0.7109375\n",
      "Batch: 105, Loss: 0.8946616649627686, Accuracy: 0.708984375\n",
      "Batch: 106, Loss: 0.8982833027839661, Accuracy: 0.70703125\n",
      "Batch: 107, Loss: 0.9162403345108032, Accuracy: 0.7021484375\n",
      "Batch: 108, Loss: 0.9058805704116821, Accuracy: 0.693359375\n",
      "Batch: 109, Loss: 1.0201401710510254, Accuracy: 0.6669921875\n",
      "Batch: 110, Loss: 0.7994795441627502, Accuracy: 0.734375\n",
      "Batch: 111, Loss: 0.948796808719635, Accuracy: 0.6826171875\n",
      "Batch: 112, Loss: 0.8665512204170227, Accuracy: 0.7353515625\n",
      "Batch: 113, Loss: 0.9236723184585571, Accuracy: 0.7099609375\n",
      "Batch: 114, Loss: 0.980097770690918, Accuracy: 0.6826171875\n",
      "Batch: 115, Loss: 1.0308736562728882, Accuracy: 0.669921875\n",
      "Batch: 116, Loss: 0.9132888317108154, Accuracy: 0.703125\n",
      "Batch: 117, Loss: 0.9321223497390747, Accuracy: 0.7041015625\n",
      "Batch: 118, Loss: 0.8109967708587646, Accuracy: 0.7373046875\n",
      "Batch: 119, Loss: 0.786564290523529, Accuracy: 0.7373046875\n",
      "Batch: 120, Loss: 0.9416139125823975, Accuracy: 0.7060546875\n",
      "Batch: 121, Loss: 0.9801101684570312, Accuracy: 0.6904296875\n",
      "Batch: 122, Loss: 0.8524190187454224, Accuracy: 0.7314453125\n",
      "Batch: 123, Loss: 0.8176285028457642, Accuracy: 0.734375\n",
      "Batch: 124, Loss: 0.9036287069320679, Accuracy: 0.69921875\n",
      "Batch: 125, Loss: 0.9411283135414124, Accuracy: 0.673828125\n",
      "Batch: 126, Loss: 0.8948334455490112, Accuracy: 0.7021484375\n",
      "Batch: 127, Loss: 0.815500020980835, Accuracy: 0.7490234375\n",
      "Batch: 128, Loss: 1.007973313331604, Accuracy: 0.6943359375\n",
      "Batch: 129, Loss: 0.8741165399551392, Accuracy: 0.71875\n",
      "Batch: 130, Loss: 1.0193142890930176, Accuracy: 0.662109375\n",
      "Batch: 131, Loss: 0.9150418043136597, Accuracy: 0.7001953125\n",
      "Batch: 132, Loss: 0.9345113039016724, Accuracy: 0.7001953125\n",
      "Batch: 133, Loss: 0.8371767997741699, Accuracy: 0.7119140625\n",
      "Batch: 134, Loss: 0.9288703799247742, Accuracy: 0.6884765625\n",
      "Batch: 135, Loss: 0.8457460403442383, Accuracy: 0.73046875\n",
      "Batch: 136, Loss: 0.8869746327400208, Accuracy: 0.7119140625\n",
      "Batch: 137, Loss: 0.8765027523040771, Accuracy: 0.708984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 138, Loss: 0.7686744928359985, Accuracy: 0.736328125\n",
      "Batch: 139, Loss: 0.823981523513794, Accuracy: 0.7294921875\n",
      "Batch: 140, Loss: 0.9207745790481567, Accuracy: 0.6865234375\n",
      "Batch: 141, Loss: 0.9175871014595032, Accuracy: 0.6923828125\n",
      "Batch: 142, Loss: 0.9419506788253784, Accuracy: 0.6904296875\n",
      "Batch: 143, Loss: 0.912781834602356, Accuracy: 0.6806640625\n",
      "Batch: 144, Loss: 0.9083244204521179, Accuracy: 0.6953125\n",
      "Batch: 145, Loss: 0.8574930429458618, Accuracy: 0.6943359375\n",
      "Batch: 146, Loss: 0.960883617401123, Accuracy: 0.6728515625\n",
      "Batch: 147, Loss: 0.9508870840072632, Accuracy: 0.6708984375\n",
      "Batch: 148, Loss: 1.0530353784561157, Accuracy: 0.6533203125\n",
      "Batch: 149, Loss: 0.9028427600860596, Accuracy: 0.693359375\n",
      "Batch: 150, Loss: 0.8821682929992676, Accuracy: 0.7041015625\n",
      "Batch: 151, Loss: 0.7827922701835632, Accuracy: 0.7353515625\n",
      "Epoch 35/80\n",
      "Batch: 1, Loss: 1.1300580501556396, Accuracy: 0.6337890625\n",
      "Batch: 2, Loss: 0.9746975898742676, Accuracy: 0.6484375\n",
      "Batch: 3, Loss: 0.835405170917511, Accuracy: 0.712890625\n",
      "Batch: 4, Loss: 0.7887974977493286, Accuracy: 0.7451171875\n",
      "Batch: 5, Loss: 0.8983663320541382, Accuracy: 0.7177734375\n",
      "Batch: 6, Loss: 0.9000062942504883, Accuracy: 0.71875\n",
      "Batch: 7, Loss: 0.8846170902252197, Accuracy: 0.6904296875\n",
      "Batch: 8, Loss: 0.8182322978973389, Accuracy: 0.732421875\n",
      "Batch: 9, Loss: 0.8042252063751221, Accuracy: 0.748046875\n",
      "Batch: 10, Loss: 0.8135759830474854, Accuracy: 0.7275390625\n",
      "Batch: 11, Loss: 0.9815945625305176, Accuracy: 0.6708984375\n",
      "Batch: 12, Loss: 0.9607830047607422, Accuracy: 0.68359375\n",
      "Batch: 13, Loss: 0.7421103715896606, Accuracy: 0.763671875\n",
      "Batch: 14, Loss: 0.9853273630142212, Accuracy: 0.671875\n",
      "Batch: 15, Loss: 0.806155800819397, Accuracy: 0.76171875\n",
      "Batch: 16, Loss: 0.8671168684959412, Accuracy: 0.7314453125\n",
      "Batch: 17, Loss: 0.9703158140182495, Accuracy: 0.673828125\n",
      "Batch: 18, Loss: 0.9664629697799683, Accuracy: 0.685546875\n",
      "Batch: 19, Loss: 0.9560362100601196, Accuracy: 0.6943359375\n",
      "Batch: 20, Loss: 0.8096923828125, Accuracy: 0.74609375\n",
      "Batch: 21, Loss: 0.8688769936561584, Accuracy: 0.7109375\n",
      "Batch: 22, Loss: 0.9568650722503662, Accuracy: 0.6953125\n",
      "Batch: 23, Loss: 0.9140273332595825, Accuracy: 0.693359375\n",
      "Batch: 24, Loss: 0.9270668029785156, Accuracy: 0.6826171875\n",
      "Batch: 25, Loss: 0.9057999849319458, Accuracy: 0.70703125\n",
      "Batch: 26, Loss: 0.8016515970230103, Accuracy: 0.7412109375\n",
      "Batch: 27, Loss: 0.8483811616897583, Accuracy: 0.712890625\n",
      "Batch: 28, Loss: 0.9324370622634888, Accuracy: 0.685546875\n",
      "Batch: 29, Loss: 0.8497384190559387, Accuracy: 0.7177734375\n",
      "Batch: 30, Loss: 0.8058863878250122, Accuracy: 0.74609375\n",
      "Batch: 31, Loss: 0.7917342185974121, Accuracy: 0.74609375\n",
      "Batch: 32, Loss: 0.8392384648323059, Accuracy: 0.7080078125\n",
      "Batch: 33, Loss: 0.9619144201278687, Accuracy: 0.6982421875\n",
      "Batch: 34, Loss: 1.0347745418548584, Accuracy: 0.6591796875\n",
      "Batch: 35, Loss: 0.9448277950286865, Accuracy: 0.685546875\n",
      "Batch: 36, Loss: 0.9722488522529602, Accuracy: 0.6875\n",
      "Batch: 37, Loss: 0.919654130935669, Accuracy: 0.71484375\n",
      "Batch: 38, Loss: 0.9448860883712769, Accuracy: 0.701171875\n",
      "Batch: 39, Loss: 0.9240407943725586, Accuracy: 0.6845703125\n",
      "Batch: 40, Loss: 0.8856515884399414, Accuracy: 0.7109375\n",
      "Batch: 41, Loss: 0.8465365171432495, Accuracy: 0.7255859375\n",
      "Batch: 42, Loss: 0.7163025736808777, Accuracy: 0.7548828125\n",
      "Batch: 43, Loss: 0.9348000884056091, Accuracy: 0.6923828125\n",
      "Batch: 44, Loss: 0.9114339351654053, Accuracy: 0.7021484375\n",
      "Batch: 45, Loss: 0.8243840336799622, Accuracy: 0.7177734375\n",
      "Batch: 46, Loss: 0.8485190868377686, Accuracy: 0.7275390625\n",
      "Batch: 47, Loss: 0.8467603921890259, Accuracy: 0.7412109375\n",
      "Batch: 48, Loss: 0.8047065138816833, Accuracy: 0.7314453125\n",
      "Batch: 49, Loss: 0.9704071879386902, Accuracy: 0.6689453125\n",
      "Batch: 50, Loss: 0.9555174112319946, Accuracy: 0.6875\n",
      "Batch: 51, Loss: 0.9827040433883667, Accuracy: 0.703125\n",
      "Batch: 52, Loss: 0.9436200857162476, Accuracy: 0.6953125\n",
      "Batch: 53, Loss: 0.8354175090789795, Accuracy: 0.712890625\n",
      "Batch: 54, Loss: 0.9108381867408752, Accuracy: 0.6953125\n",
      "Batch: 55, Loss: 0.9788380265235901, Accuracy: 0.67578125\n",
      "Batch: 56, Loss: 0.9733126163482666, Accuracy: 0.6806640625\n",
      "Batch: 57, Loss: 0.9078840017318726, Accuracy: 0.7060546875\n",
      "Batch: 58, Loss: 1.0164389610290527, Accuracy: 0.67578125\n",
      "Batch: 59, Loss: 0.8397296667098999, Accuracy: 0.720703125\n",
      "Batch: 60, Loss: 0.8065041303634644, Accuracy: 0.7578125\n",
      "Batch: 61, Loss: 0.9265164732933044, Accuracy: 0.703125\n",
      "Batch: 62, Loss: 0.8777118921279907, Accuracy: 0.7158203125\n",
      "Batch: 63, Loss: 0.9078012704849243, Accuracy: 0.7119140625\n",
      "Batch: 64, Loss: 0.8985481262207031, Accuracy: 0.7021484375\n",
      "Batch: 65, Loss: 0.9230047464370728, Accuracy: 0.703125\n",
      "Batch: 66, Loss: 0.8756343126296997, Accuracy: 0.7314453125\n",
      "Batch: 67, Loss: 0.9740235805511475, Accuracy: 0.6923828125\n",
      "Batch: 68, Loss: 1.007177472114563, Accuracy: 0.701171875\n",
      "Batch: 69, Loss: 0.9230669736862183, Accuracy: 0.6875\n",
      "Batch: 70, Loss: 0.8879563808441162, Accuracy: 0.7138671875\n",
      "Batch: 71, Loss: 0.9348859190940857, Accuracy: 0.6875\n",
      "Batch: 72, Loss: 0.7727841734886169, Accuracy: 0.740234375\n",
      "Batch: 73, Loss: 0.8105778694152832, Accuracy: 0.7314453125\n",
      "Batch: 74, Loss: 0.791825532913208, Accuracy: 0.7548828125\n",
      "Batch: 75, Loss: 0.7939243316650391, Accuracy: 0.7412109375\n",
      "Batch: 76, Loss: 0.9021062850952148, Accuracy: 0.6875\n",
      "Batch: 77, Loss: 0.8823638558387756, Accuracy: 0.705078125\n",
      "Batch: 78, Loss: 0.8548980355262756, Accuracy: 0.7197265625\n",
      "Batch: 79, Loss: 0.761756420135498, Accuracy: 0.7451171875\n",
      "Batch: 80, Loss: 0.8578249216079712, Accuracy: 0.7001953125\n",
      "Batch: 81, Loss: 0.9527859687805176, Accuracy: 0.669921875\n",
      "Batch: 82, Loss: 0.9387169480323792, Accuracy: 0.6796875\n",
      "Batch: 83, Loss: 0.7959719896316528, Accuracy: 0.7548828125\n",
      "Batch: 84, Loss: 0.8486539125442505, Accuracy: 0.7294921875\n",
      "Batch: 85, Loss: 0.802318811416626, Accuracy: 0.73046875\n",
      "Batch: 86, Loss: 1.0207240581512451, Accuracy: 0.697265625\n",
      "Batch: 87, Loss: 0.8331927061080933, Accuracy: 0.748046875\n",
      "Batch: 88, Loss: 0.9420552849769592, Accuracy: 0.712890625\n",
      "Batch: 89, Loss: 0.919308066368103, Accuracy: 0.7041015625\n",
      "Batch: 90, Loss: 0.8244390487670898, Accuracy: 0.734375\n",
      "Batch: 91, Loss: 0.855918288230896, Accuracy: 0.7197265625\n",
      "Batch: 92, Loss: 0.9058162569999695, Accuracy: 0.7001953125\n",
      "Batch: 93, Loss: 0.8554558753967285, Accuracy: 0.7314453125\n",
      "Batch: 94, Loss: 0.8814243674278259, Accuracy: 0.705078125\n",
      "Batch: 95, Loss: 0.9312553405761719, Accuracy: 0.6728515625\n",
      "Batch: 96, Loss: 0.885020911693573, Accuracy: 0.7197265625\n",
      "Batch: 97, Loss: 0.7301162481307983, Accuracy: 0.74609375\n",
      "Batch: 98, Loss: 0.822471559047699, Accuracy: 0.734375\n",
      "Batch: 99, Loss: 0.838360071182251, Accuracy: 0.7265625\n",
      "Batch: 100, Loss: 0.8731610178947449, Accuracy: 0.7216796875\n",
      "Batch: 101, Loss: 0.9325529336929321, Accuracy: 0.6982421875\n",
      "Batch: 102, Loss: 0.884196400642395, Accuracy: 0.71484375\n",
      "Batch: 103, Loss: 0.9283112287521362, Accuracy: 0.7119140625\n",
      "Batch: 104, Loss: 0.8022319674491882, Accuracy: 0.72265625\n",
      "Batch: 105, Loss: 0.9348294734954834, Accuracy: 0.69140625\n",
      "Batch: 106, Loss: 0.8579555749893188, Accuracy: 0.724609375\n",
      "Batch: 107, Loss: 0.9095233082771301, Accuracy: 0.708984375\n",
      "Batch: 108, Loss: 0.9145840406417847, Accuracy: 0.689453125\n",
      "Batch: 109, Loss: 1.0112059116363525, Accuracy: 0.662109375\n",
      "Batch: 110, Loss: 0.8018437623977661, Accuracy: 0.736328125\n",
      "Batch: 111, Loss: 0.892973780632019, Accuracy: 0.70703125\n",
      "Batch: 112, Loss: 0.8731874227523804, Accuracy: 0.7216796875\n",
      "Batch: 113, Loss: 0.8899227380752563, Accuracy: 0.7255859375\n",
      "Batch: 114, Loss: 0.9484539031982422, Accuracy: 0.6953125\n",
      "Batch: 115, Loss: 1.0067214965820312, Accuracy: 0.68359375\n",
      "Batch: 116, Loss: 0.943469226360321, Accuracy: 0.705078125\n",
      "Batch: 117, Loss: 0.9572380185127258, Accuracy: 0.6982421875\n",
      "Batch: 118, Loss: 0.7942153215408325, Accuracy: 0.7529296875\n",
      "Batch: 119, Loss: 0.7865824103355408, Accuracy: 0.744140625\n",
      "Batch: 120, Loss: 0.929556667804718, Accuracy: 0.7041015625\n",
      "Batch: 121, Loss: 0.9499850273132324, Accuracy: 0.6826171875\n",
      "Batch: 122, Loss: 0.8483400940895081, Accuracy: 0.7431640625\n",
      "Batch: 123, Loss: 0.8408678770065308, Accuracy: 0.734375\n",
      "Batch: 124, Loss: 0.8931665420532227, Accuracy: 0.703125\n",
      "Batch: 125, Loss: 0.9542495012283325, Accuracy: 0.6923828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 126, Loss: 0.8808004856109619, Accuracy: 0.716796875\n",
      "Batch: 127, Loss: 0.7980132102966309, Accuracy: 0.763671875\n",
      "Batch: 128, Loss: 0.9973411560058594, Accuracy: 0.69921875\n",
      "Batch: 129, Loss: 0.8232614994049072, Accuracy: 0.7353515625\n",
      "Batch: 130, Loss: 1.026374340057373, Accuracy: 0.66796875\n",
      "Batch: 131, Loss: 0.9040120840072632, Accuracy: 0.697265625\n",
      "Batch: 132, Loss: 0.9158419966697693, Accuracy: 0.705078125\n",
      "Batch: 133, Loss: 0.8450198173522949, Accuracy: 0.7177734375\n",
      "Batch: 134, Loss: 0.894220769405365, Accuracy: 0.6875\n",
      "Batch: 135, Loss: 0.8279379606246948, Accuracy: 0.7236328125\n",
      "Batch: 136, Loss: 0.8892176151275635, Accuracy: 0.7041015625\n",
      "Batch: 137, Loss: 0.8598024845123291, Accuracy: 0.7109375\n",
      "Batch: 138, Loss: 0.7771402597427368, Accuracy: 0.73828125\n",
      "Batch: 139, Loss: 0.8492467403411865, Accuracy: 0.7109375\n",
      "Batch: 140, Loss: 0.8676998019218445, Accuracy: 0.716796875\n",
      "Batch: 141, Loss: 0.9123736619949341, Accuracy: 0.6943359375\n",
      "Batch: 142, Loss: 0.9679923057556152, Accuracy: 0.6787109375\n",
      "Batch: 143, Loss: 0.8725330233573914, Accuracy: 0.7119140625\n",
      "Batch: 144, Loss: 0.8758281469345093, Accuracy: 0.7041015625\n",
      "Batch: 145, Loss: 0.8478110432624817, Accuracy: 0.7001953125\n",
      "Batch: 146, Loss: 0.9377261996269226, Accuracy: 0.6904296875\n",
      "Batch: 147, Loss: 0.9531040191650391, Accuracy: 0.671875\n",
      "Batch: 148, Loss: 1.0239989757537842, Accuracy: 0.6669921875\n",
      "Batch: 149, Loss: 0.8922841548919678, Accuracy: 0.703125\n",
      "Batch: 150, Loss: 0.8900424242019653, Accuracy: 0.7109375\n",
      "Batch: 151, Loss: 0.8063257932662964, Accuracy: 0.7373046875\n",
      "Epoch 36/80\n",
      "Batch: 1, Loss: 1.1341724395751953, Accuracy: 0.6357421875\n",
      "Batch: 2, Loss: 0.968217670917511, Accuracy: 0.66796875\n",
      "Batch: 3, Loss: 0.8628467321395874, Accuracy: 0.71484375\n",
      "Batch: 4, Loss: 0.780373752117157, Accuracy: 0.7314453125\n",
      "Batch: 5, Loss: 0.8456726670265198, Accuracy: 0.7177734375\n",
      "Batch: 6, Loss: 0.907852828502655, Accuracy: 0.7041015625\n",
      "Batch: 7, Loss: 0.8824076652526855, Accuracy: 0.689453125\n",
      "Batch: 8, Loss: 0.8285240530967712, Accuracy: 0.728515625\n",
      "Batch: 9, Loss: 0.7959428429603577, Accuracy: 0.7294921875\n",
      "Batch: 10, Loss: 0.828349232673645, Accuracy: 0.7421875\n",
      "Batch: 11, Loss: 0.9724873304367065, Accuracy: 0.6875\n",
      "Batch: 12, Loss: 0.936393141746521, Accuracy: 0.685546875\n",
      "Batch: 13, Loss: 0.7343554496765137, Accuracy: 0.76171875\n",
      "Batch: 14, Loss: 0.9940388202667236, Accuracy: 0.671875\n",
      "Batch: 15, Loss: 0.8160557150840759, Accuracy: 0.7451171875\n",
      "Batch: 16, Loss: 0.8695539236068726, Accuracy: 0.71875\n",
      "Batch: 17, Loss: 0.9396082162857056, Accuracy: 0.6982421875\n",
      "Batch: 18, Loss: 0.9406375288963318, Accuracy: 0.6845703125\n",
      "Batch: 19, Loss: 0.933668851852417, Accuracy: 0.697265625\n",
      "Batch: 20, Loss: 0.8175052404403687, Accuracy: 0.740234375\n",
      "Batch: 21, Loss: 0.8629654049873352, Accuracy: 0.7216796875\n",
      "Batch: 22, Loss: 0.968333899974823, Accuracy: 0.6884765625\n",
      "Batch: 23, Loss: 0.8894145488739014, Accuracy: 0.6953125\n",
      "Batch: 24, Loss: 0.904609203338623, Accuracy: 0.703125\n",
      "Batch: 25, Loss: 0.8916093111038208, Accuracy: 0.697265625\n",
      "Batch: 26, Loss: 0.7907471656799316, Accuracy: 0.7431640625\n",
      "Batch: 27, Loss: 0.8340684175491333, Accuracy: 0.7109375\n",
      "Batch: 28, Loss: 0.9250805377960205, Accuracy: 0.693359375\n",
      "Batch: 29, Loss: 0.8721242547035217, Accuracy: 0.7119140625\n",
      "Batch: 30, Loss: 0.795883059501648, Accuracy: 0.748046875\n",
      "Batch: 31, Loss: 0.763765811920166, Accuracy: 0.7607421875\n",
      "Batch: 32, Loss: 0.8129333257675171, Accuracy: 0.71484375\n",
      "Batch: 33, Loss: 0.954735517501831, Accuracy: 0.6943359375\n",
      "Batch: 34, Loss: 1.0190681219100952, Accuracy: 0.6669921875\n",
      "Batch: 35, Loss: 0.918061375617981, Accuracy: 0.7041015625\n",
      "Batch: 36, Loss: 0.9184468984603882, Accuracy: 0.72265625\n",
      "Batch: 37, Loss: 0.9063156843185425, Accuracy: 0.69921875\n",
      "Batch: 38, Loss: 0.9186360836029053, Accuracy: 0.697265625\n",
      "Batch: 39, Loss: 0.9013416767120361, Accuracy: 0.69140625\n",
      "Batch: 40, Loss: 0.8750405311584473, Accuracy: 0.7236328125\n",
      "Batch: 41, Loss: 0.8435767889022827, Accuracy: 0.720703125\n",
      "Batch: 42, Loss: 0.7232876420021057, Accuracy: 0.7529296875\n",
      "Batch: 43, Loss: 0.9416990876197815, Accuracy: 0.6865234375\n",
      "Batch: 44, Loss: 0.9349024295806885, Accuracy: 0.69140625\n",
      "Batch: 45, Loss: 0.8147562742233276, Accuracy: 0.728515625\n",
      "Batch: 46, Loss: 0.8133805990219116, Accuracy: 0.7294921875\n",
      "Batch: 47, Loss: 0.8163025379180908, Accuracy: 0.744140625\n",
      "Batch: 48, Loss: 0.8012338280677795, Accuracy: 0.7392578125\n",
      "Batch: 49, Loss: 0.969222903251648, Accuracy: 0.6845703125\n",
      "Batch: 50, Loss: 0.946020781993866, Accuracy: 0.685546875\n",
      "Batch: 51, Loss: 0.9721193313598633, Accuracy: 0.6904296875\n",
      "Batch: 52, Loss: 0.9319230318069458, Accuracy: 0.697265625\n",
      "Batch: 53, Loss: 0.8310749530792236, Accuracy: 0.7119140625\n",
      "Batch: 54, Loss: 0.878061830997467, Accuracy: 0.7275390625\n",
      "Batch: 55, Loss: 0.9833372831344604, Accuracy: 0.681640625\n",
      "Batch: 56, Loss: 0.9335739612579346, Accuracy: 0.697265625\n",
      "Batch: 57, Loss: 0.8889206647872925, Accuracy: 0.716796875\n",
      "Batch: 58, Loss: 0.9965970516204834, Accuracy: 0.69140625\n",
      "Batch: 59, Loss: 0.8241035342216492, Accuracy: 0.7392578125\n",
      "Batch: 60, Loss: 0.8054759502410889, Accuracy: 0.7373046875\n",
      "Batch: 61, Loss: 0.9234437942504883, Accuracy: 0.70703125\n",
      "Batch: 62, Loss: 0.8752586841583252, Accuracy: 0.71875\n",
      "Batch: 63, Loss: 0.9109972715377808, Accuracy: 0.701171875\n",
      "Batch: 64, Loss: 0.921306848526001, Accuracy: 0.6923828125\n",
      "Batch: 65, Loss: 0.9303742051124573, Accuracy: 0.701171875\n",
      "Batch: 66, Loss: 0.8513805270195007, Accuracy: 0.7275390625\n",
      "Batch: 67, Loss: 0.9445899724960327, Accuracy: 0.693359375\n",
      "Batch: 68, Loss: 0.9752129912376404, Accuracy: 0.7119140625\n",
      "Batch: 69, Loss: 0.9248789548873901, Accuracy: 0.703125\n",
      "Batch: 70, Loss: 0.8869800567626953, Accuracy: 0.7236328125\n",
      "Batch: 71, Loss: 0.9200742244720459, Accuracy: 0.693359375\n",
      "Batch: 72, Loss: 0.7792471647262573, Accuracy: 0.7314453125\n",
      "Batch: 73, Loss: 0.8125585317611694, Accuracy: 0.728515625\n",
      "Batch: 74, Loss: 0.7950773239135742, Accuracy: 0.744140625\n",
      "Batch: 75, Loss: 0.7839382886886597, Accuracy: 0.734375\n",
      "Batch: 76, Loss: 0.8915488123893738, Accuracy: 0.6962890625\n",
      "Batch: 77, Loss: 0.8648155331611633, Accuracy: 0.7099609375\n",
      "Batch: 78, Loss: 0.8296303749084473, Accuracy: 0.7333984375\n",
      "Batch: 79, Loss: 0.74783855676651, Accuracy: 0.7626953125\n",
      "Batch: 80, Loss: 0.8377707004547119, Accuracy: 0.697265625\n",
      "Batch: 81, Loss: 0.9592591524124146, Accuracy: 0.662109375\n",
      "Batch: 82, Loss: 0.9302149415016174, Accuracy: 0.693359375\n",
      "Batch: 83, Loss: 0.7724190950393677, Accuracy: 0.7529296875\n",
      "Batch: 84, Loss: 0.8479330539703369, Accuracy: 0.734375\n",
      "Batch: 85, Loss: 0.8095824718475342, Accuracy: 0.7275390625\n",
      "Batch: 86, Loss: 1.0119422674179077, Accuracy: 0.6953125\n",
      "Batch: 87, Loss: 0.8055318593978882, Accuracy: 0.748046875\n",
      "Batch: 88, Loss: 0.9128475785255432, Accuracy: 0.71875\n",
      "Batch: 89, Loss: 0.9078613519668579, Accuracy: 0.7158203125\n",
      "Batch: 90, Loss: 0.8542598485946655, Accuracy: 0.720703125\n",
      "Batch: 91, Loss: 0.849522054195404, Accuracy: 0.7158203125\n",
      "Batch: 92, Loss: 0.8969713449478149, Accuracy: 0.7119140625\n",
      "Batch: 93, Loss: 0.8292943835258484, Accuracy: 0.740234375\n",
      "Batch: 94, Loss: 0.8971096277236938, Accuracy: 0.720703125\n",
      "Batch: 95, Loss: 0.899789035320282, Accuracy: 0.7001953125\n",
      "Batch: 96, Loss: 0.8534718751907349, Accuracy: 0.724609375\n",
      "Batch: 97, Loss: 0.7376453876495361, Accuracy: 0.7529296875\n",
      "Batch: 98, Loss: 0.8356050252914429, Accuracy: 0.7431640625\n",
      "Batch: 99, Loss: 0.8446639180183411, Accuracy: 0.7275390625\n",
      "Batch: 100, Loss: 0.8590697050094604, Accuracy: 0.7109375\n",
      "Batch: 101, Loss: 0.9255415797233582, Accuracy: 0.69921875\n",
      "Batch: 102, Loss: 0.873820424079895, Accuracy: 0.71875\n",
      "Batch: 103, Loss: 0.8758047819137573, Accuracy: 0.7158203125\n",
      "Batch: 104, Loss: 0.8141858577728271, Accuracy: 0.728515625\n",
      "Batch: 105, Loss: 0.9012123346328735, Accuracy: 0.712890625\n",
      "Batch: 106, Loss: 0.8430732488632202, Accuracy: 0.72265625\n",
      "Batch: 107, Loss: 0.9187016487121582, Accuracy: 0.7099609375\n",
      "Batch: 108, Loss: 0.9127106666564941, Accuracy: 0.6982421875\n",
      "Batch: 109, Loss: 0.9961578249931335, Accuracy: 0.669921875\n",
      "Batch: 110, Loss: 0.7808735370635986, Accuracy: 0.75\n",
      "Batch: 111, Loss: 0.9155855178833008, Accuracy: 0.701171875\n",
      "Batch: 112, Loss: 0.8654882907867432, Accuracy: 0.7197265625\n",
      "Batch: 113, Loss: 0.8788993954658508, Accuracy: 0.71484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 114, Loss: 0.9505525827407837, Accuracy: 0.689453125\n",
      "Batch: 115, Loss: 1.0116443634033203, Accuracy: 0.6884765625\n",
      "Batch: 116, Loss: 0.9096548557281494, Accuracy: 0.705078125\n",
      "Batch: 117, Loss: 0.9472751617431641, Accuracy: 0.689453125\n",
      "Batch: 118, Loss: 0.7997515201568604, Accuracy: 0.740234375\n",
      "Batch: 119, Loss: 0.7470667362213135, Accuracy: 0.7529296875\n",
      "Batch: 120, Loss: 0.891213059425354, Accuracy: 0.703125\n",
      "Batch: 121, Loss: 0.9385371208190918, Accuracy: 0.6845703125\n",
      "Batch: 122, Loss: 0.8504594564437866, Accuracy: 0.7333984375\n",
      "Batch: 123, Loss: 0.8234860301017761, Accuracy: 0.7177734375\n",
      "Batch: 124, Loss: 0.872445821762085, Accuracy: 0.70703125\n",
      "Batch: 125, Loss: 0.9298355579376221, Accuracy: 0.6962890625\n",
      "Batch: 126, Loss: 0.892461359500885, Accuracy: 0.7001953125\n",
      "Batch: 127, Loss: 0.8075809478759766, Accuracy: 0.7451171875\n",
      "Batch: 128, Loss: 0.9998993873596191, Accuracy: 0.69921875\n",
      "Batch: 129, Loss: 0.8235255479812622, Accuracy: 0.7373046875\n",
      "Batch: 130, Loss: 1.0067895650863647, Accuracy: 0.6796875\n",
      "Batch: 131, Loss: 0.8950769305229187, Accuracy: 0.6943359375\n",
      "Batch: 132, Loss: 0.9027153253555298, Accuracy: 0.712890625\n",
      "Batch: 133, Loss: 0.8239296078681946, Accuracy: 0.7314453125\n",
      "Batch: 134, Loss: 0.8934459090232849, Accuracy: 0.6953125\n",
      "Batch: 135, Loss: 0.8200209140777588, Accuracy: 0.7353515625\n",
      "Batch: 136, Loss: 0.9017488360404968, Accuracy: 0.7060546875\n",
      "Batch: 137, Loss: 0.8514549136161804, Accuracy: 0.6982421875\n",
      "Batch: 138, Loss: 0.7433557510375977, Accuracy: 0.74609375\n",
      "Batch: 139, Loss: 0.8203649520874023, Accuracy: 0.7197265625\n",
      "Batch: 140, Loss: 0.8749920725822449, Accuracy: 0.7080078125\n",
      "Batch: 141, Loss: 0.9216305613517761, Accuracy: 0.69140625\n",
      "Batch: 142, Loss: 0.9184250831604004, Accuracy: 0.697265625\n",
      "Batch: 143, Loss: 0.8634903430938721, Accuracy: 0.70703125\n",
      "Batch: 144, Loss: 0.9062448740005493, Accuracy: 0.6982421875\n",
      "Batch: 145, Loss: 0.8494411110877991, Accuracy: 0.6884765625\n",
      "Batch: 146, Loss: 0.9386082291603088, Accuracy: 0.6767578125\n",
      "Batch: 147, Loss: 0.9058123826980591, Accuracy: 0.6904296875\n",
      "Batch: 148, Loss: 1.0328612327575684, Accuracy: 0.6572265625\n",
      "Batch: 149, Loss: 0.9049938917160034, Accuracy: 0.6943359375\n",
      "Batch: 150, Loss: 0.863911509513855, Accuracy: 0.7138671875\n",
      "Batch: 151, Loss: 0.7677755951881409, Accuracy: 0.7392578125\n",
      "Epoch 37/80\n",
      "Batch: 1, Loss: 1.1211997270584106, Accuracy: 0.64453125\n",
      "Batch: 2, Loss: 0.9452611207962036, Accuracy: 0.65625\n",
      "Batch: 3, Loss: 0.8370870351791382, Accuracy: 0.7138671875\n",
      "Batch: 4, Loss: 0.7540521025657654, Accuracy: 0.7548828125\n",
      "Batch: 5, Loss: 0.841553807258606, Accuracy: 0.736328125\n",
      "Batch: 6, Loss: 0.8993303775787354, Accuracy: 0.7001953125\n",
      "Batch: 7, Loss: 0.884140133857727, Accuracy: 0.70703125\n",
      "Batch: 8, Loss: 0.8210670948028564, Accuracy: 0.724609375\n",
      "Batch: 9, Loss: 0.7968034744262695, Accuracy: 0.7412109375\n",
      "Batch: 10, Loss: 0.8115111589431763, Accuracy: 0.7314453125\n",
      "Batch: 11, Loss: 0.968255341053009, Accuracy: 0.68359375\n",
      "Batch: 12, Loss: 0.9545793533325195, Accuracy: 0.6806640625\n",
      "Batch: 13, Loss: 0.7269560098648071, Accuracy: 0.7724609375\n",
      "Batch: 14, Loss: 0.9507037401199341, Accuracy: 0.67578125\n",
      "Batch: 15, Loss: 0.7855316996574402, Accuracy: 0.75390625\n",
      "Batch: 16, Loss: 0.877518892288208, Accuracy: 0.7216796875\n",
      "Batch: 17, Loss: 0.9395227432250977, Accuracy: 0.6953125\n",
      "Batch: 18, Loss: 0.9477312564849854, Accuracy: 0.6904296875\n",
      "Batch: 19, Loss: 0.9308619499206543, Accuracy: 0.685546875\n",
      "Batch: 20, Loss: 0.7971318960189819, Accuracy: 0.7529296875\n",
      "Batch: 21, Loss: 0.8308210372924805, Accuracy: 0.7119140625\n",
      "Batch: 22, Loss: 0.95139479637146, Accuracy: 0.7041015625\n",
      "Batch: 23, Loss: 0.8910908699035645, Accuracy: 0.71875\n",
      "Batch: 24, Loss: 0.8831442594528198, Accuracy: 0.697265625\n",
      "Batch: 25, Loss: 0.8803629279136658, Accuracy: 0.7158203125\n",
      "Batch: 26, Loss: 0.779358983039856, Accuracy: 0.7353515625\n",
      "Batch: 27, Loss: 0.8207250833511353, Accuracy: 0.71875\n",
      "Batch: 28, Loss: 0.970034122467041, Accuracy: 0.685546875\n",
      "Batch: 29, Loss: 0.8767791986465454, Accuracy: 0.6953125\n",
      "Batch: 30, Loss: 0.7975454330444336, Accuracy: 0.7548828125\n",
      "Batch: 31, Loss: 0.8058412075042725, Accuracy: 0.7607421875\n",
      "Batch: 32, Loss: 0.8071630001068115, Accuracy: 0.732421875\n",
      "Batch: 33, Loss: 0.9589649438858032, Accuracy: 0.6884765625\n",
      "Batch: 34, Loss: 1.0179946422576904, Accuracy: 0.6640625\n",
      "Batch: 35, Loss: 0.8945174217224121, Accuracy: 0.708984375\n",
      "Batch: 36, Loss: 0.93243807554245, Accuracy: 0.7001953125\n",
      "Batch: 37, Loss: 0.8599834442138672, Accuracy: 0.7236328125\n",
      "Batch: 38, Loss: 0.9583806395530701, Accuracy: 0.6767578125\n",
      "Batch: 39, Loss: 0.9114385843276978, Accuracy: 0.7041015625\n",
      "Batch: 40, Loss: 0.876846432685852, Accuracy: 0.7119140625\n",
      "Batch: 41, Loss: 0.8233551979064941, Accuracy: 0.7373046875\n",
      "Batch: 42, Loss: 0.7011820077896118, Accuracy: 0.7626953125\n",
      "Batch: 43, Loss: 0.9545899033546448, Accuracy: 0.6806640625\n",
      "Batch: 44, Loss: 0.916910707950592, Accuracy: 0.681640625\n",
      "Batch: 45, Loss: 0.8327831029891968, Accuracy: 0.7265625\n",
      "Batch: 46, Loss: 0.7992520928382874, Accuracy: 0.7587890625\n",
      "Batch: 47, Loss: 0.8290416598320007, Accuracy: 0.751953125\n",
      "Batch: 48, Loss: 0.7970518469810486, Accuracy: 0.734375\n",
      "Batch: 49, Loss: 0.9528043866157532, Accuracy: 0.681640625\n",
      "Batch: 50, Loss: 0.9463958144187927, Accuracy: 0.67578125\n",
      "Batch: 51, Loss: 0.9548712372779846, Accuracy: 0.6953125\n",
      "Batch: 52, Loss: 0.935309648513794, Accuracy: 0.6953125\n",
      "Batch: 53, Loss: 0.825374960899353, Accuracy: 0.7236328125\n",
      "Batch: 54, Loss: 0.8833379745483398, Accuracy: 0.6943359375\n",
      "Batch: 55, Loss: 0.9736957550048828, Accuracy: 0.6796875\n",
      "Batch: 56, Loss: 0.9382573962211609, Accuracy: 0.685546875\n",
      "Batch: 57, Loss: 0.8745731115341187, Accuracy: 0.708984375\n",
      "Batch: 58, Loss: 0.9879195690155029, Accuracy: 0.6962890625\n",
      "Batch: 59, Loss: 0.8022310733795166, Accuracy: 0.732421875\n",
      "Batch: 60, Loss: 0.7759326696395874, Accuracy: 0.7451171875\n",
      "Batch: 61, Loss: 0.924074113368988, Accuracy: 0.6953125\n",
      "Batch: 62, Loss: 0.8597024083137512, Accuracy: 0.7314453125\n",
      "Batch: 63, Loss: 0.9148750901222229, Accuracy: 0.7001953125\n",
      "Batch: 64, Loss: 0.8836626410484314, Accuracy: 0.705078125\n",
      "Batch: 65, Loss: 0.908666729927063, Accuracy: 0.7060546875\n",
      "Batch: 66, Loss: 0.8361232876777649, Accuracy: 0.7431640625\n",
      "Batch: 67, Loss: 0.9559170007705688, Accuracy: 0.69921875\n",
      "Batch: 68, Loss: 0.976893424987793, Accuracy: 0.7060546875\n",
      "Batch: 69, Loss: 0.8906433582305908, Accuracy: 0.70703125\n",
      "Batch: 70, Loss: 0.8846446871757507, Accuracy: 0.7197265625\n",
      "Batch: 71, Loss: 0.9266045093536377, Accuracy: 0.6875\n",
      "Batch: 72, Loss: 0.7836153507232666, Accuracy: 0.728515625\n",
      "Batch: 73, Loss: 0.830592691898346, Accuracy: 0.73828125\n",
      "Batch: 74, Loss: 0.7794415950775146, Accuracy: 0.7431640625\n",
      "Batch: 75, Loss: 0.7929524779319763, Accuracy: 0.74609375\n",
      "Batch: 76, Loss: 0.8930041790008545, Accuracy: 0.705078125\n",
      "Batch: 77, Loss: 0.8712563514709473, Accuracy: 0.7158203125\n",
      "Batch: 78, Loss: 0.8106457591056824, Accuracy: 0.744140625\n",
      "Batch: 79, Loss: 0.7551994919776917, Accuracy: 0.744140625\n",
      "Batch: 80, Loss: 0.8550770282745361, Accuracy: 0.69921875\n",
      "Batch: 81, Loss: 0.918542742729187, Accuracy: 0.677734375\n",
      "Batch: 82, Loss: 0.9086049795150757, Accuracy: 0.7021484375\n",
      "Batch: 83, Loss: 0.7642960548400879, Accuracy: 0.7587890625\n",
      "Batch: 84, Loss: 0.8285682797431946, Accuracy: 0.7392578125\n",
      "Batch: 85, Loss: 0.7965494394302368, Accuracy: 0.740234375\n",
      "Batch: 86, Loss: 1.008406400680542, Accuracy: 0.6884765625\n",
      "Batch: 87, Loss: 0.8015164136886597, Accuracy: 0.73828125\n",
      "Batch: 88, Loss: 0.9169310331344604, Accuracy: 0.70703125\n",
      "Batch: 89, Loss: 0.8957113027572632, Accuracy: 0.7109375\n",
      "Batch: 90, Loss: 0.8190588355064392, Accuracy: 0.740234375\n",
      "Batch: 91, Loss: 0.8516215682029724, Accuracy: 0.71484375\n",
      "Batch: 92, Loss: 0.8767709732055664, Accuracy: 0.7080078125\n",
      "Batch: 93, Loss: 0.8646184206008911, Accuracy: 0.7158203125\n",
      "Batch: 94, Loss: 0.8544660806655884, Accuracy: 0.7177734375\n",
      "Batch: 95, Loss: 0.8963723182678223, Accuracy: 0.693359375\n",
      "Batch: 96, Loss: 0.8608196377754211, Accuracy: 0.71875\n",
      "Batch: 97, Loss: 0.7118116617202759, Accuracy: 0.7685546875\n",
      "Batch: 98, Loss: 0.8051841259002686, Accuracy: 0.7353515625\n",
      "Batch: 99, Loss: 0.8214805126190186, Accuracy: 0.736328125\n",
      "Batch: 100, Loss: 0.8585940003395081, Accuracy: 0.72265625\n",
      "Batch: 101, Loss: 0.9149658679962158, Accuracy: 0.705078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 102, Loss: 0.884702742099762, Accuracy: 0.71875\n",
      "Batch: 103, Loss: 0.878201961517334, Accuracy: 0.716796875\n",
      "Batch: 104, Loss: 0.8249337077140808, Accuracy: 0.728515625\n",
      "Batch: 105, Loss: 0.8792497515678406, Accuracy: 0.708984375\n",
      "Batch: 106, Loss: 0.8660229444503784, Accuracy: 0.7041015625\n",
      "Batch: 107, Loss: 0.9259247779846191, Accuracy: 0.7177734375\n",
      "Batch: 108, Loss: 0.9206928014755249, Accuracy: 0.6875\n",
      "Batch: 109, Loss: 0.9632549285888672, Accuracy: 0.6845703125\n",
      "Batch: 110, Loss: 0.763546347618103, Accuracy: 0.755859375\n",
      "Batch: 111, Loss: 0.9004606008529663, Accuracy: 0.701171875\n",
      "Batch: 112, Loss: 0.8549477458000183, Accuracy: 0.724609375\n",
      "Batch: 113, Loss: 0.8586925268173218, Accuracy: 0.7255859375\n",
      "Batch: 114, Loss: 0.9571123719215393, Accuracy: 0.693359375\n",
      "Batch: 115, Loss: 1.0524377822875977, Accuracy: 0.6865234375\n",
      "Batch: 116, Loss: 0.968946635723114, Accuracy: 0.69921875\n",
      "Batch: 117, Loss: 0.9554122686386108, Accuracy: 0.6787109375\n",
      "Batch: 118, Loss: 0.7783592939376831, Accuracy: 0.7470703125\n",
      "Batch: 119, Loss: 0.7501624822616577, Accuracy: 0.7646484375\n",
      "Batch: 120, Loss: 0.8933886289596558, Accuracy: 0.712890625\n",
      "Batch: 121, Loss: 0.9407428503036499, Accuracy: 0.689453125\n",
      "Batch: 122, Loss: 0.8306996822357178, Accuracy: 0.7314453125\n",
      "Batch: 123, Loss: 0.8239091038703918, Accuracy: 0.7255859375\n",
      "Batch: 124, Loss: 0.8933324813842773, Accuracy: 0.6904296875\n",
      "Batch: 125, Loss: 0.9272048473358154, Accuracy: 0.705078125\n",
      "Batch: 126, Loss: 0.8799375295639038, Accuracy: 0.71875\n",
      "Batch: 127, Loss: 0.7842397689819336, Accuracy: 0.75390625\n",
      "Batch: 128, Loss: 1.0157384872436523, Accuracy: 0.6953125\n",
      "Batch: 129, Loss: 0.8360024690628052, Accuracy: 0.7353515625\n",
      "Batch: 130, Loss: 1.0030395984649658, Accuracy: 0.6826171875\n",
      "Batch: 131, Loss: 0.8819119930267334, Accuracy: 0.708984375\n",
      "Batch: 132, Loss: 0.9024972915649414, Accuracy: 0.7177734375\n",
      "Batch: 133, Loss: 0.8381552696228027, Accuracy: 0.7138671875\n",
      "Batch: 134, Loss: 0.9119391441345215, Accuracy: 0.6826171875\n",
      "Batch: 135, Loss: 0.8021508455276489, Accuracy: 0.7421875\n",
      "Batch: 136, Loss: 0.8811545372009277, Accuracy: 0.7138671875\n",
      "Batch: 137, Loss: 0.8376514315605164, Accuracy: 0.7138671875\n",
      "Batch: 138, Loss: 0.7768223285675049, Accuracy: 0.740234375\n",
      "Batch: 139, Loss: 0.7969285249710083, Accuracy: 0.7197265625\n",
      "Batch: 140, Loss: 0.8654962182044983, Accuracy: 0.7109375\n",
      "Batch: 141, Loss: 0.8815872669219971, Accuracy: 0.7041015625\n",
      "Batch: 142, Loss: 0.9361363053321838, Accuracy: 0.68359375\n",
      "Batch: 143, Loss: 0.9183844327926636, Accuracy: 0.705078125\n",
      "Batch: 144, Loss: 0.8863120079040527, Accuracy: 0.70703125\n",
      "Batch: 145, Loss: 0.8409748673439026, Accuracy: 0.703125\n",
      "Batch: 146, Loss: 0.911531388759613, Accuracy: 0.703125\n",
      "Batch: 147, Loss: 0.9328831434249878, Accuracy: 0.6962890625\n",
      "Batch: 148, Loss: 0.985027551651001, Accuracy: 0.6630859375\n",
      "Batch: 149, Loss: 0.8816134929656982, Accuracy: 0.705078125\n",
      "Batch: 150, Loss: 0.8678731918334961, Accuracy: 0.7001953125\n",
      "Batch: 151, Loss: 0.8032140135765076, Accuracy: 0.736328125\n",
      "Epoch 38/80\n",
      "Batch: 1, Loss: 1.1114788055419922, Accuracy: 0.6494140625\n",
      "Batch: 2, Loss: 0.9576037526130676, Accuracy: 0.6611328125\n",
      "Batch: 3, Loss: 0.848455548286438, Accuracy: 0.712890625\n",
      "Batch: 4, Loss: 0.7735714912414551, Accuracy: 0.75\n",
      "Batch: 5, Loss: 0.8554741740226746, Accuracy: 0.7236328125\n",
      "Batch: 6, Loss: 0.8884499073028564, Accuracy: 0.7021484375\n",
      "Batch: 7, Loss: 0.8660016059875488, Accuracy: 0.7001953125\n",
      "Batch: 8, Loss: 0.8152158856391907, Accuracy: 0.7353515625\n",
      "Batch: 9, Loss: 0.7981599569320679, Accuracy: 0.740234375\n",
      "Batch: 10, Loss: 0.8237991333007812, Accuracy: 0.72265625\n",
      "Batch: 11, Loss: 0.934220016002655, Accuracy: 0.68359375\n",
      "Batch: 12, Loss: 0.9447318315505981, Accuracy: 0.681640625\n",
      "Batch: 13, Loss: 0.7401196956634521, Accuracy: 0.7490234375\n",
      "Batch: 14, Loss: 0.9514079093933105, Accuracy: 0.69140625\n",
      "Batch: 15, Loss: 0.7585440874099731, Accuracy: 0.767578125\n",
      "Batch: 16, Loss: 0.8763697147369385, Accuracy: 0.7265625\n",
      "Batch: 17, Loss: 0.900974452495575, Accuracy: 0.703125\n",
      "Batch: 18, Loss: 0.932776689529419, Accuracy: 0.703125\n",
      "Batch: 19, Loss: 0.9103506803512573, Accuracy: 0.7109375\n",
      "Batch: 20, Loss: 0.7964881062507629, Accuracy: 0.7373046875\n",
      "Batch: 21, Loss: 0.8319013118743896, Accuracy: 0.7314453125\n",
      "Batch: 22, Loss: 0.9325515031814575, Accuracy: 0.7158203125\n",
      "Batch: 23, Loss: 0.8763132691383362, Accuracy: 0.7060546875\n",
      "Batch: 24, Loss: 0.8836812973022461, Accuracy: 0.708984375\n",
      "Batch: 25, Loss: 0.8862731456756592, Accuracy: 0.7177734375\n",
      "Batch: 26, Loss: 0.7828410863876343, Accuracy: 0.7431640625\n",
      "Batch: 27, Loss: 0.8295794129371643, Accuracy: 0.7138671875\n",
      "Batch: 28, Loss: 0.8887293934822083, Accuracy: 0.69921875\n",
      "Batch: 29, Loss: 0.8538490533828735, Accuracy: 0.7138671875\n",
      "Batch: 30, Loss: 0.7891021966934204, Accuracy: 0.7470703125\n",
      "Batch: 31, Loss: 0.7706494331359863, Accuracy: 0.755859375\n",
      "Batch: 32, Loss: 0.8035774230957031, Accuracy: 0.7353515625\n",
      "Batch: 33, Loss: 0.9411027431488037, Accuracy: 0.6953125\n",
      "Batch: 34, Loss: 1.0141210556030273, Accuracy: 0.673828125\n",
      "Batch: 35, Loss: 0.9034273624420166, Accuracy: 0.7001953125\n",
      "Batch: 36, Loss: 0.9174389839172363, Accuracy: 0.705078125\n",
      "Batch: 37, Loss: 0.8846057653427124, Accuracy: 0.705078125\n",
      "Batch: 38, Loss: 0.9194378852844238, Accuracy: 0.6865234375\n",
      "Batch: 39, Loss: 0.9221034049987793, Accuracy: 0.69140625\n",
      "Batch: 40, Loss: 0.8766493201255798, Accuracy: 0.71875\n",
      "Batch: 41, Loss: 0.8440800905227661, Accuracy: 0.71875\n",
      "Batch: 42, Loss: 0.7027114629745483, Accuracy: 0.7578125\n",
      "Batch: 43, Loss: 0.9163826704025269, Accuracy: 0.693359375\n",
      "Batch: 44, Loss: 0.9025974273681641, Accuracy: 0.6865234375\n",
      "Batch: 45, Loss: 0.7975034713745117, Accuracy: 0.732421875\n",
      "Batch: 46, Loss: 0.7831733822822571, Accuracy: 0.7568359375\n",
      "Batch: 47, Loss: 0.8015058040618896, Accuracy: 0.7431640625\n",
      "Batch: 48, Loss: 0.7941381931304932, Accuracy: 0.734375\n",
      "Batch: 49, Loss: 0.9569719433784485, Accuracy: 0.697265625\n",
      "Batch: 50, Loss: 0.9231166839599609, Accuracy: 0.689453125\n",
      "Batch: 51, Loss: 0.9832490086555481, Accuracy: 0.6845703125\n",
      "Batch: 52, Loss: 0.9109557867050171, Accuracy: 0.6953125\n",
      "Batch: 53, Loss: 0.8307794332504272, Accuracy: 0.71484375\n",
      "Batch: 54, Loss: 0.8611835241317749, Accuracy: 0.720703125\n",
      "Batch: 55, Loss: 0.9335269927978516, Accuracy: 0.68359375\n",
      "Batch: 56, Loss: 0.9296714663505554, Accuracy: 0.7001953125\n",
      "Batch: 57, Loss: 0.8889636993408203, Accuracy: 0.708984375\n",
      "Batch: 58, Loss: 0.9823934435844421, Accuracy: 0.6982421875\n",
      "Batch: 59, Loss: 0.8115959763526917, Accuracy: 0.7431640625\n",
      "Batch: 60, Loss: 0.8070430159568787, Accuracy: 0.74609375\n",
      "Batch: 61, Loss: 0.9050719738006592, Accuracy: 0.701171875\n",
      "Batch: 62, Loss: 0.8531801700592041, Accuracy: 0.7255859375\n",
      "Batch: 63, Loss: 0.887579619884491, Accuracy: 0.7314453125\n",
      "Batch: 64, Loss: 0.8679127097129822, Accuracy: 0.712890625\n",
      "Batch: 65, Loss: 0.9193019270896912, Accuracy: 0.7080078125\n",
      "Batch: 66, Loss: 0.8287477493286133, Accuracy: 0.7431640625\n",
      "Batch: 67, Loss: 0.9343440532684326, Accuracy: 0.701171875\n",
      "Batch: 68, Loss: 0.9667985439300537, Accuracy: 0.6845703125\n",
      "Batch: 69, Loss: 0.9111379384994507, Accuracy: 0.7041015625\n",
      "Batch: 70, Loss: 0.8866181373596191, Accuracy: 0.724609375\n",
      "Batch: 71, Loss: 0.8994008898735046, Accuracy: 0.6884765625\n",
      "Batch: 72, Loss: 0.776714563369751, Accuracy: 0.7333984375\n",
      "Batch: 73, Loss: 0.8055387735366821, Accuracy: 0.7392578125\n",
      "Batch: 74, Loss: 0.7807080745697021, Accuracy: 0.7509765625\n",
      "Batch: 75, Loss: 0.7880914211273193, Accuracy: 0.7451171875\n",
      "Batch: 76, Loss: 0.8867236971855164, Accuracy: 0.705078125\n",
      "Batch: 77, Loss: 0.839564859867096, Accuracy: 0.7216796875\n",
      "Batch: 78, Loss: 0.7957351207733154, Accuracy: 0.748046875\n",
      "Batch: 79, Loss: 0.736302375793457, Accuracy: 0.7685546875\n",
      "Batch: 80, Loss: 0.8341262340545654, Accuracy: 0.712890625\n",
      "Batch: 81, Loss: 0.9373834133148193, Accuracy: 0.6923828125\n",
      "Batch: 82, Loss: 0.8826025724411011, Accuracy: 0.69921875\n",
      "Batch: 83, Loss: 0.7579284906387329, Accuracy: 0.765625\n",
      "Batch: 84, Loss: 0.8143881559371948, Accuracy: 0.7490234375\n",
      "Batch: 85, Loss: 0.796506941318512, Accuracy: 0.7373046875\n",
      "Batch: 86, Loss: 0.9737906455993652, Accuracy: 0.689453125\n",
      "Batch: 87, Loss: 0.783268392086029, Accuracy: 0.736328125\n",
      "Batch: 88, Loss: 0.8963428139686584, Accuracy: 0.7236328125\n",
      "Batch: 89, Loss: 0.8906047344207764, Accuracy: 0.716796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 90, Loss: 0.836652934551239, Accuracy: 0.7236328125\n",
      "Batch: 91, Loss: 0.8398159146308899, Accuracy: 0.7216796875\n",
      "Batch: 92, Loss: 0.8817263841629028, Accuracy: 0.7138671875\n",
      "Batch: 93, Loss: 0.8362576961517334, Accuracy: 0.720703125\n",
      "Batch: 94, Loss: 0.8546380996704102, Accuracy: 0.712890625\n",
      "Batch: 95, Loss: 0.8881440162658691, Accuracy: 0.6904296875\n",
      "Batch: 96, Loss: 0.8464258909225464, Accuracy: 0.73046875\n",
      "Batch: 97, Loss: 0.7359976172447205, Accuracy: 0.7451171875\n",
      "Batch: 98, Loss: 0.798179566860199, Accuracy: 0.7392578125\n",
      "Batch: 99, Loss: 0.8259969353675842, Accuracy: 0.7392578125\n",
      "Batch: 100, Loss: 0.8741976618766785, Accuracy: 0.71484375\n",
      "Batch: 101, Loss: 0.9076777696609497, Accuracy: 0.72265625\n",
      "Batch: 102, Loss: 0.8659102320671082, Accuracy: 0.7158203125\n",
      "Batch: 103, Loss: 0.8985698223114014, Accuracy: 0.705078125\n",
      "Batch: 104, Loss: 0.7884417772293091, Accuracy: 0.7333984375\n",
      "Batch: 105, Loss: 0.8879963755607605, Accuracy: 0.716796875\n",
      "Batch: 106, Loss: 0.8479681611061096, Accuracy: 0.720703125\n",
      "Batch: 107, Loss: 0.8851670622825623, Accuracy: 0.7197265625\n",
      "Batch: 108, Loss: 0.9067323207855225, Accuracy: 0.68359375\n",
      "Batch: 109, Loss: 0.9991388916969299, Accuracy: 0.685546875\n",
      "Batch: 110, Loss: 0.7485515475273132, Accuracy: 0.74609375\n",
      "Batch: 111, Loss: 0.9049893021583557, Accuracy: 0.7138671875\n",
      "Batch: 112, Loss: 0.8531330227851868, Accuracy: 0.7177734375\n",
      "Batch: 113, Loss: 0.8566267490386963, Accuracy: 0.73046875\n",
      "Batch: 114, Loss: 0.9465040564537048, Accuracy: 0.697265625\n",
      "Batch: 115, Loss: 1.0094215869903564, Accuracy: 0.673828125\n",
      "Batch: 116, Loss: 0.9455434083938599, Accuracy: 0.7119140625\n",
      "Batch: 117, Loss: 0.9485199451446533, Accuracy: 0.6875\n",
      "Batch: 118, Loss: 0.7816370725631714, Accuracy: 0.740234375\n",
      "Batch: 119, Loss: 0.7363128662109375, Accuracy: 0.75\n",
      "Batch: 120, Loss: 0.8852310180664062, Accuracy: 0.7138671875\n",
      "Batch: 121, Loss: 0.9286491870880127, Accuracy: 0.6884765625\n",
      "Batch: 122, Loss: 0.8154773712158203, Accuracy: 0.7470703125\n",
      "Batch: 123, Loss: 0.8146648406982422, Accuracy: 0.7412109375\n",
      "Batch: 124, Loss: 0.8655209541320801, Accuracy: 0.7041015625\n",
      "Batch: 125, Loss: 0.9417763948440552, Accuracy: 0.685546875\n",
      "Batch: 126, Loss: 0.8852181434631348, Accuracy: 0.71484375\n",
      "Batch: 127, Loss: 0.7855043411254883, Accuracy: 0.75390625\n",
      "Batch: 128, Loss: 0.9667910933494568, Accuracy: 0.7109375\n",
      "Batch: 129, Loss: 0.8121140003204346, Accuracy: 0.744140625\n",
      "Batch: 130, Loss: 0.9654945731163025, Accuracy: 0.69140625\n",
      "Batch: 131, Loss: 0.8672184944152832, Accuracy: 0.7099609375\n",
      "Batch: 132, Loss: 0.8945932388305664, Accuracy: 0.7177734375\n",
      "Batch: 133, Loss: 0.8253459334373474, Accuracy: 0.734375\n",
      "Batch: 134, Loss: 0.888273298740387, Accuracy: 0.6904296875\n",
      "Batch: 135, Loss: 0.7947427034378052, Accuracy: 0.7470703125\n",
      "Batch: 136, Loss: 0.8718093633651733, Accuracy: 0.69921875\n",
      "Batch: 137, Loss: 0.8697348237037659, Accuracy: 0.7138671875\n",
      "Batch: 138, Loss: 0.7450337409973145, Accuracy: 0.7509765625\n",
      "Batch: 139, Loss: 0.8137264251708984, Accuracy: 0.748046875\n",
      "Batch: 140, Loss: 0.838141143321991, Accuracy: 0.7275390625\n",
      "Batch: 141, Loss: 0.8879400491714478, Accuracy: 0.703125\n",
      "Batch: 142, Loss: 0.9193172454833984, Accuracy: 0.7080078125\n",
      "Batch: 143, Loss: 0.873639702796936, Accuracy: 0.7158203125\n",
      "Batch: 144, Loss: 0.8540318012237549, Accuracy: 0.71484375\n",
      "Batch: 145, Loss: 0.8487451076507568, Accuracy: 0.6943359375\n",
      "Batch: 146, Loss: 0.9330122470855713, Accuracy: 0.689453125\n",
      "Batch: 147, Loss: 0.911017656326294, Accuracy: 0.697265625\n",
      "Batch: 148, Loss: 1.0216929912567139, Accuracy: 0.6552734375\n",
      "Batch: 149, Loss: 0.8418436646461487, Accuracy: 0.7060546875\n",
      "Batch: 150, Loss: 0.8822926878929138, Accuracy: 0.7021484375\n",
      "Batch: 151, Loss: 0.7506588697433472, Accuracy: 0.75390625\n",
      "Epoch 39/80\n",
      "Batch: 1, Loss: 1.1036921739578247, Accuracy: 0.6484375\n",
      "Batch: 2, Loss: 0.9494417905807495, Accuracy: 0.6640625\n",
      "Batch: 3, Loss: 0.812142014503479, Accuracy: 0.7353515625\n",
      "Batch: 4, Loss: 0.7387921810150146, Accuracy: 0.7548828125\n",
      "Batch: 5, Loss: 0.8378471732139587, Accuracy: 0.71875\n",
      "Batch: 6, Loss: 0.8778655529022217, Accuracy: 0.724609375\n",
      "Batch: 7, Loss: 0.8321289420127869, Accuracy: 0.7041015625\n",
      "Batch: 8, Loss: 0.7978733777999878, Accuracy: 0.7509765625\n",
      "Batch: 9, Loss: 0.8088600039482117, Accuracy: 0.7333984375\n",
      "Batch: 10, Loss: 0.7989077568054199, Accuracy: 0.7265625\n",
      "Batch: 11, Loss: 0.9363490343093872, Accuracy: 0.6923828125\n",
      "Batch: 12, Loss: 0.917486310005188, Accuracy: 0.705078125\n",
      "Batch: 13, Loss: 0.7398189902305603, Accuracy: 0.7548828125\n",
      "Batch: 14, Loss: 0.9567265510559082, Accuracy: 0.6826171875\n",
      "Batch: 15, Loss: 0.811703085899353, Accuracy: 0.751953125\n",
      "Batch: 16, Loss: 0.8480574488639832, Accuracy: 0.728515625\n",
      "Batch: 17, Loss: 0.9184353947639465, Accuracy: 0.693359375\n",
      "Batch: 18, Loss: 0.9287777543067932, Accuracy: 0.69921875\n",
      "Batch: 19, Loss: 0.9020834565162659, Accuracy: 0.7001953125\n",
      "Batch: 20, Loss: 0.7901073694229126, Accuracy: 0.748046875\n",
      "Batch: 21, Loss: 0.8294805288314819, Accuracy: 0.7255859375\n",
      "Batch: 22, Loss: 0.9322332739830017, Accuracy: 0.712890625\n",
      "Batch: 23, Loss: 0.8945711851119995, Accuracy: 0.697265625\n",
      "Batch: 24, Loss: 0.8923957347869873, Accuracy: 0.70703125\n",
      "Batch: 25, Loss: 0.8757384419441223, Accuracy: 0.7041015625\n",
      "Batch: 26, Loss: 0.7655172348022461, Accuracy: 0.73046875\n",
      "Batch: 27, Loss: 0.822033703327179, Accuracy: 0.7294921875\n",
      "Batch: 28, Loss: 0.856806755065918, Accuracy: 0.716796875\n",
      "Batch: 29, Loss: 0.8459570407867432, Accuracy: 0.705078125\n",
      "Batch: 30, Loss: 0.772950291633606, Accuracy: 0.7548828125\n",
      "Batch: 31, Loss: 0.7641856074333191, Accuracy: 0.763671875\n",
      "Batch: 32, Loss: 0.7933810949325562, Accuracy: 0.732421875\n",
      "Batch: 33, Loss: 0.9575991630554199, Accuracy: 0.6982421875\n",
      "Batch: 34, Loss: 0.9612718224525452, Accuracy: 0.6796875\n",
      "Batch: 35, Loss: 0.876699686050415, Accuracy: 0.712890625\n",
      "Batch: 36, Loss: 0.9175361394882202, Accuracy: 0.7119140625\n",
      "Batch: 37, Loss: 0.8766456842422485, Accuracy: 0.703125\n",
      "Batch: 38, Loss: 0.9100404381752014, Accuracy: 0.6953125\n",
      "Batch: 39, Loss: 0.8969069719314575, Accuracy: 0.703125\n",
      "Batch: 40, Loss: 0.8564819097518921, Accuracy: 0.7197265625\n",
      "Batch: 41, Loss: 0.7988834381103516, Accuracy: 0.73828125\n",
      "Batch: 42, Loss: 0.6907401084899902, Accuracy: 0.7744140625\n",
      "Batch: 43, Loss: 0.9092845916748047, Accuracy: 0.7001953125\n",
      "Batch: 44, Loss: 0.904877245426178, Accuracy: 0.7001953125\n",
      "Batch: 45, Loss: 0.8157250881195068, Accuracy: 0.7333984375\n",
      "Batch: 46, Loss: 0.7849162220954895, Accuracy: 0.75390625\n",
      "Batch: 47, Loss: 0.7784726619720459, Accuracy: 0.7470703125\n",
      "Batch: 48, Loss: 0.7854499816894531, Accuracy: 0.7490234375\n",
      "Batch: 49, Loss: 0.9278081655502319, Accuracy: 0.68359375\n",
      "Batch: 50, Loss: 0.9078786373138428, Accuracy: 0.697265625\n",
      "Batch: 51, Loss: 0.9351409673690796, Accuracy: 0.6904296875\n",
      "Batch: 52, Loss: 0.8813334107398987, Accuracy: 0.7109375\n",
      "Batch: 53, Loss: 0.8294951915740967, Accuracy: 0.7255859375\n",
      "Batch: 54, Loss: 0.8431721925735474, Accuracy: 0.72265625\n",
      "Batch: 55, Loss: 0.9244542717933655, Accuracy: 0.6962890625\n",
      "Batch: 56, Loss: 0.9264163970947266, Accuracy: 0.70703125\n",
      "Batch: 57, Loss: 0.8618649244308472, Accuracy: 0.71875\n",
      "Batch: 58, Loss: 0.9608839154243469, Accuracy: 0.697265625\n",
      "Batch: 59, Loss: 0.8217397332191467, Accuracy: 0.728515625\n",
      "Batch: 60, Loss: 0.7749367356300354, Accuracy: 0.74609375\n",
      "Batch: 61, Loss: 0.8913782238960266, Accuracy: 0.7109375\n",
      "Batch: 62, Loss: 0.8308706879615784, Accuracy: 0.716796875\n",
      "Batch: 63, Loss: 0.88777756690979, Accuracy: 0.7216796875\n",
      "Batch: 64, Loss: 0.8565061092376709, Accuracy: 0.7158203125\n",
      "Batch: 65, Loss: 0.903639018535614, Accuracy: 0.70703125\n",
      "Batch: 66, Loss: 0.8208043575286865, Accuracy: 0.75390625\n",
      "Batch: 67, Loss: 0.9566640853881836, Accuracy: 0.697265625\n",
      "Batch: 68, Loss: 0.9646368026733398, Accuracy: 0.7001953125\n",
      "Batch: 69, Loss: 0.8844609260559082, Accuracy: 0.716796875\n",
      "Batch: 70, Loss: 0.847294807434082, Accuracy: 0.732421875\n",
      "Batch: 71, Loss: 0.908287525177002, Accuracy: 0.693359375\n",
      "Batch: 72, Loss: 0.7518434524536133, Accuracy: 0.7470703125\n",
      "Batch: 73, Loss: 0.7730623483657837, Accuracy: 0.740234375\n",
      "Batch: 74, Loss: 0.7575867772102356, Accuracy: 0.763671875\n",
      "Batch: 75, Loss: 0.7918636798858643, Accuracy: 0.748046875\n",
      "Batch: 76, Loss: 0.8629408478736877, Accuracy: 0.712890625\n",
      "Batch: 77, Loss: 0.8259621262550354, Accuracy: 0.728515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 78, Loss: 0.7885909080505371, Accuracy: 0.7470703125\n",
      "Batch: 79, Loss: 0.7321785092353821, Accuracy: 0.759765625\n",
      "Batch: 80, Loss: 0.8048871755599976, Accuracy: 0.716796875\n",
      "Batch: 81, Loss: 0.9241243600845337, Accuracy: 0.6796875\n",
      "Batch: 82, Loss: 0.876542866230011, Accuracy: 0.703125\n",
      "Batch: 83, Loss: 0.7436468601226807, Accuracy: 0.7763671875\n",
      "Batch: 84, Loss: 0.8190991878509521, Accuracy: 0.748046875\n",
      "Batch: 85, Loss: 0.8014382719993591, Accuracy: 0.7392578125\n",
      "Batch: 86, Loss: 1.006851077079773, Accuracy: 0.6982421875\n",
      "Batch: 87, Loss: 0.7940354347229004, Accuracy: 0.76171875\n",
      "Batch: 88, Loss: 0.9137598276138306, Accuracy: 0.71484375\n",
      "Batch: 89, Loss: 0.886992335319519, Accuracy: 0.7236328125\n",
      "Batch: 90, Loss: 0.8137376308441162, Accuracy: 0.7392578125\n",
      "Batch: 91, Loss: 0.8213284015655518, Accuracy: 0.7216796875\n",
      "Batch: 92, Loss: 0.9021462202072144, Accuracy: 0.708984375\n",
      "Batch: 93, Loss: 0.841965913772583, Accuracy: 0.7177734375\n",
      "Batch: 94, Loss: 0.8504683375358582, Accuracy: 0.71484375\n",
      "Batch: 95, Loss: 0.8945608139038086, Accuracy: 0.697265625\n",
      "Batch: 96, Loss: 0.8178713321685791, Accuracy: 0.7392578125\n",
      "Batch: 97, Loss: 0.7281383275985718, Accuracy: 0.763671875\n",
      "Batch: 98, Loss: 0.7885082960128784, Accuracy: 0.734375\n",
      "Batch: 99, Loss: 0.8289597034454346, Accuracy: 0.732421875\n",
      "Batch: 100, Loss: 0.8367398977279663, Accuracy: 0.7275390625\n",
      "Batch: 101, Loss: 0.9149686098098755, Accuracy: 0.705078125\n",
      "Batch: 102, Loss: 0.8746805191040039, Accuracy: 0.7119140625\n",
      "Batch: 103, Loss: 0.8554445505142212, Accuracy: 0.724609375\n",
      "Batch: 104, Loss: 0.7917014360427856, Accuracy: 0.720703125\n",
      "Batch: 105, Loss: 0.8705552816390991, Accuracy: 0.71484375\n",
      "Batch: 106, Loss: 0.8375113010406494, Accuracy: 0.7333984375\n",
      "Batch: 107, Loss: 0.8708306550979614, Accuracy: 0.7177734375\n",
      "Batch: 108, Loss: 0.8794488310813904, Accuracy: 0.7109375\n",
      "Batch: 109, Loss: 0.9782710671424866, Accuracy: 0.677734375\n",
      "Batch: 110, Loss: 0.7584542036056519, Accuracy: 0.73828125\n",
      "Batch: 111, Loss: 0.9119588732719421, Accuracy: 0.712890625\n",
      "Batch: 112, Loss: 0.8342083692550659, Accuracy: 0.7392578125\n",
      "Batch: 113, Loss: 0.8598405122756958, Accuracy: 0.732421875\n",
      "Batch: 114, Loss: 0.9543299674987793, Accuracy: 0.705078125\n",
      "Batch: 115, Loss: 0.9800281524658203, Accuracy: 0.69921875\n",
      "Batch: 116, Loss: 0.9044687151908875, Accuracy: 0.71484375\n",
      "Batch: 117, Loss: 0.9049333930015564, Accuracy: 0.7158203125\n",
      "Batch: 118, Loss: 0.8001227378845215, Accuracy: 0.751953125\n",
      "Batch: 119, Loss: 0.7475069165229797, Accuracy: 0.759765625\n",
      "Batch: 120, Loss: 0.8959393501281738, Accuracy: 0.7158203125\n",
      "Batch: 121, Loss: 0.9027829170227051, Accuracy: 0.70703125\n",
      "Batch: 122, Loss: 0.8176831007003784, Accuracy: 0.74609375\n",
      "Batch: 123, Loss: 0.7923803925514221, Accuracy: 0.744140625\n",
      "Batch: 124, Loss: 0.8689583539962769, Accuracy: 0.71484375\n",
      "Batch: 125, Loss: 0.920540452003479, Accuracy: 0.6943359375\n",
      "Batch: 126, Loss: 0.8737385272979736, Accuracy: 0.712890625\n",
      "Batch: 127, Loss: 0.7866096496582031, Accuracy: 0.751953125\n",
      "Batch: 128, Loss: 0.9695603847503662, Accuracy: 0.7021484375\n",
      "Batch: 129, Loss: 0.8029186129570007, Accuracy: 0.7216796875\n",
      "Batch: 130, Loss: 1.0136847496032715, Accuracy: 0.6796875\n",
      "Batch: 131, Loss: 0.8601013422012329, Accuracy: 0.71875\n",
      "Batch: 132, Loss: 0.9095532298088074, Accuracy: 0.6943359375\n",
      "Batch: 133, Loss: 0.8537100553512573, Accuracy: 0.7216796875\n",
      "Batch: 134, Loss: 0.8565993905067444, Accuracy: 0.701171875\n",
      "Batch: 135, Loss: 0.785076379776001, Accuracy: 0.74609375\n",
      "Batch: 136, Loss: 0.8805602192878723, Accuracy: 0.705078125\n",
      "Batch: 137, Loss: 0.8662385940551758, Accuracy: 0.693359375\n",
      "Batch: 138, Loss: 0.748657763004303, Accuracy: 0.75390625\n",
      "Batch: 139, Loss: 0.8088816404342651, Accuracy: 0.7216796875\n",
      "Batch: 140, Loss: 0.8324799537658691, Accuracy: 0.7255859375\n",
      "Batch: 141, Loss: 0.8983076214790344, Accuracy: 0.7158203125\n",
      "Batch: 142, Loss: 0.8998805284500122, Accuracy: 0.703125\n",
      "Batch: 143, Loss: 0.8638336062431335, Accuracy: 0.7099609375\n",
      "Batch: 144, Loss: 0.8552873730659485, Accuracy: 0.70703125\n",
      "Batch: 145, Loss: 0.8176778554916382, Accuracy: 0.71875\n",
      "Batch: 146, Loss: 0.9120635986328125, Accuracy: 0.6943359375\n",
      "Batch: 147, Loss: 0.9347278475761414, Accuracy: 0.6884765625\n",
      "Batch: 148, Loss: 1.0159488916397095, Accuracy: 0.6767578125\n",
      "Batch: 149, Loss: 0.8889361023902893, Accuracy: 0.7099609375\n",
      "Batch: 150, Loss: 0.8891746401786804, Accuracy: 0.7216796875\n",
      "Batch: 151, Loss: 0.791738748550415, Accuracy: 0.740234375\n",
      "Epoch 40/80\n",
      "Batch: 1, Loss: 1.1020078659057617, Accuracy: 0.6513671875\n",
      "Batch: 2, Loss: 0.9689967632293701, Accuracy: 0.6650390625\n",
      "Batch: 3, Loss: 0.846487283706665, Accuracy: 0.7158203125\n",
      "Batch: 4, Loss: 0.7434614896774292, Accuracy: 0.7578125\n",
      "Batch: 5, Loss: 0.8192394971847534, Accuracy: 0.7373046875\n",
      "Batch: 6, Loss: 0.8744296431541443, Accuracy: 0.6953125\n",
      "Batch: 7, Loss: 0.8589979410171509, Accuracy: 0.7138671875\n",
      "Batch: 8, Loss: 0.8053925633430481, Accuracy: 0.7265625\n",
      "Batch: 9, Loss: 0.7900100946426392, Accuracy: 0.744140625\n",
      "Batch: 10, Loss: 0.827694833278656, Accuracy: 0.720703125\n",
      "Batch: 11, Loss: 0.9264014959335327, Accuracy: 0.673828125\n",
      "Batch: 12, Loss: 0.9176288843154907, Accuracy: 0.7001953125\n",
      "Batch: 13, Loss: 0.7076177597045898, Accuracy: 0.7548828125\n",
      "Batch: 14, Loss: 0.946123480796814, Accuracy: 0.6884765625\n",
      "Batch: 15, Loss: 0.7569825053215027, Accuracy: 0.7646484375\n",
      "Batch: 16, Loss: 0.828025221824646, Accuracy: 0.724609375\n",
      "Batch: 17, Loss: 0.9069801568984985, Accuracy: 0.6962890625\n",
      "Batch: 18, Loss: 0.9305711984634399, Accuracy: 0.6953125\n",
      "Batch: 19, Loss: 0.9088106155395508, Accuracy: 0.708984375\n",
      "Batch: 20, Loss: 0.7797479033470154, Accuracy: 0.7509765625\n",
      "Batch: 21, Loss: 0.8041760921478271, Accuracy: 0.7333984375\n",
      "Batch: 22, Loss: 0.930903434753418, Accuracy: 0.69140625\n",
      "Batch: 23, Loss: 0.8790981769561768, Accuracy: 0.7080078125\n",
      "Batch: 24, Loss: 0.8973767757415771, Accuracy: 0.703125\n",
      "Batch: 25, Loss: 0.8909375667572021, Accuracy: 0.7138671875\n",
      "Batch: 26, Loss: 0.7549673318862915, Accuracy: 0.734375\n",
      "Batch: 27, Loss: 0.8312973380088806, Accuracy: 0.7119140625\n",
      "Batch: 28, Loss: 0.8888044357299805, Accuracy: 0.6904296875\n",
      "Batch: 29, Loss: 0.8373821377754211, Accuracy: 0.728515625\n",
      "Batch: 30, Loss: 0.7397846579551697, Accuracy: 0.7705078125\n",
      "Batch: 31, Loss: 0.7660853862762451, Accuracy: 0.7578125\n",
      "Batch: 32, Loss: 0.8099391460418701, Accuracy: 0.7177734375\n",
      "Batch: 33, Loss: 0.9071905612945557, Accuracy: 0.7197265625\n",
      "Batch: 34, Loss: 0.999007523059845, Accuracy: 0.6669921875\n",
      "Batch: 35, Loss: 0.8713110685348511, Accuracy: 0.7197265625\n",
      "Batch: 36, Loss: 0.9173318147659302, Accuracy: 0.72265625\n",
      "Batch: 37, Loss: 0.8862950205802917, Accuracy: 0.7080078125\n",
      "Batch: 38, Loss: 0.8828582763671875, Accuracy: 0.703125\n",
      "Batch: 39, Loss: 0.8938847184181213, Accuracy: 0.7177734375\n",
      "Batch: 40, Loss: 0.8669288158416748, Accuracy: 0.7265625\n",
      "Batch: 41, Loss: 0.8034777641296387, Accuracy: 0.74609375\n",
      "Batch: 42, Loss: 0.6774370670318604, Accuracy: 0.7783203125\n",
      "Batch: 43, Loss: 0.921113133430481, Accuracy: 0.6943359375\n",
      "Batch: 44, Loss: 0.889934778213501, Accuracy: 0.7041015625\n",
      "Batch: 45, Loss: 0.7943759560585022, Accuracy: 0.7275390625\n",
      "Batch: 46, Loss: 0.8071298599243164, Accuracy: 0.74609375\n",
      "Batch: 47, Loss: 0.8074613213539124, Accuracy: 0.7431640625\n",
      "Batch: 48, Loss: 0.755262017250061, Accuracy: 0.7470703125\n",
      "Batch: 49, Loss: 0.9072811603546143, Accuracy: 0.6923828125\n",
      "Batch: 50, Loss: 0.9284842014312744, Accuracy: 0.6904296875\n",
      "Batch: 51, Loss: 0.9330720901489258, Accuracy: 0.6904296875\n",
      "Batch: 52, Loss: 0.9123444557189941, Accuracy: 0.7001953125\n",
      "Batch: 53, Loss: 0.8211108446121216, Accuracy: 0.7177734375\n",
      "Batch: 54, Loss: 0.8509061336517334, Accuracy: 0.7255859375\n",
      "Batch: 55, Loss: 0.9407349824905396, Accuracy: 0.6982421875\n",
      "Batch: 56, Loss: 0.9204782247543335, Accuracy: 0.7001953125\n",
      "Batch: 57, Loss: 0.8892287611961365, Accuracy: 0.701171875\n",
      "Batch: 58, Loss: 0.9778703451156616, Accuracy: 0.6982421875\n",
      "Batch: 59, Loss: 0.804564356803894, Accuracy: 0.7373046875\n",
      "Batch: 60, Loss: 0.7825695276260376, Accuracy: 0.7421875\n",
      "Batch: 61, Loss: 0.8680331707000732, Accuracy: 0.7275390625\n",
      "Batch: 62, Loss: 0.8391920924186707, Accuracy: 0.724609375\n",
      "Batch: 63, Loss: 0.8764086961746216, Accuracy: 0.71484375\n",
      "Batch: 64, Loss: 0.8551264405250549, Accuracy: 0.716796875\n",
      "Batch: 65, Loss: 0.8770031332969666, Accuracy: 0.720703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 66, Loss: 0.8289874792098999, Accuracy: 0.744140625\n",
      "Batch: 67, Loss: 0.9086921215057373, Accuracy: 0.7080078125\n",
      "Batch: 68, Loss: 0.9191648364067078, Accuracy: 0.7265625\n",
      "Batch: 69, Loss: 0.8998088836669922, Accuracy: 0.7041015625\n",
      "Batch: 70, Loss: 0.8301260471343994, Accuracy: 0.76171875\n",
      "Batch: 71, Loss: 0.8991336822509766, Accuracy: 0.701171875\n",
      "Batch: 72, Loss: 0.7793465852737427, Accuracy: 0.736328125\n",
      "Batch: 73, Loss: 0.8062493205070496, Accuracy: 0.74609375\n",
      "Batch: 74, Loss: 0.7637020349502563, Accuracy: 0.7724609375\n",
      "Batch: 75, Loss: 0.7581212520599365, Accuracy: 0.748046875\n",
      "Batch: 76, Loss: 0.8767253160476685, Accuracy: 0.703125\n",
      "Batch: 77, Loss: 0.8211013674736023, Accuracy: 0.7353515625\n",
      "Batch: 78, Loss: 0.7947280406951904, Accuracy: 0.748046875\n",
      "Batch: 79, Loss: 0.7642006278038025, Accuracy: 0.765625\n",
      "Batch: 80, Loss: 0.8255098462104797, Accuracy: 0.724609375\n",
      "Batch: 81, Loss: 0.941433310508728, Accuracy: 0.6826171875\n",
      "Batch: 82, Loss: 0.893062949180603, Accuracy: 0.7001953125\n",
      "Batch: 83, Loss: 0.7527422308921814, Accuracy: 0.7724609375\n",
      "Batch: 84, Loss: 0.8285629749298096, Accuracy: 0.7197265625\n",
      "Batch: 85, Loss: 0.7777184247970581, Accuracy: 0.7490234375\n",
      "Batch: 86, Loss: 0.9666643738746643, Accuracy: 0.701171875\n",
      "Batch: 87, Loss: 0.7949199676513672, Accuracy: 0.7412109375\n",
      "Batch: 88, Loss: 0.8994944095611572, Accuracy: 0.7265625\n",
      "Batch: 89, Loss: 0.9039053916931152, Accuracy: 0.71875\n",
      "Batch: 90, Loss: 0.8141418099403381, Accuracy: 0.7421875\n",
      "Batch: 91, Loss: 0.8140391111373901, Accuracy: 0.7294921875\n",
      "Batch: 92, Loss: 0.8731335997581482, Accuracy: 0.7265625\n",
      "Batch: 93, Loss: 0.8229465484619141, Accuracy: 0.7275390625\n",
      "Batch: 94, Loss: 0.8329465985298157, Accuracy: 0.71875\n",
      "Batch: 95, Loss: 0.8992771506309509, Accuracy: 0.6904296875\n",
      "Batch: 96, Loss: 0.8202900886535645, Accuracy: 0.73046875\n",
      "Batch: 97, Loss: 0.7230304479598999, Accuracy: 0.75\n",
      "Batch: 98, Loss: 0.794405460357666, Accuracy: 0.736328125\n",
      "Batch: 99, Loss: 0.8291256427764893, Accuracy: 0.720703125\n",
      "Batch: 100, Loss: 0.8278844952583313, Accuracy: 0.7275390625\n",
      "Batch: 101, Loss: 0.886016845703125, Accuracy: 0.7158203125\n",
      "Batch: 102, Loss: 0.8389655351638794, Accuracy: 0.73046875\n",
      "Batch: 103, Loss: 0.8736230731010437, Accuracy: 0.7197265625\n",
      "Batch: 104, Loss: 0.7761861085891724, Accuracy: 0.736328125\n",
      "Batch: 105, Loss: 0.8792370557785034, Accuracy: 0.7216796875\n",
      "Batch: 106, Loss: 0.8081440925598145, Accuracy: 0.73828125\n",
      "Batch: 107, Loss: 0.8741859793663025, Accuracy: 0.73046875\n",
      "Batch: 108, Loss: 0.8698367476463318, Accuracy: 0.7001953125\n",
      "Batch: 109, Loss: 0.9938652515411377, Accuracy: 0.6767578125\n",
      "Batch: 110, Loss: 0.7889739871025085, Accuracy: 0.7353515625\n",
      "Batch: 111, Loss: 0.8860893845558167, Accuracy: 0.697265625\n",
      "Batch: 112, Loss: 0.8307898044586182, Accuracy: 0.744140625\n",
      "Batch: 113, Loss: 0.8537864685058594, Accuracy: 0.72265625\n",
      "Batch: 114, Loss: 0.9601418972015381, Accuracy: 0.689453125\n",
      "Batch: 115, Loss: 0.9450631141662598, Accuracy: 0.703125\n",
      "Batch: 116, Loss: 0.8973926901817322, Accuracy: 0.708984375\n",
      "Batch: 117, Loss: 0.9082953929901123, Accuracy: 0.7080078125\n",
      "Batch: 118, Loss: 0.7921754121780396, Accuracy: 0.7412109375\n",
      "Batch: 119, Loss: 0.7290483713150024, Accuracy: 0.7626953125\n",
      "Batch: 120, Loss: 0.8925108909606934, Accuracy: 0.7109375\n",
      "Batch: 121, Loss: 0.9243299961090088, Accuracy: 0.685546875\n",
      "Batch: 122, Loss: 0.8336883187294006, Accuracy: 0.736328125\n",
      "Batch: 123, Loss: 0.7675443291664124, Accuracy: 0.76953125\n",
      "Batch: 124, Loss: 0.8393756151199341, Accuracy: 0.736328125\n",
      "Batch: 125, Loss: 0.9209240674972534, Accuracy: 0.6943359375\n",
      "Batch: 126, Loss: 0.8585647344589233, Accuracy: 0.7197265625\n",
      "Batch: 127, Loss: 0.772361159324646, Accuracy: 0.7490234375\n",
      "Batch: 128, Loss: 0.9646912813186646, Accuracy: 0.716796875\n",
      "Batch: 129, Loss: 0.796516478061676, Accuracy: 0.7373046875\n",
      "Batch: 130, Loss: 0.9589790105819702, Accuracy: 0.6904296875\n",
      "Batch: 131, Loss: 0.8468664884567261, Accuracy: 0.7099609375\n",
      "Batch: 132, Loss: 0.8641208410263062, Accuracy: 0.716796875\n",
      "Batch: 133, Loss: 0.8322259783744812, Accuracy: 0.7451171875\n",
      "Batch: 134, Loss: 0.8613885641098022, Accuracy: 0.7080078125\n",
      "Batch: 135, Loss: 0.7918906211853027, Accuracy: 0.7421875\n",
      "Batch: 136, Loss: 0.8608664274215698, Accuracy: 0.716796875\n",
      "Batch: 137, Loss: 0.8501478433609009, Accuracy: 0.703125\n",
      "Batch: 138, Loss: 0.7191581726074219, Accuracy: 0.7451171875\n",
      "Batch: 139, Loss: 0.8071339130401611, Accuracy: 0.7158203125\n",
      "Batch: 140, Loss: 0.8396119475364685, Accuracy: 0.724609375\n",
      "Batch: 141, Loss: 0.8639082908630371, Accuracy: 0.716796875\n",
      "Batch: 142, Loss: 0.9255000948905945, Accuracy: 0.6884765625\n",
      "Batch: 143, Loss: 0.8493356704711914, Accuracy: 0.7197265625\n",
      "Batch: 144, Loss: 0.8344061374664307, Accuracy: 0.7138671875\n",
      "Batch: 145, Loss: 0.8080657720565796, Accuracy: 0.7236328125\n",
      "Batch: 146, Loss: 0.9174101948738098, Accuracy: 0.6943359375\n",
      "Batch: 147, Loss: 0.8925067186355591, Accuracy: 0.703125\n",
      "Batch: 148, Loss: 0.9934123754501343, Accuracy: 0.6689453125\n",
      "Batch: 149, Loss: 0.8416633605957031, Accuracy: 0.716796875\n",
      "Batch: 150, Loss: 0.8215219378471375, Accuracy: 0.708984375\n",
      "Batch: 151, Loss: 0.7608326077461243, Accuracy: 0.7451171875\n",
      "Saved Weights at epoch 40 to file Weights_40.h5\n",
      "Epoch 41/80\n",
      "Batch: 1, Loss: 1.1254884004592896, Accuracy: 0.6396484375\n",
      "Batch: 2, Loss: 0.9328886270523071, Accuracy: 0.6904296875\n",
      "Batch: 3, Loss: 0.8005908727645874, Accuracy: 0.73828125\n",
      "Batch: 4, Loss: 0.7334822416305542, Accuracy: 0.765625\n",
      "Batch: 5, Loss: 0.8055703043937683, Accuracy: 0.73828125\n",
      "Batch: 6, Loss: 0.8501042127609253, Accuracy: 0.7138671875\n",
      "Batch: 7, Loss: 0.8409486413002014, Accuracy: 0.7197265625\n",
      "Batch: 8, Loss: 0.8165781497955322, Accuracy: 0.7197265625\n",
      "Batch: 9, Loss: 0.800017237663269, Accuracy: 0.7333984375\n",
      "Batch: 10, Loss: 0.8169874548912048, Accuracy: 0.728515625\n",
      "Batch: 11, Loss: 0.9291687607765198, Accuracy: 0.689453125\n",
      "Batch: 12, Loss: 0.8920756578445435, Accuracy: 0.7158203125\n",
      "Batch: 13, Loss: 0.7197302579879761, Accuracy: 0.7763671875\n",
      "Batch: 14, Loss: 0.9504562616348267, Accuracy: 0.69140625\n",
      "Batch: 15, Loss: 0.7606587409973145, Accuracy: 0.7705078125\n",
      "Batch: 16, Loss: 0.8229666948318481, Accuracy: 0.7353515625\n",
      "Batch: 17, Loss: 0.8790810108184814, Accuracy: 0.70703125\n",
      "Batch: 18, Loss: 0.8972076177597046, Accuracy: 0.70703125\n",
      "Batch: 19, Loss: 0.8756341934204102, Accuracy: 0.71484375\n",
      "Batch: 20, Loss: 0.775387167930603, Accuracy: 0.7412109375\n",
      "Batch: 21, Loss: 0.8125560283660889, Accuracy: 0.7177734375\n",
      "Batch: 22, Loss: 0.9133632183074951, Accuracy: 0.7099609375\n",
      "Batch: 23, Loss: 0.8541052937507629, Accuracy: 0.7109375\n",
      "Batch: 24, Loss: 0.8893473148345947, Accuracy: 0.7138671875\n",
      "Batch: 25, Loss: 0.8386610746383667, Accuracy: 0.72265625\n",
      "Batch: 26, Loss: 0.7527092695236206, Accuracy: 0.7421875\n",
      "Batch: 27, Loss: 0.7880102396011353, Accuracy: 0.7265625\n",
      "Batch: 28, Loss: 0.8646610975265503, Accuracy: 0.6982421875\n",
      "Batch: 29, Loss: 0.8287686109542847, Accuracy: 0.7275390625\n",
      "Batch: 30, Loss: 0.7468479871749878, Accuracy: 0.7666015625\n",
      "Batch: 31, Loss: 0.776439368724823, Accuracy: 0.7451171875\n",
      "Batch: 32, Loss: 0.8196153044700623, Accuracy: 0.73046875\n",
      "Batch: 33, Loss: 0.9192641973495483, Accuracy: 0.7060546875\n",
      "Batch: 34, Loss: 0.9689698219299316, Accuracy: 0.6875\n",
      "Batch: 35, Loss: 0.8492788672447205, Accuracy: 0.71484375\n",
      "Batch: 36, Loss: 0.9055328369140625, Accuracy: 0.7138671875\n",
      "Batch: 37, Loss: 0.8471963405609131, Accuracy: 0.7197265625\n",
      "Batch: 38, Loss: 0.9038437604904175, Accuracy: 0.6953125\n",
      "Batch: 39, Loss: 0.8647090792655945, Accuracy: 0.712890625\n",
      "Batch: 40, Loss: 0.8511635065078735, Accuracy: 0.72265625\n",
      "Batch: 41, Loss: 0.8066937923431396, Accuracy: 0.7373046875\n",
      "Batch: 42, Loss: 0.6677300930023193, Accuracy: 0.767578125\n",
      "Batch: 43, Loss: 0.8847586512565613, Accuracy: 0.7060546875\n",
      "Batch: 44, Loss: 0.8873292803764343, Accuracy: 0.7080078125\n",
      "Batch: 45, Loss: 0.8073939085006714, Accuracy: 0.73046875\n",
      "Batch: 46, Loss: 0.7827754020690918, Accuracy: 0.7509765625\n",
      "Batch: 47, Loss: 0.7892267107963562, Accuracy: 0.7490234375\n",
      "Batch: 48, Loss: 0.76450514793396, Accuracy: 0.7421875\n",
      "Batch: 49, Loss: 0.9262527227401733, Accuracy: 0.6904296875\n",
      "Batch: 50, Loss: 0.9101494550704956, Accuracy: 0.6982421875\n",
      "Batch: 51, Loss: 0.9207431077957153, Accuracy: 0.705078125\n",
      "Batch: 52, Loss: 0.8979873657226562, Accuracy: 0.716796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 53, Loss: 0.7902959585189819, Accuracy: 0.728515625\n",
      "Batch: 54, Loss: 0.8530831336975098, Accuracy: 0.7197265625\n",
      "Batch: 55, Loss: 0.9457472562789917, Accuracy: 0.6767578125\n",
      "Batch: 56, Loss: 0.9341429471969604, Accuracy: 0.6953125\n",
      "Batch: 57, Loss: 0.8673259615898132, Accuracy: 0.720703125\n",
      "Batch: 58, Loss: 0.967108964920044, Accuracy: 0.701171875\n",
      "Batch: 59, Loss: 0.7802022695541382, Accuracy: 0.740234375\n",
      "Batch: 60, Loss: 0.7559205293655396, Accuracy: 0.765625\n",
      "Batch: 61, Loss: 0.8490537405014038, Accuracy: 0.728515625\n",
      "Batch: 62, Loss: 0.8164054155349731, Accuracy: 0.74609375\n",
      "Batch: 63, Loss: 0.8696234226226807, Accuracy: 0.7177734375\n",
      "Batch: 64, Loss: 0.8598587512969971, Accuracy: 0.720703125\n",
      "Batch: 65, Loss: 0.8669396638870239, Accuracy: 0.7265625\n",
      "Batch: 66, Loss: 0.829572319984436, Accuracy: 0.73828125\n",
      "Batch: 67, Loss: 0.9179259538650513, Accuracy: 0.7099609375\n",
      "Batch: 68, Loss: 0.9384206533432007, Accuracy: 0.7080078125\n",
      "Batch: 69, Loss: 0.8717926144599915, Accuracy: 0.7080078125\n",
      "Batch: 70, Loss: 0.844300389289856, Accuracy: 0.74609375\n",
      "Batch: 71, Loss: 0.8711206316947937, Accuracy: 0.70703125\n",
      "Batch: 72, Loss: 0.7522352933883667, Accuracy: 0.740234375\n",
      "Batch: 73, Loss: 0.7790094017982483, Accuracy: 0.7548828125\n",
      "Batch: 74, Loss: 0.7420530319213867, Accuracy: 0.767578125\n",
      "Batch: 75, Loss: 0.7678872346878052, Accuracy: 0.755859375\n",
      "Batch: 76, Loss: 0.87149977684021, Accuracy: 0.7138671875\n",
      "Batch: 77, Loss: 0.8374828696250916, Accuracy: 0.7314453125\n",
      "Batch: 78, Loss: 0.7673848867416382, Accuracy: 0.7431640625\n",
      "Batch: 79, Loss: 0.7045825123786926, Accuracy: 0.775390625\n",
      "Batch: 80, Loss: 0.7931383848190308, Accuracy: 0.73046875\n",
      "Batch: 81, Loss: 0.9268742799758911, Accuracy: 0.673828125\n",
      "Batch: 82, Loss: 0.8985904455184937, Accuracy: 0.705078125\n",
      "Batch: 83, Loss: 0.7340430021286011, Accuracy: 0.7646484375\n",
      "Batch: 84, Loss: 0.8054256439208984, Accuracy: 0.740234375\n",
      "Batch: 85, Loss: 0.7954832315444946, Accuracy: 0.736328125\n",
      "Batch: 86, Loss: 0.959755003452301, Accuracy: 0.7001953125\n",
      "Batch: 87, Loss: 0.7688988447189331, Accuracy: 0.759765625\n",
      "Batch: 88, Loss: 0.8941911458969116, Accuracy: 0.72265625\n",
      "Batch: 89, Loss: 0.8809617757797241, Accuracy: 0.70703125\n",
      "Batch: 90, Loss: 0.7848578691482544, Accuracy: 0.7529296875\n",
      "Batch: 91, Loss: 0.7814799547195435, Accuracy: 0.728515625\n",
      "Batch: 92, Loss: 0.8482024669647217, Accuracy: 0.724609375\n",
      "Batch: 93, Loss: 0.8250501155853271, Accuracy: 0.7294921875\n",
      "Batch: 94, Loss: 0.8313154578208923, Accuracy: 0.71875\n",
      "Batch: 95, Loss: 0.8917503356933594, Accuracy: 0.69140625\n",
      "Batch: 96, Loss: 0.8380436897277832, Accuracy: 0.7236328125\n",
      "Batch: 97, Loss: 0.6794921159744263, Accuracy: 0.767578125\n",
      "Batch: 98, Loss: 0.7966674566268921, Accuracy: 0.75390625\n",
      "Batch: 99, Loss: 0.8056492805480957, Accuracy: 0.7373046875\n",
      "Batch: 100, Loss: 0.8372229933738708, Accuracy: 0.728515625\n",
      "Batch: 101, Loss: 0.8859401941299438, Accuracy: 0.734375\n",
      "Batch: 102, Loss: 0.843117356300354, Accuracy: 0.7197265625\n",
      "Batch: 103, Loss: 0.8597073554992676, Accuracy: 0.7109375\n",
      "Batch: 104, Loss: 0.7830570936203003, Accuracy: 0.73828125\n",
      "Batch: 105, Loss: 0.8674836158752441, Accuracy: 0.724609375\n",
      "Batch: 106, Loss: 0.8213887214660645, Accuracy: 0.7294921875\n",
      "Batch: 107, Loss: 0.8375005722045898, Accuracy: 0.732421875\n",
      "Batch: 108, Loss: 0.87664794921875, Accuracy: 0.7080078125\n",
      "Batch: 109, Loss: 0.9464704990386963, Accuracy: 0.6953125\n",
      "Batch: 110, Loss: 0.7664518356323242, Accuracy: 0.736328125\n",
      "Batch: 111, Loss: 0.8929335474967957, Accuracy: 0.7197265625\n",
      "Batch: 112, Loss: 0.8311389684677124, Accuracy: 0.736328125\n",
      "Batch: 113, Loss: 0.8350240588188171, Accuracy: 0.74609375\n",
      "Batch: 114, Loss: 0.9321410655975342, Accuracy: 0.7109375\n",
      "Batch: 115, Loss: 0.9431554079055786, Accuracy: 0.697265625\n",
      "Batch: 116, Loss: 0.8829092383384705, Accuracy: 0.7236328125\n",
      "Batch: 117, Loss: 0.9000189900398254, Accuracy: 0.7177734375\n",
      "Batch: 118, Loss: 0.7520303726196289, Accuracy: 0.751953125\n",
      "Batch: 119, Loss: 0.7308070659637451, Accuracy: 0.7626953125\n",
      "Batch: 120, Loss: 0.8744751214981079, Accuracy: 0.7041015625\n",
      "Batch: 121, Loss: 0.8981914520263672, Accuracy: 0.7021484375\n",
      "Batch: 122, Loss: 0.7908503413200378, Accuracy: 0.7529296875\n",
      "Batch: 123, Loss: 0.7735146284103394, Accuracy: 0.75390625\n",
      "Batch: 124, Loss: 0.8431612253189087, Accuracy: 0.71875\n",
      "Batch: 125, Loss: 0.8807960748672485, Accuracy: 0.7119140625\n",
      "Batch: 126, Loss: 0.8621495962142944, Accuracy: 0.7314453125\n",
      "Batch: 127, Loss: 0.7428967356681824, Accuracy: 0.7705078125\n",
      "Batch: 128, Loss: 0.9324249625205994, Accuracy: 0.7119140625\n",
      "Batch: 129, Loss: 0.7905083894729614, Accuracy: 0.7392578125\n",
      "Batch: 130, Loss: 0.9589036703109741, Accuracy: 0.669921875\n",
      "Batch: 131, Loss: 0.8707824349403381, Accuracy: 0.697265625\n",
      "Batch: 132, Loss: 0.8810937404632568, Accuracy: 0.7099609375\n",
      "Batch: 133, Loss: 0.7928115129470825, Accuracy: 0.734375\n",
      "Batch: 134, Loss: 0.8674639463424683, Accuracy: 0.69921875\n",
      "Batch: 135, Loss: 0.7520831227302551, Accuracy: 0.751953125\n",
      "Batch: 136, Loss: 0.8561931848526001, Accuracy: 0.7265625\n",
      "Batch: 137, Loss: 0.8415610790252686, Accuracy: 0.71875\n",
      "Batch: 138, Loss: 0.742920458316803, Accuracy: 0.767578125\n",
      "Batch: 139, Loss: 0.7804991006851196, Accuracy: 0.7353515625\n",
      "Batch: 140, Loss: 0.8329546451568604, Accuracy: 0.7314453125\n",
      "Batch: 141, Loss: 0.8910975456237793, Accuracy: 0.6962890625\n",
      "Batch: 142, Loss: 0.8788684010505676, Accuracy: 0.716796875\n",
      "Batch: 143, Loss: 0.863640546798706, Accuracy: 0.7001953125\n",
      "Batch: 144, Loss: 0.8339923620223999, Accuracy: 0.724609375\n",
      "Batch: 145, Loss: 0.8087334632873535, Accuracy: 0.73046875\n",
      "Batch: 146, Loss: 0.8683693408966064, Accuracy: 0.7177734375\n",
      "Batch: 147, Loss: 0.8851526379585266, Accuracy: 0.7216796875\n",
      "Batch: 148, Loss: 0.9553221464157104, Accuracy: 0.689453125\n",
      "Batch: 149, Loss: 0.8188134431838989, Accuracy: 0.7080078125\n",
      "Batch: 150, Loss: 0.8313658237457275, Accuracy: 0.716796875\n",
      "Batch: 151, Loss: 0.7467306852340698, Accuracy: 0.7529296875\n",
      "Epoch 42/80\n",
      "Batch: 1, Loss: 1.1124992370605469, Accuracy: 0.64453125\n",
      "Batch: 2, Loss: 0.9326263070106506, Accuracy: 0.6884765625\n",
      "Batch: 3, Loss: 0.8093825578689575, Accuracy: 0.7236328125\n",
      "Batch: 4, Loss: 0.7130911350250244, Accuracy: 0.765625\n",
      "Batch: 5, Loss: 0.8057698011398315, Accuracy: 0.744140625\n",
      "Batch: 6, Loss: 0.8428374528884888, Accuracy: 0.716796875\n",
      "Batch: 7, Loss: 0.8515057563781738, Accuracy: 0.7158203125\n",
      "Batch: 8, Loss: 0.7628957629203796, Accuracy: 0.7421875\n",
      "Batch: 9, Loss: 0.764997124671936, Accuracy: 0.7421875\n",
      "Batch: 10, Loss: 0.7725098729133606, Accuracy: 0.7568359375\n",
      "Batch: 11, Loss: 0.9086536765098572, Accuracy: 0.697265625\n",
      "Batch: 12, Loss: 0.8865252733230591, Accuracy: 0.7001953125\n",
      "Batch: 13, Loss: 0.6902949213981628, Accuracy: 0.77734375\n",
      "Batch: 14, Loss: 0.9180910587310791, Accuracy: 0.7060546875\n",
      "Batch: 15, Loss: 0.7522929906845093, Accuracy: 0.7734375\n",
      "Batch: 16, Loss: 0.8139512538909912, Accuracy: 0.734375\n",
      "Batch: 17, Loss: 0.9031791090965271, Accuracy: 0.7216796875\n",
      "Batch: 18, Loss: 0.8851562738418579, Accuracy: 0.705078125\n",
      "Batch: 19, Loss: 0.9000347852706909, Accuracy: 0.705078125\n",
      "Batch: 20, Loss: 0.7612403035163879, Accuracy: 0.755859375\n",
      "Batch: 21, Loss: 0.7968595027923584, Accuracy: 0.7255859375\n",
      "Batch: 22, Loss: 0.9046080708503723, Accuracy: 0.7080078125\n",
      "Batch: 23, Loss: 0.8481729626655579, Accuracy: 0.7119140625\n",
      "Batch: 24, Loss: 0.8767061233520508, Accuracy: 0.7099609375\n",
      "Batch: 25, Loss: 0.8199968934059143, Accuracy: 0.7314453125\n",
      "Batch: 26, Loss: 0.7515537738800049, Accuracy: 0.740234375\n",
      "Batch: 27, Loss: 0.8067606687545776, Accuracy: 0.7236328125\n",
      "Batch: 28, Loss: 0.8718835711479187, Accuracy: 0.7060546875\n",
      "Batch: 29, Loss: 0.8093769550323486, Accuracy: 0.7197265625\n",
      "Batch: 30, Loss: 0.7459938526153564, Accuracy: 0.7626953125\n",
      "Batch: 31, Loss: 0.7702577114105225, Accuracy: 0.7626953125\n",
      "Batch: 32, Loss: 0.7751210331916809, Accuracy: 0.73828125\n",
      "Batch: 33, Loss: 0.9146917462348938, Accuracy: 0.703125\n",
      "Batch: 34, Loss: 0.9865691065788269, Accuracy: 0.6650390625\n",
      "Batch: 35, Loss: 0.8603695631027222, Accuracy: 0.7177734375\n",
      "Batch: 36, Loss: 0.8907431364059448, Accuracy: 0.736328125\n",
      "Batch: 37, Loss: 0.8489170074462891, Accuracy: 0.7177734375\n",
      "Batch: 38, Loss: 0.8797608613967896, Accuracy: 0.708984375\n",
      "Batch: 39, Loss: 0.8786002993583679, Accuracy: 0.7099609375\n",
      "Batch: 40, Loss: 0.8464722633361816, Accuracy: 0.72265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 41, Loss: 0.7969038486480713, Accuracy: 0.736328125\n",
      "Batch: 42, Loss: 0.6697403788566589, Accuracy: 0.763671875\n",
      "Batch: 43, Loss: 0.8806760311126709, Accuracy: 0.7080078125\n",
      "Batch: 44, Loss: 0.8662788271903992, Accuracy: 0.7041015625\n",
      "Batch: 45, Loss: 0.7920998334884644, Accuracy: 0.724609375\n",
      "Batch: 46, Loss: 0.772559642791748, Accuracy: 0.751953125\n",
      "Batch: 47, Loss: 0.7773967981338501, Accuracy: 0.76171875\n",
      "Batch: 48, Loss: 0.7564120292663574, Accuracy: 0.7412109375\n",
      "Batch: 49, Loss: 0.9012451171875, Accuracy: 0.705078125\n",
      "Batch: 50, Loss: 0.8881662487983704, Accuracy: 0.6923828125\n",
      "Batch: 51, Loss: 0.8940192461013794, Accuracy: 0.708984375\n",
      "Batch: 52, Loss: 0.8546116948127747, Accuracy: 0.720703125\n",
      "Batch: 53, Loss: 0.7999123334884644, Accuracy: 0.7216796875\n",
      "Batch: 54, Loss: 0.8265489339828491, Accuracy: 0.740234375\n",
      "Batch: 55, Loss: 0.9391680955886841, Accuracy: 0.6875\n",
      "Batch: 56, Loss: 0.9085382223129272, Accuracy: 0.703125\n",
      "Batch: 57, Loss: 0.8685113191604614, Accuracy: 0.7236328125\n",
      "Batch: 58, Loss: 0.9625150561332703, Accuracy: 0.69140625\n",
      "Batch: 59, Loss: 0.7793411016464233, Accuracy: 0.75390625\n",
      "Batch: 60, Loss: 0.7442629933357239, Accuracy: 0.7685546875\n",
      "Batch: 61, Loss: 0.8615590333938599, Accuracy: 0.720703125\n",
      "Batch: 62, Loss: 0.8174737691879272, Accuracy: 0.7421875\n",
      "Batch: 63, Loss: 0.8556904196739197, Accuracy: 0.7216796875\n",
      "Batch: 64, Loss: 0.8316167593002319, Accuracy: 0.724609375\n",
      "Batch: 65, Loss: 0.8889271020889282, Accuracy: 0.7216796875\n",
      "Batch: 66, Loss: 0.8074177503585815, Accuracy: 0.7548828125\n",
      "Batch: 67, Loss: 0.9217239618301392, Accuracy: 0.70703125\n",
      "Batch: 68, Loss: 0.9237035512924194, Accuracy: 0.7138671875\n",
      "Batch: 69, Loss: 0.8558558225631714, Accuracy: 0.7099609375\n",
      "Batch: 70, Loss: 0.8377459049224854, Accuracy: 0.7509765625\n",
      "Batch: 71, Loss: 0.8565832376480103, Accuracy: 0.7158203125\n",
      "Batch: 72, Loss: 0.7575006484985352, Accuracy: 0.7373046875\n",
      "Batch: 73, Loss: 0.8001542091369629, Accuracy: 0.7451171875\n",
      "Batch: 74, Loss: 0.7386605739593506, Accuracy: 0.763671875\n",
      "Batch: 75, Loss: 0.7908620238304138, Accuracy: 0.734375\n",
      "Batch: 76, Loss: 0.8800134062767029, Accuracy: 0.705078125\n",
      "Batch: 77, Loss: 0.8233752250671387, Accuracy: 0.7265625\n",
      "Batch: 78, Loss: 0.7472543120384216, Accuracy: 0.765625\n",
      "Batch: 79, Loss: 0.6997764110565186, Accuracy: 0.7822265625\n",
      "Batch: 80, Loss: 0.795441746711731, Accuracy: 0.71875\n",
      "Batch: 81, Loss: 0.8749762773513794, Accuracy: 0.7041015625\n",
      "Batch: 82, Loss: 0.8653868436813354, Accuracy: 0.71484375\n",
      "Batch: 83, Loss: 0.7064249515533447, Accuracy: 0.77734375\n",
      "Batch: 84, Loss: 0.7904210686683655, Accuracy: 0.751953125\n",
      "Batch: 85, Loss: 0.7720881700515747, Accuracy: 0.755859375\n",
      "Batch: 86, Loss: 0.9534833431243896, Accuracy: 0.6982421875\n",
      "Batch: 87, Loss: 0.7637721300125122, Accuracy: 0.7626953125\n",
      "Batch: 88, Loss: 0.9132275581359863, Accuracy: 0.7041015625\n",
      "Batch: 89, Loss: 0.8853753805160522, Accuracy: 0.724609375\n",
      "Batch: 90, Loss: 0.8003337383270264, Accuracy: 0.7529296875\n",
      "Batch: 91, Loss: 0.8391393423080444, Accuracy: 0.71484375\n",
      "Batch: 92, Loss: 0.8550912737846375, Accuracy: 0.71875\n",
      "Batch: 93, Loss: 0.8179863691329956, Accuracy: 0.7236328125\n",
      "Batch: 94, Loss: 0.8274202346801758, Accuracy: 0.7158203125\n",
      "Batch: 95, Loss: 0.8676871657371521, Accuracy: 0.7099609375\n",
      "Batch: 96, Loss: 0.797814130783081, Accuracy: 0.744140625\n",
      "Batch: 97, Loss: 0.6901111602783203, Accuracy: 0.7626953125\n",
      "Batch: 98, Loss: 0.7875099778175354, Accuracy: 0.755859375\n",
      "Batch: 99, Loss: 0.8171255588531494, Accuracy: 0.7294921875\n",
      "Batch: 100, Loss: 0.8158149719238281, Accuracy: 0.72265625\n",
      "Batch: 101, Loss: 0.8526114821434021, Accuracy: 0.7158203125\n",
      "Batch: 102, Loss: 0.844539999961853, Accuracy: 0.7197265625\n",
      "Batch: 103, Loss: 0.8292577266693115, Accuracy: 0.7197265625\n",
      "Batch: 104, Loss: 0.7717223167419434, Accuracy: 0.7412109375\n",
      "Batch: 105, Loss: 0.8369269371032715, Accuracy: 0.7333984375\n",
      "Batch: 106, Loss: 0.8269202709197998, Accuracy: 0.7197265625\n",
      "Batch: 107, Loss: 0.8473650217056274, Accuracy: 0.736328125\n",
      "Batch: 108, Loss: 0.8672363758087158, Accuracy: 0.716796875\n",
      "Batch: 109, Loss: 0.9605246186256409, Accuracy: 0.6982421875\n",
      "Batch: 110, Loss: 0.7653594017028809, Accuracy: 0.7509765625\n",
      "Batch: 111, Loss: 0.861452579498291, Accuracy: 0.73828125\n",
      "Batch: 112, Loss: 0.8270873427391052, Accuracy: 0.7294921875\n",
      "Batch: 113, Loss: 0.8359140157699585, Accuracy: 0.7412109375\n",
      "Batch: 114, Loss: 0.9047592878341675, Accuracy: 0.7041015625\n",
      "Batch: 115, Loss: 0.9853971004486084, Accuracy: 0.6982421875\n",
      "Batch: 116, Loss: 0.8682248592376709, Accuracy: 0.716796875\n",
      "Batch: 117, Loss: 0.8703248500823975, Accuracy: 0.71875\n",
      "Batch: 118, Loss: 0.765256941318512, Accuracy: 0.7509765625\n",
      "Batch: 119, Loss: 0.7188084721565247, Accuracy: 0.76171875\n",
      "Batch: 120, Loss: 0.8836750984191895, Accuracy: 0.712890625\n",
      "Batch: 121, Loss: 0.9070348739624023, Accuracy: 0.6923828125\n",
      "Batch: 122, Loss: 0.7985058426856995, Accuracy: 0.7451171875\n",
      "Batch: 123, Loss: 0.7775617837905884, Accuracy: 0.7490234375\n",
      "Batch: 124, Loss: 0.8547839522361755, Accuracy: 0.7158203125\n",
      "Batch: 125, Loss: 0.8927361965179443, Accuracy: 0.712890625\n",
      "Batch: 126, Loss: 0.8303290009498596, Accuracy: 0.728515625\n",
      "Batch: 127, Loss: 0.7546523809432983, Accuracy: 0.7587890625\n",
      "Batch: 128, Loss: 0.9232368469238281, Accuracy: 0.7158203125\n",
      "Batch: 129, Loss: 0.7716876268386841, Accuracy: 0.7548828125\n",
      "Batch: 130, Loss: 0.9782114028930664, Accuracy: 0.6787109375\n",
      "Batch: 131, Loss: 0.8424043655395508, Accuracy: 0.72265625\n",
      "Batch: 132, Loss: 0.8852065801620483, Accuracy: 0.7158203125\n",
      "Batch: 133, Loss: 0.7875970602035522, Accuracy: 0.7333984375\n",
      "Batch: 134, Loss: 0.8563868403434753, Accuracy: 0.7158203125\n",
      "Batch: 135, Loss: 0.7666304111480713, Accuracy: 0.7578125\n",
      "Batch: 136, Loss: 0.8502955436706543, Accuracy: 0.716796875\n",
      "Batch: 137, Loss: 0.8328889608383179, Accuracy: 0.705078125\n",
      "Batch: 138, Loss: 0.7224690914154053, Accuracy: 0.755859375\n",
      "Batch: 139, Loss: 0.780200719833374, Accuracy: 0.724609375\n",
      "Batch: 140, Loss: 0.8161708116531372, Accuracy: 0.728515625\n",
      "Batch: 141, Loss: 0.8491827845573425, Accuracy: 0.7138671875\n",
      "Batch: 142, Loss: 0.8760702013969421, Accuracy: 0.7158203125\n",
      "Batch: 143, Loss: 0.8121382594108582, Accuracy: 0.7197265625\n",
      "Batch: 144, Loss: 0.8464549779891968, Accuracy: 0.7041015625\n",
      "Batch: 145, Loss: 0.8007938265800476, Accuracy: 0.732421875\n",
      "Batch: 146, Loss: 0.8663762807846069, Accuracy: 0.7138671875\n",
      "Batch: 147, Loss: 0.8842487335205078, Accuracy: 0.7021484375\n",
      "Batch: 148, Loss: 0.9603235721588135, Accuracy: 0.6728515625\n",
      "Batch: 149, Loss: 0.8185851573944092, Accuracy: 0.7294921875\n",
      "Batch: 150, Loss: 0.831256628036499, Accuracy: 0.716796875\n",
      "Batch: 151, Loss: 0.7180718779563904, Accuracy: 0.765625\n",
      "Epoch 43/80\n",
      "Batch: 1, Loss: 1.076967716217041, Accuracy: 0.6630859375\n",
      "Batch: 2, Loss: 0.920001745223999, Accuracy: 0.673828125\n",
      "Batch: 3, Loss: 0.7836766242980957, Accuracy: 0.7548828125\n",
      "Batch: 4, Loss: 0.7133105993270874, Accuracy: 0.765625\n",
      "Batch: 5, Loss: 0.8044991493225098, Accuracy: 0.7353515625\n",
      "Batch: 6, Loss: 0.8480345606803894, Accuracy: 0.7216796875\n",
      "Batch: 7, Loss: 0.8365569114685059, Accuracy: 0.716796875\n",
      "Batch: 8, Loss: 0.7770489454269409, Accuracy: 0.7412109375\n",
      "Batch: 9, Loss: 0.7819494009017944, Accuracy: 0.7412109375\n",
      "Batch: 10, Loss: 0.772802472114563, Accuracy: 0.740234375\n",
      "Batch: 11, Loss: 0.9059195518493652, Accuracy: 0.6982421875\n",
      "Batch: 12, Loss: 0.9004584550857544, Accuracy: 0.69921875\n",
      "Batch: 13, Loss: 0.6888601183891296, Accuracy: 0.77734375\n",
      "Batch: 14, Loss: 0.9193088412284851, Accuracy: 0.6875\n",
      "Batch: 15, Loss: 0.7376508116722107, Accuracy: 0.7783203125\n",
      "Batch: 16, Loss: 0.8312801718711853, Accuracy: 0.7236328125\n",
      "Batch: 17, Loss: 0.8920168876647949, Accuracy: 0.7041015625\n",
      "Batch: 18, Loss: 0.9173206090927124, Accuracy: 0.69140625\n",
      "Batch: 19, Loss: 0.8519839644432068, Accuracy: 0.7236328125\n",
      "Batch: 20, Loss: 0.7377834320068359, Accuracy: 0.7607421875\n",
      "Batch: 21, Loss: 0.7833811640739441, Accuracy: 0.744140625\n",
      "Batch: 22, Loss: 0.9173005819320679, Accuracy: 0.693359375\n",
      "Batch: 23, Loss: 0.851560652256012, Accuracy: 0.71484375\n",
      "Batch: 24, Loss: 0.8784133791923523, Accuracy: 0.71484375\n",
      "Batch: 25, Loss: 0.8543561697006226, Accuracy: 0.7177734375\n",
      "Batch: 26, Loss: 0.7374063730239868, Accuracy: 0.7392578125\n",
      "Batch: 27, Loss: 0.7808839082717896, Accuracy: 0.734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 28, Loss: 0.8398796319961548, Accuracy: 0.7119140625\n",
      "Batch: 29, Loss: 0.8095221519470215, Accuracy: 0.732421875\n",
      "Batch: 30, Loss: 0.7332992553710938, Accuracy: 0.7783203125\n",
      "Batch: 31, Loss: 0.732077419757843, Accuracy: 0.775390625\n",
      "Batch: 32, Loss: 0.7733982801437378, Accuracy: 0.736328125\n",
      "Batch: 33, Loss: 0.9171805381774902, Accuracy: 0.70703125\n",
      "Batch: 34, Loss: 0.9302997589111328, Accuracy: 0.7080078125\n",
      "Batch: 35, Loss: 0.8599146604537964, Accuracy: 0.7158203125\n",
      "Batch: 36, Loss: 0.8649262189865112, Accuracy: 0.724609375\n",
      "Batch: 37, Loss: 0.8536048531532288, Accuracy: 0.7294921875\n",
      "Batch: 38, Loss: 0.8472431898117065, Accuracy: 0.6962890625\n",
      "Batch: 39, Loss: 0.8580095767974854, Accuracy: 0.70703125\n",
      "Batch: 40, Loss: 0.8403264284133911, Accuracy: 0.732421875\n",
      "Batch: 41, Loss: 0.7828231453895569, Accuracy: 0.7451171875\n",
      "Batch: 42, Loss: 0.6508322954177856, Accuracy: 0.7763671875\n",
      "Batch: 43, Loss: 0.877054750919342, Accuracy: 0.703125\n",
      "Batch: 44, Loss: 0.8418595790863037, Accuracy: 0.72265625\n",
      "Batch: 45, Loss: 0.7739673256874084, Accuracy: 0.7353515625\n",
      "Batch: 46, Loss: 0.7776116132736206, Accuracy: 0.7568359375\n",
      "Batch: 47, Loss: 0.7415785789489746, Accuracy: 0.767578125\n",
      "Batch: 48, Loss: 0.7600995898246765, Accuracy: 0.73828125\n",
      "Batch: 49, Loss: 0.8977743983268738, Accuracy: 0.7119140625\n",
      "Batch: 50, Loss: 0.8826709985733032, Accuracy: 0.7109375\n",
      "Batch: 51, Loss: 0.9094079732894897, Accuracy: 0.7109375\n",
      "Batch: 52, Loss: 0.8671466708183289, Accuracy: 0.7177734375\n",
      "Batch: 53, Loss: 0.7739948034286499, Accuracy: 0.7333984375\n",
      "Batch: 54, Loss: 0.8501402735710144, Accuracy: 0.7333984375\n",
      "Batch: 55, Loss: 0.9311391115188599, Accuracy: 0.67578125\n",
      "Batch: 56, Loss: 0.901275634765625, Accuracy: 0.703125\n",
      "Batch: 57, Loss: 0.8576462268829346, Accuracy: 0.7099609375\n",
      "Batch: 58, Loss: 0.9565571546554565, Accuracy: 0.7001953125\n",
      "Batch: 59, Loss: 0.7531987428665161, Accuracy: 0.7578125\n",
      "Batch: 60, Loss: 0.745010495185852, Accuracy: 0.765625\n",
      "Batch: 61, Loss: 0.8521168231964111, Accuracy: 0.720703125\n",
      "Batch: 62, Loss: 0.8001370429992676, Accuracy: 0.732421875\n",
      "Batch: 63, Loss: 0.8604180812835693, Accuracy: 0.7158203125\n",
      "Batch: 64, Loss: 0.8391398191452026, Accuracy: 0.71875\n",
      "Batch: 65, Loss: 0.8833760023117065, Accuracy: 0.71484375\n",
      "Batch: 66, Loss: 0.8085794448852539, Accuracy: 0.7578125\n",
      "Batch: 67, Loss: 0.9053245782852173, Accuracy: 0.7060546875\n",
      "Batch: 68, Loss: 0.939902663230896, Accuracy: 0.7109375\n",
      "Batch: 69, Loss: 0.8578391075134277, Accuracy: 0.7255859375\n",
      "Batch: 70, Loss: 0.7974396347999573, Accuracy: 0.76171875\n",
      "Batch: 71, Loss: 0.8600869178771973, Accuracy: 0.708984375\n",
      "Batch: 72, Loss: 0.7320995330810547, Accuracy: 0.7470703125\n",
      "Batch: 73, Loss: 0.7767677307128906, Accuracy: 0.7421875\n",
      "Batch: 74, Loss: 0.7335434556007385, Accuracy: 0.775390625\n",
      "Batch: 75, Loss: 0.7382501363754272, Accuracy: 0.7646484375\n",
      "Batch: 76, Loss: 0.8731875419616699, Accuracy: 0.7041015625\n",
      "Batch: 77, Loss: 0.8287270069122314, Accuracy: 0.7373046875\n",
      "Batch: 78, Loss: 0.7763792276382446, Accuracy: 0.748046875\n",
      "Batch: 79, Loss: 0.6856438517570496, Accuracy: 0.78125\n",
      "Batch: 80, Loss: 0.808382511138916, Accuracy: 0.71484375\n",
      "Batch: 81, Loss: 0.9086015224456787, Accuracy: 0.6865234375\n",
      "Batch: 82, Loss: 0.8718051910400391, Accuracy: 0.716796875\n",
      "Batch: 83, Loss: 0.7237210273742676, Accuracy: 0.767578125\n",
      "Batch: 84, Loss: 0.8092221021652222, Accuracy: 0.75\n",
      "Batch: 85, Loss: 0.7693466544151306, Accuracy: 0.744140625\n",
      "Batch: 86, Loss: 0.9369881749153137, Accuracy: 0.703125\n",
      "Batch: 87, Loss: 0.7615634202957153, Accuracy: 0.755859375\n",
      "Batch: 88, Loss: 0.8593664169311523, Accuracy: 0.734375\n",
      "Batch: 89, Loss: 0.8446705341339111, Accuracy: 0.73828125\n",
      "Batch: 90, Loss: 0.80795818567276, Accuracy: 0.73828125\n",
      "Batch: 91, Loss: 0.8034304976463318, Accuracy: 0.71875\n",
      "Batch: 92, Loss: 0.8521398901939392, Accuracy: 0.7109375\n",
      "Batch: 93, Loss: 0.8177670240402222, Accuracy: 0.7275390625\n",
      "Batch: 94, Loss: 0.8293373584747314, Accuracy: 0.7216796875\n",
      "Batch: 95, Loss: 0.8705204725265503, Accuracy: 0.689453125\n",
      "Batch: 96, Loss: 0.8079386353492737, Accuracy: 0.7294921875\n",
      "Batch: 97, Loss: 0.6956092119216919, Accuracy: 0.76171875\n",
      "Batch: 98, Loss: 0.7864336967468262, Accuracy: 0.7470703125\n",
      "Batch: 99, Loss: 0.8049430847167969, Accuracy: 0.7392578125\n",
      "Batch: 100, Loss: 0.8226383924484253, Accuracy: 0.73828125\n",
      "Batch: 101, Loss: 0.8717416524887085, Accuracy: 0.7080078125\n",
      "Batch: 102, Loss: 0.8549112677574158, Accuracy: 0.7265625\n",
      "Batch: 103, Loss: 0.8303420543670654, Accuracy: 0.7421875\n",
      "Batch: 104, Loss: 0.7890190482139587, Accuracy: 0.732421875\n",
      "Batch: 105, Loss: 0.8541587591171265, Accuracy: 0.7197265625\n",
      "Batch: 106, Loss: 0.7969284057617188, Accuracy: 0.7421875\n",
      "Batch: 107, Loss: 0.8525652885437012, Accuracy: 0.7353515625\n",
      "Batch: 108, Loss: 0.8448693752288818, Accuracy: 0.7109375\n",
      "Batch: 109, Loss: 0.9586190581321716, Accuracy: 0.6630859375\n",
      "Batch: 110, Loss: 0.7409768104553223, Accuracy: 0.76171875\n",
      "Batch: 111, Loss: 0.8659143447875977, Accuracy: 0.71484375\n",
      "Batch: 112, Loss: 0.7871606349945068, Accuracy: 0.7509765625\n",
      "Batch: 113, Loss: 0.8425782322883606, Accuracy: 0.7333984375\n",
      "Batch: 114, Loss: 0.9107427000999451, Accuracy: 0.7119140625\n",
      "Batch: 115, Loss: 0.9653849005699158, Accuracy: 0.6982421875\n",
      "Batch: 116, Loss: 0.8546019196510315, Accuracy: 0.7294921875\n",
      "Batch: 117, Loss: 0.8497647643089294, Accuracy: 0.7294921875\n",
      "Batch: 118, Loss: 0.7624025344848633, Accuracy: 0.7568359375\n",
      "Batch: 119, Loss: 0.7191641330718994, Accuracy: 0.775390625\n",
      "Batch: 120, Loss: 0.85495525598526, Accuracy: 0.71875\n",
      "Batch: 121, Loss: 0.857797384262085, Accuracy: 0.716796875\n",
      "Batch: 122, Loss: 0.7849208116531372, Accuracy: 0.7451171875\n",
      "Batch: 123, Loss: 0.7393105030059814, Accuracy: 0.7568359375\n",
      "Batch: 124, Loss: 0.8293354511260986, Accuracy: 0.7294921875\n",
      "Batch: 125, Loss: 0.8504654169082642, Accuracy: 0.71875\n",
      "Batch: 126, Loss: 0.8606178164482117, Accuracy: 0.7197265625\n",
      "Batch: 127, Loss: 0.7559787631034851, Accuracy: 0.7626953125\n",
      "Batch: 128, Loss: 0.9363148212432861, Accuracy: 0.71875\n",
      "Batch: 129, Loss: 0.7640445232391357, Accuracy: 0.7587890625\n",
      "Batch: 130, Loss: 0.9729433059692383, Accuracy: 0.6982421875\n",
      "Batch: 131, Loss: 0.8509794473648071, Accuracy: 0.7275390625\n",
      "Batch: 132, Loss: 0.8757745027542114, Accuracy: 0.71875\n",
      "Batch: 133, Loss: 0.8125725984573364, Accuracy: 0.736328125\n",
      "Batch: 134, Loss: 0.8348565697669983, Accuracy: 0.7099609375\n",
      "Batch: 135, Loss: 0.7440632581710815, Accuracy: 0.751953125\n",
      "Batch: 136, Loss: 0.834149181842804, Accuracy: 0.728515625\n",
      "Batch: 137, Loss: 0.8205784559249878, Accuracy: 0.705078125\n",
      "Batch: 138, Loss: 0.6960599422454834, Accuracy: 0.767578125\n",
      "Batch: 139, Loss: 0.7840368747711182, Accuracy: 0.736328125\n",
      "Batch: 140, Loss: 0.8193677663803101, Accuracy: 0.734375\n",
      "Batch: 141, Loss: 0.8717795014381409, Accuracy: 0.724609375\n",
      "Batch: 142, Loss: 0.8639463186264038, Accuracy: 0.7236328125\n",
      "Batch: 143, Loss: 0.8160620927810669, Accuracy: 0.7294921875\n",
      "Batch: 144, Loss: 0.8122542500495911, Accuracy: 0.7177734375\n",
      "Batch: 145, Loss: 0.793440580368042, Accuracy: 0.728515625\n",
      "Batch: 146, Loss: 0.8733304738998413, Accuracy: 0.701171875\n",
      "Batch: 147, Loss: 0.8639559149742126, Accuracy: 0.7099609375\n",
      "Batch: 148, Loss: 0.956398606300354, Accuracy: 0.6826171875\n",
      "Batch: 149, Loss: 0.8188594579696655, Accuracy: 0.7275390625\n",
      "Batch: 150, Loss: 0.8175543546676636, Accuracy: 0.734375\n",
      "Batch: 151, Loss: 0.7339874505996704, Accuracy: 0.75390625\n",
      "Epoch 44/80\n",
      "Batch: 1, Loss: 1.0594027042388916, Accuracy: 0.6640625\n",
      "Batch: 2, Loss: 0.8938164710998535, Accuracy: 0.6904296875\n",
      "Batch: 3, Loss: 0.7762600183486938, Accuracy: 0.751953125\n",
      "Batch: 4, Loss: 0.7097037434577942, Accuracy: 0.76953125\n",
      "Batch: 5, Loss: 0.7906681299209595, Accuracy: 0.7421875\n",
      "Batch: 6, Loss: 0.8491100072860718, Accuracy: 0.72265625\n",
      "Batch: 7, Loss: 0.8205220103263855, Accuracy: 0.7119140625\n",
      "Batch: 8, Loss: 0.7861486077308655, Accuracy: 0.73046875\n",
      "Batch: 9, Loss: 0.7696683406829834, Accuracy: 0.759765625\n",
      "Batch: 10, Loss: 0.7904480695724487, Accuracy: 0.734375\n",
      "Batch: 11, Loss: 0.8979368209838867, Accuracy: 0.6982421875\n",
      "Batch: 12, Loss: 0.8853477239608765, Accuracy: 0.7119140625\n",
      "Batch: 13, Loss: 0.6742545366287231, Accuracy: 0.771484375\n",
      "Batch: 14, Loss: 0.8862100839614868, Accuracy: 0.7109375\n",
      "Batch: 15, Loss: 0.7414835691452026, Accuracy: 0.763671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 16, Loss: 0.8249896764755249, Accuracy: 0.73828125\n",
      "Batch: 17, Loss: 0.8622421622276306, Accuracy: 0.7294921875\n",
      "Batch: 18, Loss: 0.8675432205200195, Accuracy: 0.7177734375\n",
      "Batch: 19, Loss: 0.8436685800552368, Accuracy: 0.73828125\n",
      "Batch: 20, Loss: 0.767766535282135, Accuracy: 0.7490234375\n",
      "Batch: 21, Loss: 0.7925882339477539, Accuracy: 0.73046875\n",
      "Batch: 22, Loss: 0.9015287756919861, Accuracy: 0.7080078125\n",
      "Batch: 23, Loss: 0.8540522456169128, Accuracy: 0.7060546875\n",
      "Batch: 24, Loss: 0.8731068968772888, Accuracy: 0.7060546875\n",
      "Batch: 25, Loss: 0.8306994438171387, Accuracy: 0.7265625\n",
      "Batch: 26, Loss: 0.7306434512138367, Accuracy: 0.75390625\n",
      "Batch: 27, Loss: 0.806165337562561, Accuracy: 0.72265625\n",
      "Batch: 28, Loss: 0.8449397683143616, Accuracy: 0.7255859375\n",
      "Batch: 29, Loss: 0.7847764492034912, Accuracy: 0.75390625\n",
      "Batch: 30, Loss: 0.7382060885429382, Accuracy: 0.759765625\n",
      "Batch: 31, Loss: 0.720632791519165, Accuracy: 0.77734375\n",
      "Batch: 32, Loss: 0.7624639272689819, Accuracy: 0.755859375\n",
      "Batch: 33, Loss: 0.8994290828704834, Accuracy: 0.712890625\n",
      "Batch: 34, Loss: 0.9367178082466125, Accuracy: 0.681640625\n",
      "Batch: 35, Loss: 0.8335450887680054, Accuracy: 0.7158203125\n",
      "Batch: 36, Loss: 0.8625643253326416, Accuracy: 0.7392578125\n",
      "Batch: 37, Loss: 0.8611109256744385, Accuracy: 0.7255859375\n",
      "Batch: 38, Loss: 0.8721816539764404, Accuracy: 0.7080078125\n",
      "Batch: 39, Loss: 0.871091902256012, Accuracy: 0.71875\n",
      "Batch: 40, Loss: 0.8023970127105713, Accuracy: 0.7353515625\n",
      "Batch: 41, Loss: 0.7700495719909668, Accuracy: 0.744140625\n",
      "Batch: 42, Loss: 0.6691915988922119, Accuracy: 0.77734375\n",
      "Batch: 43, Loss: 0.8629000186920166, Accuracy: 0.708984375\n",
      "Batch: 44, Loss: 0.8781493902206421, Accuracy: 0.7099609375\n",
      "Batch: 45, Loss: 0.7765359878540039, Accuracy: 0.7470703125\n",
      "Batch: 46, Loss: 0.7598152160644531, Accuracy: 0.7568359375\n",
      "Batch: 47, Loss: 0.7551266551017761, Accuracy: 0.76953125\n",
      "Batch: 48, Loss: 0.752225399017334, Accuracy: 0.7451171875\n",
      "Batch: 49, Loss: 0.8896398544311523, Accuracy: 0.6943359375\n",
      "Batch: 50, Loss: 0.8662517070770264, Accuracy: 0.7177734375\n",
      "Batch: 51, Loss: 0.8836527466773987, Accuracy: 0.7138671875\n",
      "Batch: 52, Loss: 0.8523987531661987, Accuracy: 0.7177734375\n",
      "Batch: 53, Loss: 0.7677411437034607, Accuracy: 0.7294921875\n",
      "Batch: 54, Loss: 0.8003096580505371, Accuracy: 0.75\n",
      "Batch: 55, Loss: 0.9335265159606934, Accuracy: 0.6953125\n",
      "Batch: 56, Loss: 0.8805421590805054, Accuracy: 0.712890625\n",
      "Batch: 57, Loss: 0.8455634117126465, Accuracy: 0.7216796875\n",
      "Batch: 58, Loss: 0.9560929536819458, Accuracy: 0.69921875\n",
      "Batch: 59, Loss: 0.7607824802398682, Accuracy: 0.744140625\n",
      "Batch: 60, Loss: 0.7436841130256653, Accuracy: 0.75390625\n",
      "Batch: 61, Loss: 0.8661257028579712, Accuracy: 0.716796875\n",
      "Batch: 62, Loss: 0.8114420175552368, Accuracy: 0.73828125\n",
      "Batch: 63, Loss: 0.8354734778404236, Accuracy: 0.7158203125\n",
      "Batch: 64, Loss: 0.8201169967651367, Accuracy: 0.73828125\n",
      "Batch: 65, Loss: 0.8750116229057312, Accuracy: 0.7255859375\n",
      "Batch: 66, Loss: 0.7844140529632568, Accuracy: 0.7529296875\n",
      "Batch: 67, Loss: 0.9150223731994629, Accuracy: 0.7138671875\n",
      "Batch: 68, Loss: 0.9255485534667969, Accuracy: 0.708984375\n",
      "Batch: 69, Loss: 0.8545231819152832, Accuracy: 0.7119140625\n",
      "Batch: 70, Loss: 0.815574049949646, Accuracy: 0.7451171875\n",
      "Batch: 71, Loss: 0.8553228974342346, Accuracy: 0.7109375\n",
      "Batch: 72, Loss: 0.7323444485664368, Accuracy: 0.7509765625\n",
      "Batch: 73, Loss: 0.7548534870147705, Accuracy: 0.76171875\n",
      "Batch: 74, Loss: 0.7440671920776367, Accuracy: 0.7626953125\n",
      "Batch: 75, Loss: 0.7322204113006592, Accuracy: 0.7509765625\n",
      "Batch: 76, Loss: 0.835383951663971, Accuracy: 0.720703125\n",
      "Batch: 77, Loss: 0.7836188077926636, Accuracy: 0.7412109375\n",
      "Batch: 78, Loss: 0.7201581001281738, Accuracy: 0.76953125\n",
      "Batch: 79, Loss: 0.7103815078735352, Accuracy: 0.7548828125\n",
      "Batch: 80, Loss: 0.8214879631996155, Accuracy: 0.7353515625\n",
      "Batch: 81, Loss: 0.8998228907585144, Accuracy: 0.6865234375\n",
      "Batch: 82, Loss: 0.8673515915870667, Accuracy: 0.708984375\n",
      "Batch: 83, Loss: 0.7257541418075562, Accuracy: 0.78125\n",
      "Batch: 84, Loss: 0.7885622978210449, Accuracy: 0.73828125\n",
      "Batch: 85, Loss: 0.7838655710220337, Accuracy: 0.7421875\n",
      "Batch: 86, Loss: 0.939468264579773, Accuracy: 0.70703125\n",
      "Batch: 87, Loss: 0.7777511477470398, Accuracy: 0.763671875\n",
      "Batch: 88, Loss: 0.871432900428772, Accuracy: 0.7197265625\n",
      "Batch: 89, Loss: 0.8497535586357117, Accuracy: 0.7353515625\n",
      "Batch: 90, Loss: 0.7643563747406006, Accuracy: 0.7607421875\n",
      "Batch: 91, Loss: 0.791765570640564, Accuracy: 0.728515625\n",
      "Batch: 92, Loss: 0.8425121307373047, Accuracy: 0.720703125\n",
      "Batch: 93, Loss: 0.7873803973197937, Accuracy: 0.736328125\n",
      "Batch: 94, Loss: 0.8104780912399292, Accuracy: 0.71484375\n",
      "Batch: 95, Loss: 0.8792057037353516, Accuracy: 0.6826171875\n",
      "Batch: 96, Loss: 0.8233957290649414, Accuracy: 0.736328125\n",
      "Batch: 97, Loss: 0.6797624230384827, Accuracy: 0.7763671875\n",
      "Batch: 98, Loss: 0.7788254022598267, Accuracy: 0.755859375\n",
      "Batch: 99, Loss: 0.8008242845535278, Accuracy: 0.744140625\n",
      "Batch: 100, Loss: 0.7925261855125427, Accuracy: 0.7353515625\n",
      "Batch: 101, Loss: 0.8695460557937622, Accuracy: 0.71875\n",
      "Batch: 102, Loss: 0.8081128597259521, Accuracy: 0.740234375\n",
      "Batch: 103, Loss: 0.8594390153884888, Accuracy: 0.7197265625\n",
      "Batch: 104, Loss: 0.757564902305603, Accuracy: 0.734375\n",
      "Batch: 105, Loss: 0.8365927338600159, Accuracy: 0.7353515625\n",
      "Batch: 106, Loss: 0.783521294593811, Accuracy: 0.75\n",
      "Batch: 107, Loss: 0.8455402851104736, Accuracy: 0.734375\n",
      "Batch: 108, Loss: 0.8239100575447083, Accuracy: 0.7294921875\n",
      "Batch: 109, Loss: 0.9443156719207764, Accuracy: 0.693359375\n",
      "Batch: 110, Loss: 0.7271227836608887, Accuracy: 0.7626953125\n",
      "Batch: 111, Loss: 0.8836573362350464, Accuracy: 0.7080078125\n",
      "Batch: 112, Loss: 0.8105359673500061, Accuracy: 0.75\n",
      "Batch: 113, Loss: 0.8267456293106079, Accuracy: 0.71875\n",
      "Batch: 114, Loss: 0.9116269946098328, Accuracy: 0.71484375\n",
      "Batch: 115, Loss: 0.9284132719039917, Accuracy: 0.71484375\n",
      "Batch: 116, Loss: 0.859689474105835, Accuracy: 0.73046875\n",
      "Batch: 117, Loss: 0.8583562970161438, Accuracy: 0.732421875\n",
      "Batch: 118, Loss: 0.7311402559280396, Accuracy: 0.771484375\n",
      "Batch: 119, Loss: 0.716655969619751, Accuracy: 0.7626953125\n",
      "Batch: 120, Loss: 0.8740648627281189, Accuracy: 0.708984375\n",
      "Batch: 121, Loss: 0.8432547450065613, Accuracy: 0.7197265625\n",
      "Batch: 122, Loss: 0.7632471323013306, Accuracy: 0.7607421875\n",
      "Batch: 123, Loss: 0.739824116230011, Accuracy: 0.7470703125\n",
      "Batch: 124, Loss: 0.81231290102005, Accuracy: 0.73046875\n",
      "Batch: 125, Loss: 0.8803153038024902, Accuracy: 0.71484375\n",
      "Batch: 126, Loss: 0.8379973769187927, Accuracy: 0.7275390625\n",
      "Batch: 127, Loss: 0.7711970210075378, Accuracy: 0.7685546875\n",
      "Batch: 128, Loss: 0.9194751977920532, Accuracy: 0.7216796875\n",
      "Batch: 129, Loss: 0.759164035320282, Accuracy: 0.7451171875\n",
      "Batch: 130, Loss: 0.9270464181900024, Accuracy: 0.6943359375\n",
      "Batch: 131, Loss: 0.8165139555931091, Accuracy: 0.7197265625\n",
      "Batch: 132, Loss: 0.8510189056396484, Accuracy: 0.72265625\n",
      "Batch: 133, Loss: 0.7671077847480774, Accuracy: 0.7529296875\n",
      "Batch: 134, Loss: 0.8362764716148376, Accuracy: 0.7216796875\n",
      "Batch: 135, Loss: 0.7448628544807434, Accuracy: 0.7626953125\n",
      "Batch: 136, Loss: 0.8257514834403992, Accuracy: 0.72265625\n",
      "Batch: 137, Loss: 0.8445645570755005, Accuracy: 0.712890625\n",
      "Batch: 138, Loss: 0.7102676630020142, Accuracy: 0.76171875\n",
      "Batch: 139, Loss: 0.7896673679351807, Accuracy: 0.72265625\n",
      "Batch: 140, Loss: 0.8431743383407593, Accuracy: 0.7197265625\n",
      "Batch: 141, Loss: 0.8501989245414734, Accuracy: 0.72265625\n",
      "Batch: 142, Loss: 0.9105120897293091, Accuracy: 0.712890625\n",
      "Batch: 143, Loss: 0.8266321420669556, Accuracy: 0.7255859375\n",
      "Batch: 144, Loss: 0.8418766260147095, Accuracy: 0.73046875\n",
      "Batch: 145, Loss: 0.781667172908783, Accuracy: 0.734375\n",
      "Batch: 146, Loss: 0.8815341591835022, Accuracy: 0.7109375\n",
      "Batch: 147, Loss: 0.8279194831848145, Accuracy: 0.7158203125\n",
      "Batch: 148, Loss: 0.9469935297966003, Accuracy: 0.66796875\n",
      "Batch: 149, Loss: 0.792081356048584, Accuracy: 0.73828125\n",
      "Batch: 150, Loss: 0.8195874094963074, Accuracy: 0.732421875\n",
      "Batch: 151, Loss: 0.7086251974105835, Accuracy: 0.7734375\n",
      "Epoch 45/80\n",
      "Batch: 1, Loss: 1.0682355165481567, Accuracy: 0.6650390625\n",
      "Batch: 2, Loss: 0.9304375648498535, Accuracy: 0.6767578125\n",
      "Batch: 3, Loss: 0.7920056581497192, Accuracy: 0.734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 4, Loss: 0.7058931589126587, Accuracy: 0.7744140625\n",
      "Batch: 5, Loss: 0.8255248069763184, Accuracy: 0.7412109375\n",
      "Batch: 6, Loss: 0.8253676891326904, Accuracy: 0.732421875\n",
      "Batch: 7, Loss: 0.8016893863677979, Accuracy: 0.7216796875\n",
      "Batch: 8, Loss: 0.7961046695709229, Accuracy: 0.732421875\n",
      "Batch: 9, Loss: 0.759324312210083, Accuracy: 0.755859375\n",
      "Batch: 10, Loss: 0.7875276803970337, Accuracy: 0.7333984375\n",
      "Batch: 11, Loss: 0.8951218128204346, Accuracy: 0.7001953125\n",
      "Batch: 12, Loss: 0.8787176012992859, Accuracy: 0.7001953125\n",
      "Batch: 13, Loss: 0.6853713393211365, Accuracy: 0.7587890625\n",
      "Batch: 14, Loss: 0.8975350260734558, Accuracy: 0.69140625\n",
      "Batch: 15, Loss: 0.7597100734710693, Accuracy: 0.7685546875\n",
      "Batch: 16, Loss: 0.7910229563713074, Accuracy: 0.7451171875\n",
      "Batch: 17, Loss: 0.8635476231575012, Accuracy: 0.716796875\n",
      "Batch: 18, Loss: 0.855802059173584, Accuracy: 0.720703125\n",
      "Batch: 19, Loss: 0.8653768301010132, Accuracy: 0.7314453125\n",
      "Batch: 20, Loss: 0.7239731550216675, Accuracy: 0.7607421875\n",
      "Batch: 21, Loss: 0.7581239938735962, Accuracy: 0.73828125\n",
      "Batch: 22, Loss: 0.8943027257919312, Accuracy: 0.7138671875\n",
      "Batch: 23, Loss: 0.8192094564437866, Accuracy: 0.724609375\n",
      "Batch: 24, Loss: 0.8619096279144287, Accuracy: 0.7119140625\n",
      "Batch: 25, Loss: 0.8322515487670898, Accuracy: 0.7236328125\n",
      "Batch: 26, Loss: 0.7278976440429688, Accuracy: 0.75\n",
      "Batch: 27, Loss: 0.7805036306381226, Accuracy: 0.744140625\n",
      "Batch: 28, Loss: 0.8523684740066528, Accuracy: 0.71875\n",
      "Batch: 29, Loss: 0.7892230749130249, Accuracy: 0.7392578125\n",
      "Batch: 30, Loss: 0.7242289185523987, Accuracy: 0.7666015625\n",
      "Batch: 31, Loss: 0.7004044055938721, Accuracy: 0.7744140625\n",
      "Batch: 32, Loss: 0.7422725558280945, Accuracy: 0.755859375\n",
      "Batch: 33, Loss: 0.8879508972167969, Accuracy: 0.7197265625\n",
      "Batch: 34, Loss: 0.9403111934661865, Accuracy: 0.6904296875\n",
      "Batch: 35, Loss: 0.8528048992156982, Accuracy: 0.7197265625\n",
      "Batch: 36, Loss: 0.8765264749526978, Accuracy: 0.724609375\n",
      "Batch: 37, Loss: 0.8152790069580078, Accuracy: 0.7421875\n",
      "Batch: 38, Loss: 0.8645612001419067, Accuracy: 0.7119140625\n",
      "Batch: 39, Loss: 0.8315055966377258, Accuracy: 0.728515625\n",
      "Batch: 40, Loss: 0.8333715796470642, Accuracy: 0.7265625\n",
      "Batch: 41, Loss: 0.7635296583175659, Accuracy: 0.7431640625\n",
      "Batch: 42, Loss: 0.6499201655387878, Accuracy: 0.775390625\n",
      "Batch: 43, Loss: 0.8573319911956787, Accuracy: 0.7177734375\n",
      "Batch: 44, Loss: 0.8563750386238098, Accuracy: 0.7109375\n",
      "Batch: 45, Loss: 0.7678850889205933, Accuracy: 0.7333984375\n",
      "Batch: 46, Loss: 0.7451956868171692, Accuracy: 0.7705078125\n",
      "Batch: 47, Loss: 0.7553021311759949, Accuracy: 0.75390625\n",
      "Batch: 48, Loss: 0.7339643239974976, Accuracy: 0.7587890625\n",
      "Batch: 49, Loss: 0.8755497932434082, Accuracy: 0.7197265625\n",
      "Batch: 50, Loss: 0.8541602492332458, Accuracy: 0.705078125\n",
      "Batch: 51, Loss: 0.8885824084281921, Accuracy: 0.705078125\n",
      "Batch: 52, Loss: 0.8343280553817749, Accuracy: 0.7119140625\n",
      "Batch: 53, Loss: 0.7881207466125488, Accuracy: 0.744140625\n",
      "Batch: 54, Loss: 0.8303526043891907, Accuracy: 0.7275390625\n",
      "Batch: 55, Loss: 0.9400721788406372, Accuracy: 0.6923828125\n",
      "Batch: 56, Loss: 0.8821761012077332, Accuracy: 0.72265625\n",
      "Batch: 57, Loss: 0.8324823379516602, Accuracy: 0.7275390625\n",
      "Batch: 58, Loss: 0.9504234790802002, Accuracy: 0.7041015625\n",
      "Batch: 59, Loss: 0.779556930065155, Accuracy: 0.7509765625\n",
      "Batch: 60, Loss: 0.7332242131233215, Accuracy: 0.76953125\n",
      "Batch: 61, Loss: 0.852954626083374, Accuracy: 0.732421875\n",
      "Batch: 62, Loss: 0.7939913272857666, Accuracy: 0.7412109375\n",
      "Batch: 63, Loss: 0.8425981998443604, Accuracy: 0.724609375\n",
      "Batch: 64, Loss: 0.8090300559997559, Accuracy: 0.7392578125\n",
      "Batch: 65, Loss: 0.8534107804298401, Accuracy: 0.7197265625\n",
      "Batch: 66, Loss: 0.789441704750061, Accuracy: 0.73828125\n",
      "Batch: 67, Loss: 0.9105075597763062, Accuracy: 0.7138671875\n",
      "Batch: 68, Loss: 0.9317311644554138, Accuracy: 0.7119140625\n",
      "Batch: 69, Loss: 0.8498445749282837, Accuracy: 0.7236328125\n",
      "Batch: 70, Loss: 0.830960214138031, Accuracy: 0.7431640625\n",
      "Batch: 71, Loss: 0.8307189345359802, Accuracy: 0.7216796875\n",
      "Batch: 72, Loss: 0.7358959317207336, Accuracy: 0.7568359375\n",
      "Batch: 73, Loss: 0.7625473141670227, Accuracy: 0.7568359375\n",
      "Batch: 74, Loss: 0.7265655398368835, Accuracy: 0.7744140625\n",
      "Batch: 75, Loss: 0.7268015146255493, Accuracy: 0.7685546875\n",
      "Batch: 76, Loss: 0.8481151461601257, Accuracy: 0.71875\n",
      "Batch: 77, Loss: 0.783557653427124, Accuracy: 0.7509765625\n",
      "Batch: 78, Loss: 0.7441981434822083, Accuracy: 0.759765625\n",
      "Batch: 79, Loss: 0.7052707672119141, Accuracy: 0.771484375\n",
      "Batch: 80, Loss: 0.7923223972320557, Accuracy: 0.740234375\n",
      "Batch: 81, Loss: 0.8958985209465027, Accuracy: 0.6962890625\n",
      "Batch: 82, Loss: 0.8235793113708496, Accuracy: 0.7197265625\n",
      "Batch: 83, Loss: 0.7116498947143555, Accuracy: 0.78125\n",
      "Batch: 84, Loss: 0.7752512693405151, Accuracy: 0.73828125\n",
      "Batch: 85, Loss: 0.7623212337493896, Accuracy: 0.76171875\n",
      "Batch: 86, Loss: 0.9095977544784546, Accuracy: 0.7158203125\n",
      "Batch: 87, Loss: 0.7628679871559143, Accuracy: 0.7626953125\n",
      "Batch: 88, Loss: 0.8332539796829224, Accuracy: 0.7314453125\n",
      "Batch: 89, Loss: 0.8660440444946289, Accuracy: 0.728515625\n",
      "Batch: 90, Loss: 0.7939426898956299, Accuracy: 0.75\n",
      "Batch: 91, Loss: 0.7765153646469116, Accuracy: 0.7255859375\n",
      "Batch: 92, Loss: 0.8555874824523926, Accuracy: 0.7109375\n",
      "Batch: 93, Loss: 0.836225152015686, Accuracy: 0.7197265625\n",
      "Batch: 94, Loss: 0.8100576400756836, Accuracy: 0.73046875\n",
      "Batch: 95, Loss: 0.8464337587356567, Accuracy: 0.712890625\n",
      "Batch: 96, Loss: 0.7885733842849731, Accuracy: 0.7333984375\n",
      "Batch: 97, Loss: 0.6440988779067993, Accuracy: 0.783203125\n",
      "Batch: 98, Loss: 0.7646945714950562, Accuracy: 0.744140625\n",
      "Batch: 99, Loss: 0.7659785747528076, Accuracy: 0.7421875\n",
      "Batch: 100, Loss: 0.8202037215232849, Accuracy: 0.73046875\n",
      "Batch: 101, Loss: 0.8282065987586975, Accuracy: 0.734375\n",
      "Batch: 102, Loss: 0.826862096786499, Accuracy: 0.7392578125\n",
      "Batch: 103, Loss: 0.8146326541900635, Accuracy: 0.7412109375\n",
      "Batch: 104, Loss: 0.7541017532348633, Accuracy: 0.7431640625\n",
      "Batch: 105, Loss: 0.8482488393783569, Accuracy: 0.7158203125\n",
      "Batch: 106, Loss: 0.7810736894607544, Accuracy: 0.740234375\n",
      "Batch: 107, Loss: 0.8374984264373779, Accuracy: 0.73046875\n",
      "Batch: 108, Loss: 0.8296394348144531, Accuracy: 0.7216796875\n",
      "Batch: 109, Loss: 0.9513101577758789, Accuracy: 0.6806640625\n",
      "Batch: 110, Loss: 0.7382737398147583, Accuracy: 0.751953125\n",
      "Batch: 111, Loss: 0.8630602359771729, Accuracy: 0.7080078125\n",
      "Batch: 112, Loss: 0.8086745738983154, Accuracy: 0.7392578125\n",
      "Batch: 113, Loss: 0.832722544670105, Accuracy: 0.7333984375\n",
      "Batch: 114, Loss: 0.8923811912536621, Accuracy: 0.7177734375\n",
      "Batch: 115, Loss: 0.9361627697944641, Accuracy: 0.7060546875\n",
      "Batch: 116, Loss: 0.8345390558242798, Accuracy: 0.732421875\n",
      "Batch: 117, Loss: 0.8702447414398193, Accuracy: 0.71875\n",
      "Batch: 118, Loss: 0.7617117166519165, Accuracy: 0.7548828125\n",
      "Batch: 119, Loss: 0.6844819784164429, Accuracy: 0.7744140625\n",
      "Batch: 120, Loss: 0.8362246751785278, Accuracy: 0.72265625\n",
      "Batch: 121, Loss: 0.8762410283088684, Accuracy: 0.7109375\n",
      "Batch: 122, Loss: 0.7771026492118835, Accuracy: 0.748046875\n",
      "Batch: 123, Loss: 0.7548336982727051, Accuracy: 0.7529296875\n",
      "Batch: 124, Loss: 0.7917008399963379, Accuracy: 0.72265625\n",
      "Batch: 125, Loss: 0.8511132597923279, Accuracy: 0.71484375\n",
      "Batch: 126, Loss: 0.8170523643493652, Accuracy: 0.728515625\n",
      "Batch: 127, Loss: 0.7328553795814514, Accuracy: 0.7578125\n",
      "Batch: 128, Loss: 0.9205315113067627, Accuracy: 0.7099609375\n",
      "Batch: 129, Loss: 0.7547621726989746, Accuracy: 0.7548828125\n",
      "Batch: 130, Loss: 0.9318599700927734, Accuracy: 0.6982421875\n",
      "Batch: 131, Loss: 0.8046256303787231, Accuracy: 0.7314453125\n",
      "Batch: 132, Loss: 0.8424944877624512, Accuracy: 0.7109375\n",
      "Batch: 133, Loss: 0.8057430982589722, Accuracy: 0.734375\n",
      "Batch: 134, Loss: 0.8300741910934448, Accuracy: 0.7197265625\n",
      "Batch: 135, Loss: 0.7329179048538208, Accuracy: 0.7548828125\n",
      "Batch: 136, Loss: 0.812242865562439, Accuracy: 0.7353515625\n",
      "Batch: 137, Loss: 0.8229597210884094, Accuracy: 0.7197265625\n",
      "Batch: 138, Loss: 0.7144596576690674, Accuracy: 0.771484375\n",
      "Batch: 139, Loss: 0.7658733129501343, Accuracy: 0.740234375\n",
      "Batch: 140, Loss: 0.8022313117980957, Accuracy: 0.720703125\n",
      "Batch: 141, Loss: 0.8477755784988403, Accuracy: 0.716796875\n",
      "Batch: 142, Loss: 0.8811135292053223, Accuracy: 0.724609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 143, Loss: 0.8415189981460571, Accuracy: 0.7197265625\n",
      "Batch: 144, Loss: 0.8265969157218933, Accuracy: 0.7255859375\n",
      "Batch: 145, Loss: 0.7435566186904907, Accuracy: 0.7373046875\n",
      "Batch: 146, Loss: 0.8482779860496521, Accuracy: 0.724609375\n",
      "Batch: 147, Loss: 0.8345634937286377, Accuracy: 0.72265625\n",
      "Batch: 148, Loss: 0.9161922931671143, Accuracy: 0.685546875\n",
      "Batch: 149, Loss: 0.8184617757797241, Accuracy: 0.724609375\n",
      "Batch: 150, Loss: 0.806885838508606, Accuracy: 0.734375\n",
      "Batch: 151, Loss: 0.7144584655761719, Accuracy: 0.755859375\n",
      "Epoch 46/80\n",
      "Batch: 1, Loss: 1.0563817024230957, Accuracy: 0.6513671875\n",
      "Batch: 2, Loss: 0.9144810438156128, Accuracy: 0.6787109375\n",
      "Batch: 3, Loss: 0.797752857208252, Accuracy: 0.736328125\n",
      "Batch: 4, Loss: 0.7052714824676514, Accuracy: 0.7646484375\n",
      "Batch: 5, Loss: 0.7961287498474121, Accuracy: 0.7392578125\n",
      "Batch: 6, Loss: 0.8272427320480347, Accuracy: 0.7373046875\n",
      "Batch: 7, Loss: 0.835091233253479, Accuracy: 0.712890625\n",
      "Batch: 8, Loss: 0.7560483813285828, Accuracy: 0.74609375\n",
      "Batch: 9, Loss: 0.7493298053741455, Accuracy: 0.759765625\n",
      "Batch: 10, Loss: 0.7807356715202332, Accuracy: 0.736328125\n",
      "Batch: 11, Loss: 0.9074592590332031, Accuracy: 0.6962890625\n",
      "Batch: 12, Loss: 0.8708937168121338, Accuracy: 0.712890625\n",
      "Batch: 13, Loss: 0.6738442778587341, Accuracy: 0.7744140625\n",
      "Batch: 14, Loss: 0.9207032918930054, Accuracy: 0.6923828125\n",
      "Batch: 15, Loss: 0.7521072030067444, Accuracy: 0.7626953125\n",
      "Batch: 16, Loss: 0.7888947129249573, Accuracy: 0.755859375\n",
      "Batch: 17, Loss: 0.8586223125457764, Accuracy: 0.7138671875\n",
      "Batch: 18, Loss: 0.8622422814369202, Accuracy: 0.728515625\n",
      "Batch: 19, Loss: 0.8786238431930542, Accuracy: 0.720703125\n",
      "Batch: 20, Loss: 0.7380075454711914, Accuracy: 0.7529296875\n",
      "Batch: 21, Loss: 0.7821156978607178, Accuracy: 0.7509765625\n",
      "Batch: 22, Loss: 0.8841176629066467, Accuracy: 0.7109375\n",
      "Batch: 23, Loss: 0.8271671533584595, Accuracy: 0.71875\n",
      "Batch: 24, Loss: 0.8425354957580566, Accuracy: 0.7119140625\n",
      "Batch: 25, Loss: 0.8072790503501892, Accuracy: 0.73046875\n",
      "Batch: 26, Loss: 0.7095552682876587, Accuracy: 0.74609375\n",
      "Batch: 27, Loss: 0.7642209529876709, Accuracy: 0.7431640625\n",
      "Batch: 28, Loss: 0.8300257921218872, Accuracy: 0.7255859375\n",
      "Batch: 29, Loss: 0.770523190498352, Accuracy: 0.732421875\n",
      "Batch: 30, Loss: 0.7052891254425049, Accuracy: 0.771484375\n",
      "Batch: 31, Loss: 0.7037632465362549, Accuracy: 0.78125\n",
      "Batch: 32, Loss: 0.7816410660743713, Accuracy: 0.7451171875\n",
      "Batch: 33, Loss: 0.8743072748184204, Accuracy: 0.7275390625\n",
      "Batch: 34, Loss: 0.9492406845092773, Accuracy: 0.685546875\n",
      "Batch: 35, Loss: 0.8401223421096802, Accuracy: 0.71875\n",
      "Batch: 36, Loss: 0.8492314219474792, Accuracy: 0.73828125\n",
      "Batch: 37, Loss: 0.8043613433837891, Accuracy: 0.736328125\n",
      "Batch: 38, Loss: 0.8459540009498596, Accuracy: 0.7294921875\n",
      "Batch: 39, Loss: 0.8319351077079773, Accuracy: 0.724609375\n",
      "Batch: 40, Loss: 0.8165881633758545, Accuracy: 0.72265625\n",
      "Batch: 41, Loss: 0.7662734985351562, Accuracy: 0.7529296875\n",
      "Batch: 42, Loss: 0.6516664624214172, Accuracy: 0.7744140625\n",
      "Batch: 43, Loss: 0.8589978814125061, Accuracy: 0.71484375\n",
      "Batch: 44, Loss: 0.821760892868042, Accuracy: 0.7373046875\n",
      "Batch: 45, Loss: 0.7540433406829834, Accuracy: 0.734375\n",
      "Batch: 46, Loss: 0.7699077129364014, Accuracy: 0.763671875\n",
      "Batch: 47, Loss: 0.7488606572151184, Accuracy: 0.7578125\n",
      "Batch: 48, Loss: 0.7248601913452148, Accuracy: 0.759765625\n",
      "Batch: 49, Loss: 0.8825592994689941, Accuracy: 0.705078125\n",
      "Batch: 50, Loss: 0.8618935346603394, Accuracy: 0.7021484375\n",
      "Batch: 51, Loss: 0.8840672969818115, Accuracy: 0.7041015625\n",
      "Batch: 52, Loss: 0.8448402881622314, Accuracy: 0.7314453125\n",
      "Batch: 53, Loss: 0.7868045568466187, Accuracy: 0.7216796875\n",
      "Batch: 54, Loss: 0.812545895576477, Accuracy: 0.7333984375\n",
      "Batch: 55, Loss: 0.9231866002082825, Accuracy: 0.677734375\n",
      "Batch: 56, Loss: 0.8926230669021606, Accuracy: 0.69921875\n",
      "Batch: 57, Loss: 0.8386096358299255, Accuracy: 0.7275390625\n",
      "Batch: 58, Loss: 0.9230562448501587, Accuracy: 0.712890625\n",
      "Batch: 59, Loss: 0.7561711072921753, Accuracy: 0.755859375\n",
      "Batch: 60, Loss: 0.7426390647888184, Accuracy: 0.7685546875\n",
      "Batch: 61, Loss: 0.8439573645591736, Accuracy: 0.73046875\n",
      "Batch: 62, Loss: 0.7849112749099731, Accuracy: 0.7392578125\n",
      "Batch: 63, Loss: 0.825745701789856, Accuracy: 0.7333984375\n",
      "Batch: 64, Loss: 0.8101169466972351, Accuracy: 0.732421875\n",
      "Batch: 65, Loss: 0.8301505446434021, Accuracy: 0.73828125\n",
      "Batch: 66, Loss: 0.800503671169281, Accuracy: 0.7607421875\n",
      "Batch: 67, Loss: 0.8990719318389893, Accuracy: 0.7265625\n",
      "Batch: 68, Loss: 0.932945191860199, Accuracy: 0.7119140625\n",
      "Batch: 69, Loss: 0.8492857217788696, Accuracy: 0.7255859375\n",
      "Batch: 70, Loss: 0.8365060091018677, Accuracy: 0.7353515625\n",
      "Batch: 71, Loss: 0.8532668352127075, Accuracy: 0.703125\n",
      "Batch: 72, Loss: 0.7295632362365723, Accuracy: 0.7490234375\n",
      "Batch: 73, Loss: 0.7448369264602661, Accuracy: 0.775390625\n",
      "Batch: 74, Loss: 0.7152248620986938, Accuracy: 0.7734375\n",
      "Batch: 75, Loss: 0.7305949926376343, Accuracy: 0.7578125\n",
      "Batch: 76, Loss: 0.817391037940979, Accuracy: 0.7353515625\n",
      "Batch: 77, Loss: 0.810310423374176, Accuracy: 0.7373046875\n",
      "Batch: 78, Loss: 0.7195636034011841, Accuracy: 0.7705078125\n",
      "Batch: 79, Loss: 0.6822668313980103, Accuracy: 0.779296875\n",
      "Batch: 80, Loss: 0.7757658362388611, Accuracy: 0.734375\n",
      "Batch: 81, Loss: 0.8884221911430359, Accuracy: 0.685546875\n",
      "Batch: 82, Loss: 0.8248586654663086, Accuracy: 0.7236328125\n",
      "Batch: 83, Loss: 0.696946382522583, Accuracy: 0.78515625\n",
      "Batch: 84, Loss: 0.7512550354003906, Accuracy: 0.7587890625\n",
      "Batch: 85, Loss: 0.743880033493042, Accuracy: 0.7578125\n",
      "Batch: 86, Loss: 0.8989458084106445, Accuracy: 0.712890625\n",
      "Batch: 87, Loss: 0.7453995943069458, Accuracy: 0.765625\n",
      "Batch: 88, Loss: 0.8791525363922119, Accuracy: 0.7138671875\n",
      "Batch: 89, Loss: 0.8268303275108337, Accuracy: 0.728515625\n",
      "Batch: 90, Loss: 0.774855375289917, Accuracy: 0.7548828125\n",
      "Batch: 91, Loss: 0.7752594947814941, Accuracy: 0.7431640625\n",
      "Batch: 92, Loss: 0.8610669374465942, Accuracy: 0.712890625\n",
      "Batch: 93, Loss: 0.7889000177383423, Accuracy: 0.7431640625\n",
      "Batch: 94, Loss: 0.8025246858596802, Accuracy: 0.7265625\n",
      "Batch: 95, Loss: 0.8441115617752075, Accuracy: 0.70703125\n",
      "Batch: 96, Loss: 0.7672899961471558, Accuracy: 0.75\n",
      "Batch: 97, Loss: 0.6814982891082764, Accuracy: 0.759765625\n",
      "Batch: 98, Loss: 0.7621450424194336, Accuracy: 0.7568359375\n",
      "Batch: 99, Loss: 0.7967594861984253, Accuracy: 0.7431640625\n",
      "Batch: 100, Loss: 0.815506100654602, Accuracy: 0.7392578125\n",
      "Batch: 101, Loss: 0.8431175351142883, Accuracy: 0.7275390625\n",
      "Batch: 102, Loss: 0.8261755704879761, Accuracy: 0.7373046875\n",
      "Batch: 103, Loss: 0.8309813141822815, Accuracy: 0.7412109375\n",
      "Batch: 104, Loss: 0.7616548538208008, Accuracy: 0.7353515625\n",
      "Batch: 105, Loss: 0.8432261347770691, Accuracy: 0.720703125\n",
      "Batch: 106, Loss: 0.7656663060188293, Accuracy: 0.7431640625\n",
      "Batch: 107, Loss: 0.8060384392738342, Accuracy: 0.751953125\n",
      "Batch: 108, Loss: 0.8380840420722961, Accuracy: 0.71484375\n",
      "Batch: 109, Loss: 0.937526285648346, Accuracy: 0.69921875\n",
      "Batch: 110, Loss: 0.7451908588409424, Accuracy: 0.7548828125\n",
      "Batch: 111, Loss: 0.8373381495475769, Accuracy: 0.7314453125\n",
      "Batch: 112, Loss: 0.7909514904022217, Accuracy: 0.751953125\n",
      "Batch: 113, Loss: 0.8012486696243286, Accuracy: 0.74609375\n",
      "Batch: 114, Loss: 0.8992995023727417, Accuracy: 0.71484375\n",
      "Batch: 115, Loss: 0.8992028832435608, Accuracy: 0.7119140625\n",
      "Batch: 116, Loss: 0.8546195030212402, Accuracy: 0.736328125\n",
      "Batch: 117, Loss: 0.8512352705001831, Accuracy: 0.7314453125\n",
      "Batch: 118, Loss: 0.7195609211921692, Accuracy: 0.7646484375\n",
      "Batch: 119, Loss: 0.7151188254356384, Accuracy: 0.7685546875\n",
      "Batch: 120, Loss: 0.8255854845046997, Accuracy: 0.7060546875\n",
      "Batch: 121, Loss: 0.881830096244812, Accuracy: 0.703125\n",
      "Batch: 122, Loss: 0.7578836679458618, Accuracy: 0.7509765625\n",
      "Batch: 123, Loss: 0.7399121522903442, Accuracy: 0.771484375\n",
      "Batch: 124, Loss: 0.8214020133018494, Accuracy: 0.7333984375\n",
      "Batch: 125, Loss: 0.8794363737106323, Accuracy: 0.7109375\n",
      "Batch: 126, Loss: 0.8295168876647949, Accuracy: 0.73828125\n",
      "Batch: 127, Loss: 0.7209137678146362, Accuracy: 0.7666015625\n",
      "Batch: 128, Loss: 0.9124802350997925, Accuracy: 0.7216796875\n",
      "Batch: 129, Loss: 0.7718620300292969, Accuracy: 0.736328125\n",
      "Batch: 130, Loss: 0.9168235659599304, Accuracy: 0.701171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 131, Loss: 0.8060451745986938, Accuracy: 0.720703125\n",
      "Batch: 132, Loss: 0.8746320009231567, Accuracy: 0.720703125\n",
      "Batch: 133, Loss: 0.7711077928543091, Accuracy: 0.7392578125\n",
      "Batch: 134, Loss: 0.8243008852005005, Accuracy: 0.712890625\n",
      "Batch: 135, Loss: 0.7379308938980103, Accuracy: 0.748046875\n",
      "Batch: 136, Loss: 0.7975523471832275, Accuracy: 0.73046875\n",
      "Batch: 137, Loss: 0.8071776628494263, Accuracy: 0.72265625\n",
      "Batch: 138, Loss: 0.6900380253791809, Accuracy: 0.7705078125\n",
      "Batch: 139, Loss: 0.7744008898735046, Accuracy: 0.7353515625\n",
      "Batch: 140, Loss: 0.7905046939849854, Accuracy: 0.74609375\n",
      "Batch: 141, Loss: 0.845670223236084, Accuracy: 0.7236328125\n",
      "Batch: 142, Loss: 0.8666321635246277, Accuracy: 0.7080078125\n",
      "Batch: 143, Loss: 0.7914735078811646, Accuracy: 0.7294921875\n",
      "Batch: 144, Loss: 0.7886682152748108, Accuracy: 0.736328125\n",
      "Batch: 145, Loss: 0.7945836782455444, Accuracy: 0.734375\n",
      "Batch: 146, Loss: 0.8791046142578125, Accuracy: 0.70703125\n",
      "Batch: 147, Loss: 0.8322629332542419, Accuracy: 0.7216796875\n",
      "Batch: 148, Loss: 0.9240999817848206, Accuracy: 0.6884765625\n",
      "Batch: 149, Loss: 0.7757099866867065, Accuracy: 0.7353515625\n",
      "Batch: 150, Loss: 0.800981879234314, Accuracy: 0.73828125\n",
      "Batch: 151, Loss: 0.7476349472999573, Accuracy: 0.74609375\n",
      "Epoch 47/80\n",
      "Batch: 1, Loss: 1.043971061706543, Accuracy: 0.67578125\n",
      "Batch: 2, Loss: 0.8985288739204407, Accuracy: 0.689453125\n",
      "Batch: 3, Loss: 0.7788604497909546, Accuracy: 0.73828125\n",
      "Batch: 4, Loss: 0.6868319511413574, Accuracy: 0.771484375\n",
      "Batch: 5, Loss: 0.7936128973960876, Accuracy: 0.7470703125\n",
      "Batch: 6, Loss: 0.8292927742004395, Accuracy: 0.71875\n",
      "Batch: 7, Loss: 0.7963078022003174, Accuracy: 0.7314453125\n",
      "Batch: 8, Loss: 0.7505542635917664, Accuracy: 0.75390625\n",
      "Batch: 9, Loss: 0.7573409080505371, Accuracy: 0.75\n",
      "Batch: 10, Loss: 0.7729277610778809, Accuracy: 0.74609375\n",
      "Batch: 11, Loss: 0.8746946454048157, Accuracy: 0.705078125\n",
      "Batch: 12, Loss: 0.8897340297698975, Accuracy: 0.7080078125\n",
      "Batch: 13, Loss: 0.6656653881072998, Accuracy: 0.7802734375\n",
      "Batch: 14, Loss: 0.8850692510604858, Accuracy: 0.7197265625\n",
      "Batch: 15, Loss: 0.7134615182876587, Accuracy: 0.7744140625\n",
      "Batch: 16, Loss: 0.8029533624649048, Accuracy: 0.7431640625\n",
      "Batch: 17, Loss: 0.8155992031097412, Accuracy: 0.7333984375\n",
      "Batch: 18, Loss: 0.8805587291717529, Accuracy: 0.708984375\n",
      "Batch: 19, Loss: 0.8187438249588013, Accuracy: 0.732421875\n",
      "Batch: 20, Loss: 0.7092530727386475, Accuracy: 0.7734375\n",
      "Batch: 21, Loss: 0.782943606376648, Accuracy: 0.7451171875\n",
      "Batch: 22, Loss: 0.8937290906906128, Accuracy: 0.7333984375\n",
      "Batch: 23, Loss: 0.814803957939148, Accuracy: 0.734375\n",
      "Batch: 24, Loss: 0.8337805867195129, Accuracy: 0.7177734375\n",
      "Batch: 25, Loss: 0.788668692111969, Accuracy: 0.7392578125\n",
      "Batch: 26, Loss: 0.6995220184326172, Accuracy: 0.7666015625\n",
      "Batch: 27, Loss: 0.7305415868759155, Accuracy: 0.759765625\n",
      "Batch: 28, Loss: 0.826770544052124, Accuracy: 0.7099609375\n",
      "Batch: 29, Loss: 0.7631211876869202, Accuracy: 0.7470703125\n",
      "Batch: 30, Loss: 0.6988648176193237, Accuracy: 0.7763671875\n",
      "Batch: 31, Loss: 0.6991218328475952, Accuracy: 0.7685546875\n",
      "Batch: 32, Loss: 0.7426646947860718, Accuracy: 0.7509765625\n",
      "Batch: 33, Loss: 0.8479704260826111, Accuracy: 0.7314453125\n",
      "Batch: 34, Loss: 0.8938487768173218, Accuracy: 0.7119140625\n",
      "Batch: 35, Loss: 0.8104133605957031, Accuracy: 0.7255859375\n",
      "Batch: 36, Loss: 0.8364040851593018, Accuracy: 0.734375\n",
      "Batch: 37, Loss: 0.8234223127365112, Accuracy: 0.7333984375\n",
      "Batch: 38, Loss: 0.8367488384246826, Accuracy: 0.712890625\n",
      "Batch: 39, Loss: 0.8319023847579956, Accuracy: 0.7109375\n",
      "Batch: 40, Loss: 0.8186849355697632, Accuracy: 0.736328125\n",
      "Batch: 41, Loss: 0.7305082082748413, Accuracy: 0.76171875\n",
      "Batch: 42, Loss: 0.624281644821167, Accuracy: 0.7880859375\n",
      "Batch: 43, Loss: 0.8313871622085571, Accuracy: 0.712890625\n",
      "Batch: 44, Loss: 0.8396098017692566, Accuracy: 0.7158203125\n",
      "Batch: 45, Loss: 0.7598387002944946, Accuracy: 0.7470703125\n",
      "Batch: 46, Loss: 0.7323836088180542, Accuracy: 0.771484375\n",
      "Batch: 47, Loss: 0.7288194894790649, Accuracy: 0.759765625\n",
      "Batch: 48, Loss: 0.7354589700698853, Accuracy: 0.75\n",
      "Batch: 49, Loss: 0.8332372307777405, Accuracy: 0.7138671875\n",
      "Batch: 50, Loss: 0.8157666325569153, Accuracy: 0.7265625\n",
      "Batch: 51, Loss: 0.8553805351257324, Accuracy: 0.7158203125\n",
      "Batch: 52, Loss: 0.8333644866943359, Accuracy: 0.734375\n",
      "Batch: 53, Loss: 0.74330073595047, Accuracy: 0.7451171875\n",
      "Batch: 54, Loss: 0.7796990275382996, Accuracy: 0.7421875\n",
      "Batch: 55, Loss: 0.9060982465744019, Accuracy: 0.7021484375\n",
      "Batch: 56, Loss: 0.862949013710022, Accuracy: 0.72265625\n",
      "Batch: 57, Loss: 0.8139435052871704, Accuracy: 0.72265625\n",
      "Batch: 58, Loss: 0.9490055441856384, Accuracy: 0.7080078125\n",
      "Batch: 59, Loss: 0.7598637938499451, Accuracy: 0.7568359375\n",
      "Batch: 60, Loss: 0.7144465446472168, Accuracy: 0.767578125\n",
      "Batch: 61, Loss: 0.8379160165786743, Accuracy: 0.72265625\n",
      "Batch: 62, Loss: 0.7881625890731812, Accuracy: 0.75\n",
      "Batch: 63, Loss: 0.8081822395324707, Accuracy: 0.7412109375\n",
      "Batch: 64, Loss: 0.819230318069458, Accuracy: 0.7373046875\n",
      "Batch: 65, Loss: 0.8335530161857605, Accuracy: 0.734375\n",
      "Batch: 66, Loss: 0.7797287702560425, Accuracy: 0.755859375\n",
      "Batch: 67, Loss: 0.8656832575798035, Accuracy: 0.7294921875\n",
      "Batch: 68, Loss: 0.9153977036476135, Accuracy: 0.716796875\n",
      "Batch: 69, Loss: 0.8243552446365356, Accuracy: 0.7265625\n",
      "Batch: 70, Loss: 0.822006106376648, Accuracy: 0.736328125\n",
      "Batch: 71, Loss: 0.836383581161499, Accuracy: 0.7236328125\n",
      "Batch: 72, Loss: 0.736396312713623, Accuracy: 0.7431640625\n",
      "Batch: 73, Loss: 0.7338594198226929, Accuracy: 0.7646484375\n",
      "Batch: 74, Loss: 0.7280312776565552, Accuracy: 0.759765625\n",
      "Batch: 75, Loss: 0.7530084848403931, Accuracy: 0.75390625\n",
      "Batch: 76, Loss: 0.8266792297363281, Accuracy: 0.7294921875\n",
      "Batch: 77, Loss: 0.7787097692489624, Accuracy: 0.7373046875\n",
      "Batch: 78, Loss: 0.6930130124092102, Accuracy: 0.767578125\n",
      "Batch: 79, Loss: 0.7089653015136719, Accuracy: 0.775390625\n",
      "Batch: 80, Loss: 0.7547053694725037, Accuracy: 0.74609375\n",
      "Batch: 81, Loss: 0.880785346031189, Accuracy: 0.68359375\n",
      "Batch: 82, Loss: 0.8185634613037109, Accuracy: 0.7294921875\n",
      "Batch: 83, Loss: 0.7071727514266968, Accuracy: 0.779296875\n",
      "Batch: 84, Loss: 0.7666469812393188, Accuracy: 0.75390625\n",
      "Batch: 85, Loss: 0.740609884262085, Accuracy: 0.7607421875\n",
      "Batch: 86, Loss: 0.911780834197998, Accuracy: 0.7041015625\n",
      "Batch: 87, Loss: 0.7671515941619873, Accuracy: 0.7529296875\n",
      "Batch: 88, Loss: 0.8743415474891663, Accuracy: 0.7353515625\n",
      "Batch: 89, Loss: 0.8307689428329468, Accuracy: 0.7431640625\n",
      "Batch: 90, Loss: 0.7619742155075073, Accuracy: 0.755859375\n",
      "Batch: 91, Loss: 0.7622279524803162, Accuracy: 0.7373046875\n",
      "Batch: 92, Loss: 0.8236098289489746, Accuracy: 0.7431640625\n",
      "Batch: 93, Loss: 0.7993557453155518, Accuracy: 0.7177734375\n",
      "Batch: 94, Loss: 0.824285626411438, Accuracy: 0.716796875\n",
      "Batch: 95, Loss: 0.8577710390090942, Accuracy: 0.712890625\n",
      "Batch: 96, Loss: 0.7873085141181946, Accuracy: 0.7421875\n",
      "Batch: 97, Loss: 0.6429640054702759, Accuracy: 0.779296875\n",
      "Batch: 98, Loss: 0.7639428377151489, Accuracy: 0.7587890625\n",
      "Batch: 99, Loss: 0.7685878276824951, Accuracy: 0.7412109375\n",
      "Batch: 100, Loss: 0.8066021203994751, Accuracy: 0.7451171875\n",
      "Batch: 101, Loss: 0.8531299233436584, Accuracy: 0.7236328125\n",
      "Batch: 102, Loss: 0.7915439605712891, Accuracy: 0.75\n",
      "Batch: 103, Loss: 0.8144465684890747, Accuracy: 0.7421875\n",
      "Batch: 104, Loss: 0.759709894657135, Accuracy: 0.75390625\n",
      "Batch: 105, Loss: 0.809729814529419, Accuracy: 0.7412109375\n",
      "Batch: 106, Loss: 0.7858260273933411, Accuracy: 0.7470703125\n",
      "Batch: 107, Loss: 0.8283995389938354, Accuracy: 0.73828125\n",
      "Batch: 108, Loss: 0.8303731679916382, Accuracy: 0.71484375\n",
      "Batch: 109, Loss: 0.9436092376708984, Accuracy: 0.701171875\n",
      "Batch: 110, Loss: 0.722164511680603, Accuracy: 0.755859375\n",
      "Batch: 111, Loss: 0.8310812711715698, Accuracy: 0.72265625\n",
      "Batch: 112, Loss: 0.7990363836288452, Accuracy: 0.7421875\n",
      "Batch: 113, Loss: 0.8091645240783691, Accuracy: 0.7255859375\n",
      "Batch: 114, Loss: 0.8800710439682007, Accuracy: 0.7255859375\n",
      "Batch: 115, Loss: 0.9139999151229858, Accuracy: 0.71875\n",
      "Batch: 116, Loss: 0.8250697255134583, Accuracy: 0.7265625\n",
      "Batch: 117, Loss: 0.8642324209213257, Accuracy: 0.728515625\n",
      "Batch: 118, Loss: 0.7164658904075623, Accuracy: 0.7666015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 119, Loss: 0.6974607110023499, Accuracy: 0.771484375\n",
      "Batch: 120, Loss: 0.8413739204406738, Accuracy: 0.71875\n",
      "Batch: 121, Loss: 0.8548579216003418, Accuracy: 0.7236328125\n",
      "Batch: 122, Loss: 0.7627378702163696, Accuracy: 0.7587890625\n",
      "Batch: 123, Loss: 0.7315131425857544, Accuracy: 0.7548828125\n",
      "Batch: 124, Loss: 0.7953001260757446, Accuracy: 0.736328125\n",
      "Batch: 125, Loss: 0.8421668410301208, Accuracy: 0.7255859375\n",
      "Batch: 126, Loss: 0.8121482133865356, Accuracy: 0.7373046875\n",
      "Batch: 127, Loss: 0.7314958572387695, Accuracy: 0.767578125\n",
      "Batch: 128, Loss: 0.9019945859909058, Accuracy: 0.7255859375\n",
      "Batch: 129, Loss: 0.7387040853500366, Accuracy: 0.7607421875\n",
      "Batch: 130, Loss: 0.9270082712173462, Accuracy: 0.70703125\n",
      "Batch: 131, Loss: 0.8266013860702515, Accuracy: 0.73046875\n",
      "Batch: 132, Loss: 0.8270504474639893, Accuracy: 0.728515625\n",
      "Batch: 133, Loss: 0.7608342170715332, Accuracy: 0.7490234375\n",
      "Batch: 134, Loss: 0.8108881115913391, Accuracy: 0.7109375\n",
      "Batch: 135, Loss: 0.7157276272773743, Accuracy: 0.7626953125\n",
      "Batch: 136, Loss: 0.7940658330917358, Accuracy: 0.75390625\n",
      "Batch: 137, Loss: 0.8018133640289307, Accuracy: 0.732421875\n",
      "Batch: 138, Loss: 0.6917808055877686, Accuracy: 0.7666015625\n",
      "Batch: 139, Loss: 0.7654191255569458, Accuracy: 0.74609375\n",
      "Batch: 140, Loss: 0.8040990233421326, Accuracy: 0.73046875\n",
      "Batch: 141, Loss: 0.8055661916732788, Accuracy: 0.724609375\n",
      "Batch: 142, Loss: 0.8531593084335327, Accuracy: 0.716796875\n",
      "Batch: 143, Loss: 0.8217546343803406, Accuracy: 0.7255859375\n",
      "Batch: 144, Loss: 0.7809783220291138, Accuracy: 0.7333984375\n",
      "Batch: 145, Loss: 0.770837128162384, Accuracy: 0.73046875\n",
      "Batch: 146, Loss: 0.8402385711669922, Accuracy: 0.7109375\n",
      "Batch: 147, Loss: 0.8290469646453857, Accuracy: 0.720703125\n",
      "Batch: 148, Loss: 0.9248878955841064, Accuracy: 0.689453125\n",
      "Batch: 149, Loss: 0.7868748903274536, Accuracy: 0.7392578125\n",
      "Batch: 150, Loss: 0.7963865399360657, Accuracy: 0.740234375\n",
      "Batch: 151, Loss: 0.7191628217697144, Accuracy: 0.7626953125\n",
      "Epoch 48/80\n",
      "Batch: 1, Loss: 1.0267081260681152, Accuracy: 0.673828125\n",
      "Batch: 2, Loss: 0.8871103525161743, Accuracy: 0.689453125\n",
      "Batch: 3, Loss: 0.764716625213623, Accuracy: 0.74609375\n",
      "Batch: 4, Loss: 0.6876797676086426, Accuracy: 0.779296875\n",
      "Batch: 5, Loss: 0.7808474898338318, Accuracy: 0.748046875\n",
      "Batch: 6, Loss: 0.822662353515625, Accuracy: 0.73828125\n",
      "Batch: 7, Loss: 0.8116464614868164, Accuracy: 0.7197265625\n",
      "Batch: 8, Loss: 0.7482604384422302, Accuracy: 0.7490234375\n",
      "Batch: 9, Loss: 0.7436130046844482, Accuracy: 0.7509765625\n",
      "Batch: 10, Loss: 0.7524809837341309, Accuracy: 0.755859375\n",
      "Batch: 11, Loss: 0.8662285804748535, Accuracy: 0.7001953125\n",
      "Batch: 12, Loss: 0.8557677268981934, Accuracy: 0.724609375\n",
      "Batch: 13, Loss: 0.6699270606040955, Accuracy: 0.7734375\n",
      "Batch: 14, Loss: 0.8958163857460022, Accuracy: 0.7138671875\n",
      "Batch: 15, Loss: 0.703179657459259, Accuracy: 0.7666015625\n",
      "Batch: 16, Loss: 0.7795583605766296, Accuracy: 0.7412109375\n",
      "Batch: 17, Loss: 0.8512625694274902, Accuracy: 0.71875\n",
      "Batch: 18, Loss: 0.8536198735237122, Accuracy: 0.7197265625\n",
      "Batch: 19, Loss: 0.8355979323387146, Accuracy: 0.7236328125\n",
      "Batch: 20, Loss: 0.7084283828735352, Accuracy: 0.7626953125\n",
      "Batch: 21, Loss: 0.7650760412216187, Accuracy: 0.7392578125\n",
      "Batch: 22, Loss: 0.8636601567268372, Accuracy: 0.71484375\n",
      "Batch: 23, Loss: 0.7955887317657471, Accuracy: 0.724609375\n",
      "Batch: 24, Loss: 0.8446370959281921, Accuracy: 0.71484375\n",
      "Batch: 25, Loss: 0.810767650604248, Accuracy: 0.724609375\n",
      "Batch: 26, Loss: 0.708461344242096, Accuracy: 0.7548828125\n",
      "Batch: 27, Loss: 0.7860797643661499, Accuracy: 0.736328125\n",
      "Batch: 28, Loss: 0.8236512541770935, Accuracy: 0.7158203125\n",
      "Batch: 29, Loss: 0.7569369673728943, Accuracy: 0.7412109375\n",
      "Batch: 30, Loss: 0.6987877488136292, Accuracy: 0.771484375\n",
      "Batch: 31, Loss: 0.7073909044265747, Accuracy: 0.7666015625\n",
      "Batch: 32, Loss: 0.7477818727493286, Accuracy: 0.7421875\n",
      "Batch: 33, Loss: 0.8938614726066589, Accuracy: 0.712890625\n",
      "Batch: 34, Loss: 0.9322009086608887, Accuracy: 0.6875\n",
      "Batch: 35, Loss: 0.8171677589416504, Accuracy: 0.716796875\n",
      "Batch: 36, Loss: 0.8424288034439087, Accuracy: 0.75\n",
      "Batch: 37, Loss: 0.7985652089118958, Accuracy: 0.7412109375\n",
      "Batch: 38, Loss: 0.8303042650222778, Accuracy: 0.7177734375\n",
      "Batch: 39, Loss: 0.841566801071167, Accuracy: 0.72265625\n",
      "Batch: 40, Loss: 0.791137158870697, Accuracy: 0.7451171875\n",
      "Batch: 41, Loss: 0.7587257623672485, Accuracy: 0.7724609375\n",
      "Batch: 42, Loss: 0.6217093467712402, Accuracy: 0.802734375\n",
      "Batch: 43, Loss: 0.8449272513389587, Accuracy: 0.7177734375\n",
      "Batch: 44, Loss: 0.8198407888412476, Accuracy: 0.7265625\n",
      "Batch: 45, Loss: 0.7418220043182373, Accuracy: 0.755859375\n",
      "Batch: 46, Loss: 0.7021546363830566, Accuracy: 0.7734375\n",
      "Batch: 47, Loss: 0.7359166145324707, Accuracy: 0.7724609375\n",
      "Batch: 48, Loss: 0.7248899936676025, Accuracy: 0.765625\n",
      "Batch: 49, Loss: 0.8553457260131836, Accuracy: 0.7109375\n",
      "Batch: 50, Loss: 0.8558053374290466, Accuracy: 0.7080078125\n",
      "Batch: 51, Loss: 0.883181631565094, Accuracy: 0.71875\n",
      "Batch: 52, Loss: 0.8148281574249268, Accuracy: 0.7294921875\n",
      "Batch: 53, Loss: 0.7482187151908875, Accuracy: 0.7548828125\n",
      "Batch: 54, Loss: 0.8166763782501221, Accuracy: 0.744140625\n",
      "Batch: 55, Loss: 0.906061053276062, Accuracy: 0.708984375\n",
      "Batch: 56, Loss: 0.8717304468154907, Accuracy: 0.7109375\n",
      "Batch: 57, Loss: 0.8605693578720093, Accuracy: 0.7265625\n",
      "Batch: 58, Loss: 0.9184119701385498, Accuracy: 0.71875\n",
      "Batch: 59, Loss: 0.7637135982513428, Accuracy: 0.7568359375\n",
      "Batch: 60, Loss: 0.7414889335632324, Accuracy: 0.7646484375\n",
      "Batch: 61, Loss: 0.8266993761062622, Accuracy: 0.728515625\n",
      "Batch: 62, Loss: 0.7957971096038818, Accuracy: 0.736328125\n",
      "Batch: 63, Loss: 0.8202120065689087, Accuracy: 0.740234375\n",
      "Batch: 64, Loss: 0.7979539632797241, Accuracy: 0.7236328125\n",
      "Batch: 65, Loss: 0.8209569454193115, Accuracy: 0.73828125\n",
      "Batch: 66, Loss: 0.7884699106216431, Accuracy: 0.744140625\n",
      "Batch: 67, Loss: 0.8587596416473389, Accuracy: 0.7333984375\n",
      "Batch: 68, Loss: 0.9046184420585632, Accuracy: 0.724609375\n",
      "Batch: 69, Loss: 0.8351873755455017, Accuracy: 0.7294921875\n",
      "Batch: 70, Loss: 0.7834946513175964, Accuracy: 0.76953125\n",
      "Batch: 71, Loss: 0.847404956817627, Accuracy: 0.7138671875\n",
      "Batch: 72, Loss: 0.7174264192581177, Accuracy: 0.755859375\n",
      "Batch: 73, Loss: 0.7299188375473022, Accuracy: 0.76171875\n",
      "Batch: 74, Loss: 0.7105376124382019, Accuracy: 0.78515625\n",
      "Batch: 75, Loss: 0.7307907342910767, Accuracy: 0.763671875\n",
      "Batch: 76, Loss: 0.8171917200088501, Accuracy: 0.716796875\n",
      "Batch: 77, Loss: 0.7646311521530151, Accuracy: 0.7587890625\n",
      "Batch: 78, Loss: 0.7136473655700684, Accuracy: 0.7607421875\n",
      "Batch: 79, Loss: 0.6533753871917725, Accuracy: 0.783203125\n",
      "Batch: 80, Loss: 0.7638956308364868, Accuracy: 0.7490234375\n",
      "Batch: 81, Loss: 0.8814917802810669, Accuracy: 0.7060546875\n",
      "Batch: 82, Loss: 0.8509576320648193, Accuracy: 0.712890625\n",
      "Batch: 83, Loss: 0.7220561504364014, Accuracy: 0.7666015625\n",
      "Batch: 84, Loss: 0.7516279220581055, Accuracy: 0.7607421875\n",
      "Batch: 85, Loss: 0.7542685270309448, Accuracy: 0.759765625\n",
      "Batch: 86, Loss: 0.9276382923126221, Accuracy: 0.705078125\n",
      "Batch: 87, Loss: 0.7378811836242676, Accuracy: 0.755859375\n",
      "Batch: 88, Loss: 0.8452377319335938, Accuracy: 0.728515625\n",
      "Batch: 89, Loss: 0.8084523677825928, Accuracy: 0.7529296875\n",
      "Batch: 90, Loss: 0.7513190507888794, Accuracy: 0.7509765625\n",
      "Batch: 91, Loss: 0.7587852478027344, Accuracy: 0.7470703125\n",
      "Batch: 92, Loss: 0.8326305747032166, Accuracy: 0.7353515625\n",
      "Batch: 93, Loss: 0.7624916434288025, Accuracy: 0.7431640625\n",
      "Batch: 94, Loss: 0.801619291305542, Accuracy: 0.73828125\n",
      "Batch: 95, Loss: 0.8404550552368164, Accuracy: 0.7041015625\n",
      "Batch: 96, Loss: 0.7528374195098877, Accuracy: 0.75390625\n",
      "Batch: 97, Loss: 0.6680564880371094, Accuracy: 0.7744140625\n",
      "Batch: 98, Loss: 0.7568328976631165, Accuracy: 0.7529296875\n",
      "Batch: 99, Loss: 0.7703638076782227, Accuracy: 0.7529296875\n",
      "Batch: 100, Loss: 0.7954056262969971, Accuracy: 0.734375\n",
      "Batch: 101, Loss: 0.817866325378418, Accuracy: 0.7236328125\n",
      "Batch: 102, Loss: 0.7967528104782104, Accuracy: 0.7421875\n",
      "Batch: 103, Loss: 0.8408889770507812, Accuracy: 0.7431640625\n",
      "Batch: 104, Loss: 0.7489939332008362, Accuracy: 0.74609375\n",
      "Batch: 105, Loss: 0.8422473669052124, Accuracy: 0.7314453125\n",
      "Batch: 106, Loss: 0.7596519589424133, Accuracy: 0.744140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 107, Loss: 0.8018419146537781, Accuracy: 0.7490234375\n",
      "Batch: 108, Loss: 0.8228507041931152, Accuracy: 0.7119140625\n",
      "Batch: 109, Loss: 0.9099607467651367, Accuracy: 0.6826171875\n",
      "Batch: 110, Loss: 0.7364913821220398, Accuracy: 0.759765625\n",
      "Batch: 111, Loss: 0.8185594081878662, Accuracy: 0.7265625\n",
      "Batch: 112, Loss: 0.7845617532730103, Accuracy: 0.7421875\n",
      "Batch: 113, Loss: 0.7960938215255737, Accuracy: 0.7431640625\n",
      "Batch: 114, Loss: 0.8800359964370728, Accuracy: 0.716796875\n",
      "Batch: 115, Loss: 0.926138162612915, Accuracy: 0.716796875\n",
      "Batch: 116, Loss: 0.8394275903701782, Accuracy: 0.7236328125\n",
      "Batch: 117, Loss: 0.8339248299598694, Accuracy: 0.7275390625\n",
      "Batch: 118, Loss: 0.7161375284194946, Accuracy: 0.7685546875\n",
      "Batch: 119, Loss: 0.6694495677947998, Accuracy: 0.787109375\n",
      "Batch: 120, Loss: 0.8458791971206665, Accuracy: 0.71875\n",
      "Batch: 121, Loss: 0.8573499321937561, Accuracy: 0.7109375\n",
      "Batch: 122, Loss: 0.7505011558532715, Accuracy: 0.75390625\n",
      "Batch: 123, Loss: 0.7310980558395386, Accuracy: 0.7685546875\n",
      "Batch: 124, Loss: 0.8166562914848328, Accuracy: 0.7421875\n",
      "Batch: 125, Loss: 0.8558682203292847, Accuracy: 0.72265625\n",
      "Batch: 126, Loss: 0.8054511547088623, Accuracy: 0.7529296875\n",
      "Batch: 127, Loss: 0.7139964699745178, Accuracy: 0.7734375\n",
      "Batch: 128, Loss: 0.879625678062439, Accuracy: 0.7314453125\n",
      "Batch: 129, Loss: 0.740188717842102, Accuracy: 0.748046875\n",
      "Batch: 130, Loss: 0.9032604694366455, Accuracy: 0.7099609375\n",
      "Batch: 131, Loss: 0.7980450391769409, Accuracy: 0.734375\n",
      "Batch: 132, Loss: 0.825112521648407, Accuracy: 0.751953125\n",
      "Batch: 133, Loss: 0.7617137432098389, Accuracy: 0.744140625\n",
      "Batch: 134, Loss: 0.8196795582771301, Accuracy: 0.7080078125\n",
      "Batch: 135, Loss: 0.7187111377716064, Accuracy: 0.7607421875\n",
      "Batch: 136, Loss: 0.8051321506500244, Accuracy: 0.751953125\n",
      "Batch: 137, Loss: 0.7863218784332275, Accuracy: 0.736328125\n",
      "Batch: 138, Loss: 0.7054194808006287, Accuracy: 0.7626953125\n",
      "Batch: 139, Loss: 0.747592031955719, Accuracy: 0.7490234375\n",
      "Batch: 140, Loss: 0.7851109504699707, Accuracy: 0.7294921875\n",
      "Batch: 141, Loss: 0.8195729851722717, Accuracy: 0.732421875\n",
      "Batch: 142, Loss: 0.8555989861488342, Accuracy: 0.7265625\n",
      "Batch: 143, Loss: 0.8113983869552612, Accuracy: 0.73046875\n",
      "Batch: 144, Loss: 0.8035620450973511, Accuracy: 0.73046875\n",
      "Batch: 145, Loss: 0.7543729543685913, Accuracy: 0.744140625\n",
      "Batch: 146, Loss: 0.8439398407936096, Accuracy: 0.7119140625\n",
      "Batch: 147, Loss: 0.8076976537704468, Accuracy: 0.7421875\n",
      "Batch: 148, Loss: 0.9016677141189575, Accuracy: 0.7021484375\n",
      "Batch: 149, Loss: 0.7749086618423462, Accuracy: 0.73046875\n",
      "Batch: 150, Loss: 0.8042306303977966, Accuracy: 0.712890625\n",
      "Batch: 151, Loss: 0.6980121731758118, Accuracy: 0.765625\n",
      "Epoch 49/80\n",
      "Batch: 1, Loss: 1.033821940422058, Accuracy: 0.677734375\n",
      "Batch: 2, Loss: 0.8902651071548462, Accuracy: 0.6826171875\n",
      "Batch: 3, Loss: 0.7853788137435913, Accuracy: 0.740234375\n",
      "Batch: 4, Loss: 0.6779788732528687, Accuracy: 0.76953125\n",
      "Batch: 5, Loss: 0.7678236961364746, Accuracy: 0.7470703125\n",
      "Batch: 6, Loss: 0.8169388771057129, Accuracy: 0.728515625\n",
      "Batch: 7, Loss: 0.8004813194274902, Accuracy: 0.716796875\n",
      "Batch: 8, Loss: 0.7553005218505859, Accuracy: 0.748046875\n",
      "Batch: 9, Loss: 0.7439671754837036, Accuracy: 0.755859375\n",
      "Batch: 10, Loss: 0.77362060546875, Accuracy: 0.755859375\n",
      "Batch: 11, Loss: 0.8600022792816162, Accuracy: 0.7041015625\n",
      "Batch: 12, Loss: 0.8637858629226685, Accuracy: 0.7138671875\n",
      "Batch: 13, Loss: 0.6613238453865051, Accuracy: 0.7763671875\n",
      "Batch: 14, Loss: 0.857656717300415, Accuracy: 0.71875\n",
      "Batch: 15, Loss: 0.7019240260124207, Accuracy: 0.7734375\n",
      "Batch: 16, Loss: 0.7846283912658691, Accuracy: 0.74609375\n",
      "Batch: 17, Loss: 0.8268224000930786, Accuracy: 0.73046875\n",
      "Batch: 18, Loss: 0.8511744737625122, Accuracy: 0.7177734375\n",
      "Batch: 19, Loss: 0.8284279108047485, Accuracy: 0.7314453125\n",
      "Batch: 20, Loss: 0.7031104564666748, Accuracy: 0.771484375\n",
      "Batch: 21, Loss: 0.752926766872406, Accuracy: 0.736328125\n",
      "Batch: 22, Loss: 0.8509668111801147, Accuracy: 0.7138671875\n",
      "Batch: 23, Loss: 0.8068982362747192, Accuracy: 0.72265625\n",
      "Batch: 24, Loss: 0.828498125076294, Accuracy: 0.7119140625\n",
      "Batch: 25, Loss: 0.7937350273132324, Accuracy: 0.748046875\n",
      "Batch: 26, Loss: 0.6884154677391052, Accuracy: 0.7626953125\n",
      "Batch: 27, Loss: 0.7357063293457031, Accuracy: 0.755859375\n",
      "Batch: 28, Loss: 0.8302369117736816, Accuracy: 0.70703125\n",
      "Batch: 29, Loss: 0.7442392110824585, Accuracy: 0.744140625\n",
      "Batch: 30, Loss: 0.6757375001907349, Accuracy: 0.7802734375\n",
      "Batch: 31, Loss: 0.6852907538414001, Accuracy: 0.783203125\n",
      "Batch: 32, Loss: 0.7384046912193298, Accuracy: 0.7392578125\n",
      "Batch: 33, Loss: 0.869870662689209, Accuracy: 0.7255859375\n",
      "Batch: 34, Loss: 0.9270133972167969, Accuracy: 0.68359375\n",
      "Batch: 35, Loss: 0.8061591386795044, Accuracy: 0.728515625\n",
      "Batch: 36, Loss: 0.8447410464286804, Accuracy: 0.73046875\n",
      "Batch: 37, Loss: 0.7912124395370483, Accuracy: 0.73828125\n",
      "Batch: 38, Loss: 0.8178573846817017, Accuracy: 0.716796875\n",
      "Batch: 39, Loss: 0.8332147002220154, Accuracy: 0.7158203125\n",
      "Batch: 40, Loss: 0.7747538089752197, Accuracy: 0.748046875\n",
      "Batch: 41, Loss: 0.7172203063964844, Accuracy: 0.775390625\n",
      "Batch: 42, Loss: 0.6235830783843994, Accuracy: 0.7841796875\n",
      "Batch: 43, Loss: 0.8553115129470825, Accuracy: 0.7060546875\n",
      "Batch: 44, Loss: 0.829699695110321, Accuracy: 0.720703125\n",
      "Batch: 45, Loss: 0.7434685826301575, Accuracy: 0.7578125\n",
      "Batch: 46, Loss: 0.719809889793396, Accuracy: 0.767578125\n",
      "Batch: 47, Loss: 0.7156766653060913, Accuracy: 0.771484375\n",
      "Batch: 48, Loss: 0.717141330242157, Accuracy: 0.771484375\n",
      "Batch: 49, Loss: 0.8524748086929321, Accuracy: 0.7197265625\n",
      "Batch: 50, Loss: 0.8420017957687378, Accuracy: 0.7119140625\n",
      "Batch: 51, Loss: 0.8597472906112671, Accuracy: 0.7197265625\n",
      "Batch: 52, Loss: 0.7870121002197266, Accuracy: 0.7421875\n",
      "Batch: 53, Loss: 0.7593757510185242, Accuracy: 0.7421875\n",
      "Batch: 54, Loss: 0.7789193391799927, Accuracy: 0.74609375\n",
      "Batch: 55, Loss: 0.9031845331192017, Accuracy: 0.70703125\n",
      "Batch: 56, Loss: 0.8553591966629028, Accuracy: 0.716796875\n",
      "Batch: 57, Loss: 0.7915111184120178, Accuracy: 0.734375\n",
      "Batch: 58, Loss: 0.9256993532180786, Accuracy: 0.7216796875\n",
      "Batch: 59, Loss: 0.7445619702339172, Accuracy: 0.740234375\n",
      "Batch: 60, Loss: 0.7256696224212646, Accuracy: 0.76953125\n",
      "Batch: 61, Loss: 0.8087536692619324, Accuracy: 0.732421875\n",
      "Batch: 62, Loss: 0.7794999480247498, Accuracy: 0.759765625\n",
      "Batch: 63, Loss: 0.8067358136177063, Accuracy: 0.736328125\n",
      "Batch: 64, Loss: 0.8011256456375122, Accuracy: 0.74609375\n",
      "Batch: 65, Loss: 0.8338295221328735, Accuracy: 0.7392578125\n",
      "Batch: 66, Loss: 0.7730903029441833, Accuracy: 0.7685546875\n",
      "Batch: 67, Loss: 0.8683852553367615, Accuracy: 0.7158203125\n",
      "Batch: 68, Loss: 0.8977854251861572, Accuracy: 0.7265625\n",
      "Batch: 69, Loss: 0.8097233772277832, Accuracy: 0.724609375\n",
      "Batch: 70, Loss: 0.793420672416687, Accuracy: 0.7490234375\n",
      "Batch: 71, Loss: 0.8200578689575195, Accuracy: 0.73046875\n",
      "Batch: 72, Loss: 0.7213388681411743, Accuracy: 0.7548828125\n",
      "Batch: 73, Loss: 0.7149947881698608, Accuracy: 0.7724609375\n",
      "Batch: 74, Loss: 0.6980108022689819, Accuracy: 0.779296875\n",
      "Batch: 75, Loss: 0.7218986749649048, Accuracy: 0.7626953125\n",
      "Batch: 76, Loss: 0.8136919736862183, Accuracy: 0.7314453125\n",
      "Batch: 77, Loss: 0.7606971859931946, Accuracy: 0.7607421875\n",
      "Batch: 78, Loss: 0.6904397010803223, Accuracy: 0.771484375\n",
      "Batch: 79, Loss: 0.6501051187515259, Accuracy: 0.77734375\n",
      "Batch: 80, Loss: 0.754845142364502, Accuracy: 0.74609375\n",
      "Batch: 81, Loss: 0.8706135153770447, Accuracy: 0.6982421875\n",
      "Batch: 82, Loss: 0.8190015554428101, Accuracy: 0.7392578125\n",
      "Batch: 83, Loss: 0.6965519189834595, Accuracy: 0.7861328125\n",
      "Batch: 84, Loss: 0.7574619054794312, Accuracy: 0.75\n",
      "Batch: 85, Loss: 0.7656973600387573, Accuracy: 0.755859375\n",
      "Batch: 86, Loss: 0.9210332632064819, Accuracy: 0.7119140625\n",
      "Batch: 87, Loss: 0.7462509870529175, Accuracy: 0.7568359375\n",
      "Batch: 88, Loss: 0.8679708242416382, Accuracy: 0.71875\n",
      "Batch: 89, Loss: 0.835182249546051, Accuracy: 0.7275390625\n",
      "Batch: 90, Loss: 0.7307136058807373, Accuracy: 0.7587890625\n",
      "Batch: 91, Loss: 0.7825841903686523, Accuracy: 0.7392578125\n",
      "Batch: 92, Loss: 0.7997725605964661, Accuracy: 0.734375\n",
      "Batch: 93, Loss: 0.7879773378372192, Accuracy: 0.7412109375\n",
      "Batch: 94, Loss: 0.7778082489967346, Accuracy: 0.7412109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 95, Loss: 0.8395029902458191, Accuracy: 0.7001953125\n",
      "Batch: 96, Loss: 0.785686731338501, Accuracy: 0.7294921875\n",
      "Batch: 97, Loss: 0.6311610341072083, Accuracy: 0.791015625\n",
      "Batch: 98, Loss: 0.7585179805755615, Accuracy: 0.75390625\n",
      "Batch: 99, Loss: 0.760339617729187, Accuracy: 0.755859375\n",
      "Batch: 100, Loss: 0.7888656854629517, Accuracy: 0.7353515625\n",
      "Batch: 101, Loss: 0.8408167362213135, Accuracy: 0.72265625\n",
      "Batch: 102, Loss: 0.785105288028717, Accuracy: 0.7529296875\n",
      "Batch: 103, Loss: 0.7898873090744019, Accuracy: 0.7412109375\n",
      "Batch: 104, Loss: 0.7348251342773438, Accuracy: 0.755859375\n",
      "Batch: 105, Loss: 0.8202770948410034, Accuracy: 0.7236328125\n",
      "Batch: 106, Loss: 0.7322723865509033, Accuracy: 0.7607421875\n",
      "Batch: 107, Loss: 0.7969399690628052, Accuracy: 0.7529296875\n",
      "Batch: 108, Loss: 0.816523551940918, Accuracy: 0.7236328125\n",
      "Batch: 109, Loss: 0.9017131328582764, Accuracy: 0.697265625\n",
      "Batch: 110, Loss: 0.7202397584915161, Accuracy: 0.744140625\n",
      "Batch: 111, Loss: 0.8393802046775818, Accuracy: 0.716796875\n",
      "Batch: 112, Loss: 0.7753902673721313, Accuracy: 0.7509765625\n",
      "Batch: 113, Loss: 0.802829384803772, Accuracy: 0.7431640625\n",
      "Batch: 114, Loss: 0.8670923709869385, Accuracy: 0.72265625\n",
      "Batch: 115, Loss: 0.8875792026519775, Accuracy: 0.7236328125\n",
      "Batch: 116, Loss: 0.8385174870491028, Accuracy: 0.7431640625\n",
      "Batch: 117, Loss: 0.8283520936965942, Accuracy: 0.732421875\n",
      "Batch: 118, Loss: 0.7203617691993713, Accuracy: 0.765625\n",
      "Batch: 119, Loss: 0.6556969881057739, Accuracy: 0.779296875\n",
      "Batch: 120, Loss: 0.8147340416908264, Accuracy: 0.7197265625\n",
      "Batch: 121, Loss: 0.8501380681991577, Accuracy: 0.716796875\n",
      "Batch: 122, Loss: 0.7593399286270142, Accuracy: 0.7451171875\n",
      "Batch: 123, Loss: 0.7386718988418579, Accuracy: 0.763671875\n",
      "Batch: 124, Loss: 0.7896530628204346, Accuracy: 0.7294921875\n",
      "Batch: 125, Loss: 0.8359698057174683, Accuracy: 0.7333984375\n",
      "Batch: 126, Loss: 0.8049233555793762, Accuracy: 0.7392578125\n",
      "Batch: 127, Loss: 0.737471342086792, Accuracy: 0.7568359375\n",
      "Batch: 128, Loss: 0.8773142099380493, Accuracy: 0.720703125\n",
      "Batch: 129, Loss: 0.7493259310722351, Accuracy: 0.759765625\n",
      "Batch: 130, Loss: 0.8891969919204712, Accuracy: 0.7080078125\n",
      "Batch: 131, Loss: 0.8183165788650513, Accuracy: 0.73828125\n",
      "Batch: 132, Loss: 0.8159745931625366, Accuracy: 0.7373046875\n",
      "Batch: 133, Loss: 0.7593109011650085, Accuracy: 0.748046875\n",
      "Batch: 134, Loss: 0.8161342740058899, Accuracy: 0.7138671875\n",
      "Batch: 135, Loss: 0.6944083571434021, Accuracy: 0.7705078125\n",
      "Batch: 136, Loss: 0.8122131824493408, Accuracy: 0.736328125\n",
      "Batch: 137, Loss: 0.7706029415130615, Accuracy: 0.740234375\n",
      "Batch: 138, Loss: 0.7131117582321167, Accuracy: 0.763671875\n",
      "Batch: 139, Loss: 0.7499580383300781, Accuracy: 0.74609375\n",
      "Batch: 140, Loss: 0.7628453373908997, Accuracy: 0.7431640625\n",
      "Batch: 141, Loss: 0.8024045825004578, Accuracy: 0.7275390625\n",
      "Batch: 142, Loss: 0.8231052756309509, Accuracy: 0.7119140625\n",
      "Batch: 143, Loss: 0.7754156589508057, Accuracy: 0.734375\n",
      "Batch: 144, Loss: 0.8007584810256958, Accuracy: 0.7333984375\n",
      "Batch: 145, Loss: 0.7536593675613403, Accuracy: 0.73828125\n",
      "Batch: 146, Loss: 0.8289809823036194, Accuracy: 0.7255859375\n",
      "Batch: 147, Loss: 0.8221042156219482, Accuracy: 0.72265625\n",
      "Batch: 148, Loss: 0.8837045431137085, Accuracy: 0.7119140625\n",
      "Batch: 149, Loss: 0.766098141670227, Accuracy: 0.7451171875\n",
      "Batch: 150, Loss: 0.7629529237747192, Accuracy: 0.759765625\n",
      "Batch: 151, Loss: 0.6817494630813599, Accuracy: 0.7666015625\n",
      "Epoch 50/80\n",
      "Batch: 1, Loss: 1.040879249572754, Accuracy: 0.6708984375\n",
      "Batch: 2, Loss: 0.8796130418777466, Accuracy: 0.6923828125\n",
      "Batch: 3, Loss: 0.7671955823898315, Accuracy: 0.744140625\n",
      "Batch: 4, Loss: 0.6673142910003662, Accuracy: 0.7802734375\n",
      "Batch: 5, Loss: 0.7476580739021301, Accuracy: 0.7529296875\n",
      "Batch: 6, Loss: 0.8089605569839478, Accuracy: 0.7314453125\n",
      "Batch: 7, Loss: 0.7865638732910156, Accuracy: 0.736328125\n",
      "Batch: 8, Loss: 0.7420412302017212, Accuracy: 0.748046875\n",
      "Batch: 9, Loss: 0.7319292426109314, Accuracy: 0.759765625\n",
      "Batch: 10, Loss: 0.7408208847045898, Accuracy: 0.7431640625\n",
      "Batch: 11, Loss: 0.8598378896713257, Accuracy: 0.71484375\n",
      "Batch: 12, Loss: 0.8424032926559448, Accuracy: 0.7197265625\n",
      "Batch: 13, Loss: 0.6674661636352539, Accuracy: 0.7880859375\n",
      "Batch: 14, Loss: 0.8590459823608398, Accuracy: 0.7041015625\n",
      "Batch: 15, Loss: 0.7179547548294067, Accuracy: 0.7744140625\n",
      "Batch: 16, Loss: 0.7928256988525391, Accuracy: 0.751953125\n",
      "Batch: 17, Loss: 0.8384741544723511, Accuracy: 0.7158203125\n",
      "Batch: 18, Loss: 0.8482130169868469, Accuracy: 0.728515625\n",
      "Batch: 19, Loss: 0.8286957740783691, Accuracy: 0.73046875\n",
      "Batch: 20, Loss: 0.6985067129135132, Accuracy: 0.7685546875\n",
      "Batch: 21, Loss: 0.7597099542617798, Accuracy: 0.751953125\n",
      "Batch: 22, Loss: 0.8409222960472107, Accuracy: 0.71484375\n",
      "Batch: 23, Loss: 0.812361478805542, Accuracy: 0.7216796875\n",
      "Batch: 24, Loss: 0.8155508041381836, Accuracy: 0.72265625\n",
      "Batch: 25, Loss: 0.7911434173583984, Accuracy: 0.744140625\n",
      "Batch: 26, Loss: 0.6996227502822876, Accuracy: 0.7646484375\n",
      "Batch: 27, Loss: 0.7499380707740784, Accuracy: 0.74609375\n",
      "Batch: 28, Loss: 0.8091949224472046, Accuracy: 0.720703125\n",
      "Batch: 29, Loss: 0.7547404766082764, Accuracy: 0.7373046875\n",
      "Batch: 30, Loss: 0.7003434896469116, Accuracy: 0.7822265625\n",
      "Batch: 31, Loss: 0.6877005100250244, Accuracy: 0.7734375\n",
      "Batch: 32, Loss: 0.7388812303543091, Accuracy: 0.744140625\n",
      "Batch: 33, Loss: 0.8691436648368835, Accuracy: 0.7138671875\n",
      "Batch: 34, Loss: 0.8983571529388428, Accuracy: 0.7138671875\n",
      "Batch: 35, Loss: 0.815377414226532, Accuracy: 0.7451171875\n",
      "Batch: 36, Loss: 0.8304251432418823, Accuracy: 0.7392578125\n",
      "Batch: 37, Loss: 0.8023160099983215, Accuracy: 0.7392578125\n",
      "Batch: 38, Loss: 0.788345456123352, Accuracy: 0.73046875\n",
      "Batch: 39, Loss: 0.8222710490226746, Accuracy: 0.73046875\n",
      "Batch: 40, Loss: 0.7662826180458069, Accuracy: 0.751953125\n",
      "Batch: 41, Loss: 0.7246257066726685, Accuracy: 0.7724609375\n",
      "Batch: 42, Loss: 0.6193198561668396, Accuracy: 0.7919921875\n",
      "Batch: 43, Loss: 0.8020201325416565, Accuracy: 0.7451171875\n",
      "Batch: 44, Loss: 0.8111931085586548, Accuracy: 0.728515625\n",
      "Batch: 45, Loss: 0.7553620338439941, Accuracy: 0.73046875\n",
      "Batch: 46, Loss: 0.7251871824264526, Accuracy: 0.775390625\n",
      "Batch: 47, Loss: 0.6943841576576233, Accuracy: 0.79296875\n",
      "Batch: 48, Loss: 0.7101930379867554, Accuracy: 0.775390625\n",
      "Batch: 49, Loss: 0.7927340865135193, Accuracy: 0.7421875\n",
      "Batch: 50, Loss: 0.8213375806808472, Accuracy: 0.732421875\n",
      "Batch: 51, Loss: 0.8364317417144775, Accuracy: 0.7314453125\n",
      "Batch: 52, Loss: 0.7980493307113647, Accuracy: 0.7412109375\n",
      "Batch: 53, Loss: 0.7274270057678223, Accuracy: 0.7646484375\n",
      "Batch: 54, Loss: 0.7631447315216064, Accuracy: 0.74609375\n",
      "Batch: 55, Loss: 0.8809717893600464, Accuracy: 0.70703125\n",
      "Batch: 56, Loss: 0.8594409227371216, Accuracy: 0.720703125\n",
      "Batch: 57, Loss: 0.8109797239303589, Accuracy: 0.7275390625\n",
      "Batch: 58, Loss: 0.8959251642227173, Accuracy: 0.7275390625\n",
      "Batch: 59, Loss: 0.729948103427887, Accuracy: 0.7626953125\n",
      "Batch: 60, Loss: 0.7051911354064941, Accuracy: 0.771484375\n",
      "Batch: 61, Loss: 0.8222283124923706, Accuracy: 0.724609375\n",
      "Batch: 62, Loss: 0.7888094186782837, Accuracy: 0.7412109375\n",
      "Batch: 63, Loss: 0.8056579828262329, Accuracy: 0.73828125\n",
      "Batch: 64, Loss: 0.812909722328186, Accuracy: 0.73828125\n",
      "Batch: 65, Loss: 0.8173995018005371, Accuracy: 0.736328125\n",
      "Batch: 66, Loss: 0.7776203155517578, Accuracy: 0.763671875\n",
      "Batch: 67, Loss: 0.8471167087554932, Accuracy: 0.736328125\n",
      "Batch: 68, Loss: 0.9229319095611572, Accuracy: 0.7158203125\n",
      "Batch: 69, Loss: 0.8351885080337524, Accuracy: 0.7158203125\n",
      "Batch: 70, Loss: 0.7923031449317932, Accuracy: 0.75390625\n",
      "Batch: 71, Loss: 0.7999680042266846, Accuracy: 0.720703125\n",
      "Batch: 72, Loss: 0.7286913990974426, Accuracy: 0.7607421875\n",
      "Batch: 73, Loss: 0.7181397676467896, Accuracy: 0.779296875\n",
      "Batch: 74, Loss: 0.6936689615249634, Accuracy: 0.7880859375\n",
      "Batch: 75, Loss: 0.7197822332382202, Accuracy: 0.767578125\n",
      "Batch: 76, Loss: 0.8023457527160645, Accuracy: 0.736328125\n",
      "Batch: 77, Loss: 0.777615487575531, Accuracy: 0.740234375\n",
      "Batch: 78, Loss: 0.6956283450126648, Accuracy: 0.775390625\n",
      "Batch: 79, Loss: 0.6602450609207153, Accuracy: 0.7958984375\n",
      "Batch: 80, Loss: 0.7402027249336243, Accuracy: 0.7509765625\n",
      "Batch: 81, Loss: 0.8624318838119507, Accuracy: 0.6962890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 82, Loss: 0.8159583806991577, Accuracy: 0.7255859375\n",
      "Batch: 83, Loss: 0.6742619276046753, Accuracy: 0.787109375\n",
      "Batch: 84, Loss: 0.7317686080932617, Accuracy: 0.76171875\n",
      "Batch: 85, Loss: 0.719637393951416, Accuracy: 0.767578125\n",
      "Batch: 86, Loss: 0.8861557245254517, Accuracy: 0.712890625\n",
      "Batch: 87, Loss: 0.7046937346458435, Accuracy: 0.763671875\n",
      "Batch: 88, Loss: 0.836195170879364, Accuracy: 0.7412109375\n",
      "Batch: 89, Loss: 0.8424230813980103, Accuracy: 0.73828125\n",
      "Batch: 90, Loss: 0.7775832414627075, Accuracy: 0.7470703125\n",
      "Batch: 91, Loss: 0.7604997158050537, Accuracy: 0.7470703125\n",
      "Batch: 92, Loss: 0.8042011857032776, Accuracy: 0.732421875\n",
      "Batch: 93, Loss: 0.7738322019577026, Accuracy: 0.7490234375\n",
      "Batch: 94, Loss: 0.799206018447876, Accuracy: 0.7236328125\n",
      "Batch: 95, Loss: 0.8352292776107788, Accuracy: 0.7138671875\n",
      "Batch: 96, Loss: 0.7594645023345947, Accuracy: 0.73828125\n",
      "Batch: 97, Loss: 0.6322365999221802, Accuracy: 0.791015625\n",
      "Batch: 98, Loss: 0.7854675054550171, Accuracy: 0.744140625\n",
      "Batch: 99, Loss: 0.7818762063980103, Accuracy: 0.7333984375\n",
      "Batch: 100, Loss: 0.796952486038208, Accuracy: 0.740234375\n",
      "Batch: 101, Loss: 0.7976449728012085, Accuracy: 0.7275390625\n",
      "Batch: 102, Loss: 0.7955914735794067, Accuracy: 0.748046875\n",
      "Batch: 103, Loss: 0.8157814741134644, Accuracy: 0.7431640625\n",
      "Batch: 104, Loss: 0.7624374628067017, Accuracy: 0.7451171875\n",
      "Batch: 105, Loss: 0.8024829626083374, Accuracy: 0.736328125\n",
      "Batch: 106, Loss: 0.7581056356430054, Accuracy: 0.76171875\n",
      "Batch: 107, Loss: 0.8016483783721924, Accuracy: 0.7578125\n",
      "Batch: 108, Loss: 0.8207423686981201, Accuracy: 0.7275390625\n",
      "Batch: 109, Loss: 0.9426702857017517, Accuracy: 0.6875\n",
      "Batch: 110, Loss: 0.7228067517280579, Accuracy: 0.759765625\n",
      "Batch: 111, Loss: 0.8386589288711548, Accuracy: 0.7119140625\n",
      "Batch: 112, Loss: 0.765642523765564, Accuracy: 0.7548828125\n",
      "Batch: 113, Loss: 0.7791825532913208, Accuracy: 0.7548828125\n",
      "Batch: 114, Loss: 0.8687299489974976, Accuracy: 0.71875\n",
      "Batch: 115, Loss: 0.8771068453788757, Accuracy: 0.7275390625\n",
      "Batch: 116, Loss: 0.8319205045700073, Accuracy: 0.732421875\n",
      "Batch: 117, Loss: 0.8271593451499939, Accuracy: 0.732421875\n",
      "Batch: 118, Loss: 0.6953924894332886, Accuracy: 0.78125\n",
      "Batch: 119, Loss: 0.6935120820999146, Accuracy: 0.779296875\n",
      "Batch: 120, Loss: 0.7772492170333862, Accuracy: 0.7373046875\n",
      "Batch: 121, Loss: 0.8422263860702515, Accuracy: 0.70703125\n",
      "Batch: 122, Loss: 0.7370619773864746, Accuracy: 0.7734375\n",
      "Batch: 123, Loss: 0.7184869647026062, Accuracy: 0.7626953125\n",
      "Batch: 124, Loss: 0.7924528121948242, Accuracy: 0.7412109375\n",
      "Batch: 125, Loss: 0.8215898871421814, Accuracy: 0.728515625\n",
      "Batch: 126, Loss: 0.7932687997817993, Accuracy: 0.7490234375\n",
      "Batch: 127, Loss: 0.7164385318756104, Accuracy: 0.7802734375\n",
      "Batch: 128, Loss: 0.8580483198165894, Accuracy: 0.73828125\n",
      "Batch: 129, Loss: 0.7405079007148743, Accuracy: 0.7568359375\n",
      "Batch: 130, Loss: 0.8897533416748047, Accuracy: 0.705078125\n",
      "Batch: 131, Loss: 0.7761982679367065, Accuracy: 0.7431640625\n",
      "Batch: 132, Loss: 0.778174102306366, Accuracy: 0.75\n",
      "Batch: 133, Loss: 0.7540032863616943, Accuracy: 0.76171875\n",
      "Batch: 134, Loss: 0.8196595311164856, Accuracy: 0.7236328125\n",
      "Batch: 135, Loss: 0.7023494243621826, Accuracy: 0.775390625\n",
      "Batch: 136, Loss: 0.7954394817352295, Accuracy: 0.740234375\n",
      "Batch: 137, Loss: 0.7517173290252686, Accuracy: 0.732421875\n",
      "Batch: 138, Loss: 0.6763551235198975, Accuracy: 0.7744140625\n",
      "Batch: 139, Loss: 0.7488695383071899, Accuracy: 0.7568359375\n",
      "Batch: 140, Loss: 0.7475761771202087, Accuracy: 0.7607421875\n",
      "Batch: 141, Loss: 0.8429641723632812, Accuracy: 0.7109375\n",
      "Batch: 142, Loss: 0.8445345163345337, Accuracy: 0.7216796875\n",
      "Batch: 143, Loss: 0.8012797832489014, Accuracy: 0.7138671875\n",
      "Batch: 144, Loss: 0.7865372896194458, Accuracy: 0.734375\n",
      "Batch: 145, Loss: 0.7363055944442749, Accuracy: 0.7333984375\n",
      "Batch: 146, Loss: 0.8145343065261841, Accuracy: 0.734375\n",
      "Batch: 147, Loss: 0.8052948713302612, Accuracy: 0.734375\n",
      "Batch: 148, Loss: 0.8902177810668945, Accuracy: 0.7041015625\n",
      "Batch: 149, Loss: 0.7773157954216003, Accuracy: 0.736328125\n",
      "Batch: 150, Loss: 0.763241171836853, Accuracy: 0.7373046875\n",
      "Batch: 151, Loss: 0.6670257449150085, Accuracy: 0.78515625\n",
      "Saved Weights at epoch 50 to file Weights_50.h5\n",
      "Epoch 51/80\n",
      "Batch: 1, Loss: 1.0048203468322754, Accuracy: 0.6748046875\n",
      "Batch: 2, Loss: 0.8567731380462646, Accuracy: 0.701171875\n",
      "Batch: 3, Loss: 0.7500215768814087, Accuracy: 0.744140625\n",
      "Batch: 4, Loss: 0.6742174625396729, Accuracy: 0.787109375\n",
      "Batch: 5, Loss: 0.7510724067687988, Accuracy: 0.7568359375\n",
      "Batch: 6, Loss: 0.7762143015861511, Accuracy: 0.732421875\n",
      "Batch: 7, Loss: 0.7750975489616394, Accuracy: 0.740234375\n",
      "Batch: 8, Loss: 0.7386552691459656, Accuracy: 0.7470703125\n",
      "Batch: 9, Loss: 0.7303588390350342, Accuracy: 0.7626953125\n",
      "Batch: 10, Loss: 0.7581381797790527, Accuracy: 0.736328125\n",
      "Batch: 11, Loss: 0.8486747741699219, Accuracy: 0.716796875\n",
      "Batch: 12, Loss: 0.8554563522338867, Accuracy: 0.7255859375\n",
      "Batch: 13, Loss: 0.6635676622390747, Accuracy: 0.7822265625\n",
      "Batch: 14, Loss: 0.8705469965934753, Accuracy: 0.7177734375\n",
      "Batch: 15, Loss: 0.6919978260993958, Accuracy: 0.78515625\n",
      "Batch: 16, Loss: 0.7674692869186401, Accuracy: 0.7509765625\n",
      "Batch: 17, Loss: 0.8341884613037109, Accuracy: 0.732421875\n",
      "Batch: 18, Loss: 0.8354073762893677, Accuracy: 0.73828125\n",
      "Batch: 19, Loss: 0.8029707670211792, Accuracy: 0.744140625\n",
      "Batch: 20, Loss: 0.7034176588058472, Accuracy: 0.77734375\n",
      "Batch: 21, Loss: 0.7406477928161621, Accuracy: 0.76171875\n",
      "Batch: 22, Loss: 0.8633140921592712, Accuracy: 0.716796875\n",
      "Batch: 23, Loss: 0.7827215194702148, Accuracy: 0.7353515625\n",
      "Batch: 24, Loss: 0.815757155418396, Accuracy: 0.724609375\n",
      "Batch: 25, Loss: 0.7705469131469727, Accuracy: 0.7529296875\n",
      "Batch: 26, Loss: 0.6634486317634583, Accuracy: 0.775390625\n",
      "Batch: 27, Loss: 0.7487085461616516, Accuracy: 0.7626953125\n",
      "Batch: 28, Loss: 0.8108861446380615, Accuracy: 0.7294921875\n",
      "Batch: 29, Loss: 0.7537301778793335, Accuracy: 0.7431640625\n",
      "Batch: 30, Loss: 0.6848464012145996, Accuracy: 0.78515625\n",
      "Batch: 31, Loss: 0.6707996129989624, Accuracy: 0.787109375\n",
      "Batch: 32, Loss: 0.7425930500030518, Accuracy: 0.7470703125\n",
      "Batch: 33, Loss: 0.8427389860153198, Accuracy: 0.7314453125\n",
      "Batch: 34, Loss: 0.8887881636619568, Accuracy: 0.716796875\n",
      "Batch: 35, Loss: 0.7813465595245361, Accuracy: 0.7431640625\n",
      "Batch: 36, Loss: 0.8519145846366882, Accuracy: 0.7392578125\n",
      "Batch: 37, Loss: 0.7963538765907288, Accuracy: 0.7353515625\n",
      "Batch: 38, Loss: 0.8085533380508423, Accuracy: 0.72265625\n",
      "Batch: 39, Loss: 0.7903146147727966, Accuracy: 0.7490234375\n",
      "Batch: 40, Loss: 0.7723573446273804, Accuracy: 0.7431640625\n",
      "Batch: 41, Loss: 0.722022294998169, Accuracy: 0.7685546875\n",
      "Batch: 42, Loss: 0.6343622207641602, Accuracy: 0.783203125\n",
      "Batch: 43, Loss: 0.8254535794258118, Accuracy: 0.7109375\n",
      "Batch: 44, Loss: 0.8270021080970764, Accuracy: 0.712890625\n",
      "Batch: 45, Loss: 0.729986846446991, Accuracy: 0.7646484375\n",
      "Batch: 46, Loss: 0.6962997913360596, Accuracy: 0.78125\n",
      "Batch: 47, Loss: 0.7267007827758789, Accuracy: 0.7763671875\n",
      "Batch: 48, Loss: 0.7003406286239624, Accuracy: 0.7646484375\n",
      "Batch: 49, Loss: 0.8196561336517334, Accuracy: 0.7197265625\n",
      "Batch: 50, Loss: 0.813522458076477, Accuracy: 0.7177734375\n",
      "Batch: 51, Loss: 0.8435144424438477, Accuracy: 0.71875\n",
      "Batch: 52, Loss: 0.7805647850036621, Accuracy: 0.74609375\n",
      "Batch: 53, Loss: 0.7305135726928711, Accuracy: 0.744140625\n",
      "Batch: 54, Loss: 0.7792528867721558, Accuracy: 0.7490234375\n",
      "Batch: 55, Loss: 0.9013382196426392, Accuracy: 0.6982421875\n",
      "Batch: 56, Loss: 0.8412095308303833, Accuracy: 0.7109375\n",
      "Batch: 57, Loss: 0.8001824617385864, Accuracy: 0.74609375\n",
      "Batch: 58, Loss: 0.9046252965927124, Accuracy: 0.724609375\n",
      "Batch: 59, Loss: 0.7309956550598145, Accuracy: 0.767578125\n",
      "Batch: 60, Loss: 0.7227717638015747, Accuracy: 0.7685546875\n",
      "Batch: 61, Loss: 0.8060142993927002, Accuracy: 0.748046875\n",
      "Batch: 62, Loss: 0.7587388157844543, Accuracy: 0.7529296875\n",
      "Batch: 63, Loss: 0.7980835437774658, Accuracy: 0.7451171875\n",
      "Batch: 64, Loss: 0.7652183175086975, Accuracy: 0.7392578125\n",
      "Batch: 65, Loss: 0.8157687783241272, Accuracy: 0.73046875\n",
      "Batch: 66, Loss: 0.7670215368270874, Accuracy: 0.7578125\n",
      "Batch: 67, Loss: 0.8644073009490967, Accuracy: 0.720703125\n",
      "Batch: 68, Loss: 0.9056010246276855, Accuracy: 0.716796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 69, Loss: 0.8086234927177429, Accuracy: 0.7353515625\n",
      "Batch: 70, Loss: 0.7882806062698364, Accuracy: 0.75\n",
      "Batch: 71, Loss: 0.8337398171424866, Accuracy: 0.7197265625\n",
      "Batch: 72, Loss: 0.7238101959228516, Accuracy: 0.7587890625\n",
      "Batch: 73, Loss: 0.7093449831008911, Accuracy: 0.7802734375\n",
      "Batch: 74, Loss: 0.6950099468231201, Accuracy: 0.7802734375\n",
      "Batch: 75, Loss: 0.7131277918815613, Accuracy: 0.771484375\n",
      "Batch: 76, Loss: 0.7958219051361084, Accuracy: 0.7421875\n",
      "Batch: 77, Loss: 0.7256814241409302, Accuracy: 0.7734375\n",
      "Batch: 78, Loss: 0.7057826519012451, Accuracy: 0.771484375\n",
      "Batch: 79, Loss: 0.6600214242935181, Accuracy: 0.7841796875\n",
      "Batch: 80, Loss: 0.7550033926963806, Accuracy: 0.74609375\n",
      "Batch: 81, Loss: 0.864790678024292, Accuracy: 0.70703125\n",
      "Batch: 82, Loss: 0.797678530216217, Accuracy: 0.7255859375\n",
      "Batch: 83, Loss: 0.6846566200256348, Accuracy: 0.7822265625\n",
      "Batch: 84, Loss: 0.7573533058166504, Accuracy: 0.7578125\n",
      "Batch: 85, Loss: 0.7327091693878174, Accuracy: 0.765625\n",
      "Batch: 86, Loss: 0.8984552621841431, Accuracy: 0.71484375\n",
      "Batch: 87, Loss: 0.692225456237793, Accuracy: 0.7724609375\n",
      "Batch: 88, Loss: 0.8094226121902466, Accuracy: 0.75\n",
      "Batch: 89, Loss: 0.8290449380874634, Accuracy: 0.744140625\n",
      "Batch: 90, Loss: 0.7475360631942749, Accuracy: 0.7646484375\n",
      "Batch: 91, Loss: 0.7471351623535156, Accuracy: 0.7626953125\n",
      "Batch: 92, Loss: 0.8041826486587524, Accuracy: 0.744140625\n",
      "Batch: 93, Loss: 0.7578930258750916, Accuracy: 0.7548828125\n",
      "Batch: 94, Loss: 0.7920528650283813, Accuracy: 0.7353515625\n",
      "Batch: 95, Loss: 0.8194931745529175, Accuracy: 0.7177734375\n",
      "Batch: 96, Loss: 0.7647154331207275, Accuracy: 0.7333984375\n",
      "Batch: 97, Loss: 0.6322134733200073, Accuracy: 0.7822265625\n",
      "Batch: 98, Loss: 0.7369328737258911, Accuracy: 0.76171875\n",
      "Batch: 99, Loss: 0.7527798414230347, Accuracy: 0.734375\n",
      "Batch: 100, Loss: 0.7902930974960327, Accuracy: 0.740234375\n",
      "Batch: 101, Loss: 0.8064547777175903, Accuracy: 0.7392578125\n",
      "Batch: 102, Loss: 0.786967933177948, Accuracy: 0.7470703125\n",
      "Batch: 103, Loss: 0.7806817293167114, Accuracy: 0.7529296875\n",
      "Batch: 104, Loss: 0.7433062791824341, Accuracy: 0.7568359375\n",
      "Batch: 105, Loss: 0.8014869093894958, Accuracy: 0.73828125\n",
      "Batch: 106, Loss: 0.742422342300415, Accuracy: 0.7607421875\n",
      "Batch: 107, Loss: 0.7757327556610107, Accuracy: 0.7548828125\n",
      "Batch: 108, Loss: 0.8254668116569519, Accuracy: 0.7216796875\n",
      "Batch: 109, Loss: 0.9052814245223999, Accuracy: 0.701171875\n",
      "Batch: 110, Loss: 0.7241382598876953, Accuracy: 0.7470703125\n",
      "Batch: 111, Loss: 0.8437401652336121, Accuracy: 0.705078125\n",
      "Batch: 112, Loss: 0.7612936496734619, Accuracy: 0.75390625\n",
      "Batch: 113, Loss: 0.7698272466659546, Accuracy: 0.75390625\n",
      "Batch: 114, Loss: 0.8564908504486084, Accuracy: 0.7216796875\n",
      "Batch: 115, Loss: 0.9116120934486389, Accuracy: 0.7119140625\n",
      "Batch: 116, Loss: 0.8115901947021484, Accuracy: 0.7353515625\n",
      "Batch: 117, Loss: 0.8287696838378906, Accuracy: 0.728515625\n",
      "Batch: 118, Loss: 0.6996171474456787, Accuracy: 0.7822265625\n",
      "Batch: 119, Loss: 0.6664376258850098, Accuracy: 0.7822265625\n",
      "Batch: 120, Loss: 0.8249943256378174, Accuracy: 0.7333984375\n",
      "Batch: 121, Loss: 0.8531515598297119, Accuracy: 0.7216796875\n",
      "Batch: 122, Loss: 0.7291104793548584, Accuracy: 0.763671875\n",
      "Batch: 123, Loss: 0.7253760099411011, Accuracy: 0.76171875\n",
      "Batch: 124, Loss: 0.7923401594161987, Accuracy: 0.7353515625\n",
      "Batch: 125, Loss: 0.8451526761054993, Accuracy: 0.71875\n",
      "Batch: 126, Loss: 0.8173314332962036, Accuracy: 0.7451171875\n",
      "Batch: 127, Loss: 0.7159245610237122, Accuracy: 0.7587890625\n",
      "Batch: 128, Loss: 0.8360937237739563, Accuracy: 0.744140625\n",
      "Batch: 129, Loss: 0.7081241607666016, Accuracy: 0.767578125\n",
      "Batch: 130, Loss: 0.8959903717041016, Accuracy: 0.7177734375\n",
      "Batch: 131, Loss: 0.7993611097335815, Accuracy: 0.736328125\n",
      "Batch: 132, Loss: 0.7806991338729858, Accuracy: 0.7568359375\n",
      "Batch: 133, Loss: 0.7537209391593933, Accuracy: 0.7490234375\n",
      "Batch: 134, Loss: 0.8048300743103027, Accuracy: 0.71484375\n",
      "Batch: 135, Loss: 0.7076506614685059, Accuracy: 0.7734375\n",
      "Batch: 136, Loss: 0.784954309463501, Accuracy: 0.7392578125\n",
      "Batch: 137, Loss: 0.7857791185379028, Accuracy: 0.734375\n",
      "Batch: 138, Loss: 0.6573236584663391, Accuracy: 0.7841796875\n",
      "Batch: 139, Loss: 0.715883731842041, Accuracy: 0.7568359375\n",
      "Batch: 140, Loss: 0.7696734666824341, Accuracy: 0.7587890625\n",
      "Batch: 141, Loss: 0.8133684396743774, Accuracy: 0.7392578125\n",
      "Batch: 142, Loss: 0.8180645704269409, Accuracy: 0.7177734375\n",
      "Batch: 143, Loss: 0.75691819190979, Accuracy: 0.7509765625\n",
      "Batch: 144, Loss: 0.806513249874115, Accuracy: 0.7314453125\n",
      "Batch: 145, Loss: 0.7456566095352173, Accuracy: 0.7392578125\n",
      "Batch: 146, Loss: 0.8292599320411682, Accuracy: 0.7177734375\n",
      "Batch: 147, Loss: 0.8258352279663086, Accuracy: 0.7314453125\n",
      "Batch: 148, Loss: 0.8695616126060486, Accuracy: 0.712890625\n",
      "Batch: 149, Loss: 0.7741506099700928, Accuracy: 0.7333984375\n",
      "Batch: 150, Loss: 0.7662454843521118, Accuracy: 0.740234375\n",
      "Batch: 151, Loss: 0.678891658782959, Accuracy: 0.775390625\n",
      "Epoch 52/80\n",
      "Batch: 1, Loss: 0.9992080926895142, Accuracy: 0.68359375\n",
      "Batch: 2, Loss: 0.8757002353668213, Accuracy: 0.693359375\n",
      "Batch: 3, Loss: 0.7702367901802063, Accuracy: 0.7412109375\n",
      "Batch: 4, Loss: 0.661624550819397, Accuracy: 0.78125\n",
      "Batch: 5, Loss: 0.7541118860244751, Accuracy: 0.7470703125\n",
      "Batch: 6, Loss: 0.8019884824752808, Accuracy: 0.7353515625\n",
      "Batch: 7, Loss: 0.7850927114486694, Accuracy: 0.7412109375\n",
      "Batch: 8, Loss: 0.7406531572341919, Accuracy: 0.75\n",
      "Batch: 9, Loss: 0.7331805229187012, Accuracy: 0.76171875\n",
      "Batch: 10, Loss: 0.747268557548523, Accuracy: 0.7509765625\n",
      "Batch: 11, Loss: 0.8308199644088745, Accuracy: 0.7158203125\n",
      "Batch: 12, Loss: 0.8422364592552185, Accuracy: 0.73046875\n",
      "Batch: 13, Loss: 0.6715412139892578, Accuracy: 0.7783203125\n",
      "Batch: 14, Loss: 0.8431165814399719, Accuracy: 0.732421875\n",
      "Batch: 15, Loss: 0.7027817964553833, Accuracy: 0.78515625\n",
      "Batch: 16, Loss: 0.763080894947052, Accuracy: 0.7607421875\n",
      "Batch: 17, Loss: 0.8231098651885986, Accuracy: 0.7294921875\n",
      "Batch: 18, Loss: 0.8391786813735962, Accuracy: 0.7197265625\n",
      "Batch: 19, Loss: 0.8034152984619141, Accuracy: 0.7490234375\n",
      "Batch: 20, Loss: 0.6883135437965393, Accuracy: 0.775390625\n",
      "Batch: 21, Loss: 0.7300581932067871, Accuracy: 0.75390625\n",
      "Batch: 22, Loss: 0.8494275212287903, Accuracy: 0.73046875\n",
      "Batch: 23, Loss: 0.8172742128372192, Accuracy: 0.71875\n",
      "Batch: 24, Loss: 0.7848247289657593, Accuracy: 0.732421875\n",
      "Batch: 25, Loss: 0.7850297093391418, Accuracy: 0.744140625\n",
      "Batch: 26, Loss: 0.6670340299606323, Accuracy: 0.779296875\n",
      "Batch: 27, Loss: 0.7495859861373901, Accuracy: 0.744140625\n",
      "Batch: 28, Loss: 0.8018409013748169, Accuracy: 0.73046875\n",
      "Batch: 29, Loss: 0.7376004457473755, Accuracy: 0.7490234375\n",
      "Batch: 30, Loss: 0.6940590143203735, Accuracy: 0.78125\n",
      "Batch: 31, Loss: 0.6670419573783875, Accuracy: 0.7978515625\n",
      "Batch: 32, Loss: 0.7333586812019348, Accuracy: 0.74609375\n",
      "Batch: 33, Loss: 0.8355412483215332, Accuracy: 0.7314453125\n",
      "Batch: 34, Loss: 0.9040560126304626, Accuracy: 0.69921875\n",
      "Batch: 35, Loss: 0.8081557750701904, Accuracy: 0.71875\n",
      "Batch: 36, Loss: 0.847510039806366, Accuracy: 0.740234375\n",
      "Batch: 37, Loss: 0.8025795221328735, Accuracy: 0.732421875\n",
      "Batch: 38, Loss: 0.7807809114456177, Accuracy: 0.73046875\n",
      "Batch: 39, Loss: 0.8079907894134521, Accuracy: 0.734375\n",
      "Batch: 40, Loss: 0.7531234622001648, Accuracy: 0.744140625\n",
      "Batch: 41, Loss: 0.7112356424331665, Accuracy: 0.771484375\n",
      "Batch: 42, Loss: 0.6153883934020996, Accuracy: 0.7861328125\n",
      "Batch: 43, Loss: 0.8066481351852417, Accuracy: 0.7265625\n",
      "Batch: 44, Loss: 0.8070398569107056, Accuracy: 0.7255859375\n",
      "Batch: 45, Loss: 0.7282451391220093, Accuracy: 0.755859375\n",
      "Batch: 46, Loss: 0.6838017702102661, Accuracy: 0.76953125\n",
      "Batch: 47, Loss: 0.7229872941970825, Accuracy: 0.78125\n",
      "Batch: 48, Loss: 0.682467520236969, Accuracy: 0.7744140625\n",
      "Batch: 49, Loss: 0.8178644180297852, Accuracy: 0.7216796875\n",
      "Batch: 50, Loss: 0.8190200328826904, Accuracy: 0.7197265625\n",
      "Batch: 51, Loss: 0.8345954418182373, Accuracy: 0.7421875\n",
      "Batch: 52, Loss: 0.7975785732269287, Accuracy: 0.7412109375\n",
      "Batch: 53, Loss: 0.7458867430686951, Accuracy: 0.7314453125\n",
      "Batch: 54, Loss: 0.7798606157302856, Accuracy: 0.7490234375\n",
      "Batch: 55, Loss: 0.876847505569458, Accuracy: 0.71484375\n",
      "Batch: 56, Loss: 0.8782206773757935, Accuracy: 0.71875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 57, Loss: 0.7894716858863831, Accuracy: 0.7353515625\n",
      "Batch: 58, Loss: 0.9077023267745972, Accuracy: 0.7138671875\n",
      "Batch: 59, Loss: 0.7448650598526001, Accuracy: 0.748046875\n",
      "Batch: 60, Loss: 0.6956612467765808, Accuracy: 0.77734375\n",
      "Batch: 61, Loss: 0.782319962978363, Accuracy: 0.7529296875\n",
      "Batch: 62, Loss: 0.7495670318603516, Accuracy: 0.7509765625\n",
      "Batch: 63, Loss: 0.780800461769104, Accuracy: 0.7431640625\n",
      "Batch: 64, Loss: 0.768183171749115, Accuracy: 0.744140625\n",
      "Batch: 65, Loss: 0.8054255247116089, Accuracy: 0.7421875\n",
      "Batch: 66, Loss: 0.7362744212150574, Accuracy: 0.779296875\n",
      "Batch: 67, Loss: 0.8267205953598022, Accuracy: 0.7392578125\n",
      "Batch: 68, Loss: 0.861751914024353, Accuracy: 0.73828125\n",
      "Batch: 69, Loss: 0.8088041543960571, Accuracy: 0.734375\n",
      "Batch: 70, Loss: 0.7652596235275269, Accuracy: 0.7626953125\n",
      "Batch: 71, Loss: 0.8216121792793274, Accuracy: 0.72265625\n",
      "Batch: 72, Loss: 0.6999098062515259, Accuracy: 0.7666015625\n",
      "Batch: 73, Loss: 0.706635594367981, Accuracy: 0.7841796875\n",
      "Batch: 74, Loss: 0.6867297887802124, Accuracy: 0.7685546875\n",
      "Batch: 75, Loss: 0.7202219367027283, Accuracy: 0.7705078125\n",
      "Batch: 76, Loss: 0.8039642572402954, Accuracy: 0.73046875\n",
      "Batch: 77, Loss: 0.7436587810516357, Accuracy: 0.7529296875\n",
      "Batch: 78, Loss: 0.6713465452194214, Accuracy: 0.7802734375\n",
      "Batch: 79, Loss: 0.6347559690475464, Accuracy: 0.8046875\n",
      "Batch: 80, Loss: 0.7443230152130127, Accuracy: 0.75\n",
      "Batch: 81, Loss: 0.8791422843933105, Accuracy: 0.7021484375\n",
      "Batch: 82, Loss: 0.7793139815330505, Accuracy: 0.740234375\n",
      "Batch: 83, Loss: 0.6765152215957642, Accuracy: 0.7783203125\n",
      "Batch: 84, Loss: 0.7393107414245605, Accuracy: 0.7587890625\n",
      "Batch: 85, Loss: 0.7417948246002197, Accuracy: 0.755859375\n",
      "Batch: 86, Loss: 0.8626437187194824, Accuracy: 0.7197265625\n",
      "Batch: 87, Loss: 0.7012643218040466, Accuracy: 0.7822265625\n",
      "Batch: 88, Loss: 0.8249103426933289, Accuracy: 0.736328125\n",
      "Batch: 89, Loss: 0.8190653920173645, Accuracy: 0.74609375\n",
      "Batch: 90, Loss: 0.7113635540008545, Accuracy: 0.77734375\n",
      "Batch: 91, Loss: 0.7540296912193298, Accuracy: 0.7509765625\n",
      "Batch: 92, Loss: 0.775821328163147, Accuracy: 0.73828125\n",
      "Batch: 93, Loss: 0.7879085540771484, Accuracy: 0.7314453125\n",
      "Batch: 94, Loss: 0.7762201428413391, Accuracy: 0.7490234375\n",
      "Batch: 95, Loss: 0.813707709312439, Accuracy: 0.7236328125\n",
      "Batch: 96, Loss: 0.7518121004104614, Accuracy: 0.76171875\n",
      "Batch: 97, Loss: 0.634721040725708, Accuracy: 0.7841796875\n",
      "Batch: 98, Loss: 0.7483530044555664, Accuracy: 0.7548828125\n",
      "Batch: 99, Loss: 0.7382789254188538, Accuracy: 0.7578125\n",
      "Batch: 100, Loss: 0.7852339744567871, Accuracy: 0.7490234375\n",
      "Batch: 101, Loss: 0.8075590133666992, Accuracy: 0.7392578125\n",
      "Batch: 102, Loss: 0.789303183555603, Accuracy: 0.75\n",
      "Batch: 103, Loss: 0.7965981960296631, Accuracy: 0.74609375\n",
      "Batch: 104, Loss: 0.7282568216323853, Accuracy: 0.7373046875\n",
      "Batch: 105, Loss: 0.8295315504074097, Accuracy: 0.73828125\n",
      "Batch: 106, Loss: 0.7194961309432983, Accuracy: 0.767578125\n",
      "Batch: 107, Loss: 0.772979736328125, Accuracy: 0.7587890625\n",
      "Batch: 108, Loss: 0.7911917567253113, Accuracy: 0.7216796875\n",
      "Batch: 109, Loss: 0.8923153877258301, Accuracy: 0.7041015625\n",
      "Batch: 110, Loss: 0.6986786127090454, Accuracy: 0.7548828125\n",
      "Batch: 111, Loss: 0.8234819173812866, Accuracy: 0.7265625\n",
      "Batch: 112, Loss: 0.7814826369285583, Accuracy: 0.7587890625\n",
      "Batch: 113, Loss: 0.7578596472740173, Accuracy: 0.759765625\n",
      "Batch: 114, Loss: 0.8664327263832092, Accuracy: 0.7236328125\n",
      "Batch: 115, Loss: 0.9060818552970886, Accuracy: 0.7255859375\n",
      "Batch: 116, Loss: 0.7904407978057861, Accuracy: 0.75\n",
      "Batch: 117, Loss: 0.825955867767334, Accuracy: 0.736328125\n",
      "Batch: 118, Loss: 0.7111955285072327, Accuracy: 0.7744140625\n",
      "Batch: 119, Loss: 0.6737873554229736, Accuracy: 0.7841796875\n",
      "Batch: 120, Loss: 0.7928667068481445, Accuracy: 0.7333984375\n",
      "Batch: 121, Loss: 0.822604775428772, Accuracy: 0.73828125\n",
      "Batch: 122, Loss: 0.7349634170532227, Accuracy: 0.7705078125\n",
      "Batch: 123, Loss: 0.6745027303695679, Accuracy: 0.7841796875\n",
      "Batch: 124, Loss: 0.7818325161933899, Accuracy: 0.736328125\n",
      "Batch: 125, Loss: 0.8359296321868896, Accuracy: 0.71875\n",
      "Batch: 126, Loss: 0.752518892288208, Accuracy: 0.7607421875\n",
      "Batch: 127, Loss: 0.7118953466415405, Accuracy: 0.7802734375\n",
      "Batch: 128, Loss: 0.8326090574264526, Accuracy: 0.75\n",
      "Batch: 129, Loss: 0.6996464133262634, Accuracy: 0.775390625\n",
      "Batch: 130, Loss: 0.8905491828918457, Accuracy: 0.7080078125\n",
      "Batch: 131, Loss: 0.7591841220855713, Accuracy: 0.7421875\n",
      "Batch: 132, Loss: 0.8196735382080078, Accuracy: 0.7353515625\n",
      "Batch: 133, Loss: 0.7287040948867798, Accuracy: 0.759765625\n",
      "Batch: 134, Loss: 0.7976386547088623, Accuracy: 0.7294921875\n",
      "Batch: 135, Loss: 0.7129383087158203, Accuracy: 0.767578125\n",
      "Batch: 136, Loss: 0.7888017892837524, Accuracy: 0.75\n",
      "Batch: 137, Loss: 0.7986137866973877, Accuracy: 0.7314453125\n",
      "Batch: 138, Loss: 0.6800225973129272, Accuracy: 0.7705078125\n",
      "Batch: 139, Loss: 0.7383104562759399, Accuracy: 0.76171875\n",
      "Batch: 140, Loss: 0.7467149496078491, Accuracy: 0.74609375\n",
      "Batch: 141, Loss: 0.8096731901168823, Accuracy: 0.7353515625\n",
      "Batch: 142, Loss: 0.8282438516616821, Accuracy: 0.73828125\n",
      "Batch: 143, Loss: 0.7811665534973145, Accuracy: 0.7294921875\n",
      "Batch: 144, Loss: 0.7774739265441895, Accuracy: 0.7421875\n",
      "Batch: 145, Loss: 0.7554510235786438, Accuracy: 0.744140625\n",
      "Batch: 146, Loss: 0.8202139139175415, Accuracy: 0.720703125\n",
      "Batch: 147, Loss: 0.8379730582237244, Accuracy: 0.7265625\n",
      "Batch: 148, Loss: 0.8683738112449646, Accuracy: 0.7109375\n",
      "Batch: 149, Loss: 0.7480003833770752, Accuracy: 0.736328125\n",
      "Batch: 150, Loss: 0.7364755272865295, Accuracy: 0.7490234375\n",
      "Batch: 151, Loss: 0.6691738963127136, Accuracy: 0.7685546875\n",
      "Epoch 53/80\n",
      "Batch: 1, Loss: 1.013443946838379, Accuracy: 0.6884765625\n",
      "Batch: 2, Loss: 0.871704638004303, Accuracy: 0.689453125\n",
      "Batch: 3, Loss: 0.7400332093238831, Accuracy: 0.75390625\n",
      "Batch: 4, Loss: 0.659804105758667, Accuracy: 0.7861328125\n",
      "Batch: 5, Loss: 0.7253627181053162, Accuracy: 0.763671875\n",
      "Batch: 6, Loss: 0.7959729433059692, Accuracy: 0.7236328125\n",
      "Batch: 7, Loss: 0.7676640748977661, Accuracy: 0.7421875\n",
      "Batch: 8, Loss: 0.7165783643722534, Accuracy: 0.765625\n",
      "Batch: 9, Loss: 0.7508652210235596, Accuracy: 0.765625\n",
      "Batch: 10, Loss: 0.7405320405960083, Accuracy: 0.7431640625\n",
      "Batch: 11, Loss: 0.8457591533660889, Accuracy: 0.7275390625\n",
      "Batch: 12, Loss: 0.824882984161377, Accuracy: 0.7294921875\n",
      "Batch: 13, Loss: 0.665922999382019, Accuracy: 0.77734375\n",
      "Batch: 14, Loss: 0.8256440162658691, Accuracy: 0.7275390625\n",
      "Batch: 15, Loss: 0.6609532237052917, Accuracy: 0.783203125\n",
      "Batch: 16, Loss: 0.7680622935295105, Accuracy: 0.7431640625\n",
      "Batch: 17, Loss: 0.8275406360626221, Accuracy: 0.736328125\n",
      "Batch: 18, Loss: 0.8390370011329651, Accuracy: 0.720703125\n",
      "Batch: 19, Loss: 0.8068174123764038, Accuracy: 0.736328125\n",
      "Batch: 20, Loss: 0.6912309527397156, Accuracy: 0.7724609375\n",
      "Batch: 21, Loss: 0.7530823945999146, Accuracy: 0.7392578125\n",
      "Batch: 22, Loss: 0.825780987739563, Accuracy: 0.7216796875\n",
      "Batch: 23, Loss: 0.8183398246765137, Accuracy: 0.728515625\n",
      "Batch: 24, Loss: 0.8047102689743042, Accuracy: 0.7353515625\n",
      "Batch: 25, Loss: 0.7945655584335327, Accuracy: 0.7373046875\n",
      "Batch: 26, Loss: 0.6857607960700989, Accuracy: 0.7646484375\n",
      "Batch: 27, Loss: 0.746883749961853, Accuracy: 0.7431640625\n",
      "Batch: 28, Loss: 0.7855292558670044, Accuracy: 0.73046875\n",
      "Batch: 29, Loss: 0.7350459694862366, Accuracy: 0.7353515625\n",
      "Batch: 30, Loss: 0.663276195526123, Accuracy: 0.79296875\n",
      "Batch: 31, Loss: 0.6709252595901489, Accuracy: 0.783203125\n",
      "Batch: 32, Loss: 0.6942706108093262, Accuracy: 0.76953125\n",
      "Batch: 33, Loss: 0.8281757831573486, Accuracy: 0.7255859375\n",
      "Batch: 34, Loss: 0.8814787864685059, Accuracy: 0.7099609375\n",
      "Batch: 35, Loss: 0.7586967945098877, Accuracy: 0.75390625\n",
      "Batch: 36, Loss: 0.8201476335525513, Accuracy: 0.748046875\n",
      "Batch: 37, Loss: 0.7681444883346558, Accuracy: 0.75\n",
      "Batch: 38, Loss: 0.8022443056106567, Accuracy: 0.7333984375\n",
      "Batch: 39, Loss: 0.7939958572387695, Accuracy: 0.73046875\n",
      "Batch: 40, Loss: 0.752575695514679, Accuracy: 0.7548828125\n",
      "Batch: 41, Loss: 0.7293833494186401, Accuracy: 0.759765625\n",
      "Batch: 42, Loss: 0.5924230813980103, Accuracy: 0.8037109375\n",
      "Batch: 43, Loss: 0.7936103343963623, Accuracy: 0.7236328125\n",
      "Batch: 44, Loss: 0.7724345922470093, Accuracy: 0.734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 45, Loss: 0.7261070609092712, Accuracy: 0.744140625\n",
      "Batch: 46, Loss: 0.6983836889266968, Accuracy: 0.7763671875\n",
      "Batch: 47, Loss: 0.7136971950531006, Accuracy: 0.7763671875\n",
      "Batch: 48, Loss: 0.6603736877441406, Accuracy: 0.7705078125\n",
      "Batch: 49, Loss: 0.7944062948226929, Accuracy: 0.744140625\n",
      "Batch: 50, Loss: 0.7773345708847046, Accuracy: 0.740234375\n",
      "Batch: 51, Loss: 0.8152741193771362, Accuracy: 0.7333984375\n",
      "Batch: 52, Loss: 0.7607303857803345, Accuracy: 0.75390625\n",
      "Batch: 53, Loss: 0.7260358929634094, Accuracy: 0.7578125\n",
      "Batch: 54, Loss: 0.7584333419799805, Accuracy: 0.748046875\n",
      "Batch: 55, Loss: 0.8598260879516602, Accuracy: 0.720703125\n",
      "Batch: 56, Loss: 0.8048871755599976, Accuracy: 0.71484375\n",
      "Batch: 57, Loss: 0.7846251726150513, Accuracy: 0.7529296875\n",
      "Batch: 58, Loss: 0.8938862085342407, Accuracy: 0.734375\n",
      "Batch: 59, Loss: 0.729554295539856, Accuracy: 0.7705078125\n",
      "Batch: 60, Loss: 0.6902599930763245, Accuracy: 0.7685546875\n",
      "Batch: 61, Loss: 0.7894439697265625, Accuracy: 0.7333984375\n",
      "Batch: 62, Loss: 0.749289870262146, Accuracy: 0.744140625\n",
      "Batch: 63, Loss: 0.774885356426239, Accuracy: 0.75\n",
      "Batch: 64, Loss: 0.7662661075592041, Accuracy: 0.7470703125\n",
      "Batch: 65, Loss: 0.7856175899505615, Accuracy: 0.7412109375\n",
      "Batch: 66, Loss: 0.7335942387580872, Accuracy: 0.7802734375\n",
      "Batch: 67, Loss: 0.8433266878128052, Accuracy: 0.74609375\n",
      "Batch: 68, Loss: 0.8762058019638062, Accuracy: 0.716796875\n",
      "Batch: 69, Loss: 0.7886389493942261, Accuracy: 0.74609375\n",
      "Batch: 70, Loss: 0.7618024945259094, Accuracy: 0.76953125\n",
      "Batch: 71, Loss: 0.8189873695373535, Accuracy: 0.71875\n",
      "Batch: 72, Loss: 0.6894512176513672, Accuracy: 0.763671875\n",
      "Batch: 73, Loss: 0.6960799098014832, Accuracy: 0.771484375\n",
      "Batch: 74, Loss: 0.6824209690093994, Accuracy: 0.7841796875\n",
      "Batch: 75, Loss: 0.7198793888092041, Accuracy: 0.7607421875\n",
      "Batch: 76, Loss: 0.7913932800292969, Accuracy: 0.73828125\n",
      "Batch: 77, Loss: 0.744260311126709, Accuracy: 0.75390625\n",
      "Batch: 78, Loss: 0.6943057775497437, Accuracy: 0.76953125\n",
      "Batch: 79, Loss: 0.6327521204948425, Accuracy: 0.7919921875\n",
      "Batch: 80, Loss: 0.7519926428794861, Accuracy: 0.7451171875\n",
      "Batch: 81, Loss: 0.8557310700416565, Accuracy: 0.7021484375\n",
      "Batch: 82, Loss: 0.8188983798027039, Accuracy: 0.7314453125\n",
      "Batch: 83, Loss: 0.670950174331665, Accuracy: 0.779296875\n",
      "Batch: 84, Loss: 0.742835283279419, Accuracy: 0.7548828125\n",
      "Batch: 85, Loss: 0.7180443406105042, Accuracy: 0.75390625\n",
      "Batch: 86, Loss: 0.9042569398880005, Accuracy: 0.7177734375\n",
      "Batch: 87, Loss: 0.7161320447921753, Accuracy: 0.759765625\n",
      "Batch: 88, Loss: 0.7724417448043823, Accuracy: 0.7392578125\n",
      "Batch: 89, Loss: 0.7901291251182556, Accuracy: 0.765625\n",
      "Batch: 90, Loss: 0.7439041137695312, Accuracy: 0.751953125\n",
      "Batch: 91, Loss: 0.742206335067749, Accuracy: 0.7626953125\n",
      "Batch: 92, Loss: 0.8075787425041199, Accuracy: 0.7333984375\n",
      "Batch: 93, Loss: 0.7630351781845093, Accuracy: 0.75\n",
      "Batch: 94, Loss: 0.7967630624771118, Accuracy: 0.7431640625\n",
      "Batch: 95, Loss: 0.8193842172622681, Accuracy: 0.7099609375\n",
      "Batch: 96, Loss: 0.7636317610740662, Accuracy: 0.75390625\n",
      "Batch: 97, Loss: 0.6300915479660034, Accuracy: 0.7880859375\n",
      "Batch: 98, Loss: 0.759621262550354, Accuracy: 0.748046875\n",
      "Batch: 99, Loss: 0.7409712672233582, Accuracy: 0.7421875\n",
      "Batch: 100, Loss: 0.797828197479248, Accuracy: 0.744140625\n",
      "Batch: 101, Loss: 0.8171665668487549, Accuracy: 0.7373046875\n",
      "Batch: 102, Loss: 0.8081891536712646, Accuracy: 0.74609375\n",
      "Batch: 103, Loss: 0.773391842842102, Accuracy: 0.7529296875\n",
      "Batch: 104, Loss: 0.7068363428115845, Accuracy: 0.751953125\n",
      "Batch: 105, Loss: 0.7745212912559509, Accuracy: 0.75\n",
      "Batch: 106, Loss: 0.7241798639297485, Accuracy: 0.7705078125\n",
      "Batch: 107, Loss: 0.7794870138168335, Accuracy: 0.7529296875\n",
      "Batch: 108, Loss: 0.7869918942451477, Accuracy: 0.7265625\n",
      "Batch: 109, Loss: 0.8825057148933411, Accuracy: 0.705078125\n",
      "Batch: 110, Loss: 0.7094262838363647, Accuracy: 0.7685546875\n",
      "Batch: 111, Loss: 0.8163822889328003, Accuracy: 0.7294921875\n",
      "Batch: 112, Loss: 0.7704266309738159, Accuracy: 0.73828125\n",
      "Batch: 113, Loss: 0.7785047292709351, Accuracy: 0.7470703125\n",
      "Batch: 114, Loss: 0.8321914672851562, Accuracy: 0.734375\n",
      "Batch: 115, Loss: 0.8692438006401062, Accuracy: 0.728515625\n",
      "Batch: 116, Loss: 0.7999155521392822, Accuracy: 0.7412109375\n",
      "Batch: 117, Loss: 0.8314635753631592, Accuracy: 0.7314453125\n",
      "Batch: 118, Loss: 0.6838846206665039, Accuracy: 0.783203125\n",
      "Batch: 119, Loss: 0.6901301145553589, Accuracy: 0.7822265625\n",
      "Batch: 120, Loss: 0.7889012098312378, Accuracy: 0.7431640625\n",
      "Batch: 121, Loss: 0.7975221872329712, Accuracy: 0.732421875\n",
      "Batch: 122, Loss: 0.7053801417350769, Accuracy: 0.76953125\n",
      "Batch: 123, Loss: 0.7187238931655884, Accuracy: 0.763671875\n",
      "Batch: 124, Loss: 0.7485740184783936, Accuracy: 0.7529296875\n",
      "Batch: 125, Loss: 0.8296891450881958, Accuracy: 0.740234375\n",
      "Batch: 126, Loss: 0.8072026968002319, Accuracy: 0.7333984375\n",
      "Batch: 127, Loss: 0.7049851417541504, Accuracy: 0.7666015625\n",
      "Batch: 128, Loss: 0.8646409511566162, Accuracy: 0.744140625\n",
      "Batch: 129, Loss: 0.6911840438842773, Accuracy: 0.765625\n",
      "Batch: 130, Loss: 0.8851500749588013, Accuracy: 0.7099609375\n",
      "Batch: 131, Loss: 0.774758517742157, Accuracy: 0.73046875\n",
      "Batch: 132, Loss: 0.7874622344970703, Accuracy: 0.7412109375\n",
      "Batch: 133, Loss: 0.710618257522583, Accuracy: 0.767578125\n",
      "Batch: 134, Loss: 0.7867730259895325, Accuracy: 0.7373046875\n",
      "Batch: 135, Loss: 0.6989285945892334, Accuracy: 0.7548828125\n",
      "Batch: 136, Loss: 0.7762384414672852, Accuracy: 0.7587890625\n",
      "Batch: 137, Loss: 0.7787903547286987, Accuracy: 0.7294921875\n",
      "Batch: 138, Loss: 0.6821732521057129, Accuracy: 0.7607421875\n",
      "Batch: 139, Loss: 0.7577523589134216, Accuracy: 0.7548828125\n",
      "Batch: 140, Loss: 0.7797127962112427, Accuracy: 0.73046875\n",
      "Batch: 141, Loss: 0.7867063879966736, Accuracy: 0.744140625\n",
      "Batch: 142, Loss: 0.7970186471939087, Accuracy: 0.7373046875\n",
      "Batch: 143, Loss: 0.7935583591461182, Accuracy: 0.7236328125\n",
      "Batch: 144, Loss: 0.7668899297714233, Accuracy: 0.748046875\n",
      "Batch: 145, Loss: 0.7091974020004272, Accuracy: 0.7490234375\n",
      "Batch: 146, Loss: 0.7904912233352661, Accuracy: 0.7353515625\n",
      "Batch: 147, Loss: 0.7723106145858765, Accuracy: 0.7353515625\n",
      "Batch: 148, Loss: 0.8747545480728149, Accuracy: 0.7060546875\n",
      "Batch: 149, Loss: 0.7255478501319885, Accuracy: 0.755859375\n",
      "Batch: 150, Loss: 0.7602354884147644, Accuracy: 0.75390625\n",
      "Batch: 151, Loss: 0.6730015277862549, Accuracy: 0.7822265625\n",
      "Epoch 54/80\n",
      "Batch: 1, Loss: 1.007637858390808, Accuracy: 0.6796875\n",
      "Batch: 2, Loss: 0.8531321287155151, Accuracy: 0.708984375\n",
      "Batch: 3, Loss: 0.7469420433044434, Accuracy: 0.7548828125\n",
      "Batch: 4, Loss: 0.6581361889839172, Accuracy: 0.779296875\n",
      "Batch: 5, Loss: 0.7246115207672119, Accuracy: 0.759765625\n",
      "Batch: 6, Loss: 0.7597537040710449, Accuracy: 0.736328125\n",
      "Batch: 7, Loss: 0.7665449976921082, Accuracy: 0.7392578125\n",
      "Batch: 8, Loss: 0.7382656335830688, Accuracy: 0.755859375\n",
      "Batch: 9, Loss: 0.7270492315292358, Accuracy: 0.7763671875\n",
      "Batch: 10, Loss: 0.7256962060928345, Accuracy: 0.7568359375\n",
      "Batch: 11, Loss: 0.8638173341751099, Accuracy: 0.7060546875\n",
      "Batch: 12, Loss: 0.8083624243736267, Accuracy: 0.7265625\n",
      "Batch: 13, Loss: 0.6500890851020813, Accuracy: 0.7861328125\n",
      "Batch: 14, Loss: 0.856835126876831, Accuracy: 0.7158203125\n",
      "Batch: 15, Loss: 0.6974869966506958, Accuracy: 0.7783203125\n",
      "Batch: 16, Loss: 0.7529340982437134, Accuracy: 0.7529296875\n",
      "Batch: 17, Loss: 0.8050640821456909, Accuracy: 0.728515625\n",
      "Batch: 18, Loss: 0.8027141094207764, Accuracy: 0.73828125\n",
      "Batch: 19, Loss: 0.8082388043403625, Accuracy: 0.74609375\n",
      "Batch: 20, Loss: 0.6634514331817627, Accuracy: 0.7822265625\n",
      "Batch: 21, Loss: 0.7330202460289001, Accuracy: 0.7578125\n",
      "Batch: 22, Loss: 0.8565850853919983, Accuracy: 0.71484375\n",
      "Batch: 23, Loss: 0.7928993701934814, Accuracy: 0.7333984375\n",
      "Batch: 24, Loss: 0.7944047451019287, Accuracy: 0.7353515625\n",
      "Batch: 25, Loss: 0.7729160785675049, Accuracy: 0.734375\n",
      "Batch: 26, Loss: 0.6533253788948059, Accuracy: 0.7763671875\n",
      "Batch: 27, Loss: 0.7194105386734009, Accuracy: 0.7578125\n",
      "Batch: 28, Loss: 0.7730555534362793, Accuracy: 0.7392578125\n",
      "Batch: 29, Loss: 0.7330640554428101, Accuracy: 0.7607421875\n",
      "Batch: 30, Loss: 0.6694713830947876, Accuracy: 0.77734375\n",
      "Batch: 31, Loss: 0.6762849688529968, Accuracy: 0.7685546875\n",
      "Batch: 32, Loss: 0.7077010869979858, Accuracy: 0.755859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 33, Loss: 0.8069740533828735, Accuracy: 0.73046875\n",
      "Batch: 34, Loss: 0.907194197177887, Accuracy: 0.7041015625\n",
      "Batch: 35, Loss: 0.7732129096984863, Accuracy: 0.7451171875\n",
      "Batch: 36, Loss: 0.808869481086731, Accuracy: 0.740234375\n",
      "Batch: 37, Loss: 0.7545112371444702, Accuracy: 0.7626953125\n",
      "Batch: 38, Loss: 0.8168265223503113, Accuracy: 0.728515625\n",
      "Batch: 39, Loss: 0.7832441329956055, Accuracy: 0.7421875\n",
      "Batch: 40, Loss: 0.7656071782112122, Accuracy: 0.755859375\n",
      "Batch: 41, Loss: 0.7069065570831299, Accuracy: 0.7724609375\n",
      "Batch: 42, Loss: 0.5960832834243774, Accuracy: 0.7919921875\n",
      "Batch: 43, Loss: 0.7959312200546265, Accuracy: 0.7373046875\n",
      "Batch: 44, Loss: 0.8127591609954834, Accuracy: 0.7353515625\n",
      "Batch: 45, Loss: 0.7088449597358704, Accuracy: 0.7568359375\n",
      "Batch: 46, Loss: 0.670035719871521, Accuracy: 0.7822265625\n",
      "Batch: 47, Loss: 0.6890398263931274, Accuracy: 0.7802734375\n",
      "Batch: 48, Loss: 0.6775450110435486, Accuracy: 0.7724609375\n",
      "Batch: 49, Loss: 0.7940405607223511, Accuracy: 0.73828125\n",
      "Batch: 50, Loss: 0.7966790199279785, Accuracy: 0.7294921875\n",
      "Batch: 51, Loss: 0.8055222034454346, Accuracy: 0.7373046875\n",
      "Batch: 52, Loss: 0.7647490501403809, Accuracy: 0.7509765625\n",
      "Batch: 53, Loss: 0.7410691380500793, Accuracy: 0.74609375\n",
      "Batch: 54, Loss: 0.7518453598022461, Accuracy: 0.7646484375\n",
      "Batch: 55, Loss: 0.8629015684127808, Accuracy: 0.7177734375\n",
      "Batch: 56, Loss: 0.8322632908821106, Accuracy: 0.7197265625\n",
      "Batch: 57, Loss: 0.7824832201004028, Accuracy: 0.7412109375\n",
      "Batch: 58, Loss: 0.8563680648803711, Accuracy: 0.724609375\n",
      "Batch: 59, Loss: 0.6951792240142822, Accuracy: 0.767578125\n",
      "Batch: 60, Loss: 0.685519814491272, Accuracy: 0.77734375\n",
      "Batch: 61, Loss: 0.7807432413101196, Accuracy: 0.7490234375\n",
      "Batch: 62, Loss: 0.7173402905464172, Accuracy: 0.7734375\n",
      "Batch: 63, Loss: 0.7686923742294312, Accuracy: 0.751953125\n",
      "Batch: 64, Loss: 0.7744371891021729, Accuracy: 0.7431640625\n",
      "Batch: 65, Loss: 0.7756975293159485, Accuracy: 0.7421875\n",
      "Batch: 66, Loss: 0.7468035221099854, Accuracy: 0.7705078125\n",
      "Batch: 67, Loss: 0.8178364038467407, Accuracy: 0.744140625\n",
      "Batch: 68, Loss: 0.8709996938705444, Accuracy: 0.7265625\n",
      "Batch: 69, Loss: 0.773914098739624, Accuracy: 0.7490234375\n",
      "Batch: 70, Loss: 0.784052848815918, Accuracy: 0.7587890625\n",
      "Batch: 71, Loss: 0.8291735053062439, Accuracy: 0.72265625\n",
      "Batch: 72, Loss: 0.6733235120773315, Accuracy: 0.7763671875\n",
      "Batch: 73, Loss: 0.7095261216163635, Accuracy: 0.76953125\n",
      "Batch: 74, Loss: 0.6794254779815674, Accuracy: 0.775390625\n",
      "Batch: 75, Loss: 0.6971371173858643, Accuracy: 0.7685546875\n",
      "Batch: 76, Loss: 0.7707067728042603, Accuracy: 0.75\n",
      "Batch: 77, Loss: 0.7425084114074707, Accuracy: 0.755859375\n",
      "Batch: 78, Loss: 0.6838549971580505, Accuracy: 0.78125\n",
      "Batch: 79, Loss: 0.608678936958313, Accuracy: 0.7939453125\n",
      "Batch: 80, Loss: 0.765770435333252, Accuracy: 0.7470703125\n",
      "Batch: 81, Loss: 0.8506500720977783, Accuracy: 0.705078125\n",
      "Batch: 82, Loss: 0.7947283983230591, Accuracy: 0.7373046875\n",
      "Batch: 83, Loss: 0.6823482513427734, Accuracy: 0.7880859375\n",
      "Batch: 84, Loss: 0.7214057445526123, Accuracy: 0.767578125\n",
      "Batch: 85, Loss: 0.7323509454727173, Accuracy: 0.7607421875\n",
      "Batch: 86, Loss: 0.8654052019119263, Accuracy: 0.7314453125\n",
      "Batch: 87, Loss: 0.7188177704811096, Accuracy: 0.7578125\n",
      "Batch: 88, Loss: 0.8130402565002441, Accuracy: 0.7294921875\n",
      "Batch: 89, Loss: 0.7924860119819641, Accuracy: 0.7470703125\n",
      "Batch: 90, Loss: 0.7221781015396118, Accuracy: 0.7724609375\n",
      "Batch: 91, Loss: 0.7281538248062134, Accuracy: 0.7470703125\n",
      "Batch: 92, Loss: 0.7795065641403198, Accuracy: 0.7578125\n",
      "Batch: 93, Loss: 0.7558830976486206, Accuracy: 0.7548828125\n",
      "Batch: 94, Loss: 0.8064438104629517, Accuracy: 0.744140625\n",
      "Batch: 95, Loss: 0.8150725960731506, Accuracy: 0.7294921875\n",
      "Batch: 96, Loss: 0.7614424824714661, Accuracy: 0.75\n",
      "Batch: 97, Loss: 0.6448571681976318, Accuracy: 0.7763671875\n",
      "Batch: 98, Loss: 0.7115528583526611, Accuracy: 0.7568359375\n",
      "Batch: 99, Loss: 0.7502063512802124, Accuracy: 0.7392578125\n",
      "Batch: 100, Loss: 0.7610584497451782, Accuracy: 0.7470703125\n",
      "Batch: 101, Loss: 0.8051135540008545, Accuracy: 0.7451171875\n",
      "Batch: 102, Loss: 0.7949929237365723, Accuracy: 0.75390625\n",
      "Batch: 103, Loss: 0.7642728686332703, Accuracy: 0.7607421875\n",
      "Batch: 104, Loss: 0.7246836423873901, Accuracy: 0.7490234375\n",
      "Batch: 105, Loss: 0.8068305253982544, Accuracy: 0.7314453125\n",
      "Batch: 106, Loss: 0.7134338021278381, Accuracy: 0.7822265625\n",
      "Batch: 107, Loss: 0.7599915862083435, Accuracy: 0.76953125\n",
      "Batch: 108, Loss: 0.7668277025222778, Accuracy: 0.759765625\n",
      "Batch: 109, Loss: 0.8773598670959473, Accuracy: 0.7080078125\n",
      "Batch: 110, Loss: 0.6988787651062012, Accuracy: 0.7705078125\n",
      "Batch: 111, Loss: 0.7821654677391052, Accuracy: 0.744140625\n",
      "Batch: 112, Loss: 0.7694047689437866, Accuracy: 0.755859375\n",
      "Batch: 113, Loss: 0.7339574098587036, Accuracy: 0.7744140625\n",
      "Batch: 114, Loss: 0.8353085517883301, Accuracy: 0.7353515625\n",
      "Batch: 115, Loss: 0.8873807787895203, Accuracy: 0.7236328125\n",
      "Batch: 116, Loss: 0.8015761375427246, Accuracy: 0.7333984375\n",
      "Batch: 117, Loss: 0.7951644659042358, Accuracy: 0.7412109375\n",
      "Batch: 118, Loss: 0.687486469745636, Accuracy: 0.7724609375\n",
      "Batch: 119, Loss: 0.6719286441802979, Accuracy: 0.7734375\n",
      "Batch: 120, Loss: 0.7724236845970154, Accuracy: 0.740234375\n",
      "Batch: 121, Loss: 0.8554432988166809, Accuracy: 0.7265625\n",
      "Batch: 122, Loss: 0.7056677937507629, Accuracy: 0.7734375\n",
      "Batch: 123, Loss: 0.6821735501289368, Accuracy: 0.7900390625\n",
      "Batch: 124, Loss: 0.763645589351654, Accuracy: 0.7451171875\n",
      "Batch: 125, Loss: 0.8119624257087708, Accuracy: 0.7392578125\n",
      "Batch: 126, Loss: 0.7839410901069641, Accuracy: 0.7587890625\n",
      "Batch: 127, Loss: 0.6995054483413696, Accuracy: 0.7744140625\n",
      "Batch: 128, Loss: 0.8731403350830078, Accuracy: 0.73828125\n",
      "Batch: 129, Loss: 0.7218823432922363, Accuracy: 0.755859375\n",
      "Batch: 130, Loss: 0.8745006322860718, Accuracy: 0.7197265625\n",
      "Batch: 131, Loss: 0.7689919471740723, Accuracy: 0.7333984375\n",
      "Batch: 132, Loss: 0.7825080156326294, Accuracy: 0.7412109375\n",
      "Batch: 133, Loss: 0.752650797367096, Accuracy: 0.759765625\n",
      "Batch: 134, Loss: 0.7625880837440491, Accuracy: 0.7421875\n",
      "Batch: 135, Loss: 0.6842716336250305, Accuracy: 0.7705078125\n",
      "Batch: 136, Loss: 0.7806043028831482, Accuracy: 0.7353515625\n",
      "Batch: 137, Loss: 0.7542880177497864, Accuracy: 0.7568359375\n",
      "Batch: 138, Loss: 0.7048568725585938, Accuracy: 0.7666015625\n",
      "Batch: 139, Loss: 0.7180725336074829, Accuracy: 0.76171875\n",
      "Batch: 140, Loss: 0.758283257484436, Accuracy: 0.748046875\n",
      "Batch: 141, Loss: 0.7940155267715454, Accuracy: 0.7412109375\n",
      "Batch: 142, Loss: 0.829191267490387, Accuracy: 0.708984375\n",
      "Batch: 143, Loss: 0.770577609539032, Accuracy: 0.732421875\n",
      "Batch: 144, Loss: 0.7660669088363647, Accuracy: 0.7470703125\n",
      "Batch: 145, Loss: 0.7157089114189148, Accuracy: 0.7626953125\n",
      "Batch: 146, Loss: 0.7733319997787476, Accuracy: 0.73828125\n",
      "Batch: 147, Loss: 0.7828179597854614, Accuracy: 0.7373046875\n",
      "Batch: 148, Loss: 0.8541631102561951, Accuracy: 0.7177734375\n",
      "Batch: 149, Loss: 0.73655104637146, Accuracy: 0.7451171875\n",
      "Batch: 150, Loss: 0.7234904170036316, Accuracy: 0.7509765625\n",
      "Batch: 151, Loss: 0.6462726593017578, Accuracy: 0.7822265625\n",
      "Epoch 55/80\n",
      "Batch: 1, Loss: 0.9981510639190674, Accuracy: 0.6845703125\n",
      "Batch: 2, Loss: 0.8611093759536743, Accuracy: 0.7060546875\n",
      "Batch: 3, Loss: 0.716037392616272, Accuracy: 0.7509765625\n",
      "Batch: 4, Loss: 0.6470979452133179, Accuracy: 0.7900390625\n",
      "Batch: 5, Loss: 0.725611686706543, Accuracy: 0.765625\n",
      "Batch: 6, Loss: 0.7964693903923035, Accuracy: 0.734375\n",
      "Batch: 7, Loss: 0.7575170397758484, Accuracy: 0.736328125\n",
      "Batch: 8, Loss: 0.7539623975753784, Accuracy: 0.7509765625\n",
      "Batch: 9, Loss: 0.7344611287117004, Accuracy: 0.767578125\n",
      "Batch: 10, Loss: 0.7398113012313843, Accuracy: 0.75390625\n",
      "Batch: 11, Loss: 0.8342527151107788, Accuracy: 0.705078125\n",
      "Batch: 12, Loss: 0.829723596572876, Accuracy: 0.72265625\n",
      "Batch: 13, Loss: 0.6389665007591248, Accuracy: 0.7978515625\n",
      "Batch: 14, Loss: 0.8474084138870239, Accuracy: 0.716796875\n",
      "Batch: 15, Loss: 0.69361412525177, Accuracy: 0.7724609375\n",
      "Batch: 16, Loss: 0.7567926645278931, Accuracy: 0.75\n",
      "Batch: 17, Loss: 0.7861837148666382, Accuracy: 0.7451171875\n",
      "Batch: 18, Loss: 0.8159654140472412, Accuracy: 0.7431640625\n",
      "Batch: 19, Loss: 0.747295618057251, Accuracy: 0.7529296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20, Loss: 0.6817331910133362, Accuracy: 0.775390625\n",
      "Batch: 21, Loss: 0.708249568939209, Accuracy: 0.75\n",
      "Batch: 22, Loss: 0.8075244426727295, Accuracy: 0.7412109375\n",
      "Batch: 23, Loss: 0.8045268654823303, Accuracy: 0.720703125\n",
      "Batch: 24, Loss: 0.7736856341362, Accuracy: 0.7431640625\n",
      "Batch: 25, Loss: 0.7581733465194702, Accuracy: 0.75390625\n",
      "Batch: 26, Loss: 0.6417866945266724, Accuracy: 0.7880859375\n",
      "Batch: 27, Loss: 0.7407711148262024, Accuracy: 0.74609375\n",
      "Batch: 28, Loss: 0.8051818013191223, Accuracy: 0.7197265625\n",
      "Batch: 29, Loss: 0.7213196754455566, Accuracy: 0.7705078125\n",
      "Batch: 30, Loss: 0.6597784757614136, Accuracy: 0.7783203125\n",
      "Batch: 31, Loss: 0.6353452205657959, Accuracy: 0.7958984375\n",
      "Batch: 32, Loss: 0.7145520448684692, Accuracy: 0.765625\n",
      "Batch: 33, Loss: 0.820428729057312, Accuracy: 0.7294921875\n",
      "Batch: 34, Loss: 0.8746865391731262, Accuracy: 0.7109375\n",
      "Batch: 35, Loss: 0.7883602380752563, Accuracy: 0.7294921875\n",
      "Batch: 36, Loss: 0.8115327954292297, Accuracy: 0.7353515625\n",
      "Batch: 37, Loss: 0.7512883543968201, Accuracy: 0.759765625\n",
      "Batch: 38, Loss: 0.7780594825744629, Accuracy: 0.736328125\n",
      "Batch: 39, Loss: 0.8065921068191528, Accuracy: 0.7275390625\n",
      "Batch: 40, Loss: 0.7556342482566833, Accuracy: 0.7587890625\n",
      "Batch: 41, Loss: 0.7180582284927368, Accuracy: 0.7587890625\n",
      "Batch: 42, Loss: 0.6154454946517944, Accuracy: 0.78125\n",
      "Batch: 43, Loss: 0.774812638759613, Accuracy: 0.7392578125\n",
      "Batch: 44, Loss: 0.7837620973587036, Accuracy: 0.751953125\n",
      "Batch: 45, Loss: 0.7238847017288208, Accuracy: 0.7470703125\n",
      "Batch: 46, Loss: 0.7001541256904602, Accuracy: 0.7626953125\n",
      "Batch: 47, Loss: 0.6701797246932983, Accuracy: 0.787109375\n",
      "Batch: 48, Loss: 0.6675158143043518, Accuracy: 0.7822265625\n",
      "Batch: 49, Loss: 0.8142516016960144, Accuracy: 0.7431640625\n",
      "Batch: 50, Loss: 0.788916289806366, Accuracy: 0.748046875\n",
      "Batch: 51, Loss: 0.8112432956695557, Accuracy: 0.740234375\n",
      "Batch: 52, Loss: 0.7793664932250977, Accuracy: 0.7470703125\n",
      "Batch: 53, Loss: 0.720451831817627, Accuracy: 0.748046875\n",
      "Batch: 54, Loss: 0.7701632976531982, Accuracy: 0.75390625\n",
      "Batch: 55, Loss: 0.8556486368179321, Accuracy: 0.7119140625\n",
      "Batch: 56, Loss: 0.8157832622528076, Accuracy: 0.7314453125\n",
      "Batch: 57, Loss: 0.7921748161315918, Accuracy: 0.744140625\n",
      "Batch: 58, Loss: 0.9157606363296509, Accuracy: 0.71484375\n",
      "Batch: 59, Loss: 0.7243789434432983, Accuracy: 0.7607421875\n",
      "Batch: 60, Loss: 0.6951890587806702, Accuracy: 0.7802734375\n",
      "Batch: 61, Loss: 0.7792096138000488, Accuracy: 0.751953125\n",
      "Batch: 62, Loss: 0.7242782115936279, Accuracy: 0.7666015625\n",
      "Batch: 63, Loss: 0.7904711961746216, Accuracy: 0.744140625\n",
      "Batch: 64, Loss: 0.7354764938354492, Accuracy: 0.7607421875\n",
      "Batch: 65, Loss: 0.7779545783996582, Accuracy: 0.7548828125\n",
      "Batch: 66, Loss: 0.7409778833389282, Accuracy: 0.7763671875\n",
      "Batch: 67, Loss: 0.8254848718643188, Accuracy: 0.73046875\n",
      "Batch: 68, Loss: 0.8712483644485474, Accuracy: 0.7041015625\n",
      "Batch: 69, Loss: 0.8011901378631592, Accuracy: 0.7314453125\n",
      "Batch: 70, Loss: 0.7701996564865112, Accuracy: 0.755859375\n",
      "Batch: 71, Loss: 0.8098163604736328, Accuracy: 0.7373046875\n",
      "Batch: 72, Loss: 0.6760871410369873, Accuracy: 0.76953125\n",
      "Batch: 73, Loss: 0.6954942941665649, Accuracy: 0.779296875\n",
      "Batch: 74, Loss: 0.6732936501502991, Accuracy: 0.7763671875\n",
      "Batch: 75, Loss: 0.7143212556838989, Accuracy: 0.7666015625\n",
      "Batch: 76, Loss: 0.7899903655052185, Accuracy: 0.724609375\n",
      "Batch: 77, Loss: 0.7389506697654724, Accuracy: 0.7646484375\n",
      "Batch: 78, Loss: 0.6735388040542603, Accuracy: 0.7900390625\n",
      "Batch: 79, Loss: 0.6240981817245483, Accuracy: 0.798828125\n",
      "Batch: 80, Loss: 0.7217268943786621, Accuracy: 0.7529296875\n",
      "Batch: 81, Loss: 0.8351813554763794, Accuracy: 0.716796875\n",
      "Batch: 82, Loss: 0.8195573687553406, Accuracy: 0.71484375\n",
      "Batch: 83, Loss: 0.6769775748252869, Accuracy: 0.791015625\n",
      "Batch: 84, Loss: 0.7399014234542847, Accuracy: 0.7568359375\n",
      "Batch: 85, Loss: 0.7206305861473083, Accuracy: 0.7568359375\n",
      "Batch: 86, Loss: 0.8762270212173462, Accuracy: 0.7294921875\n",
      "Batch: 87, Loss: 0.6934654712677002, Accuracy: 0.765625\n",
      "Batch: 88, Loss: 0.8308723568916321, Accuracy: 0.728515625\n",
      "Batch: 89, Loss: 0.8182811737060547, Accuracy: 0.740234375\n",
      "Batch: 90, Loss: 0.7526463270187378, Accuracy: 0.7529296875\n",
      "Batch: 91, Loss: 0.7166401147842407, Accuracy: 0.7685546875\n",
      "Batch: 92, Loss: 0.7703542709350586, Accuracy: 0.7392578125\n",
      "Batch: 93, Loss: 0.762305736541748, Accuracy: 0.7568359375\n",
      "Batch: 94, Loss: 0.7871302366256714, Accuracy: 0.7373046875\n",
      "Batch: 95, Loss: 0.8087823390960693, Accuracy: 0.712890625\n",
      "Batch: 96, Loss: 0.7476112842559814, Accuracy: 0.7509765625\n",
      "Batch: 97, Loss: 0.636811375617981, Accuracy: 0.7734375\n",
      "Batch: 98, Loss: 0.7536430358886719, Accuracy: 0.755859375\n",
      "Batch: 99, Loss: 0.7387139201164246, Accuracy: 0.7587890625\n",
      "Batch: 100, Loss: 0.799655556678772, Accuracy: 0.732421875\n",
      "Batch: 101, Loss: 0.8055691719055176, Accuracy: 0.7421875\n",
      "Batch: 102, Loss: 0.7657089233398438, Accuracy: 0.7421875\n",
      "Batch: 103, Loss: 0.7431656122207642, Accuracy: 0.7626953125\n",
      "Batch: 104, Loss: 0.7355802655220032, Accuracy: 0.755859375\n",
      "Batch: 105, Loss: 0.7780047655105591, Accuracy: 0.7587890625\n",
      "Batch: 106, Loss: 0.7138190269470215, Accuracy: 0.7705078125\n",
      "Batch: 107, Loss: 0.765368640422821, Accuracy: 0.7490234375\n",
      "Batch: 108, Loss: 0.7732746005058289, Accuracy: 0.74609375\n",
      "Batch: 109, Loss: 0.9124882817268372, Accuracy: 0.69921875\n",
      "Batch: 110, Loss: 0.7064303755760193, Accuracy: 0.7421875\n",
      "Batch: 111, Loss: 0.7960292100906372, Accuracy: 0.7255859375\n",
      "Batch: 112, Loss: 0.7401565313339233, Accuracy: 0.759765625\n",
      "Batch: 113, Loss: 0.7666558027267456, Accuracy: 0.748046875\n",
      "Batch: 114, Loss: 0.8502275347709656, Accuracy: 0.7236328125\n",
      "Batch: 115, Loss: 0.8630800843238831, Accuracy: 0.73828125\n",
      "Batch: 116, Loss: 0.8181873559951782, Accuracy: 0.7373046875\n",
      "Batch: 117, Loss: 0.8522619009017944, Accuracy: 0.72265625\n",
      "Batch: 118, Loss: 0.6963033080101013, Accuracy: 0.787109375\n",
      "Batch: 119, Loss: 0.6668109893798828, Accuracy: 0.7763671875\n",
      "Batch: 120, Loss: 0.7765529751777649, Accuracy: 0.75390625\n",
      "Batch: 121, Loss: 0.8175241351127625, Accuracy: 0.7294921875\n",
      "Batch: 122, Loss: 0.7031365633010864, Accuracy: 0.7705078125\n",
      "Batch: 123, Loss: 0.6789414882659912, Accuracy: 0.779296875\n",
      "Batch: 124, Loss: 0.7479764223098755, Accuracy: 0.7626953125\n",
      "Batch: 125, Loss: 0.8039274215698242, Accuracy: 0.732421875\n",
      "Batch: 126, Loss: 0.7669766545295715, Accuracy: 0.7490234375\n",
      "Batch: 127, Loss: 0.6938321590423584, Accuracy: 0.7841796875\n",
      "Batch: 128, Loss: 0.8313921093940735, Accuracy: 0.73828125\n",
      "Batch: 129, Loss: 0.7006827592849731, Accuracy: 0.7841796875\n",
      "Batch: 130, Loss: 0.872697114944458, Accuracy: 0.7275390625\n",
      "Batch: 131, Loss: 0.7473329305648804, Accuracy: 0.744140625\n",
      "Batch: 132, Loss: 0.8249783515930176, Accuracy: 0.736328125\n",
      "Batch: 133, Loss: 0.7374653816223145, Accuracy: 0.751953125\n",
      "Batch: 134, Loss: 0.7861900329589844, Accuracy: 0.7138671875\n",
      "Batch: 135, Loss: 0.7040138244628906, Accuracy: 0.7607421875\n",
      "Batch: 136, Loss: 0.775152325630188, Accuracy: 0.744140625\n",
      "Batch: 137, Loss: 0.7450025081634521, Accuracy: 0.75\n",
      "Batch: 138, Loss: 0.6714621782302856, Accuracy: 0.76953125\n",
      "Batch: 139, Loss: 0.7011885643005371, Accuracy: 0.7578125\n",
      "Batch: 140, Loss: 0.7339093685150146, Accuracy: 0.748046875\n",
      "Batch: 141, Loss: 0.7889349460601807, Accuracy: 0.7548828125\n",
      "Batch: 142, Loss: 0.8086702227592468, Accuracy: 0.73046875\n",
      "Batch: 143, Loss: 0.7509820461273193, Accuracy: 0.7421875\n",
      "Batch: 144, Loss: 0.7443243265151978, Accuracy: 0.75\n",
      "Batch: 145, Loss: 0.7345430850982666, Accuracy: 0.7529296875\n",
      "Batch: 146, Loss: 0.7647889852523804, Accuracy: 0.7421875\n",
      "Batch: 147, Loss: 0.7801514863967896, Accuracy: 0.740234375\n",
      "Batch: 148, Loss: 0.8371368050575256, Accuracy: 0.732421875\n",
      "Batch: 149, Loss: 0.732787013053894, Accuracy: 0.732421875\n",
      "Batch: 150, Loss: 0.704655647277832, Accuracy: 0.7626953125\n",
      "Batch: 151, Loss: 0.6655445098876953, Accuracy: 0.78515625\n",
      "Epoch 56/80\n",
      "Batch: 1, Loss: 1.0161476135253906, Accuracy: 0.6796875\n",
      "Batch: 2, Loss: 0.8364130258560181, Accuracy: 0.703125\n",
      "Batch: 3, Loss: 0.7283048629760742, Accuracy: 0.7587890625\n",
      "Batch: 4, Loss: 0.6522349119186401, Accuracy: 0.7919921875\n",
      "Batch: 5, Loss: 0.7141788005828857, Accuracy: 0.7724609375\n",
      "Batch: 6, Loss: 0.7826069593429565, Accuracy: 0.728515625\n",
      "Batch: 7, Loss: 0.7613321542739868, Accuracy: 0.7587890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 8, Loss: 0.7038017511367798, Accuracy: 0.76171875\n",
      "Batch: 9, Loss: 0.7393432855606079, Accuracy: 0.759765625\n",
      "Batch: 10, Loss: 0.7172443270683289, Accuracy: 0.7607421875\n",
      "Batch: 11, Loss: 0.8231339454650879, Accuracy: 0.71875\n",
      "Batch: 12, Loss: 0.802944004535675, Accuracy: 0.7333984375\n",
      "Batch: 13, Loss: 0.6409648656845093, Accuracy: 0.8017578125\n",
      "Batch: 14, Loss: 0.8405490517616272, Accuracy: 0.7265625\n",
      "Batch: 15, Loss: 0.6840945482254028, Accuracy: 0.7890625\n",
      "Batch: 16, Loss: 0.7494993805885315, Accuracy: 0.75390625\n",
      "Batch: 17, Loss: 0.785069465637207, Accuracy: 0.732421875\n",
      "Batch: 18, Loss: 0.8418455123901367, Accuracy: 0.7265625\n",
      "Batch: 19, Loss: 0.7670906782150269, Accuracy: 0.7509765625\n",
      "Batch: 20, Loss: 0.689998209476471, Accuracy: 0.7734375\n",
      "Batch: 21, Loss: 0.7240791916847229, Accuracy: 0.75390625\n",
      "Batch: 22, Loss: 0.799933135509491, Accuracy: 0.7353515625\n",
      "Batch: 23, Loss: 0.7892290353775024, Accuracy: 0.7412109375\n",
      "Batch: 24, Loss: 0.7882730960845947, Accuracy: 0.7353515625\n",
      "Batch: 25, Loss: 0.7435483336448669, Accuracy: 0.7578125\n",
      "Batch: 26, Loss: 0.6518337726593018, Accuracy: 0.7724609375\n",
      "Batch: 27, Loss: 0.7243740558624268, Accuracy: 0.755859375\n",
      "Batch: 28, Loss: 0.7609452605247498, Accuracy: 0.7431640625\n",
      "Batch: 29, Loss: 0.684800386428833, Accuracy: 0.77734375\n",
      "Batch: 30, Loss: 0.6481527090072632, Accuracy: 0.7890625\n",
      "Batch: 31, Loss: 0.6493933200836182, Accuracy: 0.796875\n",
      "Batch: 32, Loss: 0.7015215754508972, Accuracy: 0.7587890625\n",
      "Batch: 33, Loss: 0.8326742649078369, Accuracy: 0.7265625\n",
      "Batch: 34, Loss: 0.8572940230369568, Accuracy: 0.724609375\n",
      "Batch: 35, Loss: 0.7853834629058838, Accuracy: 0.7275390625\n",
      "Batch: 36, Loss: 0.800592839717865, Accuracy: 0.75390625\n",
      "Batch: 37, Loss: 0.7800401449203491, Accuracy: 0.751953125\n",
      "Batch: 38, Loss: 0.7404816150665283, Accuracy: 0.7490234375\n",
      "Batch: 39, Loss: 0.8075193166732788, Accuracy: 0.740234375\n",
      "Batch: 40, Loss: 0.7557333111763, Accuracy: 0.76171875\n",
      "Batch: 41, Loss: 0.6976915001869202, Accuracy: 0.7724609375\n",
      "Batch: 42, Loss: 0.6222046613693237, Accuracy: 0.787109375\n",
      "Batch: 43, Loss: 0.8146666288375854, Accuracy: 0.7294921875\n",
      "Batch: 44, Loss: 0.7973335981369019, Accuracy: 0.732421875\n",
      "Batch: 45, Loss: 0.718462347984314, Accuracy: 0.7568359375\n",
      "Batch: 46, Loss: 0.6842530965805054, Accuracy: 0.7734375\n",
      "Batch: 47, Loss: 0.7024500370025635, Accuracy: 0.7802734375\n",
      "Batch: 48, Loss: 0.6596420407295227, Accuracy: 0.7861328125\n",
      "Batch: 49, Loss: 0.7987761497497559, Accuracy: 0.7333984375\n",
      "Batch: 50, Loss: 0.7886888980865479, Accuracy: 0.74609375\n",
      "Batch: 51, Loss: 0.8090299367904663, Accuracy: 0.7373046875\n",
      "Batch: 52, Loss: 0.7467165589332581, Accuracy: 0.763671875\n",
      "Batch: 53, Loss: 0.6995267868041992, Accuracy: 0.7548828125\n",
      "Batch: 54, Loss: 0.7610601186752319, Accuracy: 0.7587890625\n",
      "Batch: 55, Loss: 0.875399649143219, Accuracy: 0.7041015625\n",
      "Batch: 56, Loss: 0.8377617597579956, Accuracy: 0.7109375\n",
      "Batch: 57, Loss: 0.8046338558197021, Accuracy: 0.736328125\n",
      "Batch: 58, Loss: 0.8726862668991089, Accuracy: 0.736328125\n",
      "Batch: 59, Loss: 0.7243708968162537, Accuracy: 0.7802734375\n",
      "Batch: 60, Loss: 0.7013776898384094, Accuracy: 0.7763671875\n",
      "Batch: 61, Loss: 0.7774975299835205, Accuracy: 0.76171875\n",
      "Batch: 62, Loss: 0.7462321519851685, Accuracy: 0.75390625\n",
      "Batch: 63, Loss: 0.7735002040863037, Accuracy: 0.73828125\n",
      "Batch: 64, Loss: 0.7776281833648682, Accuracy: 0.732421875\n",
      "Batch: 65, Loss: 0.7736939191818237, Accuracy: 0.7646484375\n",
      "Batch: 66, Loss: 0.7463861107826233, Accuracy: 0.7626953125\n",
      "Batch: 67, Loss: 0.8348798751831055, Accuracy: 0.7412109375\n",
      "Batch: 68, Loss: 0.8382210731506348, Accuracy: 0.7333984375\n",
      "Batch: 69, Loss: 0.7752169370651245, Accuracy: 0.7333984375\n",
      "Batch: 70, Loss: 0.7910985350608826, Accuracy: 0.7578125\n",
      "Batch: 71, Loss: 0.7693142890930176, Accuracy: 0.7265625\n",
      "Batch: 72, Loss: 0.6944588422775269, Accuracy: 0.7783203125\n",
      "Batch: 73, Loss: 0.7071750164031982, Accuracy: 0.7626953125\n",
      "Batch: 74, Loss: 0.6526796817779541, Accuracy: 0.80078125\n",
      "Batch: 75, Loss: 0.699103832244873, Accuracy: 0.7587890625\n",
      "Batch: 76, Loss: 0.7795094847679138, Accuracy: 0.7314453125\n",
      "Batch: 77, Loss: 0.7034345865249634, Accuracy: 0.775390625\n",
      "Batch: 78, Loss: 0.6788827180862427, Accuracy: 0.7900390625\n",
      "Batch: 79, Loss: 0.6515151262283325, Accuracy: 0.7880859375\n",
      "Batch: 80, Loss: 0.7188891172409058, Accuracy: 0.76171875\n",
      "Batch: 81, Loss: 0.8170080780982971, Accuracy: 0.71484375\n",
      "Batch: 82, Loss: 0.8101754188537598, Accuracy: 0.7197265625\n",
      "Batch: 83, Loss: 0.6861778497695923, Accuracy: 0.77734375\n",
      "Batch: 84, Loss: 0.7549751996994019, Accuracy: 0.748046875\n",
      "Batch: 85, Loss: 0.7061164379119873, Accuracy: 0.7646484375\n",
      "Batch: 86, Loss: 0.8846094608306885, Accuracy: 0.716796875\n",
      "Batch: 87, Loss: 0.6994600296020508, Accuracy: 0.779296875\n",
      "Batch: 88, Loss: 0.8026642799377441, Accuracy: 0.744140625\n",
      "Batch: 89, Loss: 0.7837689518928528, Accuracy: 0.75390625\n",
      "Batch: 90, Loss: 0.730265736579895, Accuracy: 0.751953125\n",
      "Batch: 91, Loss: 0.713970422744751, Accuracy: 0.763671875\n",
      "Batch: 92, Loss: 0.7586714029312134, Accuracy: 0.7509765625\n",
      "Batch: 93, Loss: 0.7412699460983276, Accuracy: 0.76953125\n",
      "Batch: 94, Loss: 0.7826382517814636, Accuracy: 0.7314453125\n",
      "Batch: 95, Loss: 0.8288460969924927, Accuracy: 0.70703125\n",
      "Batch: 96, Loss: 0.7395481467247009, Accuracy: 0.7666015625\n",
      "Batch: 97, Loss: 0.6522363424301147, Accuracy: 0.783203125\n",
      "Batch: 98, Loss: 0.743698000907898, Accuracy: 0.7626953125\n",
      "Batch: 99, Loss: 0.7436670064926147, Accuracy: 0.7509765625\n",
      "Batch: 100, Loss: 0.7878097295761108, Accuracy: 0.73828125\n",
      "Batch: 101, Loss: 0.8000066876411438, Accuracy: 0.72265625\n",
      "Batch: 102, Loss: 0.7787525653839111, Accuracy: 0.740234375\n",
      "Batch: 103, Loss: 0.7586612105369568, Accuracy: 0.7509765625\n",
      "Batch: 104, Loss: 0.693885087966919, Accuracy: 0.7734375\n",
      "Batch: 105, Loss: 0.8106533288955688, Accuracy: 0.7353515625\n",
      "Batch: 106, Loss: 0.7221857905387878, Accuracy: 0.7607421875\n",
      "Batch: 107, Loss: 0.772502601146698, Accuracy: 0.7548828125\n",
      "Batch: 108, Loss: 0.7804685235023499, Accuracy: 0.748046875\n",
      "Batch: 109, Loss: 0.9046896696090698, Accuracy: 0.69921875\n",
      "Batch: 110, Loss: 0.6880286931991577, Accuracy: 0.7646484375\n",
      "Batch: 111, Loss: 0.7957611083984375, Accuracy: 0.7294921875\n",
      "Batch: 112, Loss: 0.7586649656295776, Accuracy: 0.755859375\n",
      "Batch: 113, Loss: 0.7319287657737732, Accuracy: 0.7626953125\n",
      "Batch: 114, Loss: 0.8378196954727173, Accuracy: 0.7353515625\n",
      "Batch: 115, Loss: 0.8853600025177002, Accuracy: 0.7236328125\n",
      "Batch: 116, Loss: 0.7975916862487793, Accuracy: 0.74609375\n",
      "Batch: 117, Loss: 0.8379905819892883, Accuracy: 0.7275390625\n",
      "Batch: 118, Loss: 0.6495466232299805, Accuracy: 0.7763671875\n",
      "Batch: 119, Loss: 0.6535050868988037, Accuracy: 0.791015625\n",
      "Batch: 120, Loss: 0.7731744050979614, Accuracy: 0.76171875\n",
      "Batch: 121, Loss: 0.8245139122009277, Accuracy: 0.7392578125\n",
      "Batch: 122, Loss: 0.7188583612442017, Accuracy: 0.765625\n",
      "Batch: 123, Loss: 0.6726930737495422, Accuracy: 0.7890625\n",
      "Batch: 124, Loss: 0.7508901953697205, Accuracy: 0.748046875\n",
      "Batch: 125, Loss: 0.8171112537384033, Accuracy: 0.7353515625\n",
      "Batch: 126, Loss: 0.7628902196884155, Accuracy: 0.75\n",
      "Batch: 127, Loss: 0.6872498989105225, Accuracy: 0.7919921875\n",
      "Batch: 128, Loss: 0.8119232654571533, Accuracy: 0.7626953125\n",
      "Batch: 129, Loss: 0.6827592253684998, Accuracy: 0.783203125\n",
      "Batch: 130, Loss: 0.8889404535293579, Accuracy: 0.7099609375\n",
      "Batch: 131, Loss: 0.7855163812637329, Accuracy: 0.732421875\n",
      "Batch: 132, Loss: 0.7715681791305542, Accuracy: 0.7607421875\n",
      "Batch: 133, Loss: 0.7293201684951782, Accuracy: 0.763671875\n",
      "Batch: 134, Loss: 0.7679303884506226, Accuracy: 0.7353515625\n",
      "Batch: 135, Loss: 0.6960588097572327, Accuracy: 0.765625\n",
      "Batch: 136, Loss: 0.771443247795105, Accuracy: 0.7431640625\n",
      "Batch: 137, Loss: 0.7370141744613647, Accuracy: 0.7607421875\n",
      "Batch: 138, Loss: 0.6747226715087891, Accuracy: 0.76953125\n",
      "Batch: 139, Loss: 0.6814465522766113, Accuracy: 0.7646484375\n",
      "Batch: 140, Loss: 0.7130541801452637, Accuracy: 0.7568359375\n",
      "Batch: 141, Loss: 0.7846380472183228, Accuracy: 0.7392578125\n",
      "Batch: 142, Loss: 0.7932201027870178, Accuracy: 0.7451171875\n",
      "Batch: 143, Loss: 0.7221279144287109, Accuracy: 0.7490234375\n",
      "Batch: 144, Loss: 0.7451562285423279, Accuracy: 0.74609375\n",
      "Batch: 145, Loss: 0.7016270160675049, Accuracy: 0.7607421875\n",
      "Batch: 146, Loss: 0.7924559116363525, Accuracy: 0.7392578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 147, Loss: 0.7792636156082153, Accuracy: 0.7568359375\n",
      "Batch: 148, Loss: 0.8384115099906921, Accuracy: 0.732421875\n",
      "Batch: 149, Loss: 0.7426782846450806, Accuracy: 0.74609375\n",
      "Batch: 150, Loss: 0.7348463535308838, Accuracy: 0.7431640625\n",
      "Batch: 151, Loss: 0.6735339164733887, Accuracy: 0.7744140625\n",
      "Epoch 57/80\n",
      "Batch: 1, Loss: 0.9742358922958374, Accuracy: 0.68359375\n",
      "Batch: 2, Loss: 0.8269447684288025, Accuracy: 0.7177734375\n",
      "Batch: 3, Loss: 0.7427362203598022, Accuracy: 0.7451171875\n",
      "Batch: 4, Loss: 0.6240453720092773, Accuracy: 0.7978515625\n",
      "Batch: 5, Loss: 0.7375253438949585, Accuracy: 0.7568359375\n",
      "Batch: 6, Loss: 0.755867600440979, Accuracy: 0.7412109375\n",
      "Batch: 7, Loss: 0.7672002911567688, Accuracy: 0.732421875\n",
      "Batch: 8, Loss: 0.6938268542289734, Accuracy: 0.7763671875\n",
      "Batch: 9, Loss: 0.7041192054748535, Accuracy: 0.7734375\n",
      "Batch: 10, Loss: 0.7179301977157593, Accuracy: 0.7724609375\n",
      "Batch: 11, Loss: 0.8162019848823547, Accuracy: 0.7314453125\n",
      "Batch: 12, Loss: 0.8042150735855103, Accuracy: 0.7333984375\n",
      "Batch: 13, Loss: 0.6225528717041016, Accuracy: 0.7958984375\n",
      "Batch: 14, Loss: 0.841202974319458, Accuracy: 0.7177734375\n",
      "Batch: 15, Loss: 0.650973916053772, Accuracy: 0.7978515625\n",
      "Batch: 16, Loss: 0.7323680520057678, Accuracy: 0.767578125\n",
      "Batch: 17, Loss: 0.762222170829773, Accuracy: 0.748046875\n",
      "Batch: 18, Loss: 0.7838671207427979, Accuracy: 0.7578125\n",
      "Batch: 19, Loss: 0.7855095863342285, Accuracy: 0.7373046875\n",
      "Batch: 20, Loss: 0.6703227758407593, Accuracy: 0.7744140625\n",
      "Batch: 21, Loss: 0.7265914678573608, Accuracy: 0.763671875\n",
      "Batch: 22, Loss: 0.8439681529998779, Accuracy: 0.7216796875\n",
      "Batch: 23, Loss: 0.7673417329788208, Accuracy: 0.732421875\n",
      "Batch: 24, Loss: 0.7615163922309875, Accuracy: 0.734375\n",
      "Batch: 25, Loss: 0.753760576248169, Accuracy: 0.7548828125\n",
      "Batch: 26, Loss: 0.664597749710083, Accuracy: 0.7763671875\n",
      "Batch: 27, Loss: 0.7123348712921143, Accuracy: 0.765625\n",
      "Batch: 28, Loss: 0.7974324226379395, Accuracy: 0.728515625\n",
      "Batch: 29, Loss: 0.73127281665802, Accuracy: 0.7509765625\n",
      "Batch: 30, Loss: 0.6258434653282166, Accuracy: 0.8037109375\n",
      "Batch: 31, Loss: 0.6506551504135132, Accuracy: 0.802734375\n",
      "Batch: 32, Loss: 0.7030653953552246, Accuracy: 0.771484375\n",
      "Batch: 33, Loss: 0.786808967590332, Accuracy: 0.7509765625\n",
      "Batch: 34, Loss: 0.8766893148422241, Accuracy: 0.7138671875\n",
      "Batch: 35, Loss: 0.7959480881690979, Accuracy: 0.75\n",
      "Batch: 36, Loss: 0.8047760725021362, Accuracy: 0.7431640625\n",
      "Batch: 37, Loss: 0.7477105855941772, Accuracy: 0.7666015625\n",
      "Batch: 38, Loss: 0.7751587629318237, Accuracy: 0.7333984375\n",
      "Batch: 39, Loss: 0.7887920141220093, Accuracy: 0.7373046875\n",
      "Batch: 40, Loss: 0.7118253707885742, Accuracy: 0.7529296875\n",
      "Batch: 41, Loss: 0.7069022059440613, Accuracy: 0.7802734375\n",
      "Batch: 42, Loss: 0.5803312063217163, Accuracy: 0.794921875\n",
      "Batch: 43, Loss: 0.7806427478790283, Accuracy: 0.732421875\n",
      "Batch: 44, Loss: 0.79227614402771, Accuracy: 0.7333984375\n",
      "Batch: 45, Loss: 0.7019656300544739, Accuracy: 0.7568359375\n",
      "Batch: 46, Loss: 0.6940776109695435, Accuracy: 0.76953125\n",
      "Batch: 47, Loss: 0.6855576038360596, Accuracy: 0.787109375\n",
      "Batch: 48, Loss: 0.7037235498428345, Accuracy: 0.767578125\n",
      "Batch: 49, Loss: 0.7954226732254028, Accuracy: 0.7421875\n",
      "Batch: 50, Loss: 0.7869503498077393, Accuracy: 0.7451171875\n",
      "Batch: 51, Loss: 0.7627488374710083, Accuracy: 0.7587890625\n",
      "Batch: 52, Loss: 0.7438218593597412, Accuracy: 0.75390625\n",
      "Batch: 53, Loss: 0.7180016040802002, Accuracy: 0.751953125\n",
      "Batch: 54, Loss: 0.7267942428588867, Accuracy: 0.7587890625\n",
      "Batch: 55, Loss: 0.8730466365814209, Accuracy: 0.70703125\n",
      "Batch: 56, Loss: 0.8034036159515381, Accuracy: 0.73046875\n",
      "Batch: 57, Loss: 0.787062406539917, Accuracy: 0.7451171875\n",
      "Batch: 58, Loss: 0.8965792655944824, Accuracy: 0.71875\n",
      "Batch: 59, Loss: 0.714464008808136, Accuracy: 0.76171875\n",
      "Batch: 60, Loss: 0.6862592697143555, Accuracy: 0.7744140625\n",
      "Batch: 61, Loss: 0.7985305786132812, Accuracy: 0.7421875\n",
      "Batch: 62, Loss: 0.7370343208312988, Accuracy: 0.7607421875\n",
      "Batch: 63, Loss: 0.7475503087043762, Accuracy: 0.763671875\n",
      "Batch: 64, Loss: 0.7658103704452515, Accuracy: 0.7373046875\n",
      "Batch: 65, Loss: 0.7596629858016968, Accuracy: 0.75390625\n",
      "Batch: 66, Loss: 0.7489638328552246, Accuracy: 0.7646484375\n",
      "Batch: 67, Loss: 0.8425910472869873, Accuracy: 0.7197265625\n",
      "Batch: 68, Loss: 0.8855668306350708, Accuracy: 0.7158203125\n",
      "Batch: 69, Loss: 0.8127774000167847, Accuracy: 0.724609375\n",
      "Batch: 70, Loss: 0.7566901445388794, Accuracy: 0.7578125\n",
      "Batch: 71, Loss: 0.7941778898239136, Accuracy: 0.73828125\n",
      "Batch: 72, Loss: 0.6777671575546265, Accuracy: 0.771484375\n",
      "Batch: 73, Loss: 0.6731305122375488, Accuracy: 0.779296875\n",
      "Batch: 74, Loss: 0.6594628691673279, Accuracy: 0.783203125\n",
      "Batch: 75, Loss: 0.6897252798080444, Accuracy: 0.765625\n",
      "Batch: 76, Loss: 0.7768102884292603, Accuracy: 0.7333984375\n",
      "Batch: 77, Loss: 0.7039665579795837, Accuracy: 0.76953125\n",
      "Batch: 78, Loss: 0.6451069116592407, Accuracy: 0.7900390625\n",
      "Batch: 79, Loss: 0.6356690526008606, Accuracy: 0.7978515625\n",
      "Batch: 80, Loss: 0.7129407525062561, Accuracy: 0.76171875\n",
      "Batch: 81, Loss: 0.8419132232666016, Accuracy: 0.70703125\n",
      "Batch: 82, Loss: 0.7674126625061035, Accuracy: 0.7451171875\n",
      "Batch: 83, Loss: 0.6547685861587524, Accuracy: 0.7919921875\n",
      "Batch: 84, Loss: 0.7139362096786499, Accuracy: 0.7646484375\n",
      "Batch: 85, Loss: 0.7295957803726196, Accuracy: 0.765625\n",
      "Batch: 86, Loss: 0.874787449836731, Accuracy: 0.7177734375\n",
      "Batch: 87, Loss: 0.6920721530914307, Accuracy: 0.7841796875\n",
      "Batch: 88, Loss: 0.8059329390525818, Accuracy: 0.7451171875\n",
      "Batch: 89, Loss: 0.7883514165878296, Accuracy: 0.7490234375\n",
      "Batch: 90, Loss: 0.6961812376976013, Accuracy: 0.76953125\n",
      "Batch: 91, Loss: 0.6901951432228088, Accuracy: 0.7587890625\n",
      "Batch: 92, Loss: 0.7615253925323486, Accuracy: 0.7451171875\n",
      "Batch: 93, Loss: 0.7488071918487549, Accuracy: 0.73828125\n",
      "Batch: 94, Loss: 0.7983767986297607, Accuracy: 0.7294921875\n",
      "Batch: 95, Loss: 0.8181272149085999, Accuracy: 0.7060546875\n",
      "Batch: 96, Loss: 0.7218894958496094, Accuracy: 0.755859375\n",
      "Batch: 97, Loss: 0.6451131105422974, Accuracy: 0.783203125\n",
      "Batch: 98, Loss: 0.7487826347351074, Accuracy: 0.7568359375\n",
      "Batch: 99, Loss: 0.7475128173828125, Accuracy: 0.734375\n",
      "Batch: 100, Loss: 0.7656049728393555, Accuracy: 0.7392578125\n",
      "Batch: 101, Loss: 0.7587713599205017, Accuracy: 0.7490234375\n",
      "Batch: 102, Loss: 0.7788442373275757, Accuracy: 0.7353515625\n",
      "Batch: 103, Loss: 0.7388906478881836, Accuracy: 0.7666015625\n",
      "Batch: 104, Loss: 0.6898829936981201, Accuracy: 0.771484375\n",
      "Batch: 105, Loss: 0.8195818662643433, Accuracy: 0.7373046875\n",
      "Batch: 106, Loss: 0.7312485575675964, Accuracy: 0.763671875\n",
      "Batch: 107, Loss: 0.7401639223098755, Accuracy: 0.7626953125\n",
      "Batch: 108, Loss: 0.7754218578338623, Accuracy: 0.73828125\n",
      "Batch: 109, Loss: 0.8986939787864685, Accuracy: 0.6962890625\n",
      "Batch: 110, Loss: 0.7085413336753845, Accuracy: 0.7587890625\n",
      "Batch: 111, Loss: 0.7785219550132751, Accuracy: 0.7412109375\n",
      "Batch: 112, Loss: 0.7497850656509399, Accuracy: 0.7548828125\n",
      "Batch: 113, Loss: 0.7584861516952515, Accuracy: 0.755859375\n",
      "Batch: 114, Loss: 0.8449690341949463, Accuracy: 0.7197265625\n",
      "Batch: 115, Loss: 0.8720389604568481, Accuracy: 0.7314453125\n",
      "Batch: 116, Loss: 0.7796473503112793, Accuracy: 0.7470703125\n",
      "Batch: 117, Loss: 0.7836437225341797, Accuracy: 0.73828125\n",
      "Batch: 118, Loss: 0.679419994354248, Accuracy: 0.7880859375\n",
      "Batch: 119, Loss: 0.6540989875793457, Accuracy: 0.7998046875\n",
      "Batch: 120, Loss: 0.7763477563858032, Accuracy: 0.7451171875\n",
      "Batch: 121, Loss: 0.7929929494857788, Accuracy: 0.734375\n",
      "Batch: 122, Loss: 0.6867475509643555, Accuracy: 0.775390625\n",
      "Batch: 123, Loss: 0.6980035305023193, Accuracy: 0.7646484375\n",
      "Batch: 124, Loss: 0.7461948394775391, Accuracy: 0.7470703125\n",
      "Batch: 125, Loss: 0.7653670907020569, Accuracy: 0.748046875\n",
      "Batch: 126, Loss: 0.7720558643341064, Accuracy: 0.7548828125\n",
      "Batch: 127, Loss: 0.6875156164169312, Accuracy: 0.775390625\n",
      "Batch: 128, Loss: 0.8034747242927551, Accuracy: 0.751953125\n",
      "Batch: 129, Loss: 0.7048362493515015, Accuracy: 0.7587890625\n",
      "Batch: 130, Loss: 0.8432686924934387, Accuracy: 0.732421875\n",
      "Batch: 131, Loss: 0.7263742685317993, Accuracy: 0.7626953125\n",
      "Batch: 132, Loss: 0.7695698142051697, Accuracy: 0.744140625\n",
      "Batch: 133, Loss: 0.7115362882614136, Accuracy: 0.759765625\n",
      "Batch: 134, Loss: 0.768545925617218, Accuracy: 0.7197265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 135, Loss: 0.6964035034179688, Accuracy: 0.767578125\n",
      "Batch: 136, Loss: 0.7550672292709351, Accuracy: 0.75390625\n",
      "Batch: 137, Loss: 0.7877241373062134, Accuracy: 0.736328125\n",
      "Batch: 138, Loss: 0.659708559513092, Accuracy: 0.771484375\n",
      "Batch: 139, Loss: 0.7134395837783813, Accuracy: 0.763671875\n",
      "Batch: 140, Loss: 0.7356343269348145, Accuracy: 0.74609375\n",
      "Batch: 141, Loss: 0.7737044095993042, Accuracy: 0.7451171875\n",
      "Batch: 142, Loss: 0.8132103085517883, Accuracy: 0.7431640625\n",
      "Batch: 143, Loss: 0.7479970455169678, Accuracy: 0.748046875\n",
      "Batch: 144, Loss: 0.7396919131278992, Accuracy: 0.7568359375\n",
      "Batch: 145, Loss: 0.6980835795402527, Accuracy: 0.7578125\n",
      "Batch: 146, Loss: 0.776878833770752, Accuracy: 0.7373046875\n",
      "Batch: 147, Loss: 0.7573155164718628, Accuracy: 0.7607421875\n",
      "Batch: 148, Loss: 0.8217126131057739, Accuracy: 0.7177734375\n",
      "Batch: 149, Loss: 0.7287236452102661, Accuracy: 0.7412109375\n",
      "Batch: 150, Loss: 0.7384432554244995, Accuracy: 0.7470703125\n",
      "Batch: 151, Loss: 0.6632834672927856, Accuracy: 0.7666015625\n",
      "Epoch 58/80\n",
      "Batch: 1, Loss: 0.9224507808685303, Accuracy: 0.6982421875\n",
      "Batch: 2, Loss: 0.8312948346138, Accuracy: 0.7001953125\n",
      "Batch: 3, Loss: 0.7146944403648376, Accuracy: 0.7666015625\n",
      "Batch: 4, Loss: 0.66515052318573, Accuracy: 0.78515625\n",
      "Batch: 5, Loss: 0.7061336040496826, Accuracy: 0.775390625\n",
      "Batch: 6, Loss: 0.7551045417785645, Accuracy: 0.74609375\n",
      "Batch: 7, Loss: 0.7785921692848206, Accuracy: 0.7275390625\n",
      "Batch: 8, Loss: 0.7118539810180664, Accuracy: 0.7578125\n",
      "Batch: 9, Loss: 0.7394269108772278, Accuracy: 0.7568359375\n",
      "Batch: 10, Loss: 0.7078053951263428, Accuracy: 0.7705078125\n",
      "Batch: 11, Loss: 0.834679126739502, Accuracy: 0.71484375\n",
      "Batch: 12, Loss: 0.8229098320007324, Accuracy: 0.7412109375\n",
      "Batch: 13, Loss: 0.6177500486373901, Accuracy: 0.798828125\n",
      "Batch: 14, Loss: 0.8509271144866943, Accuracy: 0.734375\n",
      "Batch: 15, Loss: 0.6581045985221863, Accuracy: 0.8017578125\n",
      "Batch: 16, Loss: 0.7230225801467896, Accuracy: 0.7578125\n",
      "Batch: 17, Loss: 0.7647762298583984, Accuracy: 0.7607421875\n",
      "Batch: 18, Loss: 0.7829002737998962, Accuracy: 0.7529296875\n",
      "Batch: 19, Loss: 0.7936461567878723, Accuracy: 0.7431640625\n",
      "Batch: 20, Loss: 0.6712775230407715, Accuracy: 0.783203125\n",
      "Batch: 21, Loss: 0.7003341913223267, Accuracy: 0.7763671875\n",
      "Batch: 22, Loss: 0.8100756406784058, Accuracy: 0.732421875\n",
      "Batch: 23, Loss: 0.7477625608444214, Accuracy: 0.7451171875\n",
      "Batch: 24, Loss: 0.7592964172363281, Accuracy: 0.74609375\n",
      "Batch: 25, Loss: 0.7553467154502869, Accuracy: 0.7529296875\n",
      "Batch: 26, Loss: 0.6658943891525269, Accuracy: 0.7626953125\n",
      "Batch: 27, Loss: 0.7192168235778809, Accuracy: 0.7587890625\n",
      "Batch: 28, Loss: 0.7520796656608582, Accuracy: 0.7568359375\n",
      "Batch: 29, Loss: 0.7075226902961731, Accuracy: 0.7587890625\n",
      "Batch: 30, Loss: 0.6356399059295654, Accuracy: 0.8037109375\n",
      "Batch: 31, Loss: 0.6352480053901672, Accuracy: 0.7978515625\n",
      "Batch: 32, Loss: 0.701151430606842, Accuracy: 0.751953125\n",
      "Batch: 33, Loss: 0.8133088946342468, Accuracy: 0.7236328125\n",
      "Batch: 34, Loss: 0.8512612581253052, Accuracy: 0.7236328125\n",
      "Batch: 35, Loss: 0.7530419826507568, Accuracy: 0.7353515625\n",
      "Batch: 36, Loss: 0.783683180809021, Accuracy: 0.75390625\n",
      "Batch: 37, Loss: 0.7571648359298706, Accuracy: 0.7529296875\n",
      "Batch: 38, Loss: 0.7899699211120605, Accuracy: 0.744140625\n",
      "Batch: 39, Loss: 0.7812966108322144, Accuracy: 0.7646484375\n",
      "Batch: 40, Loss: 0.7244412899017334, Accuracy: 0.767578125\n",
      "Batch: 41, Loss: 0.681835412979126, Accuracy: 0.787109375\n",
      "Batch: 42, Loss: 0.584815502166748, Accuracy: 0.806640625\n",
      "Batch: 43, Loss: 0.8051631450653076, Accuracy: 0.7275390625\n",
      "Batch: 44, Loss: 0.7662596702575684, Accuracy: 0.7490234375\n",
      "Batch: 45, Loss: 0.6901737451553345, Accuracy: 0.7705078125\n",
      "Batch: 46, Loss: 0.6770602464675903, Accuracy: 0.7802734375\n",
      "Batch: 47, Loss: 0.6716433763504028, Accuracy: 0.7880859375\n",
      "Batch: 48, Loss: 0.6490778923034668, Accuracy: 0.78515625\n",
      "Batch: 49, Loss: 0.7835249304771423, Accuracy: 0.7353515625\n",
      "Batch: 50, Loss: 0.7482737898826599, Accuracy: 0.759765625\n",
      "Batch: 51, Loss: 0.7768604755401611, Accuracy: 0.7578125\n",
      "Batch: 52, Loss: 0.7417125701904297, Accuracy: 0.7431640625\n",
      "Batch: 53, Loss: 0.7122653722763062, Accuracy: 0.7607421875\n",
      "Batch: 54, Loss: 0.7425684928894043, Accuracy: 0.755859375\n",
      "Batch: 55, Loss: 0.852979302406311, Accuracy: 0.7177734375\n",
      "Batch: 56, Loss: 0.7831671237945557, Accuracy: 0.7353515625\n",
      "Batch: 57, Loss: 0.7660481333732605, Accuracy: 0.7548828125\n",
      "Batch: 58, Loss: 0.8622195720672607, Accuracy: 0.7392578125\n",
      "Batch: 59, Loss: 0.7042065262794495, Accuracy: 0.7734375\n",
      "Batch: 60, Loss: 0.6847113370895386, Accuracy: 0.7705078125\n",
      "Batch: 61, Loss: 0.7542277574539185, Accuracy: 0.7509765625\n",
      "Batch: 62, Loss: 0.7274991273880005, Accuracy: 0.7578125\n",
      "Batch: 63, Loss: 0.7691128849983215, Accuracy: 0.7392578125\n",
      "Batch: 64, Loss: 0.7408892512321472, Accuracy: 0.7568359375\n",
      "Batch: 65, Loss: 0.7575125694274902, Accuracy: 0.7451171875\n",
      "Batch: 66, Loss: 0.7386550903320312, Accuracy: 0.7607421875\n",
      "Batch: 67, Loss: 0.8326764702796936, Accuracy: 0.7255859375\n",
      "Batch: 68, Loss: 0.8513031005859375, Accuracy: 0.7373046875\n",
      "Batch: 69, Loss: 0.7698643803596497, Accuracy: 0.7392578125\n",
      "Batch: 70, Loss: 0.7527382373809814, Accuracy: 0.76953125\n",
      "Batch: 71, Loss: 0.8096360564231873, Accuracy: 0.7255859375\n",
      "Batch: 72, Loss: 0.6545418500900269, Accuracy: 0.7822265625\n",
      "Batch: 73, Loss: 0.6613180637359619, Accuracy: 0.7978515625\n",
      "Batch: 74, Loss: 0.6715022325515747, Accuracy: 0.796875\n",
      "Batch: 75, Loss: 0.6643309593200684, Accuracy: 0.7822265625\n",
      "Batch: 76, Loss: 0.7475847005844116, Accuracy: 0.7509765625\n",
      "Batch: 77, Loss: 0.7139793634414673, Accuracy: 0.7509765625\n",
      "Batch: 78, Loss: 0.6226978302001953, Accuracy: 0.79296875\n",
      "Batch: 79, Loss: 0.6471566557884216, Accuracy: 0.7919921875\n",
      "Batch: 80, Loss: 0.7012254595756531, Accuracy: 0.7646484375\n",
      "Batch: 81, Loss: 0.7997647523880005, Accuracy: 0.712890625\n",
      "Batch: 82, Loss: 0.7785807847976685, Accuracy: 0.7373046875\n",
      "Batch: 83, Loss: 0.6620151996612549, Accuracy: 0.798828125\n",
      "Batch: 84, Loss: 0.6950291395187378, Accuracy: 0.765625\n",
      "Batch: 85, Loss: 0.6994907855987549, Accuracy: 0.779296875\n",
      "Batch: 86, Loss: 0.8357931971549988, Accuracy: 0.7314453125\n",
      "Batch: 87, Loss: 0.6998856067657471, Accuracy: 0.7705078125\n",
      "Batch: 88, Loss: 0.8233293294906616, Accuracy: 0.734375\n",
      "Batch: 89, Loss: 0.7848712205886841, Accuracy: 0.7548828125\n",
      "Batch: 90, Loss: 0.7381042242050171, Accuracy: 0.751953125\n",
      "Batch: 91, Loss: 0.6782869696617126, Accuracy: 0.7841796875\n",
      "Batch: 92, Loss: 0.7619696855545044, Accuracy: 0.751953125\n",
      "Batch: 93, Loss: 0.7546398639678955, Accuracy: 0.7451171875\n",
      "Batch: 94, Loss: 0.7692276239395142, Accuracy: 0.7353515625\n",
      "Batch: 95, Loss: 0.7897734642028809, Accuracy: 0.7197265625\n",
      "Batch: 96, Loss: 0.736768364906311, Accuracy: 0.7509765625\n",
      "Batch: 97, Loss: 0.6194323301315308, Accuracy: 0.791015625\n",
      "Batch: 98, Loss: 0.7196347117424011, Accuracy: 0.751953125\n",
      "Batch: 99, Loss: 0.7518801689147949, Accuracy: 0.7607421875\n",
      "Batch: 100, Loss: 0.7604649662971497, Accuracy: 0.7451171875\n",
      "Batch: 101, Loss: 0.7533196210861206, Accuracy: 0.7470703125\n",
      "Batch: 102, Loss: 0.7496007680892944, Accuracy: 0.7587890625\n",
      "Batch: 103, Loss: 0.7818946242332458, Accuracy: 0.7509765625\n",
      "Batch: 104, Loss: 0.6814146041870117, Accuracy: 0.763671875\n",
      "Batch: 105, Loss: 0.7692643404006958, Accuracy: 0.7412109375\n",
      "Batch: 106, Loss: 0.7095251679420471, Accuracy: 0.7734375\n",
      "Batch: 107, Loss: 0.7390293478965759, Accuracy: 0.76953125\n",
      "Batch: 108, Loss: 0.7593764066696167, Accuracy: 0.744140625\n",
      "Batch: 109, Loss: 0.8667754530906677, Accuracy: 0.705078125\n",
      "Batch: 110, Loss: 0.7092146873474121, Accuracy: 0.7724609375\n",
      "Batch: 111, Loss: 0.7894504070281982, Accuracy: 0.7431640625\n",
      "Batch: 112, Loss: 0.7309404015541077, Accuracy: 0.7607421875\n",
      "Batch: 113, Loss: 0.7205074429512024, Accuracy: 0.7646484375\n",
      "Batch: 114, Loss: 0.810240626335144, Accuracy: 0.7470703125\n",
      "Batch: 115, Loss: 0.843546986579895, Accuracy: 0.7255859375\n",
      "Batch: 116, Loss: 0.7691245675086975, Accuracy: 0.75\n",
      "Batch: 117, Loss: 0.7950717806816101, Accuracy: 0.7392578125\n",
      "Batch: 118, Loss: 0.6582381725311279, Accuracy: 0.7734375\n",
      "Batch: 119, Loss: 0.615668535232544, Accuracy: 0.80078125\n",
      "Batch: 120, Loss: 0.7665532231330872, Accuracy: 0.7568359375\n",
      "Batch: 121, Loss: 0.8216996192932129, Accuracy: 0.7294921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 122, Loss: 0.6869040727615356, Accuracy: 0.7734375\n",
      "Batch: 123, Loss: 0.6522034406661987, Accuracy: 0.787109375\n",
      "Batch: 124, Loss: 0.7289732694625854, Accuracy: 0.765625\n",
      "Batch: 125, Loss: 0.8124313950538635, Accuracy: 0.7421875\n",
      "Batch: 126, Loss: 0.7411198616027832, Accuracy: 0.7548828125\n",
      "Batch: 127, Loss: 0.6977897882461548, Accuracy: 0.783203125\n",
      "Batch: 128, Loss: 0.7837834358215332, Accuracy: 0.765625\n",
      "Batch: 129, Loss: 0.682675302028656, Accuracy: 0.7646484375\n",
      "Batch: 130, Loss: 0.8502583503723145, Accuracy: 0.7265625\n",
      "Batch: 131, Loss: 0.7424142956733704, Accuracy: 0.74609375\n",
      "Batch: 132, Loss: 0.7939931154251099, Accuracy: 0.748046875\n",
      "Batch: 133, Loss: 0.705014705657959, Accuracy: 0.7548828125\n",
      "Batch: 134, Loss: 0.7422049641609192, Accuracy: 0.75\n",
      "Batch: 135, Loss: 0.6710900664329529, Accuracy: 0.771484375\n",
      "Batch: 136, Loss: 0.7360156178474426, Accuracy: 0.7578125\n",
      "Batch: 137, Loss: 0.7684004306793213, Accuracy: 0.7236328125\n",
      "Batch: 138, Loss: 0.6647042036056519, Accuracy: 0.7841796875\n",
      "Batch: 139, Loss: 0.6992989182472229, Accuracy: 0.767578125\n",
      "Batch: 140, Loss: 0.7340784072875977, Accuracy: 0.751953125\n",
      "Batch: 141, Loss: 0.7802571654319763, Accuracy: 0.7490234375\n",
      "Batch: 142, Loss: 0.8141199350357056, Accuracy: 0.736328125\n",
      "Batch: 143, Loss: 0.7531667947769165, Accuracy: 0.7548828125\n",
      "Batch: 144, Loss: 0.7673944234848022, Accuracy: 0.73828125\n",
      "Batch: 145, Loss: 0.7024961709976196, Accuracy: 0.7626953125\n",
      "Batch: 146, Loss: 0.7566162347793579, Accuracy: 0.7451171875\n",
      "Batch: 147, Loss: 0.7550649642944336, Accuracy: 0.7490234375\n",
      "Batch: 148, Loss: 0.8017522096633911, Accuracy: 0.7509765625\n",
      "Batch: 149, Loss: 0.7173701524734497, Accuracy: 0.7490234375\n",
      "Batch: 150, Loss: 0.7063267827033997, Accuracy: 0.7666015625\n",
      "Batch: 151, Loss: 0.6696864366531372, Accuracy: 0.77734375\n",
      "Epoch 59/80\n",
      "Batch: 1, Loss: 0.9813810586929321, Accuracy: 0.7001953125\n",
      "Batch: 2, Loss: 0.8482757806777954, Accuracy: 0.7158203125\n",
      "Batch: 3, Loss: 0.7141368389129639, Accuracy: 0.7626953125\n",
      "Batch: 4, Loss: 0.5949004888534546, Accuracy: 0.796875\n",
      "Batch: 5, Loss: 0.71300208568573, Accuracy: 0.759765625\n",
      "Batch: 6, Loss: 0.7596949338912964, Accuracy: 0.7294921875\n",
      "Batch: 7, Loss: 0.7803769111633301, Accuracy: 0.734375\n",
      "Batch: 8, Loss: 0.7149792909622192, Accuracy: 0.763671875\n",
      "Batch: 9, Loss: 0.6887294054031372, Accuracy: 0.7734375\n",
      "Batch: 10, Loss: 0.7104747295379639, Accuracy: 0.7587890625\n",
      "Batch: 11, Loss: 0.8112928867340088, Accuracy: 0.724609375\n",
      "Batch: 12, Loss: 0.7918086051940918, Accuracy: 0.75390625\n",
      "Batch: 13, Loss: 0.6339680552482605, Accuracy: 0.796875\n",
      "Batch: 14, Loss: 0.8295093774795532, Accuracy: 0.7353515625\n",
      "Batch: 15, Loss: 0.6849768161773682, Accuracy: 0.78125\n",
      "Batch: 16, Loss: 0.7463454008102417, Accuracy: 0.759765625\n",
      "Batch: 17, Loss: 0.7819523811340332, Accuracy: 0.736328125\n",
      "Batch: 18, Loss: 0.7739291191101074, Accuracy: 0.75\n",
      "Batch: 19, Loss: 0.743610143661499, Accuracy: 0.75390625\n",
      "Batch: 20, Loss: 0.6594104766845703, Accuracy: 0.787109375\n",
      "Batch: 21, Loss: 0.7006772756576538, Accuracy: 0.7685546875\n",
      "Batch: 22, Loss: 0.8022412657737732, Accuracy: 0.7353515625\n",
      "Batch: 23, Loss: 0.7596325874328613, Accuracy: 0.740234375\n",
      "Batch: 24, Loss: 0.7604764103889465, Accuracy: 0.740234375\n",
      "Batch: 25, Loss: 0.757835865020752, Accuracy: 0.7373046875\n",
      "Batch: 26, Loss: 0.6392288208007812, Accuracy: 0.7734375\n",
      "Batch: 27, Loss: 0.7354506254196167, Accuracy: 0.7548828125\n",
      "Batch: 28, Loss: 0.7543212175369263, Accuracy: 0.73828125\n",
      "Batch: 29, Loss: 0.7054852247238159, Accuracy: 0.76953125\n",
      "Batch: 30, Loss: 0.6295260190963745, Accuracy: 0.798828125\n",
      "Batch: 31, Loss: 0.6338140368461609, Accuracy: 0.7919921875\n",
      "Batch: 32, Loss: 0.6826349496841431, Accuracy: 0.7685546875\n",
      "Batch: 33, Loss: 0.815697431564331, Accuracy: 0.7353515625\n",
      "Batch: 34, Loss: 0.8444113731384277, Accuracy: 0.734375\n",
      "Batch: 35, Loss: 0.7396272420883179, Accuracy: 0.75\n",
      "Batch: 36, Loss: 0.7388977408409119, Accuracy: 0.765625\n",
      "Batch: 37, Loss: 0.7504957914352417, Accuracy: 0.7705078125\n",
      "Batch: 38, Loss: 0.7788746356964111, Accuracy: 0.7529296875\n",
      "Batch: 39, Loss: 0.7602800130844116, Accuracy: 0.7529296875\n",
      "Batch: 40, Loss: 0.7174054980278015, Accuracy: 0.76953125\n",
      "Batch: 41, Loss: 0.6570333242416382, Accuracy: 0.7919921875\n",
      "Batch: 42, Loss: 0.5818301439285278, Accuracy: 0.7998046875\n",
      "Batch: 43, Loss: 0.7752707004547119, Accuracy: 0.7392578125\n",
      "Batch: 44, Loss: 0.7784414887428284, Accuracy: 0.7353515625\n",
      "Batch: 45, Loss: 0.7095932960510254, Accuracy: 0.7607421875\n",
      "Batch: 46, Loss: 0.6542430520057678, Accuracy: 0.8017578125\n",
      "Batch: 47, Loss: 0.6523813009262085, Accuracy: 0.7978515625\n",
      "Batch: 48, Loss: 0.641718864440918, Accuracy: 0.7880859375\n",
      "Batch: 49, Loss: 0.7504693269729614, Accuracy: 0.7587890625\n",
      "Batch: 50, Loss: 0.7378045320510864, Accuracy: 0.7626953125\n",
      "Batch: 51, Loss: 0.7886570692062378, Accuracy: 0.7451171875\n",
      "Batch: 52, Loss: 0.7591444849967957, Accuracy: 0.75\n",
      "Batch: 53, Loss: 0.6870208978652954, Accuracy: 0.765625\n",
      "Batch: 54, Loss: 0.6962161660194397, Accuracy: 0.7666015625\n",
      "Batch: 55, Loss: 0.8496766090393066, Accuracy: 0.7197265625\n",
      "Batch: 56, Loss: 0.7940906286239624, Accuracy: 0.7470703125\n",
      "Batch: 57, Loss: 0.7678613662719727, Accuracy: 0.7578125\n",
      "Batch: 58, Loss: 0.8774939775466919, Accuracy: 0.736328125\n",
      "Batch: 59, Loss: 0.7156369090080261, Accuracy: 0.767578125\n",
      "Batch: 60, Loss: 0.6935045719146729, Accuracy: 0.78125\n",
      "Batch: 61, Loss: 0.7522412538528442, Accuracy: 0.765625\n",
      "Batch: 62, Loss: 0.7002010345458984, Accuracy: 0.76953125\n",
      "Batch: 63, Loss: 0.7674243450164795, Accuracy: 0.7412109375\n",
      "Batch: 64, Loss: 0.7386665940284729, Accuracy: 0.7626953125\n",
      "Batch: 65, Loss: 0.7633596658706665, Accuracy: 0.7490234375\n",
      "Batch: 66, Loss: 0.7403361797332764, Accuracy: 0.7734375\n",
      "Batch: 67, Loss: 0.8247323632240295, Accuracy: 0.732421875\n",
      "Batch: 68, Loss: 0.885515570640564, Accuracy: 0.7158203125\n",
      "Batch: 69, Loss: 0.7637873291969299, Accuracy: 0.759765625\n",
      "Batch: 70, Loss: 0.7264242768287659, Accuracy: 0.7841796875\n",
      "Batch: 71, Loss: 0.7881854772567749, Accuracy: 0.740234375\n",
      "Batch: 72, Loss: 0.6721197366714478, Accuracy: 0.78125\n",
      "Batch: 73, Loss: 0.6595393419265747, Accuracy: 0.8037109375\n",
      "Batch: 74, Loss: 0.6422385573387146, Accuracy: 0.791015625\n",
      "Batch: 75, Loss: 0.6521120667457581, Accuracy: 0.794921875\n",
      "Batch: 76, Loss: 0.7443770170211792, Accuracy: 0.7587890625\n",
      "Batch: 77, Loss: 0.681643009185791, Accuracy: 0.779296875\n",
      "Batch: 78, Loss: 0.6331655383110046, Accuracy: 0.796875\n",
      "Batch: 79, Loss: 0.6225959062576294, Accuracy: 0.794921875\n",
      "Batch: 80, Loss: 0.6901646852493286, Accuracy: 0.759765625\n",
      "Batch: 81, Loss: 0.8186759948730469, Accuracy: 0.7236328125\n",
      "Batch: 82, Loss: 0.7599288821220398, Accuracy: 0.7421875\n",
      "Batch: 83, Loss: 0.6518247723579407, Accuracy: 0.7939453125\n",
      "Batch: 84, Loss: 0.7272311449050903, Accuracy: 0.7578125\n",
      "Batch: 85, Loss: 0.6802335381507874, Accuracy: 0.765625\n",
      "Batch: 86, Loss: 0.8537868857383728, Accuracy: 0.734375\n",
      "Batch: 87, Loss: 0.6905776262283325, Accuracy: 0.79296875\n",
      "Batch: 88, Loss: 0.7673457860946655, Accuracy: 0.7548828125\n",
      "Batch: 89, Loss: 0.7585630416870117, Accuracy: 0.7705078125\n",
      "Batch: 90, Loss: 0.6997511386871338, Accuracy: 0.775390625\n",
      "Batch: 91, Loss: 0.716428816318512, Accuracy: 0.755859375\n",
      "Batch: 92, Loss: 0.7371212244033813, Accuracy: 0.767578125\n",
      "Batch: 93, Loss: 0.7330726981163025, Accuracy: 0.7607421875\n",
      "Batch: 94, Loss: 0.7665945887565613, Accuracy: 0.7431640625\n",
      "Batch: 95, Loss: 0.757429301738739, Accuracy: 0.728515625\n",
      "Batch: 96, Loss: 0.735582172870636, Accuracy: 0.7666015625\n",
      "Batch: 97, Loss: 0.6085739135742188, Accuracy: 0.79296875\n",
      "Batch: 98, Loss: 0.7368946075439453, Accuracy: 0.759765625\n",
      "Batch: 99, Loss: 0.7115216255187988, Accuracy: 0.7685546875\n",
      "Batch: 100, Loss: 0.7570152282714844, Accuracy: 0.74609375\n",
      "Batch: 101, Loss: 0.7680808901786804, Accuracy: 0.7529296875\n",
      "Batch: 102, Loss: 0.7483758926391602, Accuracy: 0.7626953125\n",
      "Batch: 103, Loss: 0.731160581111908, Accuracy: 0.7685546875\n",
      "Batch: 104, Loss: 0.6923657655715942, Accuracy: 0.7626953125\n",
      "Batch: 105, Loss: 0.7835485935211182, Accuracy: 0.7412109375\n",
      "Batch: 106, Loss: 0.7183905839920044, Accuracy: 0.759765625\n",
      "Batch: 107, Loss: 0.733622133731842, Accuracy: 0.765625\n",
      "Batch: 108, Loss: 0.7186751961708069, Accuracy: 0.7509765625\n",
      "Batch: 109, Loss: 0.8603067398071289, Accuracy: 0.7041015625\n",
      "Batch: 110, Loss: 0.6781426668167114, Accuracy: 0.7734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 111, Loss: 0.7851766347885132, Accuracy: 0.7490234375\n",
      "Batch: 112, Loss: 0.7337467670440674, Accuracy: 0.767578125\n",
      "Batch: 113, Loss: 0.7256772518157959, Accuracy: 0.771484375\n",
      "Batch: 114, Loss: 0.8371490240097046, Accuracy: 0.7392578125\n",
      "Batch: 115, Loss: 0.8801933526992798, Accuracy: 0.7216796875\n",
      "Batch: 116, Loss: 0.8207612037658691, Accuracy: 0.73828125\n",
      "Batch: 117, Loss: 0.8099260926246643, Accuracy: 0.7265625\n",
      "Batch: 118, Loss: 0.6909414529800415, Accuracy: 0.775390625\n",
      "Batch: 119, Loss: 0.6485496759414673, Accuracy: 0.7861328125\n",
      "Batch: 120, Loss: 0.7701717615127563, Accuracy: 0.7294921875\n",
      "Batch: 121, Loss: 0.7820602655410767, Accuracy: 0.7353515625\n",
      "Batch: 122, Loss: 0.6983945965766907, Accuracy: 0.7705078125\n",
      "Batch: 123, Loss: 0.6895636320114136, Accuracy: 0.7822265625\n",
      "Batch: 124, Loss: 0.751274585723877, Accuracy: 0.7470703125\n",
      "Batch: 125, Loss: 0.7874635457992554, Accuracy: 0.7412109375\n",
      "Batch: 126, Loss: 0.7604729533195496, Accuracy: 0.7412109375\n",
      "Batch: 127, Loss: 0.7161980867385864, Accuracy: 0.7705078125\n",
      "Batch: 128, Loss: 0.8217523694038391, Accuracy: 0.7509765625\n",
      "Batch: 129, Loss: 0.6738266944885254, Accuracy: 0.7744140625\n",
      "Batch: 130, Loss: 0.8624752759933472, Accuracy: 0.7275390625\n",
      "Batch: 131, Loss: 0.7570873498916626, Accuracy: 0.7421875\n",
      "Batch: 132, Loss: 0.7870296835899353, Accuracy: 0.7275390625\n",
      "Batch: 133, Loss: 0.7194408774375916, Accuracy: 0.755859375\n",
      "Batch: 134, Loss: 0.7732734680175781, Accuracy: 0.7412109375\n",
      "Batch: 135, Loss: 0.6697527766227722, Accuracy: 0.783203125\n",
      "Batch: 136, Loss: 0.7652829885482788, Accuracy: 0.740234375\n",
      "Batch: 137, Loss: 0.7354816198348999, Accuracy: 0.7470703125\n",
      "Batch: 138, Loss: 0.6638525724411011, Accuracy: 0.7724609375\n",
      "Batch: 139, Loss: 0.729314923286438, Accuracy: 0.7548828125\n",
      "Batch: 140, Loss: 0.870936393737793, Accuracy: 0.7275390625\n",
      "Batch: 141, Loss: 0.9227793216705322, Accuracy: 0.70703125\n",
      "Batch: 142, Loss: 0.8891955614089966, Accuracy: 0.720703125\n",
      "Batch: 143, Loss: 0.781975269317627, Accuracy: 0.7431640625\n",
      "Batch: 144, Loss: 0.8189573287963867, Accuracy: 0.7421875\n",
      "Batch: 145, Loss: 0.783164381980896, Accuracy: 0.7412109375\n",
      "Batch: 146, Loss: 0.8556749820709229, Accuracy: 0.7099609375\n",
      "Batch: 147, Loss: 0.8336026072502136, Accuracy: 0.7255859375\n",
      "Batch: 148, Loss: 0.8587237596511841, Accuracy: 0.7041015625\n",
      "Batch: 149, Loss: 0.7656780481338501, Accuracy: 0.73828125\n",
      "Batch: 150, Loss: 0.7471903562545776, Accuracy: 0.755859375\n",
      "Batch: 151, Loss: 0.6438201665878296, Accuracy: 0.783203125\n",
      "Epoch 60/80\n",
      "Batch: 1, Loss: 0.9932011365890503, Accuracy: 0.6962890625\n",
      "Batch: 2, Loss: 0.8576834201812744, Accuracy: 0.6982421875\n",
      "Batch: 3, Loss: 0.7169309258460999, Accuracy: 0.7685546875\n",
      "Batch: 4, Loss: 0.6560075283050537, Accuracy: 0.78125\n",
      "Batch: 5, Loss: 0.7127186059951782, Accuracy: 0.767578125\n",
      "Batch: 6, Loss: 0.7623282670974731, Accuracy: 0.744140625\n",
      "Batch: 7, Loss: 0.7563396692276001, Accuracy: 0.748046875\n",
      "Batch: 8, Loss: 0.7215573787689209, Accuracy: 0.7587890625\n",
      "Batch: 9, Loss: 0.7209970951080322, Accuracy: 0.767578125\n",
      "Batch: 10, Loss: 0.7311481237411499, Accuracy: 0.751953125\n",
      "Batch: 11, Loss: 0.8086382150650024, Accuracy: 0.7255859375\n",
      "Batch: 12, Loss: 0.7715237736701965, Accuracy: 0.744140625\n",
      "Batch: 13, Loss: 0.6436741352081299, Accuracy: 0.7880859375\n",
      "Batch: 14, Loss: 0.8597886562347412, Accuracy: 0.7255859375\n",
      "Batch: 15, Loss: 0.6708887815475464, Accuracy: 0.7861328125\n",
      "Batch: 16, Loss: 0.7503113150596619, Accuracy: 0.7548828125\n",
      "Batch: 17, Loss: 0.8008450269699097, Accuracy: 0.7255859375\n",
      "Batch: 18, Loss: 0.7950419187545776, Accuracy: 0.75\n",
      "Batch: 19, Loss: 0.7828185558319092, Accuracy: 0.75\n",
      "Batch: 20, Loss: 0.6770691871643066, Accuracy: 0.7900390625\n",
      "Batch: 21, Loss: 0.7080605030059814, Accuracy: 0.755859375\n",
      "Batch: 22, Loss: 0.8279464244842529, Accuracy: 0.7314453125\n",
      "Batch: 23, Loss: 0.7601560354232788, Accuracy: 0.7294921875\n",
      "Batch: 24, Loss: 0.7476229667663574, Accuracy: 0.748046875\n",
      "Batch: 25, Loss: 0.7282358407974243, Accuracy: 0.7587890625\n",
      "Batch: 26, Loss: 0.6620417833328247, Accuracy: 0.7734375\n",
      "Batch: 27, Loss: 0.7285411357879639, Accuracy: 0.7548828125\n",
      "Batch: 28, Loss: 0.7395558953285217, Accuracy: 0.755859375\n",
      "Batch: 29, Loss: 0.7144405841827393, Accuracy: 0.7529296875\n",
      "Batch: 30, Loss: 0.6228040456771851, Accuracy: 0.794921875\n",
      "Batch: 31, Loss: 0.649115264415741, Accuracy: 0.80078125\n",
      "Batch: 32, Loss: 0.696367621421814, Accuracy: 0.76953125\n",
      "Batch: 33, Loss: 0.8051397800445557, Accuracy: 0.740234375\n",
      "Batch: 34, Loss: 0.858626127243042, Accuracy: 0.71484375\n",
      "Batch: 35, Loss: 0.7405632138252258, Accuracy: 0.7587890625\n",
      "Batch: 36, Loss: 0.7907940745353699, Accuracy: 0.7392578125\n",
      "Batch: 37, Loss: 0.7460602521896362, Accuracy: 0.76171875\n",
      "Batch: 38, Loss: 0.7461047172546387, Accuracy: 0.7451171875\n",
      "Batch: 39, Loss: 0.7604970335960388, Accuracy: 0.744140625\n",
      "Batch: 40, Loss: 0.7391901016235352, Accuracy: 0.7626953125\n",
      "Batch: 41, Loss: 0.6928996443748474, Accuracy: 0.775390625\n",
      "Batch: 42, Loss: 0.5962308645248413, Accuracy: 0.798828125\n",
      "Batch: 43, Loss: 0.7604506015777588, Accuracy: 0.7431640625\n",
      "Batch: 44, Loss: 0.7647120952606201, Accuracy: 0.7529296875\n",
      "Batch: 45, Loss: 0.7043592929840088, Accuracy: 0.7587890625\n",
      "Batch: 46, Loss: 0.6886779069900513, Accuracy: 0.7783203125\n",
      "Batch: 47, Loss: 0.6606343984603882, Accuracy: 0.78515625\n",
      "Batch: 48, Loss: 0.6486088037490845, Accuracy: 0.783203125\n",
      "Batch: 49, Loss: 0.8019291162490845, Accuracy: 0.7412109375\n",
      "Batch: 50, Loss: 0.7801480889320374, Accuracy: 0.751953125\n",
      "Batch: 51, Loss: 0.7666117548942566, Accuracy: 0.7509765625\n",
      "Batch: 52, Loss: 0.7815555334091187, Accuracy: 0.728515625\n",
      "Batch: 53, Loss: 0.6978576183319092, Accuracy: 0.7734375\n",
      "Batch: 54, Loss: 0.7337905168533325, Accuracy: 0.75\n",
      "Batch: 55, Loss: 0.8560046553611755, Accuracy: 0.7138671875\n",
      "Batch: 56, Loss: 0.7668706178665161, Accuracy: 0.7529296875\n",
      "Batch: 57, Loss: 0.7787510752677917, Accuracy: 0.7431640625\n",
      "Batch: 58, Loss: 0.8562333583831787, Accuracy: 0.7255859375\n",
      "Batch: 59, Loss: 0.7017083168029785, Accuracy: 0.7626953125\n",
      "Batch: 60, Loss: 0.6888836622238159, Accuracy: 0.76953125\n",
      "Batch: 61, Loss: 0.7493879795074463, Accuracy: 0.771484375\n",
      "Batch: 62, Loss: 0.7208006381988525, Accuracy: 0.763671875\n",
      "Batch: 63, Loss: 0.7440112829208374, Accuracy: 0.7490234375\n",
      "Batch: 64, Loss: 0.7420371770858765, Accuracy: 0.755859375\n",
      "Batch: 65, Loss: 0.777808666229248, Accuracy: 0.7451171875\n",
      "Batch: 66, Loss: 0.7227315306663513, Accuracy: 0.7685546875\n",
      "Batch: 67, Loss: 0.81912761926651, Accuracy: 0.7509765625\n",
      "Batch: 68, Loss: 0.837540864944458, Accuracy: 0.7421875\n",
      "Batch: 69, Loss: 0.7998890280723572, Accuracy: 0.7451171875\n",
      "Batch: 70, Loss: 0.7506190538406372, Accuracy: 0.7685546875\n",
      "Batch: 71, Loss: 0.7818336486816406, Accuracy: 0.7431640625\n",
      "Batch: 72, Loss: 0.693778395652771, Accuracy: 0.75390625\n",
      "Batch: 73, Loss: 0.6850355863571167, Accuracy: 0.77734375\n",
      "Batch: 74, Loss: 0.6457204818725586, Accuracy: 0.80078125\n",
      "Batch: 75, Loss: 0.6935095191001892, Accuracy: 0.7763671875\n",
      "Batch: 76, Loss: 0.7787385582923889, Accuracy: 0.7333984375\n",
      "Batch: 77, Loss: 0.6881896257400513, Accuracy: 0.767578125\n",
      "Batch: 78, Loss: 0.6543722152709961, Accuracy: 0.783203125\n",
      "Batch: 79, Loss: 0.6200466752052307, Accuracy: 0.7861328125\n",
      "Batch: 80, Loss: 0.6905996799468994, Accuracy: 0.7666015625\n",
      "Batch: 81, Loss: 0.8285248279571533, Accuracy: 0.7109375\n",
      "Batch: 82, Loss: 0.7733311653137207, Accuracy: 0.7412109375\n",
      "Batch: 83, Loss: 0.647067666053772, Accuracy: 0.8056640625\n",
      "Batch: 84, Loss: 0.7209172248840332, Accuracy: 0.755859375\n",
      "Batch: 85, Loss: 0.6982595920562744, Accuracy: 0.7734375\n",
      "Batch: 86, Loss: 0.8295341730117798, Accuracy: 0.73046875\n",
      "Batch: 87, Loss: 0.6788340210914612, Accuracy: 0.7802734375\n",
      "Batch: 88, Loss: 0.7658821940422058, Accuracy: 0.7509765625\n",
      "Batch: 89, Loss: 0.7685933113098145, Accuracy: 0.76171875\n",
      "Batch: 90, Loss: 0.7152053713798523, Accuracy: 0.7646484375\n",
      "Batch: 91, Loss: 0.6899638772010803, Accuracy: 0.7666015625\n",
      "Batch: 92, Loss: 0.7372689247131348, Accuracy: 0.767578125\n",
      "Batch: 93, Loss: 0.7130286693572998, Accuracy: 0.7607421875\n",
      "Batch: 94, Loss: 0.7404160499572754, Accuracy: 0.744140625\n",
      "Batch: 95, Loss: 0.7897189855575562, Accuracy: 0.7265625\n",
      "Batch: 96, Loss: 0.7148959636688232, Accuracy: 0.7705078125\n",
      "Batch: 97, Loss: 0.6000332832336426, Accuracy: 0.7890625\n",
      "Batch: 98, Loss: 0.7469901442527771, Accuracy: 0.765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 99, Loss: 0.7290788888931274, Accuracy: 0.76953125\n",
      "Batch: 100, Loss: 0.7507559061050415, Accuracy: 0.75390625\n",
      "Batch: 101, Loss: 0.7681704759597778, Accuracy: 0.7607421875\n",
      "Batch: 102, Loss: 0.7465468645095825, Accuracy: 0.7578125\n",
      "Batch: 103, Loss: 0.7730128765106201, Accuracy: 0.7529296875\n",
      "Batch: 104, Loss: 0.7066131234169006, Accuracy: 0.7548828125\n",
      "Batch: 105, Loss: 0.7523102760314941, Accuracy: 0.755859375\n",
      "Batch: 106, Loss: 0.6805456280708313, Accuracy: 0.7900390625\n",
      "Batch: 107, Loss: 0.7299422025680542, Accuracy: 0.7744140625\n",
      "Batch: 108, Loss: 0.7424135208129883, Accuracy: 0.7578125\n",
      "Batch: 109, Loss: 0.852546215057373, Accuracy: 0.7119140625\n",
      "Batch: 110, Loss: 0.7059023380279541, Accuracy: 0.7724609375\n",
      "Batch: 111, Loss: 0.7521368265151978, Accuracy: 0.7490234375\n",
      "Batch: 112, Loss: 0.7334389686584473, Accuracy: 0.76171875\n",
      "Batch: 113, Loss: 0.7466399669647217, Accuracy: 0.76953125\n",
      "Batch: 114, Loss: 0.7957726716995239, Accuracy: 0.7333984375\n",
      "Batch: 115, Loss: 0.8196324110031128, Accuracy: 0.7470703125\n",
      "Batch: 116, Loss: 0.7182285785675049, Accuracy: 0.7626953125\n",
      "Batch: 117, Loss: 0.7681472301483154, Accuracy: 0.7431640625\n",
      "Batch: 118, Loss: 0.671018123626709, Accuracy: 0.787109375\n",
      "Batch: 119, Loss: 0.6353724002838135, Accuracy: 0.7861328125\n",
      "Batch: 120, Loss: 0.7485240697860718, Accuracy: 0.755859375\n",
      "Batch: 121, Loss: 0.778850793838501, Accuracy: 0.748046875\n",
      "Batch: 122, Loss: 0.6991155743598938, Accuracy: 0.76953125\n",
      "Batch: 123, Loss: 0.6655794978141785, Accuracy: 0.78125\n",
      "Batch: 124, Loss: 0.72757887840271, Accuracy: 0.75\n",
      "Batch: 125, Loss: 0.8034347295761108, Accuracy: 0.7451171875\n",
      "Batch: 126, Loss: 0.7364046573638916, Accuracy: 0.7490234375\n",
      "Batch: 127, Loss: 0.6911789774894714, Accuracy: 0.7734375\n",
      "Batch: 128, Loss: 0.7929776906967163, Accuracy: 0.7509765625\n",
      "Batch: 129, Loss: 0.664434552192688, Accuracy: 0.7841796875\n",
      "Batch: 130, Loss: 0.8331845998764038, Accuracy: 0.7314453125\n",
      "Batch: 131, Loss: 0.741693377494812, Accuracy: 0.748046875\n",
      "Batch: 132, Loss: 0.7878410816192627, Accuracy: 0.751953125\n",
      "Batch: 133, Loss: 0.7113020420074463, Accuracy: 0.763671875\n",
      "Batch: 134, Loss: 0.7563809156417847, Accuracy: 0.736328125\n",
      "Batch: 135, Loss: 0.6918268799781799, Accuracy: 0.7783203125\n",
      "Batch: 136, Loss: 0.7460247278213501, Accuracy: 0.7734375\n",
      "Batch: 137, Loss: 0.7482460737228394, Accuracy: 0.736328125\n",
      "Batch: 138, Loss: 0.653533935546875, Accuracy: 0.78125\n",
      "Batch: 139, Loss: 0.7053543329238892, Accuracy: 0.7626953125\n",
      "Batch: 140, Loss: 0.6942811012268066, Accuracy: 0.767578125\n",
      "Batch: 141, Loss: 0.7789969444274902, Accuracy: 0.7451171875\n",
      "Batch: 142, Loss: 0.7879496812820435, Accuracy: 0.7412109375\n",
      "Batch: 143, Loss: 0.7578974962234497, Accuracy: 0.7412109375\n",
      "Batch: 144, Loss: 0.7609294056892395, Accuracy: 0.7431640625\n",
      "Batch: 145, Loss: 0.7096068859100342, Accuracy: 0.7529296875\n",
      "Batch: 146, Loss: 0.7632550001144409, Accuracy: 0.748046875\n",
      "Batch: 147, Loss: 0.7625160217285156, Accuracy: 0.74609375\n",
      "Batch: 148, Loss: 0.7974247336387634, Accuracy: 0.7255859375\n",
      "Batch: 149, Loss: 0.7060551643371582, Accuracy: 0.7578125\n",
      "Batch: 150, Loss: 0.7007805109024048, Accuracy: 0.7685546875\n",
      "Batch: 151, Loss: 0.6247929930686951, Accuracy: 0.7978515625\n",
      "Saved Weights at epoch 60 to file Weights_60.h5\n",
      "Epoch 61/80\n",
      "Batch: 1, Loss: 0.945386528968811, Accuracy: 0.7119140625\n",
      "Batch: 2, Loss: 0.8453390598297119, Accuracy: 0.6962890625\n",
      "Batch: 3, Loss: 0.71775221824646, Accuracy: 0.7705078125\n",
      "Batch: 4, Loss: 0.6106183528900146, Accuracy: 0.8037109375\n",
      "Batch: 5, Loss: 0.7213666439056396, Accuracy: 0.7734375\n",
      "Batch: 6, Loss: 0.7325721979141235, Accuracy: 0.736328125\n",
      "Batch: 7, Loss: 0.7655492424964905, Accuracy: 0.7353515625\n",
      "Batch: 8, Loss: 0.701465904712677, Accuracy: 0.7607421875\n",
      "Batch: 9, Loss: 0.6893308162689209, Accuracy: 0.7763671875\n",
      "Batch: 10, Loss: 0.6944972276687622, Accuracy: 0.7705078125\n",
      "Batch: 11, Loss: 0.8269506096839905, Accuracy: 0.7177734375\n",
      "Batch: 12, Loss: 0.7696701288223267, Accuracy: 0.7470703125\n",
      "Batch: 13, Loss: 0.6283807754516602, Accuracy: 0.7998046875\n",
      "Batch: 14, Loss: 0.8239376544952393, Accuracy: 0.732421875\n",
      "Batch: 15, Loss: 0.6488097906112671, Accuracy: 0.7939453125\n",
      "Batch: 16, Loss: 0.7253308296203613, Accuracy: 0.7626953125\n",
      "Batch: 17, Loss: 0.7675759792327881, Accuracy: 0.7373046875\n",
      "Batch: 18, Loss: 0.7790370583534241, Accuracy: 0.7548828125\n",
      "Batch: 19, Loss: 0.7719675898551941, Accuracy: 0.748046875\n",
      "Batch: 20, Loss: 0.6541295647621155, Accuracy: 0.7890625\n",
      "Batch: 21, Loss: 0.6919525861740112, Accuracy: 0.76953125\n",
      "Batch: 22, Loss: 0.8021808862686157, Accuracy: 0.7431640625\n",
      "Batch: 23, Loss: 0.7395994663238525, Accuracy: 0.7529296875\n",
      "Batch: 24, Loss: 0.7422603368759155, Accuracy: 0.7568359375\n",
      "Batch: 25, Loss: 0.7216054201126099, Accuracy: 0.7666015625\n",
      "Batch: 26, Loss: 0.6553986072540283, Accuracy: 0.7724609375\n",
      "Batch: 27, Loss: 0.6928514242172241, Accuracy: 0.7509765625\n",
      "Batch: 28, Loss: 0.756356954574585, Accuracy: 0.7314453125\n",
      "Batch: 29, Loss: 0.6874785423278809, Accuracy: 0.7626953125\n",
      "Batch: 30, Loss: 0.627386748790741, Accuracy: 0.80859375\n",
      "Batch: 31, Loss: 0.6439809799194336, Accuracy: 0.8076171875\n",
      "Batch: 32, Loss: 0.6600964069366455, Accuracy: 0.779296875\n",
      "Batch: 33, Loss: 0.8074512481689453, Accuracy: 0.7275390625\n",
      "Batch: 34, Loss: 0.8533252477645874, Accuracy: 0.728515625\n",
      "Batch: 35, Loss: 0.7519832849502563, Accuracy: 0.7578125\n",
      "Batch: 36, Loss: 0.7215083241462708, Accuracy: 0.771484375\n",
      "Batch: 37, Loss: 0.7475953102111816, Accuracy: 0.7607421875\n",
      "Batch: 38, Loss: 0.7652053833007812, Accuracy: 0.74609375\n",
      "Batch: 39, Loss: 0.7651965618133545, Accuracy: 0.75390625\n",
      "Batch: 40, Loss: 0.7154628038406372, Accuracy: 0.76171875\n",
      "Batch: 41, Loss: 0.6946640014648438, Accuracy: 0.78515625\n",
      "Batch: 42, Loss: 0.5764386653900146, Accuracy: 0.80859375\n",
      "Batch: 43, Loss: 0.7743353843688965, Accuracy: 0.7421875\n",
      "Batch: 44, Loss: 0.7673388719558716, Accuracy: 0.734375\n",
      "Batch: 45, Loss: 0.6778387427330017, Accuracy: 0.77734375\n",
      "Batch: 46, Loss: 0.6639562845230103, Accuracy: 0.78125\n",
      "Batch: 47, Loss: 0.6427507400512695, Accuracy: 0.8017578125\n",
      "Batch: 48, Loss: 0.6397958993911743, Accuracy: 0.791015625\n",
      "Batch: 49, Loss: 0.7516104578971863, Accuracy: 0.7578125\n",
      "Batch: 50, Loss: 0.7517349720001221, Accuracy: 0.7451171875\n",
      "Batch: 51, Loss: 0.7003164887428284, Accuracy: 0.765625\n",
      "Batch: 52, Loss: 0.7125183939933777, Accuracy: 0.759765625\n",
      "Batch: 53, Loss: 0.6920838952064514, Accuracy: 0.7705078125\n",
      "Batch: 54, Loss: 0.7219556570053101, Accuracy: 0.7607421875\n",
      "Batch: 55, Loss: 0.8285096883773804, Accuracy: 0.724609375\n",
      "Batch: 56, Loss: 0.7987685203552246, Accuracy: 0.73046875\n",
      "Batch: 57, Loss: 0.7799754738807678, Accuracy: 0.7568359375\n",
      "Batch: 58, Loss: 0.859988272190094, Accuracy: 0.7314453125\n",
      "Batch: 59, Loss: 0.6860946416854858, Accuracy: 0.783203125\n",
      "Batch: 60, Loss: 0.6847754716873169, Accuracy: 0.7783203125\n",
      "Batch: 61, Loss: 0.7587242126464844, Accuracy: 0.7705078125\n",
      "Batch: 62, Loss: 0.723281741142273, Accuracy: 0.767578125\n",
      "Batch: 63, Loss: 0.7342582941055298, Accuracy: 0.7705078125\n",
      "Batch: 64, Loss: 0.7381008863449097, Accuracy: 0.7666015625\n",
      "Batch: 65, Loss: 0.7360121607780457, Accuracy: 0.7607421875\n",
      "Batch: 66, Loss: 0.7133597731590271, Accuracy: 0.7744140625\n",
      "Batch: 67, Loss: 0.8038173913955688, Accuracy: 0.740234375\n",
      "Batch: 68, Loss: 0.8434121608734131, Accuracy: 0.7470703125\n",
      "Batch: 69, Loss: 0.7598212957382202, Accuracy: 0.7392578125\n",
      "Batch: 70, Loss: 0.7352132201194763, Accuracy: 0.78125\n",
      "Batch: 71, Loss: 0.7915071845054626, Accuracy: 0.7412109375\n",
      "Batch: 72, Loss: 0.6504091024398804, Accuracy: 0.775390625\n",
      "Batch: 73, Loss: 0.6638245582580566, Accuracy: 0.7861328125\n",
      "Batch: 74, Loss: 0.6335179209709167, Accuracy: 0.81640625\n",
      "Batch: 75, Loss: 0.6598447561264038, Accuracy: 0.78125\n",
      "Batch: 76, Loss: 0.7625513076782227, Accuracy: 0.7373046875\n",
      "Batch: 77, Loss: 0.6797033548355103, Accuracy: 0.7734375\n",
      "Batch: 78, Loss: 0.6568403244018555, Accuracy: 0.783203125\n",
      "Batch: 79, Loss: 0.6215400695800781, Accuracy: 0.7939453125\n",
      "Batch: 80, Loss: 0.6839540004730225, Accuracy: 0.763671875\n",
      "Batch: 81, Loss: 0.7973660230636597, Accuracy: 0.7236328125\n",
      "Batch: 82, Loss: 0.7680906653404236, Accuracy: 0.744140625\n",
      "Batch: 83, Loss: 0.6150554418563843, Accuracy: 0.8125\n",
      "Batch: 84, Loss: 0.6778714656829834, Accuracy: 0.7802734375\n",
      "Batch: 85, Loss: 0.6773805022239685, Accuracy: 0.7802734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 86, Loss: 0.8490377068519592, Accuracy: 0.7314453125\n",
      "Batch: 87, Loss: 0.6855760812759399, Accuracy: 0.779296875\n",
      "Batch: 88, Loss: 0.7689059972763062, Accuracy: 0.7470703125\n",
      "Batch: 89, Loss: 0.7451799511909485, Accuracy: 0.7666015625\n",
      "Batch: 90, Loss: 0.6782042980194092, Accuracy: 0.78125\n",
      "Batch: 91, Loss: 0.7219679951667786, Accuracy: 0.75390625\n",
      "Batch: 92, Loss: 0.7383949160575867, Accuracy: 0.7548828125\n",
      "Batch: 93, Loss: 0.7060872912406921, Accuracy: 0.7744140625\n",
      "Batch: 94, Loss: 0.7275424003601074, Accuracy: 0.7470703125\n",
      "Batch: 95, Loss: 0.7714126110076904, Accuracy: 0.7236328125\n",
      "Batch: 96, Loss: 0.6856367588043213, Accuracy: 0.7783203125\n",
      "Batch: 97, Loss: 0.5970102548599243, Accuracy: 0.7939453125\n",
      "Batch: 98, Loss: 0.7165598273277283, Accuracy: 0.76171875\n",
      "Batch: 99, Loss: 0.7147833108901978, Accuracy: 0.763671875\n",
      "Batch: 100, Loss: 0.7602827548980713, Accuracy: 0.748046875\n",
      "Batch: 101, Loss: 0.7547484636306763, Accuracy: 0.740234375\n",
      "Batch: 102, Loss: 0.7499691843986511, Accuracy: 0.7548828125\n",
      "Batch: 103, Loss: 0.7406373620033264, Accuracy: 0.7568359375\n",
      "Batch: 104, Loss: 0.6890676021575928, Accuracy: 0.755859375\n",
      "Batch: 105, Loss: 0.7423162460327148, Accuracy: 0.7626953125\n",
      "Batch: 106, Loss: 0.7068340182304382, Accuracy: 0.7666015625\n",
      "Batch: 107, Loss: 0.7009271383285522, Accuracy: 0.775390625\n",
      "Batch: 108, Loss: 0.7267141342163086, Accuracy: 0.765625\n",
      "Batch: 109, Loss: 0.8361043334007263, Accuracy: 0.7158203125\n",
      "Batch: 110, Loss: 0.6822992563247681, Accuracy: 0.7666015625\n",
      "Batch: 111, Loss: 0.761672854423523, Accuracy: 0.74609375\n",
      "Batch: 112, Loss: 0.7583274841308594, Accuracy: 0.75\n",
      "Batch: 113, Loss: 0.7579984664916992, Accuracy: 0.75390625\n",
      "Batch: 114, Loss: 0.8065441250801086, Accuracy: 0.7412109375\n",
      "Batch: 115, Loss: 0.8274499773979187, Accuracy: 0.7421875\n",
      "Batch: 116, Loss: 0.77446448802948, Accuracy: 0.74609375\n",
      "Batch: 117, Loss: 0.7944402098655701, Accuracy: 0.724609375\n",
      "Batch: 118, Loss: 0.6627473831176758, Accuracy: 0.7861328125\n",
      "Batch: 119, Loss: 0.5835087299346924, Accuracy: 0.8125\n",
      "Batch: 120, Loss: 0.727808952331543, Accuracy: 0.76171875\n",
      "Batch: 121, Loss: 0.8094589710235596, Accuracy: 0.71875\n",
      "Batch: 122, Loss: 0.6823270320892334, Accuracy: 0.7861328125\n",
      "Batch: 123, Loss: 0.6451672315597534, Accuracy: 0.794921875\n",
      "Batch: 124, Loss: 0.7388485074043274, Accuracy: 0.7568359375\n",
      "Batch: 125, Loss: 0.7817610502243042, Accuracy: 0.7470703125\n",
      "Batch: 126, Loss: 0.769312858581543, Accuracy: 0.75390625\n",
      "Batch: 127, Loss: 0.670248806476593, Accuracy: 0.794921875\n",
      "Batch: 128, Loss: 0.7820221781730652, Accuracy: 0.7568359375\n",
      "Batch: 129, Loss: 0.6674083471298218, Accuracy: 0.7861328125\n",
      "Batch: 130, Loss: 0.7980445027351379, Accuracy: 0.7421875\n",
      "Batch: 131, Loss: 0.7162307500839233, Accuracy: 0.7578125\n",
      "Batch: 132, Loss: 0.7468121647834778, Accuracy: 0.7626953125\n",
      "Batch: 133, Loss: 0.6820330619812012, Accuracy: 0.787109375\n",
      "Batch: 134, Loss: 0.7293465733528137, Accuracy: 0.751953125\n",
      "Batch: 135, Loss: 0.6904317140579224, Accuracy: 0.7646484375\n",
      "Batch: 136, Loss: 0.7259241938591003, Accuracy: 0.763671875\n",
      "Batch: 137, Loss: 0.7378451824188232, Accuracy: 0.7568359375\n",
      "Batch: 138, Loss: 0.6566191911697388, Accuracy: 0.783203125\n",
      "Batch: 139, Loss: 0.6717185974121094, Accuracy: 0.7666015625\n",
      "Batch: 140, Loss: 0.7088056206703186, Accuracy: 0.755859375\n",
      "Batch: 141, Loss: 0.7652443647384644, Accuracy: 0.7490234375\n",
      "Batch: 142, Loss: 0.781523585319519, Accuracy: 0.736328125\n",
      "Batch: 143, Loss: 0.7468051910400391, Accuracy: 0.7626953125\n",
      "Batch: 144, Loss: 0.7307036519050598, Accuracy: 0.75\n",
      "Batch: 145, Loss: 0.7019855380058289, Accuracy: 0.7451171875\n",
      "Batch: 146, Loss: 0.757172703742981, Accuracy: 0.7421875\n",
      "Batch: 147, Loss: 0.7455668449401855, Accuracy: 0.7412109375\n",
      "Batch: 148, Loss: 0.8047455549240112, Accuracy: 0.71875\n",
      "Batch: 149, Loss: 0.6918964982032776, Accuracy: 0.7734375\n",
      "Batch: 150, Loss: 0.7192355394363403, Accuracy: 0.7509765625\n",
      "Batch: 151, Loss: 0.63626629114151, Accuracy: 0.7880859375\n",
      "Epoch 62/80\n",
      "Batch: 1, Loss: 0.9412118792533875, Accuracy: 0.7216796875\n",
      "Batch: 2, Loss: 0.8352139592170715, Accuracy: 0.70703125\n",
      "Batch: 3, Loss: 0.6885822415351868, Accuracy: 0.76171875\n",
      "Batch: 4, Loss: 0.6071475744247437, Accuracy: 0.802734375\n",
      "Batch: 5, Loss: 0.7486263513565063, Accuracy: 0.7568359375\n",
      "Batch: 6, Loss: 0.7708033919334412, Accuracy: 0.740234375\n",
      "Batch: 7, Loss: 0.7703827619552612, Accuracy: 0.7421875\n",
      "Batch: 8, Loss: 0.6881522536277771, Accuracy: 0.767578125\n",
      "Batch: 9, Loss: 0.6938813328742981, Accuracy: 0.78125\n",
      "Batch: 10, Loss: 0.7044792175292969, Accuracy: 0.767578125\n",
      "Batch: 11, Loss: 0.8058260679244995, Accuracy: 0.7412109375\n",
      "Batch: 12, Loss: 0.7702623605728149, Accuracy: 0.74609375\n",
      "Batch: 13, Loss: 0.6269427537918091, Accuracy: 0.798828125\n",
      "Batch: 14, Loss: 0.8047095537185669, Accuracy: 0.73828125\n",
      "Batch: 15, Loss: 0.6546583771705627, Accuracy: 0.7958984375\n",
      "Batch: 16, Loss: 0.728638231754303, Accuracy: 0.76953125\n",
      "Batch: 17, Loss: 0.7643480896949768, Accuracy: 0.7490234375\n",
      "Batch: 18, Loss: 0.7699261903762817, Accuracy: 0.75\n",
      "Batch: 19, Loss: 0.7576302886009216, Accuracy: 0.7568359375\n",
      "Batch: 20, Loss: 0.6541229486465454, Accuracy: 0.7900390625\n",
      "Batch: 21, Loss: 0.6770932674407959, Accuracy: 0.7822265625\n",
      "Batch: 22, Loss: 0.818631649017334, Accuracy: 0.740234375\n",
      "Batch: 23, Loss: 0.7322753667831421, Accuracy: 0.75\n",
      "Batch: 24, Loss: 0.7550466060638428, Accuracy: 0.7373046875\n",
      "Batch: 25, Loss: 0.7247166633605957, Accuracy: 0.767578125\n",
      "Batch: 26, Loss: 0.6333178281784058, Accuracy: 0.7783203125\n",
      "Batch: 27, Loss: 0.7113548517227173, Accuracy: 0.7529296875\n",
      "Batch: 28, Loss: 0.7331879734992981, Accuracy: 0.7470703125\n",
      "Batch: 29, Loss: 0.703209638595581, Accuracy: 0.7666015625\n",
      "Batch: 30, Loss: 0.630502462387085, Accuracy: 0.791015625\n",
      "Batch: 31, Loss: 0.665347695350647, Accuracy: 0.783203125\n",
      "Batch: 32, Loss: 0.6804817914962769, Accuracy: 0.775390625\n",
      "Batch: 33, Loss: 0.7913551330566406, Accuracy: 0.759765625\n",
      "Batch: 34, Loss: 0.8502448797225952, Accuracy: 0.7109375\n",
      "Batch: 35, Loss: 0.7355378866195679, Accuracy: 0.7451171875\n",
      "Batch: 36, Loss: 0.7402978539466858, Accuracy: 0.767578125\n",
      "Batch: 37, Loss: 0.7069603204727173, Accuracy: 0.76953125\n",
      "Batch: 38, Loss: 0.7385649085044861, Accuracy: 0.7470703125\n",
      "Batch: 39, Loss: 0.7722102403640747, Accuracy: 0.7470703125\n",
      "Batch: 40, Loss: 0.7044070959091187, Accuracy: 0.779296875\n",
      "Batch: 41, Loss: 0.6378354430198669, Accuracy: 0.7841796875\n",
      "Batch: 42, Loss: 0.5924892425537109, Accuracy: 0.80078125\n",
      "Batch: 43, Loss: 0.768861711025238, Accuracy: 0.7412109375\n",
      "Batch: 44, Loss: 0.7620559334754944, Accuracy: 0.7421875\n",
      "Batch: 45, Loss: 0.7151032090187073, Accuracy: 0.7509765625\n",
      "Batch: 46, Loss: 0.6572437286376953, Accuracy: 0.7919921875\n",
      "Batch: 47, Loss: 0.6658651828765869, Accuracy: 0.791015625\n",
      "Batch: 48, Loss: 0.6345914602279663, Accuracy: 0.796875\n",
      "Batch: 49, Loss: 0.753954291343689, Accuracy: 0.7470703125\n",
      "Batch: 50, Loss: 0.7593668699264526, Accuracy: 0.7373046875\n",
      "Batch: 51, Loss: 0.7855868339538574, Accuracy: 0.748046875\n",
      "Batch: 52, Loss: 0.7282660007476807, Accuracy: 0.765625\n",
      "Batch: 53, Loss: 0.6480803489685059, Accuracy: 0.7763671875\n",
      "Batch: 54, Loss: 0.7371147871017456, Accuracy: 0.7548828125\n",
      "Batch: 55, Loss: 0.808358371257782, Accuracy: 0.716796875\n",
      "Batch: 56, Loss: 0.7714324593544006, Accuracy: 0.7421875\n",
      "Batch: 57, Loss: 0.7800272107124329, Accuracy: 0.7353515625\n",
      "Batch: 58, Loss: 0.8782951831817627, Accuracy: 0.7158203125\n",
      "Batch: 59, Loss: 0.6950124502182007, Accuracy: 0.7783203125\n",
      "Batch: 60, Loss: 0.7047979235649109, Accuracy: 0.7705078125\n",
      "Batch: 61, Loss: 0.7472238540649414, Accuracy: 0.748046875\n",
      "Batch: 62, Loss: 0.7043687105178833, Accuracy: 0.76953125\n",
      "Batch: 63, Loss: 0.742195725440979, Accuracy: 0.76171875\n",
      "Batch: 64, Loss: 0.7409664392471313, Accuracy: 0.75390625\n",
      "Batch: 65, Loss: 0.7323122024536133, Accuracy: 0.76953125\n",
      "Batch: 66, Loss: 0.7096259593963623, Accuracy: 0.7705078125\n",
      "Batch: 67, Loss: 0.8146596550941467, Accuracy: 0.751953125\n",
      "Batch: 68, Loss: 0.8332303762435913, Accuracy: 0.7451171875\n",
      "Batch: 69, Loss: 0.7338500022888184, Accuracy: 0.76953125\n",
      "Batch: 70, Loss: 0.7350404858589172, Accuracy: 0.76953125\n",
      "Batch: 71, Loss: 0.76080322265625, Accuracy: 0.74609375\n",
      "Batch: 72, Loss: 0.6604183912277222, Accuracy: 0.7685546875\n",
      "Batch: 73, Loss: 0.6668565273284912, Accuracy: 0.787109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 74, Loss: 0.6340614557266235, Accuracy: 0.8056640625\n",
      "Batch: 75, Loss: 0.6949735879898071, Accuracy: 0.7744140625\n",
      "Batch: 76, Loss: 0.7678951025009155, Accuracy: 0.7353515625\n",
      "Batch: 77, Loss: 0.6735442280769348, Accuracy: 0.7724609375\n",
      "Batch: 78, Loss: 0.647244930267334, Accuracy: 0.7861328125\n",
      "Batch: 79, Loss: 0.6188886165618896, Accuracy: 0.787109375\n",
      "Batch: 80, Loss: 0.6884190440177917, Accuracy: 0.77734375\n",
      "Batch: 81, Loss: 0.8288016319274902, Accuracy: 0.7138671875\n",
      "Batch: 82, Loss: 0.7501169443130493, Accuracy: 0.73828125\n",
      "Batch: 83, Loss: 0.6346802115440369, Accuracy: 0.80078125\n",
      "Batch: 84, Loss: 0.7008339166641235, Accuracy: 0.767578125\n",
      "Batch: 85, Loss: 0.6858527660369873, Accuracy: 0.7705078125\n",
      "Batch: 86, Loss: 0.8089996576309204, Accuracy: 0.7548828125\n",
      "Batch: 87, Loss: 0.6610233783721924, Accuracy: 0.791015625\n",
      "Batch: 88, Loss: 0.7833635807037354, Accuracy: 0.7529296875\n",
      "Batch: 89, Loss: 0.769929051399231, Accuracy: 0.751953125\n",
      "Batch: 90, Loss: 0.6897209882736206, Accuracy: 0.78515625\n",
      "Batch: 91, Loss: 0.6788080334663391, Accuracy: 0.775390625\n",
      "Batch: 92, Loss: 0.7105016708374023, Accuracy: 0.7646484375\n",
      "Batch: 93, Loss: 0.722132682800293, Accuracy: 0.7734375\n",
      "Batch: 94, Loss: 0.7331111431121826, Accuracy: 0.767578125\n",
      "Batch: 95, Loss: 0.7561140656471252, Accuracy: 0.7353515625\n",
      "Batch: 96, Loss: 0.6979247331619263, Accuracy: 0.7705078125\n",
      "Batch: 97, Loss: 0.5899699926376343, Accuracy: 0.802734375\n",
      "Batch: 98, Loss: 0.7323596477508545, Accuracy: 0.7705078125\n",
      "Batch: 99, Loss: 0.7039169073104858, Accuracy: 0.7666015625\n",
      "Batch: 100, Loss: 0.7454684376716614, Accuracy: 0.7529296875\n",
      "Batch: 101, Loss: 0.761330246925354, Accuracy: 0.75\n",
      "Batch: 102, Loss: 0.7428600788116455, Accuracy: 0.7578125\n",
      "Batch: 103, Loss: 0.7145336270332336, Accuracy: 0.7763671875\n",
      "Batch: 104, Loss: 0.6824814081192017, Accuracy: 0.76953125\n",
      "Batch: 105, Loss: 0.7542366981506348, Accuracy: 0.75390625\n",
      "Batch: 106, Loss: 0.660650908946991, Accuracy: 0.7822265625\n",
      "Batch: 107, Loss: 0.7269628047943115, Accuracy: 0.7734375\n",
      "Batch: 108, Loss: 0.7658998966217041, Accuracy: 0.7392578125\n",
      "Batch: 109, Loss: 0.84074866771698, Accuracy: 0.712890625\n",
      "Batch: 110, Loss: 0.6640533208847046, Accuracy: 0.7744140625\n",
      "Batch: 111, Loss: 0.7374398708343506, Accuracy: 0.7529296875\n",
      "Batch: 112, Loss: 0.7565510272979736, Accuracy: 0.7529296875\n",
      "Batch: 113, Loss: 0.712135910987854, Accuracy: 0.787109375\n",
      "Batch: 114, Loss: 0.7910085916519165, Accuracy: 0.7421875\n",
      "Batch: 115, Loss: 0.838712751865387, Accuracy: 0.7333984375\n",
      "Batch: 116, Loss: 0.7445674538612366, Accuracy: 0.759765625\n",
      "Batch: 117, Loss: 0.7820460796356201, Accuracy: 0.7265625\n",
      "Batch: 118, Loss: 0.6617276072502136, Accuracy: 0.791015625\n",
      "Batch: 119, Loss: 0.6130205392837524, Accuracy: 0.8046875\n",
      "Batch: 120, Loss: 0.7481324672698975, Accuracy: 0.7626953125\n",
      "Batch: 121, Loss: 0.7856033444404602, Accuracy: 0.7353515625\n",
      "Batch: 122, Loss: 0.6814112663269043, Accuracy: 0.7783203125\n",
      "Batch: 123, Loss: 0.6434858441352844, Accuracy: 0.78125\n",
      "Batch: 124, Loss: 0.7233928442001343, Accuracy: 0.7587890625\n",
      "Batch: 125, Loss: 0.7689101696014404, Accuracy: 0.740234375\n",
      "Batch: 126, Loss: 0.765583872795105, Accuracy: 0.763671875\n",
      "Batch: 127, Loss: 0.6573349833488464, Accuracy: 0.7919921875\n",
      "Batch: 128, Loss: 0.7984127998352051, Accuracy: 0.7451171875\n",
      "Batch: 129, Loss: 0.6782068014144897, Accuracy: 0.787109375\n",
      "Batch: 130, Loss: 0.8261523246765137, Accuracy: 0.732421875\n",
      "Batch: 131, Loss: 0.736510157585144, Accuracy: 0.755859375\n",
      "Batch: 132, Loss: 0.7569584846496582, Accuracy: 0.7607421875\n",
      "Batch: 133, Loss: 0.6994046568870544, Accuracy: 0.7744140625\n",
      "Batch: 134, Loss: 0.7428063154220581, Accuracy: 0.7451171875\n",
      "Batch: 135, Loss: 0.6391888856887817, Accuracy: 0.79296875\n",
      "Batch: 136, Loss: 0.7185254096984863, Accuracy: 0.775390625\n",
      "Batch: 137, Loss: 0.7219648361206055, Accuracy: 0.75390625\n",
      "Batch: 138, Loss: 0.6640013456344604, Accuracy: 0.783203125\n",
      "Batch: 139, Loss: 0.6922599673271179, Accuracy: 0.765625\n",
      "Batch: 140, Loss: 0.7397647500038147, Accuracy: 0.7587890625\n",
      "Batch: 141, Loss: 0.7279471755027771, Accuracy: 0.767578125\n",
      "Batch: 142, Loss: 0.7596008777618408, Accuracy: 0.751953125\n",
      "Batch: 143, Loss: 0.7074241042137146, Accuracy: 0.7578125\n",
      "Batch: 144, Loss: 0.7362303733825684, Accuracy: 0.76171875\n",
      "Batch: 145, Loss: 0.6947648525238037, Accuracy: 0.7607421875\n",
      "Batch: 146, Loss: 0.7704582214355469, Accuracy: 0.7294921875\n",
      "Batch: 147, Loss: 0.7201544046401978, Accuracy: 0.7626953125\n",
      "Batch: 148, Loss: 0.7985131740570068, Accuracy: 0.734375\n",
      "Batch: 149, Loss: 0.6942055225372314, Accuracy: 0.763671875\n",
      "Batch: 150, Loss: 0.6896975040435791, Accuracy: 0.7626953125\n",
      "Batch: 151, Loss: 0.6555535197257996, Accuracy: 0.767578125\n",
      "Epoch 63/80\n",
      "Batch: 1, Loss: 0.9466091394424438, Accuracy: 0.7021484375\n",
      "Batch: 2, Loss: 0.7991496324539185, Accuracy: 0.72265625\n",
      "Batch: 3, Loss: 0.7050752639770508, Accuracy: 0.76953125\n",
      "Batch: 4, Loss: 0.6226393580436707, Accuracy: 0.7998046875\n",
      "Batch: 5, Loss: 0.7287557125091553, Accuracy: 0.765625\n",
      "Batch: 6, Loss: 0.724632740020752, Accuracy: 0.76171875\n",
      "Batch: 7, Loss: 0.7342780232429504, Accuracy: 0.755859375\n",
      "Batch: 8, Loss: 0.6809213161468506, Accuracy: 0.775390625\n",
      "Batch: 9, Loss: 0.7074204683303833, Accuracy: 0.7705078125\n",
      "Batch: 10, Loss: 0.691631555557251, Accuracy: 0.7470703125\n",
      "Batch: 11, Loss: 0.8005470037460327, Accuracy: 0.7255859375\n",
      "Batch: 12, Loss: 0.7469249963760376, Accuracy: 0.7587890625\n",
      "Batch: 13, Loss: 0.6085542440414429, Accuracy: 0.80078125\n",
      "Batch: 14, Loss: 0.7933641672134399, Accuracy: 0.7421875\n",
      "Batch: 15, Loss: 0.6163794994354248, Accuracy: 0.7939453125\n",
      "Batch: 16, Loss: 0.719016432762146, Accuracy: 0.771484375\n",
      "Batch: 17, Loss: 0.7444823980331421, Accuracy: 0.7431640625\n",
      "Batch: 18, Loss: 0.7967314720153809, Accuracy: 0.75\n",
      "Batch: 19, Loss: 0.7408360838890076, Accuracy: 0.7529296875\n",
      "Batch: 20, Loss: 0.6528176069259644, Accuracy: 0.7802734375\n",
      "Batch: 21, Loss: 0.6834249496459961, Accuracy: 0.759765625\n",
      "Batch: 22, Loss: 0.7859813570976257, Accuracy: 0.7392578125\n",
      "Batch: 23, Loss: 0.7605306506156921, Accuracy: 0.7412109375\n",
      "Batch: 24, Loss: 0.7483959197998047, Accuracy: 0.75390625\n",
      "Batch: 25, Loss: 0.724044919013977, Accuracy: 0.751953125\n",
      "Batch: 26, Loss: 0.6444981694221497, Accuracy: 0.7763671875\n",
      "Batch: 27, Loss: 0.7392975687980652, Accuracy: 0.7626953125\n",
      "Batch: 28, Loss: 0.7487989664077759, Accuracy: 0.751953125\n",
      "Batch: 29, Loss: 0.712395966053009, Accuracy: 0.7685546875\n",
      "Batch: 30, Loss: 0.628381609916687, Accuracy: 0.7822265625\n",
      "Batch: 31, Loss: 0.6205205917358398, Accuracy: 0.8115234375\n",
      "Batch: 32, Loss: 0.6628009676933289, Accuracy: 0.77734375\n",
      "Batch: 33, Loss: 0.7828060388565063, Accuracy: 0.748046875\n",
      "Batch: 34, Loss: 0.8524593114852905, Accuracy: 0.734375\n",
      "Batch: 35, Loss: 0.7659271955490112, Accuracy: 0.76171875\n",
      "Batch: 36, Loss: 0.7368159890174866, Accuracy: 0.75390625\n",
      "Batch: 37, Loss: 0.7292934060096741, Accuracy: 0.7529296875\n",
      "Batch: 38, Loss: 0.7445073127746582, Accuracy: 0.7412109375\n",
      "Batch: 39, Loss: 0.7611453533172607, Accuracy: 0.7587890625\n",
      "Batch: 40, Loss: 0.7095552682876587, Accuracy: 0.7763671875\n",
      "Batch: 41, Loss: 0.6361457109451294, Accuracy: 0.7919921875\n",
      "Batch: 42, Loss: 0.5833291411399841, Accuracy: 0.80859375\n",
      "Batch: 43, Loss: 0.7891597747802734, Accuracy: 0.7392578125\n",
      "Batch: 44, Loss: 0.7647160887718201, Accuracy: 0.736328125\n",
      "Batch: 45, Loss: 0.6876529455184937, Accuracy: 0.7548828125\n",
      "Batch: 46, Loss: 0.654497504234314, Accuracy: 0.796875\n",
      "Batch: 47, Loss: 0.6471133232116699, Accuracy: 0.7958984375\n",
      "Batch: 48, Loss: 0.6374315023422241, Accuracy: 0.783203125\n",
      "Batch: 49, Loss: 0.7506442070007324, Accuracy: 0.7587890625\n",
      "Batch: 50, Loss: 0.7184938788414001, Accuracy: 0.7587890625\n",
      "Batch: 51, Loss: 0.7691120505332947, Accuracy: 0.763671875\n",
      "Batch: 52, Loss: 0.7555044889450073, Accuracy: 0.7470703125\n",
      "Batch: 53, Loss: 0.6938484907150269, Accuracy: 0.7587890625\n",
      "Batch: 54, Loss: 0.7425334453582764, Accuracy: 0.76171875\n",
      "Batch: 55, Loss: 0.8127928972244263, Accuracy: 0.724609375\n",
      "Batch: 56, Loss: 0.788739025592804, Accuracy: 0.740234375\n",
      "Batch: 57, Loss: 0.7600535750389099, Accuracy: 0.744140625\n",
      "Batch: 58, Loss: 0.8372069001197815, Accuracy: 0.7255859375\n",
      "Batch: 59, Loss: 0.7037795782089233, Accuracy: 0.7763671875\n",
      "Batch: 60, Loss: 0.6564077138900757, Accuracy: 0.783203125\n",
      "Batch: 61, Loss: 0.7431446313858032, Accuracy: 0.755859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 62, Loss: 0.7120288014411926, Accuracy: 0.7705078125\n",
      "Batch: 63, Loss: 0.7371214628219604, Accuracy: 0.7529296875\n",
      "Batch: 64, Loss: 0.7115679979324341, Accuracy: 0.7626953125\n",
      "Batch: 65, Loss: 0.7481786012649536, Accuracy: 0.7529296875\n",
      "Batch: 66, Loss: 0.706591010093689, Accuracy: 0.7763671875\n",
      "Batch: 67, Loss: 0.7977222204208374, Accuracy: 0.736328125\n",
      "Batch: 68, Loss: 0.8273453712463379, Accuracy: 0.7392578125\n",
      "Batch: 69, Loss: 0.7430667877197266, Accuracy: 0.75390625\n",
      "Batch: 70, Loss: 0.7364116311073303, Accuracy: 0.767578125\n",
      "Batch: 71, Loss: 0.7690520882606506, Accuracy: 0.73828125\n",
      "Batch: 72, Loss: 0.6668992638587952, Accuracy: 0.7744140625\n",
      "Batch: 73, Loss: 0.6398041844367981, Accuracy: 0.7900390625\n",
      "Batch: 74, Loss: 0.6093543767929077, Accuracy: 0.8076171875\n",
      "Batch: 75, Loss: 0.6592962741851807, Accuracy: 0.7685546875\n",
      "Batch: 76, Loss: 0.7648593187332153, Accuracy: 0.732421875\n",
      "Batch: 77, Loss: 0.6528443694114685, Accuracy: 0.7861328125\n",
      "Batch: 78, Loss: 0.5947945713996887, Accuracy: 0.7939453125\n",
      "Batch: 79, Loss: 0.61958247423172, Accuracy: 0.7978515625\n",
      "Batch: 80, Loss: 0.6869270205497742, Accuracy: 0.763671875\n",
      "Batch: 81, Loss: 0.8020952939987183, Accuracy: 0.73828125\n",
      "Batch: 82, Loss: 0.7438333034515381, Accuracy: 0.759765625\n",
      "Batch: 83, Loss: 0.6045734882354736, Accuracy: 0.8125\n",
      "Batch: 84, Loss: 0.7027311325073242, Accuracy: 0.7783203125\n",
      "Batch: 85, Loss: 0.6552225351333618, Accuracy: 0.78515625\n",
      "Batch: 86, Loss: 0.8250958919525146, Accuracy: 0.7265625\n",
      "Batch: 87, Loss: 0.6721076965332031, Accuracy: 0.787109375\n",
      "Batch: 88, Loss: 0.7543683052062988, Accuracy: 0.7490234375\n",
      "Batch: 89, Loss: 0.7658040523529053, Accuracy: 0.7724609375\n",
      "Batch: 90, Loss: 0.6889517903327942, Accuracy: 0.7685546875\n",
      "Batch: 91, Loss: 0.6967891454696655, Accuracy: 0.767578125\n",
      "Batch: 92, Loss: 0.7474386692047119, Accuracy: 0.7568359375\n",
      "Batch: 93, Loss: 0.6949189901351929, Accuracy: 0.767578125\n",
      "Batch: 94, Loss: 0.7682931423187256, Accuracy: 0.7490234375\n",
      "Batch: 95, Loss: 0.7518320679664612, Accuracy: 0.728515625\n",
      "Batch: 96, Loss: 0.7153363227844238, Accuracy: 0.7626953125\n",
      "Batch: 97, Loss: 0.6073118448257446, Accuracy: 0.7900390625\n",
      "Batch: 98, Loss: 0.7063495516777039, Accuracy: 0.771484375\n",
      "Batch: 99, Loss: 0.722997784614563, Accuracy: 0.755859375\n",
      "Batch: 100, Loss: 0.7455622553825378, Accuracy: 0.7568359375\n",
      "Batch: 101, Loss: 0.7418091297149658, Accuracy: 0.7548828125\n",
      "Batch: 102, Loss: 0.7331380844116211, Accuracy: 0.7744140625\n",
      "Batch: 103, Loss: 0.7323621511459351, Accuracy: 0.7607421875\n",
      "Batch: 104, Loss: 0.6734104156494141, Accuracy: 0.7705078125\n",
      "Batch: 105, Loss: 0.7585791349411011, Accuracy: 0.7470703125\n",
      "Batch: 106, Loss: 0.7031115293502808, Accuracy: 0.7705078125\n",
      "Batch: 107, Loss: 0.7257615327835083, Accuracy: 0.7744140625\n",
      "Batch: 108, Loss: 0.7378182411193848, Accuracy: 0.74609375\n",
      "Batch: 109, Loss: 0.8401583433151245, Accuracy: 0.71875\n",
      "Batch: 110, Loss: 0.673784613609314, Accuracy: 0.775390625\n",
      "Batch: 111, Loss: 0.7246818542480469, Accuracy: 0.748046875\n",
      "Batch: 112, Loss: 0.7199703454971313, Accuracy: 0.7607421875\n",
      "Batch: 113, Loss: 0.7064580917358398, Accuracy: 0.78515625\n",
      "Batch: 114, Loss: 0.7949547171592712, Accuracy: 0.740234375\n",
      "Batch: 115, Loss: 0.8067606687545776, Accuracy: 0.7353515625\n",
      "Batch: 116, Loss: 0.7235836386680603, Accuracy: 0.763671875\n",
      "Batch: 117, Loss: 0.7593238949775696, Accuracy: 0.7451171875\n",
      "Batch: 118, Loss: 0.6581649780273438, Accuracy: 0.7998046875\n",
      "Batch: 119, Loss: 0.5984368324279785, Accuracy: 0.7958984375\n",
      "Batch: 120, Loss: 0.7186234593391418, Accuracy: 0.7724609375\n",
      "Batch: 121, Loss: 0.7890784740447998, Accuracy: 0.7490234375\n",
      "Batch: 122, Loss: 0.6571711301803589, Accuracy: 0.7841796875\n",
      "Batch: 123, Loss: 0.6446355581283569, Accuracy: 0.7939453125\n",
      "Batch: 124, Loss: 0.6950857639312744, Accuracy: 0.77734375\n",
      "Batch: 125, Loss: 0.7879750728607178, Accuracy: 0.73828125\n",
      "Batch: 126, Loss: 0.7251243591308594, Accuracy: 0.76953125\n",
      "Batch: 127, Loss: 0.6453083753585815, Accuracy: 0.7958984375\n",
      "Batch: 128, Loss: 0.7682567238807678, Accuracy: 0.7578125\n",
      "Batch: 129, Loss: 0.6787225008010864, Accuracy: 0.7685546875\n",
      "Batch: 130, Loss: 0.8271400928497314, Accuracy: 0.7314453125\n",
      "Batch: 131, Loss: 0.7369404435157776, Accuracy: 0.744140625\n",
      "Batch: 132, Loss: 0.7319933772087097, Accuracy: 0.7568359375\n",
      "Batch: 133, Loss: 0.6726237535476685, Accuracy: 0.779296875\n",
      "Batch: 134, Loss: 0.7473611831665039, Accuracy: 0.75\n",
      "Batch: 135, Loss: 0.6641279458999634, Accuracy: 0.78515625\n",
      "Batch: 136, Loss: 0.7248635292053223, Accuracy: 0.7685546875\n",
      "Batch: 137, Loss: 0.7380853891372681, Accuracy: 0.7509765625\n",
      "Batch: 138, Loss: 0.6495578289031982, Accuracy: 0.7861328125\n",
      "Batch: 139, Loss: 0.6737307906150818, Accuracy: 0.7548828125\n",
      "Batch: 140, Loss: 0.707921028137207, Accuracy: 0.7607421875\n",
      "Batch: 141, Loss: 0.7339084148406982, Accuracy: 0.7509765625\n",
      "Batch: 142, Loss: 0.7575671076774597, Accuracy: 0.74609375\n",
      "Batch: 143, Loss: 0.7076420783996582, Accuracy: 0.7578125\n",
      "Batch: 144, Loss: 0.7418520450592041, Accuracy: 0.74609375\n",
      "Batch: 145, Loss: 0.702375054359436, Accuracy: 0.7578125\n",
      "Batch: 146, Loss: 0.7406997084617615, Accuracy: 0.751953125\n",
      "Batch: 147, Loss: 0.7232319116592407, Accuracy: 0.759765625\n",
      "Batch: 148, Loss: 0.8007357120513916, Accuracy: 0.7236328125\n",
      "Batch: 149, Loss: 0.6817442178726196, Accuracy: 0.771484375\n",
      "Batch: 150, Loss: 0.6721150875091553, Accuracy: 0.7548828125\n",
      "Batch: 151, Loss: 0.5953351259231567, Accuracy: 0.8056640625\n",
      "Epoch 64/80\n",
      "Batch: 1, Loss: 0.9485384821891785, Accuracy: 0.7099609375\n",
      "Batch: 2, Loss: 0.8332126140594482, Accuracy: 0.716796875\n",
      "Batch: 3, Loss: 0.6924548149108887, Accuracy: 0.7744140625\n",
      "Batch: 4, Loss: 0.6155849099159241, Accuracy: 0.80078125\n",
      "Batch: 5, Loss: 0.6836827993392944, Accuracy: 0.77734375\n",
      "Batch: 6, Loss: 0.7321137189865112, Accuracy: 0.7490234375\n",
      "Batch: 7, Loss: 0.7396981120109558, Accuracy: 0.751953125\n",
      "Batch: 8, Loss: 0.6877428889274597, Accuracy: 0.7724609375\n",
      "Batch: 9, Loss: 0.6865779161453247, Accuracy: 0.7705078125\n",
      "Batch: 10, Loss: 0.6727702617645264, Accuracy: 0.775390625\n",
      "Batch: 11, Loss: 0.7909151315689087, Accuracy: 0.71875\n",
      "Batch: 12, Loss: 0.7536827325820923, Accuracy: 0.75\n",
      "Batch: 13, Loss: 0.5949785113334656, Accuracy: 0.806640625\n",
      "Batch: 14, Loss: 0.8026336431503296, Accuracy: 0.7314453125\n",
      "Batch: 15, Loss: 0.6432331800460815, Accuracy: 0.8037109375\n",
      "Batch: 16, Loss: 0.702621579170227, Accuracy: 0.7763671875\n",
      "Batch: 17, Loss: 0.7433030605316162, Accuracy: 0.75390625\n",
      "Batch: 18, Loss: 0.786750078201294, Accuracy: 0.7392578125\n",
      "Batch: 19, Loss: 0.7379845380783081, Accuracy: 0.7578125\n",
      "Batch: 20, Loss: 0.6291083097457886, Accuracy: 0.7900390625\n",
      "Batch: 21, Loss: 0.665400505065918, Accuracy: 0.779296875\n",
      "Batch: 22, Loss: 0.7640140652656555, Accuracy: 0.7412109375\n",
      "Batch: 23, Loss: 0.7206912040710449, Accuracy: 0.748046875\n",
      "Batch: 24, Loss: 0.7299656867980957, Accuracy: 0.7529296875\n",
      "Batch: 25, Loss: 0.7284173369407654, Accuracy: 0.765625\n",
      "Batch: 26, Loss: 0.5958737730979919, Accuracy: 0.796875\n",
      "Batch: 27, Loss: 0.6847018003463745, Accuracy: 0.759765625\n",
      "Batch: 28, Loss: 0.7363337278366089, Accuracy: 0.755859375\n",
      "Batch: 29, Loss: 0.6652384996414185, Accuracy: 0.771484375\n",
      "Batch: 30, Loss: 0.5943377614021301, Accuracy: 0.8125\n",
      "Batch: 31, Loss: 0.6541664600372314, Accuracy: 0.79296875\n",
      "Batch: 32, Loss: 0.661249041557312, Accuracy: 0.7900390625\n",
      "Batch: 33, Loss: 0.7885306477546692, Accuracy: 0.7421875\n",
      "Batch: 34, Loss: 0.8027657866477966, Accuracy: 0.751953125\n",
      "Batch: 35, Loss: 0.7415722608566284, Accuracy: 0.76171875\n",
      "Batch: 36, Loss: 0.7629629969596863, Accuracy: 0.755859375\n",
      "Batch: 37, Loss: 0.716044008731842, Accuracy: 0.7685546875\n",
      "Batch: 38, Loss: 0.7448008060455322, Accuracy: 0.7421875\n",
      "Batch: 39, Loss: 0.7680002450942993, Accuracy: 0.7548828125\n",
      "Batch: 40, Loss: 0.698880672454834, Accuracy: 0.7783203125\n",
      "Batch: 41, Loss: 0.647252082824707, Accuracy: 0.7900390625\n",
      "Batch: 42, Loss: 0.573930025100708, Accuracy: 0.81640625\n",
      "Batch: 43, Loss: 0.7624982595443726, Accuracy: 0.7373046875\n",
      "Batch: 44, Loss: 0.7251879572868347, Accuracy: 0.7568359375\n",
      "Batch: 45, Loss: 0.6890556812286377, Accuracy: 0.7607421875\n",
      "Batch: 46, Loss: 0.6199460625648499, Accuracy: 0.7900390625\n",
      "Batch: 47, Loss: 0.6553641557693481, Accuracy: 0.794921875\n",
      "Batch: 48, Loss: 0.6621581315994263, Accuracy: 0.763671875\n",
      "Batch: 49, Loss: 0.7471200227737427, Accuracy: 0.7607421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Loss: 0.734520673751831, Accuracy: 0.7490234375\n",
      "Batch: 51, Loss: 0.7195234894752502, Accuracy: 0.75390625\n",
      "Batch: 52, Loss: 0.707368791103363, Accuracy: 0.76953125\n",
      "Batch: 53, Loss: 0.6546192169189453, Accuracy: 0.7724609375\n",
      "Batch: 54, Loss: 0.6901716589927673, Accuracy: 0.771484375\n",
      "Batch: 55, Loss: 0.8048889636993408, Accuracy: 0.7236328125\n",
      "Batch: 56, Loss: 0.7614777088165283, Accuracy: 0.7353515625\n",
      "Batch: 57, Loss: 0.7315118908882141, Accuracy: 0.7578125\n",
      "Batch: 58, Loss: 0.8476365804672241, Accuracy: 0.7314453125\n",
      "Batch: 59, Loss: 0.7011375427246094, Accuracy: 0.7705078125\n",
      "Batch: 60, Loss: 0.6753334999084473, Accuracy: 0.7734375\n",
      "Batch: 61, Loss: 0.7433815002441406, Accuracy: 0.763671875\n",
      "Batch: 62, Loss: 0.7068039178848267, Accuracy: 0.76953125\n",
      "Batch: 63, Loss: 0.7304247617721558, Accuracy: 0.7568359375\n",
      "Batch: 64, Loss: 0.7011691331863403, Accuracy: 0.7666015625\n",
      "Batch: 65, Loss: 0.7266591787338257, Accuracy: 0.7529296875\n",
      "Batch: 66, Loss: 0.6814340949058533, Accuracy: 0.7783203125\n",
      "Batch: 67, Loss: 0.7787797451019287, Accuracy: 0.75\n",
      "Batch: 68, Loss: 0.7936789393424988, Accuracy: 0.74609375\n",
      "Batch: 69, Loss: 0.7603830099105835, Accuracy: 0.75\n",
      "Batch: 70, Loss: 0.7246414422988892, Accuracy: 0.775390625\n",
      "Batch: 71, Loss: 0.7533179521560669, Accuracy: 0.744140625\n",
      "Batch: 72, Loss: 0.6472636461257935, Accuracy: 0.78515625\n",
      "Batch: 73, Loss: 0.6539207696914673, Accuracy: 0.794921875\n",
      "Batch: 74, Loss: 0.6497621536254883, Accuracy: 0.78125\n",
      "Batch: 75, Loss: 0.6564617156982422, Accuracy: 0.7880859375\n",
      "Batch: 76, Loss: 0.738615095615387, Accuracy: 0.7470703125\n",
      "Batch: 77, Loss: 0.6915693879127502, Accuracy: 0.7783203125\n",
      "Batch: 78, Loss: 0.6135203838348389, Accuracy: 0.794921875\n",
      "Batch: 79, Loss: 0.5919204950332642, Accuracy: 0.8017578125\n",
      "Batch: 80, Loss: 0.6761043667793274, Accuracy: 0.765625\n",
      "Batch: 81, Loss: 0.8046451210975647, Accuracy: 0.732421875\n",
      "Batch: 82, Loss: 0.7381525039672852, Accuracy: 0.7568359375\n",
      "Batch: 83, Loss: 0.6311056613922119, Accuracy: 0.8056640625\n",
      "Batch: 84, Loss: 0.6758264899253845, Accuracy: 0.7900390625\n",
      "Batch: 85, Loss: 0.6835585832595825, Accuracy: 0.78515625\n",
      "Batch: 86, Loss: 0.833584189414978, Accuracy: 0.7294921875\n",
      "Batch: 87, Loss: 0.643412709236145, Accuracy: 0.7880859375\n",
      "Batch: 88, Loss: 0.7827290892601013, Accuracy: 0.740234375\n",
      "Batch: 89, Loss: 0.7564195990562439, Accuracy: 0.748046875\n",
      "Batch: 90, Loss: 0.6624787449836731, Accuracy: 0.791015625\n",
      "Batch: 91, Loss: 0.6989213228225708, Accuracy: 0.75\n",
      "Batch: 92, Loss: 0.7238351702690125, Accuracy: 0.759765625\n",
      "Batch: 93, Loss: 0.7021743059158325, Accuracy: 0.76953125\n",
      "Batch: 94, Loss: 0.7190007567405701, Accuracy: 0.7568359375\n",
      "Batch: 95, Loss: 0.7572264075279236, Accuracy: 0.7392578125\n",
      "Batch: 96, Loss: 0.7182148098945618, Accuracy: 0.76171875\n",
      "Batch: 97, Loss: 0.5982530117034912, Accuracy: 0.78515625\n",
      "Batch: 98, Loss: 0.6989386081695557, Accuracy: 0.7734375\n",
      "Batch: 99, Loss: 0.6905878186225891, Accuracy: 0.7724609375\n",
      "Batch: 100, Loss: 0.7313156127929688, Accuracy: 0.7568359375\n",
      "Batch: 101, Loss: 0.7790127396583557, Accuracy: 0.736328125\n",
      "Batch: 102, Loss: 0.7348041534423828, Accuracy: 0.7626953125\n",
      "Batch: 103, Loss: 0.7109323740005493, Accuracy: 0.7763671875\n",
      "Batch: 104, Loss: 0.6687850952148438, Accuracy: 0.77734375\n",
      "Batch: 105, Loss: 0.731829047203064, Accuracy: 0.767578125\n",
      "Batch: 106, Loss: 0.6635048389434814, Accuracy: 0.7880859375\n",
      "Batch: 107, Loss: 0.7041282653808594, Accuracy: 0.7705078125\n",
      "Batch: 108, Loss: 0.7115082740783691, Accuracy: 0.75390625\n",
      "Batch: 109, Loss: 0.8200404047966003, Accuracy: 0.7236328125\n",
      "Batch: 110, Loss: 0.6714869737625122, Accuracy: 0.7724609375\n",
      "Batch: 111, Loss: 0.7168596386909485, Accuracy: 0.7607421875\n",
      "Batch: 112, Loss: 0.6919931173324585, Accuracy: 0.78125\n",
      "Batch: 113, Loss: 0.7079805731773376, Accuracy: 0.7568359375\n",
      "Batch: 114, Loss: 0.7973659038543701, Accuracy: 0.74609375\n",
      "Batch: 115, Loss: 0.799899697303772, Accuracy: 0.744140625\n",
      "Batch: 116, Loss: 0.7204090356826782, Accuracy: 0.7646484375\n",
      "Batch: 117, Loss: 0.7522211074829102, Accuracy: 0.7587890625\n",
      "Batch: 118, Loss: 0.6154749393463135, Accuracy: 0.8037109375\n",
      "Batch: 119, Loss: 0.6377624273300171, Accuracy: 0.7890625\n",
      "Batch: 120, Loss: 0.7279883027076721, Accuracy: 0.75390625\n",
      "Batch: 121, Loss: 0.7627720236778259, Accuracy: 0.75\n",
      "Batch: 122, Loss: 0.6287957429885864, Accuracy: 0.7900390625\n",
      "Batch: 123, Loss: 0.6314210295677185, Accuracy: 0.791015625\n",
      "Batch: 124, Loss: 0.6951055526733398, Accuracy: 0.7724609375\n",
      "Batch: 125, Loss: 0.7849106192588806, Accuracy: 0.736328125\n",
      "Batch: 126, Loss: 0.7177655696868896, Accuracy: 0.767578125\n",
      "Batch: 127, Loss: 0.6464231014251709, Accuracy: 0.7900390625\n",
      "Batch: 128, Loss: 0.7680268287658691, Accuracy: 0.7705078125\n",
      "Batch: 129, Loss: 0.6442630887031555, Accuracy: 0.791015625\n",
      "Batch: 130, Loss: 0.8358259201049805, Accuracy: 0.7275390625\n",
      "Batch: 131, Loss: 0.7171527743339539, Accuracy: 0.7578125\n",
      "Batch: 132, Loss: 0.7236086130142212, Accuracy: 0.7705078125\n",
      "Batch: 133, Loss: 0.6892772912979126, Accuracy: 0.779296875\n",
      "Batch: 134, Loss: 0.726936936378479, Accuracy: 0.7412109375\n",
      "Batch: 135, Loss: 0.6347735524177551, Accuracy: 0.7841796875\n",
      "Batch: 136, Loss: 0.722409188747406, Accuracy: 0.7744140625\n",
      "Batch: 137, Loss: 0.7261452674865723, Accuracy: 0.75390625\n",
      "Batch: 138, Loss: 0.6204797029495239, Accuracy: 0.787109375\n",
      "Batch: 139, Loss: 0.6658293604850769, Accuracy: 0.7705078125\n",
      "Batch: 140, Loss: 0.6914116144180298, Accuracy: 0.7568359375\n",
      "Batch: 141, Loss: 0.7418193817138672, Accuracy: 0.755859375\n",
      "Batch: 142, Loss: 0.7747020721435547, Accuracy: 0.7392578125\n",
      "Batch: 143, Loss: 0.686846137046814, Accuracy: 0.7578125\n",
      "Batch: 144, Loss: 0.7248797416687012, Accuracy: 0.7548828125\n",
      "Batch: 145, Loss: 0.676866888999939, Accuracy: 0.7763671875\n",
      "Batch: 146, Loss: 0.7133185863494873, Accuracy: 0.759765625\n",
      "Batch: 147, Loss: 0.7106887102127075, Accuracy: 0.7734375\n",
      "Batch: 148, Loss: 0.7674896717071533, Accuracy: 0.7431640625\n",
      "Batch: 149, Loss: 0.6829835176467896, Accuracy: 0.7685546875\n",
      "Batch: 150, Loss: 0.6854275465011597, Accuracy: 0.755859375\n",
      "Batch: 151, Loss: 0.5886883735656738, Accuracy: 0.802734375\n",
      "Epoch 65/80\n",
      "Batch: 1, Loss: 0.9175718426704407, Accuracy: 0.7109375\n",
      "Batch: 2, Loss: 0.8194756507873535, Accuracy: 0.724609375\n",
      "Batch: 3, Loss: 0.6734124422073364, Accuracy: 0.7802734375\n",
      "Batch: 4, Loss: 0.6194033026695251, Accuracy: 0.80078125\n",
      "Batch: 5, Loss: 0.6839349269866943, Accuracy: 0.7763671875\n",
      "Batch: 6, Loss: 0.728306770324707, Accuracy: 0.7509765625\n",
      "Batch: 7, Loss: 0.7234439849853516, Accuracy: 0.755859375\n",
      "Batch: 8, Loss: 0.6584900617599487, Accuracy: 0.783203125\n",
      "Batch: 9, Loss: 0.6878095269203186, Accuracy: 0.767578125\n",
      "Batch: 10, Loss: 0.6476441621780396, Accuracy: 0.7841796875\n",
      "Batch: 11, Loss: 0.7763234376907349, Accuracy: 0.7470703125\n",
      "Batch: 12, Loss: 0.7671445608139038, Accuracy: 0.7509765625\n",
      "Batch: 13, Loss: 0.6096295714378357, Accuracy: 0.7939453125\n",
      "Batch: 14, Loss: 0.7853823304176331, Accuracy: 0.7431640625\n",
      "Batch: 15, Loss: 0.6248121857643127, Accuracy: 0.791015625\n",
      "Batch: 16, Loss: 0.713943362236023, Accuracy: 0.7744140625\n",
      "Batch: 17, Loss: 0.7356873750686646, Accuracy: 0.7470703125\n",
      "Batch: 18, Loss: 0.7716957330703735, Accuracy: 0.7431640625\n",
      "Batch: 19, Loss: 0.7192136645317078, Accuracy: 0.755859375\n",
      "Batch: 20, Loss: 0.6412884593009949, Accuracy: 0.7744140625\n",
      "Batch: 21, Loss: 0.6834816932678223, Accuracy: 0.779296875\n",
      "Batch: 22, Loss: 0.7693167924880981, Accuracy: 0.75\n",
      "Batch: 23, Loss: 0.7353935241699219, Accuracy: 0.7431640625\n",
      "Batch: 24, Loss: 0.7162246704101562, Accuracy: 0.7490234375\n",
      "Batch: 25, Loss: 0.725273609161377, Accuracy: 0.7724609375\n",
      "Batch: 26, Loss: 0.6127275228500366, Accuracy: 0.7890625\n",
      "Batch: 27, Loss: 0.6865904331207275, Accuracy: 0.76171875\n",
      "Batch: 28, Loss: 0.7606310844421387, Accuracy: 0.7392578125\n",
      "Batch: 29, Loss: 0.6845346689224243, Accuracy: 0.76171875\n",
      "Batch: 30, Loss: 0.5994191765785217, Accuracy: 0.806640625\n",
      "Batch: 31, Loss: 0.6293944120407104, Accuracy: 0.802734375\n",
      "Batch: 32, Loss: 0.6516435146331787, Accuracy: 0.767578125\n",
      "Batch: 33, Loss: 0.7515066862106323, Accuracy: 0.75390625\n",
      "Batch: 34, Loss: 0.8191940784454346, Accuracy: 0.724609375\n",
      "Batch: 35, Loss: 0.735403299331665, Accuracy: 0.7509765625\n",
      "Batch: 36, Loss: 0.7547973394393921, Accuracy: 0.75\n",
      "Batch: 37, Loss: 0.7064119577407837, Accuracy: 0.765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 38, Loss: 0.7230280637741089, Accuracy: 0.7509765625\n",
      "Batch: 39, Loss: 0.7373751401901245, Accuracy: 0.76171875\n",
      "Batch: 40, Loss: 0.6979638338088989, Accuracy: 0.76953125\n",
      "Batch: 41, Loss: 0.646919846534729, Accuracy: 0.791015625\n",
      "Batch: 42, Loss: 0.563539445400238, Accuracy: 0.814453125\n",
      "Batch: 43, Loss: 0.7259423732757568, Accuracy: 0.7578125\n",
      "Batch: 44, Loss: 0.7429260015487671, Accuracy: 0.7470703125\n",
      "Batch: 45, Loss: 0.6764551401138306, Accuracy: 0.7685546875\n",
      "Batch: 46, Loss: 0.6300635933876038, Accuracy: 0.80859375\n",
      "Batch: 47, Loss: 0.65578293800354, Accuracy: 0.7861328125\n",
      "Batch: 48, Loss: 0.6431772708892822, Accuracy: 0.787109375\n",
      "Batch: 49, Loss: 0.7400166988372803, Accuracy: 0.7666015625\n",
      "Batch: 50, Loss: 0.7436987161636353, Accuracy: 0.7607421875\n",
      "Batch: 51, Loss: 0.7214019894599915, Accuracy: 0.7568359375\n",
      "Batch: 52, Loss: 0.7411302328109741, Accuracy: 0.759765625\n",
      "Batch: 53, Loss: 0.6230366826057434, Accuracy: 0.78515625\n",
      "Batch: 54, Loss: 0.6896899938583374, Accuracy: 0.775390625\n",
      "Batch: 55, Loss: 0.7777267694473267, Accuracy: 0.7275390625\n",
      "Batch: 56, Loss: 0.7943198680877686, Accuracy: 0.7255859375\n",
      "Batch: 57, Loss: 0.7563589215278625, Accuracy: 0.7509765625\n",
      "Batch: 58, Loss: 0.8271874189376831, Accuracy: 0.728515625\n",
      "Batch: 59, Loss: 0.6975619792938232, Accuracy: 0.7822265625\n",
      "Batch: 60, Loss: 0.6735924482345581, Accuracy: 0.7783203125\n",
      "Batch: 61, Loss: 0.7362442016601562, Accuracy: 0.7587890625\n",
      "Batch: 62, Loss: 0.6874923706054688, Accuracy: 0.78125\n",
      "Batch: 63, Loss: 0.7120391726493835, Accuracy: 0.7666015625\n",
      "Batch: 64, Loss: 0.7148057222366333, Accuracy: 0.759765625\n",
      "Batch: 65, Loss: 0.735682487487793, Accuracy: 0.7626953125\n",
      "Batch: 66, Loss: 0.6787629723548889, Accuracy: 0.7861328125\n",
      "Batch: 67, Loss: 0.8212683796882629, Accuracy: 0.7431640625\n",
      "Batch: 68, Loss: 0.8258320093154907, Accuracy: 0.7490234375\n",
      "Batch: 69, Loss: 0.729127049446106, Accuracy: 0.767578125\n",
      "Batch: 70, Loss: 0.7125282287597656, Accuracy: 0.775390625\n",
      "Batch: 71, Loss: 0.7749828696250916, Accuracy: 0.72265625\n",
      "Batch: 72, Loss: 0.6496782302856445, Accuracy: 0.7900390625\n",
      "Batch: 73, Loss: 0.6243726015090942, Accuracy: 0.80078125\n",
      "Batch: 74, Loss: 0.6493579149246216, Accuracy: 0.802734375\n",
      "Batch: 75, Loss: 0.6199261546134949, Accuracy: 0.8076171875\n",
      "Batch: 76, Loss: 0.7406689524650574, Accuracy: 0.751953125\n",
      "Batch: 77, Loss: 0.6797231435775757, Accuracy: 0.775390625\n",
      "Batch: 78, Loss: 0.6534618139266968, Accuracy: 0.779296875\n",
      "Batch: 79, Loss: 0.6093268990516663, Accuracy: 0.798828125\n",
      "Batch: 80, Loss: 0.6702096462249756, Accuracy: 0.7763671875\n",
      "Batch: 81, Loss: 0.7792447805404663, Accuracy: 0.732421875\n",
      "Batch: 82, Loss: 0.7269574999809265, Accuracy: 0.7451171875\n",
      "Batch: 83, Loss: 0.627814769744873, Accuracy: 0.7998046875\n",
      "Batch: 84, Loss: 0.6960963010787964, Accuracy: 0.7646484375\n",
      "Batch: 85, Loss: 0.6687732934951782, Accuracy: 0.7744140625\n",
      "Batch: 86, Loss: 0.8342798948287964, Accuracy: 0.7353515625\n",
      "Batch: 87, Loss: 0.6659461259841919, Accuracy: 0.78515625\n",
      "Batch: 88, Loss: 0.7815967798233032, Accuracy: 0.751953125\n",
      "Batch: 89, Loss: 0.757331132888794, Accuracy: 0.7646484375\n",
      "Batch: 90, Loss: 0.6905274391174316, Accuracy: 0.763671875\n",
      "Batch: 91, Loss: 0.6674948334693909, Accuracy: 0.7734375\n",
      "Batch: 92, Loss: 0.7346268892288208, Accuracy: 0.751953125\n",
      "Batch: 93, Loss: 0.6998775005340576, Accuracy: 0.77734375\n",
      "Batch: 94, Loss: 0.7351861000061035, Accuracy: 0.7509765625\n",
      "Batch: 95, Loss: 0.7556815147399902, Accuracy: 0.7373046875\n",
      "Batch: 96, Loss: 0.707385778427124, Accuracy: 0.75390625\n",
      "Batch: 97, Loss: 0.6084409952163696, Accuracy: 0.7890625\n",
      "Batch: 98, Loss: 0.7003813982009888, Accuracy: 0.779296875\n",
      "Batch: 99, Loss: 0.6898559331893921, Accuracy: 0.759765625\n",
      "Batch: 100, Loss: 0.6844280958175659, Accuracy: 0.7607421875\n",
      "Batch: 101, Loss: 0.734592080116272, Accuracy: 0.7587890625\n",
      "Batch: 102, Loss: 0.7473226189613342, Accuracy: 0.7470703125\n",
      "Batch: 103, Loss: 0.7144423127174377, Accuracy: 0.7734375\n",
      "Batch: 104, Loss: 0.6497964859008789, Accuracy: 0.7783203125\n",
      "Batch: 105, Loss: 0.7669546604156494, Accuracy: 0.7451171875\n",
      "Batch: 106, Loss: 0.6630581617355347, Accuracy: 0.787109375\n",
      "Batch: 107, Loss: 0.6990920305252075, Accuracy: 0.783203125\n",
      "Batch: 108, Loss: 0.7411901354789734, Accuracy: 0.744140625\n",
      "Batch: 109, Loss: 0.8038383722305298, Accuracy: 0.732421875\n",
      "Batch: 110, Loss: 0.6854647397994995, Accuracy: 0.7783203125\n",
      "Batch: 111, Loss: 0.7427517175674438, Accuracy: 0.7509765625\n",
      "Batch: 112, Loss: 0.703338086605072, Accuracy: 0.7724609375\n",
      "Batch: 113, Loss: 0.7455748319625854, Accuracy: 0.7626953125\n",
      "Batch: 114, Loss: 0.7655807733535767, Accuracy: 0.7509765625\n",
      "Batch: 115, Loss: 0.842475175857544, Accuracy: 0.7373046875\n",
      "Batch: 116, Loss: 0.7648117542266846, Accuracy: 0.7490234375\n",
      "Batch: 117, Loss: 0.7789162397384644, Accuracy: 0.734375\n",
      "Batch: 118, Loss: 0.603193998336792, Accuracy: 0.8037109375\n",
      "Batch: 119, Loss: 0.6013625860214233, Accuracy: 0.8125\n",
      "Batch: 120, Loss: 0.7127959132194519, Accuracy: 0.7626953125\n",
      "Batch: 121, Loss: 0.7622159123420715, Accuracy: 0.7412109375\n",
      "Batch: 122, Loss: 0.6600947380065918, Accuracy: 0.7841796875\n",
      "Batch: 123, Loss: 0.6583389043807983, Accuracy: 0.7861328125\n",
      "Batch: 124, Loss: 0.7199536561965942, Accuracy: 0.7734375\n",
      "Batch: 125, Loss: 0.7649741768836975, Accuracy: 0.759765625\n",
      "Batch: 126, Loss: 0.7311474680900574, Accuracy: 0.7568359375\n",
      "Batch: 127, Loss: 0.6543163657188416, Accuracy: 0.796875\n",
      "Batch: 128, Loss: 0.7913511395454407, Accuracy: 0.759765625\n",
      "Batch: 129, Loss: 0.6801669597625732, Accuracy: 0.7802734375\n",
      "Batch: 130, Loss: 0.8082804679870605, Accuracy: 0.736328125\n",
      "Batch: 131, Loss: 0.7084040641784668, Accuracy: 0.765625\n",
      "Batch: 132, Loss: 0.6997277736663818, Accuracy: 0.7666015625\n",
      "Batch: 133, Loss: 0.6750019788742065, Accuracy: 0.7802734375\n",
      "Batch: 134, Loss: 0.7410582900047302, Accuracy: 0.751953125\n",
      "Batch: 135, Loss: 0.6509891152381897, Accuracy: 0.77734375\n",
      "Batch: 136, Loss: 0.7144910097122192, Accuracy: 0.7744140625\n",
      "Batch: 137, Loss: 0.6919443607330322, Accuracy: 0.759765625\n",
      "Batch: 138, Loss: 0.6257058382034302, Accuracy: 0.7890625\n",
      "Batch: 139, Loss: 0.6694773435592651, Accuracy: 0.76171875\n",
      "Batch: 140, Loss: 0.7020271420478821, Accuracy: 0.7578125\n",
      "Batch: 141, Loss: 0.7352408170700073, Accuracy: 0.7451171875\n",
      "Batch: 142, Loss: 0.7537269592285156, Accuracy: 0.74609375\n",
      "Batch: 143, Loss: 0.6979632377624512, Accuracy: 0.7578125\n",
      "Batch: 144, Loss: 0.7321410179138184, Accuracy: 0.76953125\n",
      "Batch: 145, Loss: 0.6674463748931885, Accuracy: 0.76953125\n",
      "Batch: 146, Loss: 0.7481503486633301, Accuracy: 0.7412109375\n",
      "Batch: 147, Loss: 0.7141151428222656, Accuracy: 0.759765625\n",
      "Batch: 148, Loss: 0.8031940460205078, Accuracy: 0.732421875\n",
      "Batch: 149, Loss: 0.7045287489891052, Accuracy: 0.76171875\n",
      "Batch: 150, Loss: 0.6694474816322327, Accuracy: 0.7734375\n",
      "Batch: 151, Loss: 0.6290388703346252, Accuracy: 0.791015625\n",
      "Epoch 66/80\n",
      "Batch: 1, Loss: 0.9376893639564514, Accuracy: 0.703125\n",
      "Batch: 2, Loss: 0.8430954217910767, Accuracy: 0.7021484375\n",
      "Batch: 3, Loss: 0.6978120803833008, Accuracy: 0.765625\n",
      "Batch: 4, Loss: 0.6368712186813354, Accuracy: 0.7939453125\n",
      "Batch: 5, Loss: 0.7082971930503845, Accuracy: 0.7607421875\n",
      "Batch: 6, Loss: 0.7386457920074463, Accuracy: 0.744140625\n",
      "Batch: 7, Loss: 0.7137541770935059, Accuracy: 0.759765625\n",
      "Batch: 8, Loss: 0.6923593282699585, Accuracy: 0.76171875\n",
      "Batch: 9, Loss: 0.708554744720459, Accuracy: 0.76953125\n",
      "Batch: 10, Loss: 0.6869409084320068, Accuracy: 0.7734375\n",
      "Batch: 11, Loss: 0.7881940603256226, Accuracy: 0.7294921875\n",
      "Batch: 12, Loss: 0.7741509675979614, Accuracy: 0.7421875\n",
      "Batch: 13, Loss: 0.6123415231704712, Accuracy: 0.7978515625\n",
      "Batch: 14, Loss: 0.7872858047485352, Accuracy: 0.7451171875\n",
      "Batch: 15, Loss: 0.6366662979125977, Accuracy: 0.791015625\n",
      "Batch: 16, Loss: 0.7342528700828552, Accuracy: 0.759765625\n",
      "Batch: 17, Loss: 0.7326371669769287, Accuracy: 0.7568359375\n",
      "Batch: 18, Loss: 0.7675780057907104, Accuracy: 0.75\n",
      "Batch: 19, Loss: 0.7550450563430786, Accuracy: 0.7509765625\n",
      "Batch: 20, Loss: 0.6332447528839111, Accuracy: 0.79296875\n",
      "Batch: 21, Loss: 0.6724206805229187, Accuracy: 0.7763671875\n",
      "Batch: 22, Loss: 0.8040827512741089, Accuracy: 0.734375\n",
      "Batch: 23, Loss: 0.7548341751098633, Accuracy: 0.7470703125\n",
      "Batch: 24, Loss: 0.7219221591949463, Accuracy: 0.7490234375\n",
      "Batch: 25, Loss: 0.6857410073280334, Accuracy: 0.7802734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 26, Loss: 0.6206119060516357, Accuracy: 0.78125\n",
      "Batch: 27, Loss: 0.6847022771835327, Accuracy: 0.7578125\n",
      "Batch: 28, Loss: 0.7202447056770325, Accuracy: 0.7412109375\n",
      "Batch: 29, Loss: 0.6684662699699402, Accuracy: 0.7734375\n",
      "Batch: 30, Loss: 0.6187639236450195, Accuracy: 0.7919921875\n",
      "Batch: 31, Loss: 0.6297166347503662, Accuracy: 0.78515625\n",
      "Batch: 32, Loss: 0.6489302515983582, Accuracy: 0.7822265625\n",
      "Batch: 33, Loss: 0.7671111822128296, Accuracy: 0.748046875\n",
      "Batch: 34, Loss: 0.8172692656517029, Accuracy: 0.7265625\n",
      "Batch: 35, Loss: 0.7244257926940918, Accuracy: 0.759765625\n",
      "Batch: 36, Loss: 0.757766842842102, Accuracy: 0.7509765625\n",
      "Batch: 37, Loss: 0.727036714553833, Accuracy: 0.7568359375\n",
      "Batch: 38, Loss: 0.7411937713623047, Accuracy: 0.74609375\n",
      "Batch: 39, Loss: 0.7733440399169922, Accuracy: 0.7392578125\n",
      "Batch: 40, Loss: 0.6698706150054932, Accuracy: 0.775390625\n",
      "Batch: 41, Loss: 0.630155086517334, Accuracy: 0.798828125\n",
      "Batch: 42, Loss: 0.5644412040710449, Accuracy: 0.8046875\n",
      "Batch: 43, Loss: 0.7483057975769043, Accuracy: 0.7333984375\n",
      "Batch: 44, Loss: 0.7586125135421753, Accuracy: 0.7509765625\n",
      "Batch: 45, Loss: 0.6680788397789001, Accuracy: 0.759765625\n",
      "Batch: 46, Loss: 0.6393352746963501, Accuracy: 0.7802734375\n",
      "Batch: 47, Loss: 0.6394379734992981, Accuracy: 0.7998046875\n",
      "Batch: 48, Loss: 0.6260628700256348, Accuracy: 0.791015625\n",
      "Batch: 49, Loss: 0.7353968024253845, Accuracy: 0.7578125\n",
      "Batch: 50, Loss: 0.7119244337081909, Accuracy: 0.7646484375\n",
      "Batch: 51, Loss: 0.7446909546852112, Accuracy: 0.7509765625\n",
      "Batch: 52, Loss: 0.7146477699279785, Accuracy: 0.7626953125\n",
      "Batch: 53, Loss: 0.6582062244415283, Accuracy: 0.7734375\n",
      "Batch: 54, Loss: 0.708625078201294, Accuracy: 0.765625\n",
      "Batch: 55, Loss: 0.8137984275817871, Accuracy: 0.708984375\n",
      "Batch: 56, Loss: 0.7466353178024292, Accuracy: 0.74609375\n",
      "Batch: 57, Loss: 0.7411613464355469, Accuracy: 0.7607421875\n",
      "Batch: 58, Loss: 0.8202604055404663, Accuracy: 0.732421875\n",
      "Batch: 59, Loss: 0.6727775931358337, Accuracy: 0.7802734375\n",
      "Batch: 60, Loss: 0.6544408798217773, Accuracy: 0.7783203125\n",
      "Batch: 61, Loss: 0.7157840728759766, Accuracy: 0.751953125\n",
      "Batch: 62, Loss: 0.678651750087738, Accuracy: 0.7978515625\n",
      "Batch: 63, Loss: 0.7254420518875122, Accuracy: 0.7734375\n",
      "Batch: 64, Loss: 0.7154509425163269, Accuracy: 0.771484375\n",
      "Batch: 65, Loss: 0.7211373448371887, Accuracy: 0.7626953125\n",
      "Batch: 66, Loss: 0.6815253496170044, Accuracy: 0.791015625\n",
      "Batch: 67, Loss: 0.779297411441803, Accuracy: 0.7470703125\n",
      "Batch: 68, Loss: 0.8177056908607483, Accuracy: 0.72265625\n",
      "Batch: 69, Loss: 0.7392752766609192, Accuracy: 0.748046875\n",
      "Batch: 70, Loss: 0.7133485078811646, Accuracy: 0.7783203125\n",
      "Batch: 71, Loss: 0.7575017213821411, Accuracy: 0.7421875\n",
      "Batch: 72, Loss: 0.6438930034637451, Accuracy: 0.763671875\n",
      "Batch: 73, Loss: 0.6413654088973999, Accuracy: 0.7919921875\n",
      "Batch: 74, Loss: 0.5993448495864868, Accuracy: 0.8134765625\n",
      "Batch: 75, Loss: 0.6464495062828064, Accuracy: 0.8076171875\n",
      "Batch: 76, Loss: 0.71687251329422, Accuracy: 0.75390625\n",
      "Batch: 77, Loss: 0.6488426327705383, Accuracy: 0.787109375\n",
      "Batch: 78, Loss: 0.6057791709899902, Accuracy: 0.80078125\n",
      "Batch: 79, Loss: 0.5785642266273499, Accuracy: 0.8037109375\n",
      "Batch: 80, Loss: 0.6667637825012207, Accuracy: 0.76953125\n",
      "Batch: 81, Loss: 0.7722544074058533, Accuracy: 0.7255859375\n",
      "Batch: 82, Loss: 0.7293378710746765, Accuracy: 0.7529296875\n",
      "Batch: 83, Loss: 0.6220923066139221, Accuracy: 0.8056640625\n",
      "Batch: 84, Loss: 0.6637415289878845, Accuracy: 0.77734375\n",
      "Batch: 85, Loss: 0.6677451133728027, Accuracy: 0.7802734375\n",
      "Batch: 86, Loss: 0.8088967800140381, Accuracy: 0.744140625\n",
      "Batch: 87, Loss: 0.6749196648597717, Accuracy: 0.7978515625\n",
      "Batch: 88, Loss: 0.7561315298080444, Accuracy: 0.7529296875\n",
      "Batch: 89, Loss: 0.7508686780929565, Accuracy: 0.7646484375\n",
      "Batch: 90, Loss: 0.6588991284370422, Accuracy: 0.7802734375\n",
      "Batch: 91, Loss: 0.6964011788368225, Accuracy: 0.76953125\n",
      "Batch: 92, Loss: 0.7334867715835571, Accuracy: 0.7626953125\n",
      "Batch: 93, Loss: 0.7121086120605469, Accuracy: 0.7783203125\n",
      "Batch: 94, Loss: 0.703925609588623, Accuracy: 0.7607421875\n",
      "Batch: 95, Loss: 0.7502697706222534, Accuracy: 0.7275390625\n",
      "Batch: 96, Loss: 0.6745171546936035, Accuracy: 0.7734375\n",
      "Batch: 97, Loss: 0.6092812418937683, Accuracy: 0.79296875\n",
      "Batch: 98, Loss: 0.7162275314331055, Accuracy: 0.7509765625\n",
      "Batch: 99, Loss: 0.7233309745788574, Accuracy: 0.759765625\n",
      "Batch: 100, Loss: 0.7330582737922668, Accuracy: 0.748046875\n",
      "Batch: 101, Loss: 0.7463318109512329, Accuracy: 0.7578125\n",
      "Batch: 102, Loss: 0.7109310030937195, Accuracy: 0.765625\n",
      "Batch: 103, Loss: 0.711812436580658, Accuracy: 0.775390625\n",
      "Batch: 104, Loss: 0.6667839288711548, Accuracy: 0.771484375\n",
      "Batch: 105, Loss: 0.7660329937934875, Accuracy: 0.7529296875\n",
      "Batch: 106, Loss: 0.6722834706306458, Accuracy: 0.775390625\n",
      "Batch: 107, Loss: 0.6959091424942017, Accuracy: 0.7939453125\n",
      "Batch: 108, Loss: 0.707642138004303, Accuracy: 0.7490234375\n",
      "Batch: 109, Loss: 0.8067629337310791, Accuracy: 0.7294921875\n",
      "Batch: 110, Loss: 0.6487395167350769, Accuracy: 0.7822265625\n",
      "Batch: 111, Loss: 0.7394734025001526, Accuracy: 0.7607421875\n",
      "Batch: 112, Loss: 0.7178394794464111, Accuracy: 0.78125\n",
      "Batch: 113, Loss: 0.7062084674835205, Accuracy: 0.7666015625\n",
      "Batch: 114, Loss: 0.7706589698791504, Accuracy: 0.74609375\n",
      "Batch: 115, Loss: 0.8394932746887207, Accuracy: 0.744140625\n",
      "Batch: 116, Loss: 0.7726128101348877, Accuracy: 0.740234375\n",
      "Batch: 117, Loss: 0.7925727963447571, Accuracy: 0.7392578125\n",
      "Batch: 118, Loss: 0.6591331362724304, Accuracy: 0.7890625\n",
      "Batch: 119, Loss: 0.6083361506462097, Accuracy: 0.8154296875\n",
      "Batch: 120, Loss: 0.7255330085754395, Accuracy: 0.759765625\n",
      "Batch: 121, Loss: 0.7617142200469971, Accuracy: 0.748046875\n",
      "Batch: 122, Loss: 0.6444443464279175, Accuracy: 0.80078125\n",
      "Batch: 123, Loss: 0.633700966835022, Accuracy: 0.794921875\n",
      "Batch: 124, Loss: 0.7050769925117493, Accuracy: 0.77734375\n",
      "Batch: 125, Loss: 0.7578686475753784, Accuracy: 0.7490234375\n",
      "Batch: 126, Loss: 0.7148527503013611, Accuracy: 0.759765625\n",
      "Batch: 127, Loss: 0.6681430339813232, Accuracy: 0.779296875\n",
      "Batch: 128, Loss: 0.7777254581451416, Accuracy: 0.763671875\n",
      "Batch: 129, Loss: 0.6560717821121216, Accuracy: 0.794921875\n",
      "Batch: 130, Loss: 0.7884121537208557, Accuracy: 0.7490234375\n",
      "Batch: 131, Loss: 0.7118111848831177, Accuracy: 0.75390625\n",
      "Batch: 132, Loss: 0.7306042909622192, Accuracy: 0.7734375\n",
      "Batch: 133, Loss: 0.6940767765045166, Accuracy: 0.7880859375\n",
      "Batch: 134, Loss: 0.7081522345542908, Accuracy: 0.755859375\n",
      "Batch: 135, Loss: 0.6519396305084229, Accuracy: 0.7958984375\n",
      "Batch: 136, Loss: 0.7192237377166748, Accuracy: 0.7822265625\n",
      "Batch: 137, Loss: 0.7312673926353455, Accuracy: 0.7421875\n",
      "Batch: 138, Loss: 0.6408140063285828, Accuracy: 0.7822265625\n",
      "Batch: 139, Loss: 0.6759817004203796, Accuracy: 0.7724609375\n",
      "Batch: 140, Loss: 0.6849415302276611, Accuracy: 0.7666015625\n",
      "Batch: 141, Loss: 0.7535282373428345, Accuracy: 0.755859375\n",
      "Batch: 142, Loss: 0.7751179933547974, Accuracy: 0.7431640625\n",
      "Batch: 143, Loss: 0.6814206838607788, Accuracy: 0.7734375\n",
      "Batch: 144, Loss: 0.7077367305755615, Accuracy: 0.765625\n",
      "Batch: 145, Loss: 0.6855025291442871, Accuracy: 0.7734375\n",
      "Batch: 146, Loss: 0.7071850299835205, Accuracy: 0.7724609375\n",
      "Batch: 147, Loss: 0.7291830778121948, Accuracy: 0.7587890625\n",
      "Batch: 148, Loss: 0.7650271654129028, Accuracy: 0.7275390625\n",
      "Batch: 149, Loss: 0.684450089931488, Accuracy: 0.7666015625\n",
      "Batch: 150, Loss: 0.6884574890136719, Accuracy: 0.7666015625\n",
      "Batch: 151, Loss: 0.615948498249054, Accuracy: 0.8017578125\n",
      "Epoch 67/80\n",
      "Batch: 1, Loss: 0.8992919325828552, Accuracy: 0.7275390625\n",
      "Batch: 2, Loss: 0.7938400506973267, Accuracy: 0.7216796875\n",
      "Batch: 3, Loss: 0.6913615465164185, Accuracy: 0.76953125\n",
      "Batch: 4, Loss: 0.5675115585327148, Accuracy: 0.802734375\n",
      "Batch: 5, Loss: 0.6824848651885986, Accuracy: 0.771484375\n",
      "Batch: 6, Loss: 0.7436740398406982, Accuracy: 0.7392578125\n",
      "Batch: 7, Loss: 0.7300770282745361, Accuracy: 0.76171875\n",
      "Batch: 8, Loss: 0.666272759437561, Accuracy: 0.7744140625\n",
      "Batch: 9, Loss: 0.7079702615737915, Accuracy: 0.7666015625\n",
      "Batch: 10, Loss: 0.6814373135566711, Accuracy: 0.77734375\n",
      "Batch: 11, Loss: 0.7885008454322815, Accuracy: 0.72265625\n",
      "Batch: 12, Loss: 0.7563996315002441, Accuracy: 0.7451171875\n",
      "Batch: 13, Loss: 0.6003948450088501, Accuracy: 0.8056640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 14, Loss: 0.7881820797920227, Accuracy: 0.7470703125\n",
      "Batch: 15, Loss: 0.6361154317855835, Accuracy: 0.7958984375\n",
      "Batch: 16, Loss: 0.7027022838592529, Accuracy: 0.7685546875\n",
      "Batch: 17, Loss: 0.7127475738525391, Accuracy: 0.7607421875\n",
      "Batch: 18, Loss: 0.7519827485084534, Accuracy: 0.7578125\n",
      "Batch: 19, Loss: 0.7162229418754578, Accuracy: 0.75390625\n",
      "Batch: 20, Loss: 0.5934700965881348, Accuracy: 0.8037109375\n",
      "Batch: 21, Loss: 0.6580249071121216, Accuracy: 0.78515625\n",
      "Batch: 22, Loss: 0.7525674104690552, Accuracy: 0.765625\n",
      "Batch: 23, Loss: 0.7013952732086182, Accuracy: 0.7685546875\n",
      "Batch: 24, Loss: 0.7154250144958496, Accuracy: 0.7568359375\n",
      "Batch: 25, Loss: 0.6870245337486267, Accuracy: 0.7724609375\n",
      "Batch: 26, Loss: 0.6031352877616882, Accuracy: 0.791015625\n",
      "Batch: 27, Loss: 0.6889210343360901, Accuracy: 0.7548828125\n",
      "Batch: 28, Loss: 0.7323389053344727, Accuracy: 0.76171875\n",
      "Batch: 29, Loss: 0.6952764987945557, Accuracy: 0.759765625\n",
      "Batch: 30, Loss: 0.5890475511550903, Accuracy: 0.80078125\n",
      "Batch: 31, Loss: 0.6186345815658569, Accuracy: 0.80859375\n",
      "Batch: 32, Loss: 0.6353039741516113, Accuracy: 0.787109375\n",
      "Batch: 33, Loss: 0.7668393850326538, Accuracy: 0.7431640625\n",
      "Batch: 34, Loss: 0.816105842590332, Accuracy: 0.7265625\n",
      "Batch: 35, Loss: 0.7156752943992615, Accuracy: 0.76171875\n",
      "Batch: 36, Loss: 0.73473060131073, Accuracy: 0.7646484375\n",
      "Batch: 37, Loss: 0.7326062917709351, Accuracy: 0.7666015625\n",
      "Batch: 38, Loss: 0.7223584651947021, Accuracy: 0.7548828125\n",
      "Batch: 39, Loss: 0.7264139652252197, Accuracy: 0.763671875\n",
      "Batch: 40, Loss: 0.7021719217300415, Accuracy: 0.77734375\n",
      "Batch: 41, Loss: 0.6136177778244019, Accuracy: 0.8037109375\n",
      "Batch: 42, Loss: 0.5809171199798584, Accuracy: 0.8125\n",
      "Batch: 43, Loss: 0.7277005314826965, Accuracy: 0.755859375\n",
      "Batch: 44, Loss: 0.7245107889175415, Accuracy: 0.75390625\n",
      "Batch: 45, Loss: 0.6451733112335205, Accuracy: 0.7705078125\n",
      "Batch: 46, Loss: 0.6300186514854431, Accuracy: 0.7890625\n",
      "Batch: 47, Loss: 0.6099538207054138, Accuracy: 0.8017578125\n",
      "Batch: 48, Loss: 0.6410783529281616, Accuracy: 0.7919921875\n",
      "Batch: 49, Loss: 0.7300400733947754, Accuracy: 0.7548828125\n",
      "Batch: 50, Loss: 0.7168004512786865, Accuracy: 0.7626953125\n",
      "Batch: 51, Loss: 0.7074321508407593, Accuracy: 0.7734375\n",
      "Batch: 52, Loss: 0.7111343741416931, Accuracy: 0.7705078125\n",
      "Batch: 53, Loss: 0.657355785369873, Accuracy: 0.775390625\n",
      "Batch: 54, Loss: 0.679284930229187, Accuracy: 0.771484375\n",
      "Batch: 55, Loss: 0.7693530321121216, Accuracy: 0.7451171875\n",
      "Batch: 56, Loss: 0.7525427341461182, Accuracy: 0.7470703125\n",
      "Batch: 57, Loss: 0.739802360534668, Accuracy: 0.75\n",
      "Batch: 58, Loss: 0.8177291750907898, Accuracy: 0.736328125\n",
      "Batch: 59, Loss: 0.6601177453994751, Accuracy: 0.7900390625\n",
      "Batch: 60, Loss: 0.6708197593688965, Accuracy: 0.779296875\n",
      "Batch: 61, Loss: 0.7299473285675049, Accuracy: 0.7685546875\n",
      "Batch: 62, Loss: 0.6881176233291626, Accuracy: 0.77734375\n",
      "Batch: 63, Loss: 0.7061719298362732, Accuracy: 0.7724609375\n",
      "Batch: 64, Loss: 0.6704503893852234, Accuracy: 0.78515625\n",
      "Batch: 65, Loss: 0.7010900974273682, Accuracy: 0.76953125\n",
      "Batch: 66, Loss: 0.7158764600753784, Accuracy: 0.767578125\n",
      "Batch: 67, Loss: 0.7740992307662964, Accuracy: 0.751953125\n",
      "Batch: 68, Loss: 0.7953193187713623, Accuracy: 0.748046875\n",
      "Batch: 69, Loss: 0.745500385761261, Accuracy: 0.7607421875\n",
      "Batch: 70, Loss: 0.7124093770980835, Accuracy: 0.7841796875\n",
      "Batch: 71, Loss: 0.7546773552894592, Accuracy: 0.7412109375\n",
      "Batch: 72, Loss: 0.6621577143669128, Accuracy: 0.7646484375\n",
      "Batch: 73, Loss: 0.6312171220779419, Accuracy: 0.794921875\n",
      "Batch: 74, Loss: 0.6169034242630005, Accuracy: 0.7919921875\n",
      "Batch: 75, Loss: 0.6488370895385742, Accuracy: 0.7939453125\n",
      "Batch: 76, Loss: 0.7206248641014099, Accuracy: 0.7587890625\n",
      "Batch: 77, Loss: 0.6439237594604492, Accuracy: 0.791015625\n",
      "Batch: 78, Loss: 0.6170519590377808, Accuracy: 0.796875\n",
      "Batch: 79, Loss: 0.5799655318260193, Accuracy: 0.8115234375\n",
      "Batch: 80, Loss: 0.6476033926010132, Accuracy: 0.78515625\n",
      "Batch: 81, Loss: 0.7699207067489624, Accuracy: 0.728515625\n",
      "Batch: 82, Loss: 0.7312781810760498, Accuracy: 0.759765625\n",
      "Batch: 83, Loss: 0.5907754898071289, Accuracy: 0.8115234375\n",
      "Batch: 84, Loss: 0.697770893573761, Accuracy: 0.77734375\n",
      "Batch: 85, Loss: 0.6582074165344238, Accuracy: 0.7744140625\n",
      "Batch: 86, Loss: 0.81507807970047, Accuracy: 0.7421875\n",
      "Batch: 87, Loss: 0.6651149988174438, Accuracy: 0.783203125\n",
      "Batch: 88, Loss: 0.7371081113815308, Accuracy: 0.7529296875\n",
      "Batch: 89, Loss: 0.7149171829223633, Accuracy: 0.77734375\n",
      "Batch: 90, Loss: 0.6584383249282837, Accuracy: 0.7958984375\n",
      "Batch: 91, Loss: 0.6585357189178467, Accuracy: 0.7724609375\n",
      "Batch: 92, Loss: 0.7004895210266113, Accuracy: 0.7578125\n",
      "Batch: 93, Loss: 0.6797835826873779, Accuracy: 0.7880859375\n",
      "Batch: 94, Loss: 0.7367235422134399, Accuracy: 0.744140625\n",
      "Batch: 95, Loss: 0.7412976026535034, Accuracy: 0.744140625\n",
      "Batch: 96, Loss: 0.6860032081604004, Accuracy: 0.7685546875\n",
      "Batch: 97, Loss: 0.5931453704833984, Accuracy: 0.798828125\n",
      "Batch: 98, Loss: 0.7194603085517883, Accuracy: 0.765625\n",
      "Batch: 99, Loss: 0.6958475112915039, Accuracy: 0.765625\n",
      "Batch: 100, Loss: 0.7148918509483337, Accuracy: 0.7568359375\n",
      "Batch: 101, Loss: 0.7307969331741333, Accuracy: 0.7607421875\n",
      "Batch: 102, Loss: 0.7263914346694946, Accuracy: 0.7607421875\n",
      "Batch: 103, Loss: 0.696305513381958, Accuracy: 0.7744140625\n",
      "Batch: 104, Loss: 0.6596298217773438, Accuracy: 0.7724609375\n",
      "Batch: 105, Loss: 0.7334496974945068, Accuracy: 0.75\n",
      "Batch: 106, Loss: 0.6589351892471313, Accuracy: 0.7919921875\n",
      "Batch: 107, Loss: 0.7075207829475403, Accuracy: 0.77734375\n",
      "Batch: 108, Loss: 0.7030076384544373, Accuracy: 0.7744140625\n",
      "Batch: 109, Loss: 0.8275690078735352, Accuracy: 0.7177734375\n",
      "Batch: 110, Loss: 0.6421124935150146, Accuracy: 0.7822265625\n",
      "Batch: 111, Loss: 0.7218133211135864, Accuracy: 0.75390625\n",
      "Batch: 112, Loss: 0.6993861198425293, Accuracy: 0.763671875\n",
      "Batch: 113, Loss: 0.7147427797317505, Accuracy: 0.7646484375\n",
      "Batch: 114, Loss: 0.7928035259246826, Accuracy: 0.7490234375\n",
      "Batch: 115, Loss: 0.8138015270233154, Accuracy: 0.74609375\n",
      "Batch: 116, Loss: 0.7423141002655029, Accuracy: 0.7568359375\n",
      "Batch: 117, Loss: 0.7282907962799072, Accuracy: 0.765625\n",
      "Batch: 118, Loss: 0.6333822011947632, Accuracy: 0.7939453125\n",
      "Batch: 119, Loss: 0.6024974584579468, Accuracy: 0.798828125\n",
      "Batch: 120, Loss: 0.7449772357940674, Accuracy: 0.7626953125\n",
      "Batch: 121, Loss: 0.7557748556137085, Accuracy: 0.7490234375\n",
      "Batch: 122, Loss: 0.6432886719703674, Accuracy: 0.787109375\n",
      "Batch: 123, Loss: 0.596105694770813, Accuracy: 0.8115234375\n",
      "Batch: 124, Loss: 0.7059959173202515, Accuracy: 0.7685546875\n",
      "Batch: 125, Loss: 0.7553340196609497, Accuracy: 0.7578125\n",
      "Batch: 126, Loss: 0.7311939001083374, Accuracy: 0.763671875\n",
      "Batch: 127, Loss: 0.6342555284500122, Accuracy: 0.79296875\n",
      "Batch: 128, Loss: 0.7710416913032532, Accuracy: 0.759765625\n",
      "Batch: 129, Loss: 0.65907222032547, Accuracy: 0.7861328125\n",
      "Batch: 130, Loss: 0.7996440529823303, Accuracy: 0.748046875\n",
      "Batch: 131, Loss: 0.7004383206367493, Accuracy: 0.7607421875\n",
      "Batch: 132, Loss: 0.7267141342163086, Accuracy: 0.775390625\n",
      "Batch: 133, Loss: 0.6974310278892517, Accuracy: 0.7578125\n",
      "Batch: 134, Loss: 0.7224936485290527, Accuracy: 0.7587890625\n",
      "Batch: 135, Loss: 0.6713943481445312, Accuracy: 0.7802734375\n",
      "Batch: 136, Loss: 0.7243340015411377, Accuracy: 0.7509765625\n",
      "Batch: 137, Loss: 0.7263630628585815, Accuracy: 0.7412109375\n",
      "Batch: 138, Loss: 0.6459182500839233, Accuracy: 0.7802734375\n",
      "Batch: 139, Loss: 0.6729167699813843, Accuracy: 0.775390625\n",
      "Batch: 140, Loss: 0.7043206095695496, Accuracy: 0.7548828125\n",
      "Batch: 141, Loss: 0.7296432852745056, Accuracy: 0.7626953125\n",
      "Batch: 142, Loss: 0.7653560042381287, Accuracy: 0.7548828125\n",
      "Batch: 143, Loss: 0.6736993789672852, Accuracy: 0.7685546875\n",
      "Batch: 144, Loss: 0.7020442485809326, Accuracy: 0.7744140625\n",
      "Batch: 145, Loss: 0.6389498114585876, Accuracy: 0.779296875\n",
      "Batch: 146, Loss: 0.7167650461196899, Accuracy: 0.7529296875\n",
      "Batch: 147, Loss: 0.7128205299377441, Accuracy: 0.759765625\n",
      "Batch: 148, Loss: 0.7593117952346802, Accuracy: 0.7431640625\n",
      "Batch: 149, Loss: 0.6524084806442261, Accuracy: 0.779296875\n",
      "Batch: 150, Loss: 0.6754350662231445, Accuracy: 0.767578125\n",
      "Batch: 151, Loss: 0.6269690990447998, Accuracy: 0.787109375\n",
      "Epoch 68/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1, Loss: 0.9314173460006714, Accuracy: 0.7060546875\n",
      "Batch: 2, Loss: 0.7882990837097168, Accuracy: 0.72265625\n",
      "Batch: 3, Loss: 0.6565912365913391, Accuracy: 0.7802734375\n",
      "Batch: 4, Loss: 0.6121527552604675, Accuracy: 0.8115234375\n",
      "Batch: 5, Loss: 0.6477771401405334, Accuracy: 0.7861328125\n",
      "Batch: 6, Loss: 0.7285857200622559, Accuracy: 0.7568359375\n",
      "Batch: 7, Loss: 0.7002068161964417, Accuracy: 0.763671875\n",
      "Batch: 8, Loss: 0.6508398056030273, Accuracy: 0.775390625\n",
      "Batch: 9, Loss: 0.6997405886650085, Accuracy: 0.76953125\n",
      "Batch: 10, Loss: 0.6827530264854431, Accuracy: 0.7646484375\n",
      "Batch: 11, Loss: 0.7653518915176392, Accuracy: 0.748046875\n",
      "Batch: 12, Loss: 0.7641599774360657, Accuracy: 0.7587890625\n",
      "Batch: 13, Loss: 0.5912463665008545, Accuracy: 0.798828125\n",
      "Batch: 14, Loss: 0.7705541849136353, Accuracy: 0.7421875\n",
      "Batch: 15, Loss: 0.623343825340271, Accuracy: 0.794921875\n",
      "Batch: 16, Loss: 0.6694300174713135, Accuracy: 0.78125\n",
      "Batch: 17, Loss: 0.7394477128982544, Accuracy: 0.744140625\n",
      "Batch: 18, Loss: 0.7300281524658203, Accuracy: 0.751953125\n",
      "Batch: 19, Loss: 0.7201493978500366, Accuracy: 0.76953125\n",
      "Batch: 20, Loss: 0.6270983815193176, Accuracy: 0.798828125\n",
      "Batch: 21, Loss: 0.6648030281066895, Accuracy: 0.763671875\n",
      "Batch: 22, Loss: 0.7790120840072632, Accuracy: 0.7470703125\n",
      "Batch: 23, Loss: 0.7070116996765137, Accuracy: 0.75\n",
      "Batch: 24, Loss: 0.724535346031189, Accuracy: 0.75\n",
      "Batch: 25, Loss: 0.7121614217758179, Accuracy: 0.77734375\n",
      "Batch: 26, Loss: 0.5947390198707581, Accuracy: 0.7900390625\n",
      "Batch: 27, Loss: 0.6869906187057495, Accuracy: 0.7646484375\n",
      "Batch: 28, Loss: 0.7283017635345459, Accuracy: 0.7587890625\n",
      "Batch: 29, Loss: 0.6824837327003479, Accuracy: 0.76171875\n",
      "Batch: 30, Loss: 0.6101632118225098, Accuracy: 0.8056640625\n",
      "Batch: 31, Loss: 0.6445671916007996, Accuracy: 0.80078125\n",
      "Batch: 32, Loss: 0.6625403761863708, Accuracy: 0.763671875\n",
      "Batch: 33, Loss: 0.7488199472427368, Accuracy: 0.751953125\n",
      "Batch: 34, Loss: 0.8172804117202759, Accuracy: 0.7314453125\n",
      "Batch: 35, Loss: 0.6952962279319763, Accuracy: 0.7666015625\n",
      "Batch: 36, Loss: 0.7262791395187378, Accuracy: 0.7705078125\n",
      "Batch: 37, Loss: 0.7239111661911011, Accuracy: 0.75390625\n",
      "Batch: 38, Loss: 0.6972953081130981, Accuracy: 0.7568359375\n",
      "Batch: 39, Loss: 0.7278640866279602, Accuracy: 0.771484375\n",
      "Batch: 40, Loss: 0.6768682599067688, Accuracy: 0.7802734375\n",
      "Batch: 41, Loss: 0.6223611831665039, Accuracy: 0.7978515625\n",
      "Batch: 42, Loss: 0.5462664365768433, Accuracy: 0.826171875\n",
      "Batch: 43, Loss: 0.7332069873809814, Accuracy: 0.74609375\n",
      "Batch: 44, Loss: 0.7568093538284302, Accuracy: 0.75\n",
      "Batch: 45, Loss: 0.6590813398361206, Accuracy: 0.78515625\n",
      "Batch: 46, Loss: 0.6388438940048218, Accuracy: 0.7861328125\n",
      "Batch: 47, Loss: 0.6424971222877502, Accuracy: 0.798828125\n",
      "Batch: 48, Loss: 0.6316398978233337, Accuracy: 0.7919921875\n",
      "Batch: 49, Loss: 0.7151327133178711, Accuracy: 0.763671875\n",
      "Batch: 50, Loss: 0.6913336515426636, Accuracy: 0.7705078125\n",
      "Batch: 51, Loss: 0.6869202852249146, Accuracy: 0.783203125\n",
      "Batch: 52, Loss: 0.6857219338417053, Accuracy: 0.7734375\n",
      "Batch: 53, Loss: 0.6409258842468262, Accuracy: 0.7880859375\n",
      "Batch: 54, Loss: 0.6711516380310059, Accuracy: 0.7880859375\n",
      "Batch: 55, Loss: 0.8126006126403809, Accuracy: 0.7197265625\n",
      "Batch: 56, Loss: 0.7711405754089355, Accuracy: 0.7529296875\n",
      "Batch: 57, Loss: 0.7514042854309082, Accuracy: 0.751953125\n",
      "Batch: 58, Loss: 0.8223452568054199, Accuracy: 0.7392578125\n",
      "Batch: 59, Loss: 0.665725588798523, Accuracy: 0.7744140625\n",
      "Batch: 60, Loss: 0.6463689208030701, Accuracy: 0.7841796875\n",
      "Batch: 61, Loss: 0.7396981716156006, Accuracy: 0.76171875\n",
      "Batch: 62, Loss: 0.6910764575004578, Accuracy: 0.7802734375\n",
      "Batch: 63, Loss: 0.6899614334106445, Accuracy: 0.76171875\n",
      "Batch: 64, Loss: 0.6925437450408936, Accuracy: 0.7734375\n",
      "Batch: 65, Loss: 0.713903546333313, Accuracy: 0.7626953125\n",
      "Batch: 66, Loss: 0.6999968886375427, Accuracy: 0.783203125\n",
      "Batch: 67, Loss: 0.768065333366394, Accuracy: 0.7568359375\n",
      "Batch: 68, Loss: 0.815056562423706, Accuracy: 0.7451171875\n",
      "Batch: 69, Loss: 0.741468608379364, Accuracy: 0.75\n",
      "Batch: 70, Loss: 0.6851304769515991, Accuracy: 0.7919921875\n",
      "Batch: 71, Loss: 0.7757065296173096, Accuracy: 0.7431640625\n",
      "Batch: 72, Loss: 0.6307717561721802, Accuracy: 0.78125\n",
      "Batch: 73, Loss: 0.6376870274543762, Accuracy: 0.8076171875\n",
      "Batch: 74, Loss: 0.5996320247650146, Accuracy: 0.814453125\n",
      "Batch: 75, Loss: 0.6466414928436279, Accuracy: 0.7861328125\n",
      "Batch: 76, Loss: 0.729045033454895, Accuracy: 0.755859375\n",
      "Batch: 77, Loss: 0.6457191109657288, Accuracy: 0.7900390625\n",
      "Batch: 78, Loss: 0.605719804763794, Accuracy: 0.802734375\n",
      "Batch: 79, Loss: 0.6137480735778809, Accuracy: 0.8076171875\n",
      "Batch: 80, Loss: 0.6510378122329712, Accuracy: 0.7802734375\n",
      "Batch: 81, Loss: 0.7620915174484253, Accuracy: 0.7470703125\n",
      "Batch: 82, Loss: 0.7233177423477173, Accuracy: 0.7578125\n",
      "Batch: 83, Loss: 0.6346124410629272, Accuracy: 0.8076171875\n",
      "Batch: 84, Loss: 0.671553373336792, Accuracy: 0.78515625\n",
      "Batch: 85, Loss: 0.6703457832336426, Accuracy: 0.7763671875\n",
      "Batch: 86, Loss: 0.8122738003730774, Accuracy: 0.7431640625\n",
      "Batch: 87, Loss: 0.6759581565856934, Accuracy: 0.7861328125\n",
      "Batch: 88, Loss: 0.7662742137908936, Accuracy: 0.7548828125\n",
      "Batch: 89, Loss: 0.7565389275550842, Accuracy: 0.7724609375\n",
      "Batch: 90, Loss: 0.6793104410171509, Accuracy: 0.7783203125\n",
      "Batch: 91, Loss: 0.6697585582733154, Accuracy: 0.775390625\n",
      "Batch: 92, Loss: 0.713763952255249, Accuracy: 0.76171875\n",
      "Batch: 93, Loss: 0.6668988466262817, Accuracy: 0.775390625\n",
      "Batch: 94, Loss: 0.696744441986084, Accuracy: 0.76953125\n",
      "Batch: 95, Loss: 0.7519983649253845, Accuracy: 0.740234375\n",
      "Batch: 96, Loss: 0.6997015476226807, Accuracy: 0.7705078125\n",
      "Batch: 97, Loss: 0.5780105590820312, Accuracy: 0.8046875\n",
      "Batch: 98, Loss: 0.7168920040130615, Accuracy: 0.76171875\n",
      "Batch: 99, Loss: 0.6802501678466797, Accuracy: 0.771484375\n",
      "Batch: 100, Loss: 0.7144622802734375, Accuracy: 0.751953125\n",
      "Batch: 101, Loss: 0.737796425819397, Accuracy: 0.767578125\n",
      "Batch: 102, Loss: 0.7227116823196411, Accuracy: 0.76171875\n",
      "Batch: 103, Loss: 0.695465087890625, Accuracy: 0.7822265625\n",
      "Batch: 104, Loss: 0.6532222032546997, Accuracy: 0.7861328125\n",
      "Batch: 105, Loss: 0.7340539693832397, Accuracy: 0.759765625\n",
      "Batch: 106, Loss: 0.6788524389266968, Accuracy: 0.7841796875\n",
      "Batch: 107, Loss: 0.7376258969306946, Accuracy: 0.7666015625\n",
      "Batch: 108, Loss: 0.7145051956176758, Accuracy: 0.7509765625\n",
      "Batch: 109, Loss: 0.8093435168266296, Accuracy: 0.7294921875\n",
      "Batch: 110, Loss: 0.6510826349258423, Accuracy: 0.7861328125\n",
      "Batch: 111, Loss: 0.7538836598396301, Accuracy: 0.7470703125\n",
      "Batch: 112, Loss: 0.7095915079116821, Accuracy: 0.7763671875\n",
      "Batch: 113, Loss: 0.6716446280479431, Accuracy: 0.7861328125\n",
      "Batch: 114, Loss: 0.7304596900939941, Accuracy: 0.7685546875\n",
      "Batch: 115, Loss: 0.7804660797119141, Accuracy: 0.75\n",
      "Batch: 116, Loss: 0.756005585193634, Accuracy: 0.7431640625\n",
      "Batch: 117, Loss: 0.7616012692451477, Accuracy: 0.75\n",
      "Batch: 118, Loss: 0.6260256171226501, Accuracy: 0.7919921875\n",
      "Batch: 119, Loss: 0.5783517360687256, Accuracy: 0.810546875\n",
      "Batch: 120, Loss: 0.7326231002807617, Accuracy: 0.75390625\n",
      "Batch: 121, Loss: 0.7729299664497375, Accuracy: 0.7509765625\n",
      "Batch: 122, Loss: 0.6347986459732056, Accuracy: 0.78125\n",
      "Batch: 123, Loss: 0.6155868768692017, Accuracy: 0.8076171875\n",
      "Batch: 124, Loss: 0.6849424242973328, Accuracy: 0.7802734375\n",
      "Batch: 125, Loss: 0.7641631364822388, Accuracy: 0.7587890625\n",
      "Batch: 126, Loss: 0.702394962310791, Accuracy: 0.765625\n",
      "Batch: 127, Loss: 0.6206439733505249, Accuracy: 0.80859375\n",
      "Batch: 128, Loss: 0.7536167502403259, Accuracy: 0.771484375\n",
      "Batch: 129, Loss: 0.672645092010498, Accuracy: 0.7724609375\n",
      "Batch: 130, Loss: 0.8057940006256104, Accuracy: 0.7470703125\n",
      "Batch: 131, Loss: 0.7005659341812134, Accuracy: 0.7666015625\n",
      "Batch: 132, Loss: 0.7016599774360657, Accuracy: 0.7705078125\n",
      "Batch: 133, Loss: 0.6660764217376709, Accuracy: 0.771484375\n",
      "Batch: 134, Loss: 0.7021178603172302, Accuracy: 0.7763671875\n",
      "Batch: 135, Loss: 0.6306229829788208, Accuracy: 0.796875\n",
      "Batch: 136, Loss: 0.6786773204803467, Accuracy: 0.7900390625\n",
      "Batch: 137, Loss: 0.7033584117889404, Accuracy: 0.7607421875\n",
      "Batch: 138, Loss: 0.6141103506088257, Accuracy: 0.7890625\n",
      "Batch: 139, Loss: 0.6534160375595093, Accuracy: 0.77734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 140, Loss: 0.6994621157646179, Accuracy: 0.7783203125\n",
      "Batch: 141, Loss: 0.7228606939315796, Accuracy: 0.7529296875\n",
      "Batch: 142, Loss: 0.7509647011756897, Accuracy: 0.755859375\n",
      "Batch: 143, Loss: 0.684076189994812, Accuracy: 0.7607421875\n",
      "Batch: 144, Loss: 0.6831611394882202, Accuracy: 0.791015625\n",
      "Batch: 145, Loss: 0.6582002639770508, Accuracy: 0.779296875\n",
      "Batch: 146, Loss: 0.712769091129303, Accuracy: 0.7509765625\n",
      "Batch: 147, Loss: 0.7230997681617737, Accuracy: 0.75390625\n",
      "Batch: 148, Loss: 0.8000917434692383, Accuracy: 0.740234375\n",
      "Batch: 149, Loss: 0.6747975945472717, Accuracy: 0.765625\n",
      "Batch: 150, Loss: 0.6710845828056335, Accuracy: 0.7734375\n",
      "Batch: 151, Loss: 0.6066957712173462, Accuracy: 0.79296875\n",
      "Epoch 69/80\n",
      "Batch: 1, Loss: 0.9145810008049011, Accuracy: 0.705078125\n",
      "Batch: 2, Loss: 0.7918382287025452, Accuracy: 0.720703125\n",
      "Batch: 3, Loss: 0.677702784538269, Accuracy: 0.7744140625\n",
      "Batch: 4, Loss: 0.6002930998802185, Accuracy: 0.806640625\n",
      "Batch: 5, Loss: 0.6942380666732788, Accuracy: 0.779296875\n",
      "Batch: 6, Loss: 0.80448317527771, Accuracy: 0.73046875\n",
      "Batch: 7, Loss: 0.8437292575836182, Accuracy: 0.7216796875\n",
      "Batch: 8, Loss: 0.7678778171539307, Accuracy: 0.7373046875\n",
      "Batch: 9, Loss: 0.7830379009246826, Accuracy: 0.7451171875\n",
      "Batch: 10, Loss: 0.7058645486831665, Accuracy: 0.7607421875\n",
      "Batch: 11, Loss: 0.8100139498710632, Accuracy: 0.724609375\n",
      "Batch: 12, Loss: 0.7626166343688965, Accuracy: 0.7509765625\n",
      "Batch: 13, Loss: 0.5956569910049438, Accuracy: 0.796875\n",
      "Batch: 14, Loss: 0.8252731561660767, Accuracy: 0.734375\n",
      "Batch: 15, Loss: 0.6392307877540588, Accuracy: 0.787109375\n",
      "Batch: 16, Loss: 0.7243635654449463, Accuracy: 0.759765625\n",
      "Batch: 17, Loss: 0.7397515773773193, Accuracy: 0.7529296875\n",
      "Batch: 18, Loss: 0.783087968826294, Accuracy: 0.736328125\n",
      "Batch: 19, Loss: 0.7682980895042419, Accuracy: 0.7529296875\n",
      "Batch: 20, Loss: 0.669854998588562, Accuracy: 0.7802734375\n",
      "Batch: 21, Loss: 0.6876814961433411, Accuracy: 0.78125\n",
      "Batch: 22, Loss: 0.8033682107925415, Accuracy: 0.73828125\n",
      "Batch: 23, Loss: 0.7752517461776733, Accuracy: 0.74609375\n",
      "Batch: 24, Loss: 0.8474621176719666, Accuracy: 0.7421875\n",
      "Batch: 25, Loss: 0.7529507875442505, Accuracy: 0.76171875\n",
      "Batch: 26, Loss: 0.6302775144577026, Accuracy: 0.7763671875\n",
      "Batch: 27, Loss: 0.6908048391342163, Accuracy: 0.75390625\n",
      "Batch: 28, Loss: 0.8411386013031006, Accuracy: 0.734375\n",
      "Batch: 29, Loss: 0.7271411418914795, Accuracy: 0.7490234375\n",
      "Batch: 30, Loss: 0.610394299030304, Accuracy: 0.7919921875\n",
      "Batch: 31, Loss: 0.6239385604858398, Accuracy: 0.7900390625\n",
      "Batch: 32, Loss: 0.680610716342926, Accuracy: 0.7626953125\n",
      "Batch: 33, Loss: 0.7625551223754883, Accuracy: 0.751953125\n",
      "Batch: 34, Loss: 0.8080319166183472, Accuracy: 0.73046875\n",
      "Batch: 35, Loss: 0.7458646297454834, Accuracy: 0.7587890625\n",
      "Batch: 36, Loss: 0.7464487552642822, Accuracy: 0.755859375\n",
      "Batch: 37, Loss: 0.7502686381340027, Accuracy: 0.748046875\n",
      "Batch: 38, Loss: 0.7372003793716431, Accuracy: 0.7529296875\n",
      "Batch: 39, Loss: 0.7470575571060181, Accuracy: 0.75390625\n",
      "Batch: 40, Loss: 0.6853675246238708, Accuracy: 0.7744140625\n",
      "Batch: 41, Loss: 0.6584832668304443, Accuracy: 0.7822265625\n",
      "Batch: 42, Loss: 0.5652347803115845, Accuracy: 0.798828125\n",
      "Batch: 43, Loss: 0.7508784532546997, Accuracy: 0.7548828125\n",
      "Batch: 44, Loss: 0.735234260559082, Accuracy: 0.7509765625\n",
      "Batch: 45, Loss: 0.6607527136802673, Accuracy: 0.767578125\n",
      "Batch: 46, Loss: 0.6242251396179199, Accuracy: 0.791015625\n",
      "Batch: 47, Loss: 0.6316850185394287, Accuracy: 0.796875\n",
      "Batch: 48, Loss: 0.6186144351959229, Accuracy: 0.7861328125\n",
      "Batch: 49, Loss: 0.7437880635261536, Accuracy: 0.7509765625\n",
      "Batch: 50, Loss: 0.7266839146614075, Accuracy: 0.7587890625\n",
      "Batch: 51, Loss: 0.7336447238922119, Accuracy: 0.765625\n",
      "Batch: 52, Loss: 0.7134120464324951, Accuracy: 0.7724609375\n",
      "Batch: 53, Loss: 0.6472561359405518, Accuracy: 0.7841796875\n",
      "Batch: 54, Loss: 0.7117488384246826, Accuracy: 0.7666015625\n",
      "Batch: 55, Loss: 0.8087916374206543, Accuracy: 0.73828125\n",
      "Batch: 56, Loss: 0.7288687229156494, Accuracy: 0.748046875\n",
      "Batch: 57, Loss: 0.7196654081344604, Accuracy: 0.759765625\n",
      "Batch: 58, Loss: 0.8299676179885864, Accuracy: 0.736328125\n",
      "Batch: 59, Loss: 0.6607506275177002, Accuracy: 0.78515625\n",
      "Batch: 60, Loss: 0.6618094444274902, Accuracy: 0.779296875\n",
      "Batch: 61, Loss: 0.7030751705169678, Accuracy: 0.771484375\n",
      "Batch: 62, Loss: 0.6817140579223633, Accuracy: 0.7841796875\n",
      "Batch: 63, Loss: 0.7227820158004761, Accuracy: 0.7666015625\n",
      "Batch: 64, Loss: 0.712852954864502, Accuracy: 0.7587890625\n",
      "Batch: 65, Loss: 0.718768298625946, Accuracy: 0.771484375\n",
      "Batch: 66, Loss: 0.6975307464599609, Accuracy: 0.78125\n",
      "Batch: 67, Loss: 0.7885130047798157, Accuracy: 0.75\n",
      "Batch: 68, Loss: 0.8075503706932068, Accuracy: 0.74609375\n",
      "Batch: 69, Loss: 0.7361285090446472, Accuracy: 0.75390625\n",
      "Batch: 70, Loss: 0.7171218395233154, Accuracy: 0.7783203125\n",
      "Batch: 71, Loss: 0.7424799203872681, Accuracy: 0.7470703125\n",
      "Batch: 72, Loss: 0.6395087242126465, Accuracy: 0.77734375\n",
      "Batch: 73, Loss: 0.6357153654098511, Accuracy: 0.802734375\n",
      "Batch: 74, Loss: 0.6111987233161926, Accuracy: 0.796875\n",
      "Batch: 75, Loss: 0.672121524810791, Accuracy: 0.791015625\n",
      "Batch: 76, Loss: 0.70806884765625, Accuracy: 0.765625\n",
      "Batch: 77, Loss: 0.6569730639457703, Accuracy: 0.7822265625\n",
      "Batch: 78, Loss: 0.6199005842208862, Accuracy: 0.787109375\n",
      "Batch: 79, Loss: 0.5819747447967529, Accuracy: 0.80859375\n",
      "Batch: 80, Loss: 0.6809004545211792, Accuracy: 0.779296875\n",
      "Batch: 81, Loss: 0.7499802112579346, Accuracy: 0.7451171875\n",
      "Batch: 82, Loss: 0.721167266368866, Accuracy: 0.7587890625\n",
      "Batch: 83, Loss: 0.6043518781661987, Accuracy: 0.818359375\n",
      "Batch: 84, Loss: 0.6973143815994263, Accuracy: 0.7724609375\n",
      "Batch: 85, Loss: 0.6740906238555908, Accuracy: 0.78125\n",
      "Batch: 86, Loss: 0.8231925964355469, Accuracy: 0.7490234375\n",
      "Batch: 87, Loss: 0.6542983055114746, Accuracy: 0.7822265625\n",
      "Batch: 88, Loss: 0.7603566646575928, Accuracy: 0.7626953125\n",
      "Batch: 89, Loss: 0.7476406693458557, Accuracy: 0.7587890625\n",
      "Batch: 90, Loss: 0.6677452921867371, Accuracy: 0.7744140625\n",
      "Batch: 91, Loss: 0.6674772500991821, Accuracy: 0.783203125\n",
      "Batch: 92, Loss: 0.708950400352478, Accuracy: 0.7744140625\n",
      "Batch: 93, Loss: 0.673168420791626, Accuracy: 0.7587890625\n",
      "Batch: 94, Loss: 0.7511349320411682, Accuracy: 0.7490234375\n",
      "Batch: 95, Loss: 0.7321950197219849, Accuracy: 0.7490234375\n",
      "Batch: 96, Loss: 0.661655604839325, Accuracy: 0.76953125\n",
      "Batch: 97, Loss: 0.5759359002113342, Accuracy: 0.8056640625\n",
      "Batch: 98, Loss: 0.7314732074737549, Accuracy: 0.7626953125\n",
      "Batch: 99, Loss: 0.6872515678405762, Accuracy: 0.7705078125\n",
      "Batch: 100, Loss: 0.7036633491516113, Accuracy: 0.7685546875\n",
      "Batch: 101, Loss: 0.729864776134491, Accuracy: 0.76171875\n",
      "Batch: 102, Loss: 0.7064477801322937, Accuracy: 0.7744140625\n",
      "Batch: 103, Loss: 0.6824883818626404, Accuracy: 0.7783203125\n",
      "Batch: 104, Loss: 0.6576514840126038, Accuracy: 0.7705078125\n",
      "Batch: 105, Loss: 0.7015097737312317, Accuracy: 0.771484375\n",
      "Batch: 106, Loss: 0.6918681859970093, Accuracy: 0.783203125\n",
      "Batch: 107, Loss: 0.7114620804786682, Accuracy: 0.76953125\n",
      "Batch: 108, Loss: 0.7235843539237976, Accuracy: 0.7587890625\n",
      "Batch: 109, Loss: 0.8170996904373169, Accuracy: 0.7216796875\n",
      "Batch: 110, Loss: 0.6902626156806946, Accuracy: 0.7685546875\n",
      "Batch: 111, Loss: 0.7325230836868286, Accuracy: 0.767578125\n",
      "Batch: 112, Loss: 0.707951009273529, Accuracy: 0.771484375\n",
      "Batch: 113, Loss: 0.6915206909179688, Accuracy: 0.7890625\n",
      "Batch: 114, Loss: 0.7503314018249512, Accuracy: 0.7607421875\n",
      "Batch: 115, Loss: 0.7749017477035522, Accuracy: 0.7509765625\n",
      "Batch: 116, Loss: 0.744235098361969, Accuracy: 0.7568359375\n",
      "Batch: 117, Loss: 0.737153172492981, Accuracy: 0.763671875\n",
      "Batch: 118, Loss: 0.6472349166870117, Accuracy: 0.7919921875\n",
      "Batch: 119, Loss: 0.6147314310073853, Accuracy: 0.80078125\n",
      "Batch: 120, Loss: 0.7199065685272217, Accuracy: 0.74609375\n",
      "Batch: 121, Loss: 0.777363657951355, Accuracy: 0.73828125\n",
      "Batch: 122, Loss: 0.6725202798843384, Accuracy: 0.7763671875\n",
      "Batch: 123, Loss: 0.6179463267326355, Accuracy: 0.796875\n",
      "Batch: 124, Loss: 0.7376656532287598, Accuracy: 0.75\n",
      "Batch: 125, Loss: 0.7785810828208923, Accuracy: 0.7470703125\n",
      "Batch: 126, Loss: 0.6953576803207397, Accuracy: 0.7646484375\n",
      "Batch: 127, Loss: 0.615902841091156, Accuracy: 0.7890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 128, Loss: 0.7685148119926453, Accuracy: 0.7646484375\n",
      "Batch: 129, Loss: 0.6494122743606567, Accuracy: 0.78515625\n",
      "Batch: 130, Loss: 0.8006675839424133, Accuracy: 0.7412109375\n",
      "Batch: 131, Loss: 0.6843486428260803, Accuracy: 0.76953125\n",
      "Batch: 132, Loss: 0.7188173532485962, Accuracy: 0.7734375\n",
      "Batch: 133, Loss: 0.6961416006088257, Accuracy: 0.765625\n",
      "Batch: 134, Loss: 0.7153146862983704, Accuracy: 0.7529296875\n",
      "Batch: 135, Loss: 0.640830397605896, Accuracy: 0.7841796875\n",
      "Batch: 136, Loss: 0.685183584690094, Accuracy: 0.78125\n",
      "Batch: 137, Loss: 0.7060827016830444, Accuracy: 0.7607421875\n",
      "Batch: 138, Loss: 0.6233541369438171, Accuracy: 0.7890625\n",
      "Batch: 139, Loss: 0.6619030237197876, Accuracy: 0.7763671875\n",
      "Batch: 140, Loss: 0.6667186617851257, Accuracy: 0.775390625\n",
      "Batch: 141, Loss: 0.7111241817474365, Accuracy: 0.7685546875\n",
      "Batch: 142, Loss: 0.7804715633392334, Accuracy: 0.7568359375\n",
      "Batch: 143, Loss: 0.6926605701446533, Accuracy: 0.7724609375\n",
      "Batch: 144, Loss: 0.7002313137054443, Accuracy: 0.771484375\n",
      "Batch: 145, Loss: 0.6562005281448364, Accuracy: 0.78125\n",
      "Batch: 146, Loss: 0.7096590995788574, Accuracy: 0.771484375\n",
      "Batch: 147, Loss: 0.7102019786834717, Accuracy: 0.76953125\n",
      "Batch: 148, Loss: 0.761688768863678, Accuracy: 0.744140625\n",
      "Batch: 149, Loss: 0.6699126362800598, Accuracy: 0.7705078125\n",
      "Batch: 150, Loss: 0.6571922302246094, Accuracy: 0.7802734375\n",
      "Batch: 151, Loss: 0.5977391004562378, Accuracy: 0.79296875\n",
      "Epoch 70/80\n",
      "Batch: 1, Loss: 0.9102833271026611, Accuracy: 0.7021484375\n",
      "Batch: 2, Loss: 0.8102033138275146, Accuracy: 0.7119140625\n",
      "Batch: 3, Loss: 0.677504301071167, Accuracy: 0.767578125\n",
      "Batch: 4, Loss: 0.6073460578918457, Accuracy: 0.80078125\n",
      "Batch: 5, Loss: 0.6979942321777344, Accuracy: 0.7734375\n",
      "Batch: 6, Loss: 0.7175180912017822, Accuracy: 0.7587890625\n",
      "Batch: 7, Loss: 0.7093629240989685, Accuracy: 0.7529296875\n",
      "Batch: 8, Loss: 0.6498148441314697, Accuracy: 0.7978515625\n",
      "Batch: 9, Loss: 0.6788599491119385, Accuracy: 0.767578125\n",
      "Batch: 10, Loss: 0.6501302719116211, Accuracy: 0.7841796875\n",
      "Batch: 11, Loss: 0.7347284555435181, Accuracy: 0.7646484375\n",
      "Batch: 12, Loss: 0.7831515073776245, Accuracy: 0.7294921875\n",
      "Batch: 13, Loss: 0.5871262550354004, Accuracy: 0.814453125\n",
      "Batch: 14, Loss: 0.7624751329421997, Accuracy: 0.7373046875\n",
      "Batch: 15, Loss: 0.6139870882034302, Accuracy: 0.8017578125\n",
      "Batch: 16, Loss: 0.6807752847671509, Accuracy: 0.771484375\n",
      "Batch: 17, Loss: 0.6902033090591431, Accuracy: 0.7705078125\n",
      "Batch: 18, Loss: 0.7400261163711548, Accuracy: 0.76953125\n",
      "Batch: 19, Loss: 0.7043236494064331, Accuracy: 0.78515625\n",
      "Batch: 20, Loss: 0.6119663119316101, Accuracy: 0.802734375\n",
      "Batch: 21, Loss: 0.6714751720428467, Accuracy: 0.7685546875\n",
      "Batch: 22, Loss: 0.773381233215332, Accuracy: 0.7529296875\n",
      "Batch: 23, Loss: 0.7210674285888672, Accuracy: 0.7568359375\n",
      "Batch: 24, Loss: 0.7253878116607666, Accuracy: 0.7666015625\n",
      "Batch: 25, Loss: 0.6916617155075073, Accuracy: 0.7607421875\n",
      "Batch: 26, Loss: 0.6157318353652954, Accuracy: 0.7939453125\n",
      "Batch: 27, Loss: 0.6687549352645874, Accuracy: 0.7734375\n",
      "Batch: 28, Loss: 0.7451272010803223, Accuracy: 0.7373046875\n",
      "Batch: 29, Loss: 0.6447036266326904, Accuracy: 0.802734375\n",
      "Batch: 30, Loss: 0.5678019523620605, Accuracy: 0.8134765625\n",
      "Batch: 31, Loss: 0.6206449866294861, Accuracy: 0.796875\n",
      "Batch: 32, Loss: 0.628725528717041, Accuracy: 0.7919921875\n",
      "Batch: 33, Loss: 0.7320454120635986, Accuracy: 0.765625\n",
      "Batch: 34, Loss: 0.7958936095237732, Accuracy: 0.73046875\n",
      "Batch: 35, Loss: 0.7215946912765503, Accuracy: 0.7666015625\n",
      "Batch: 36, Loss: 0.7144710421562195, Accuracy: 0.76171875\n",
      "Batch: 37, Loss: 0.6787151098251343, Accuracy: 0.771484375\n",
      "Batch: 38, Loss: 0.6848799586296082, Accuracy: 0.7626953125\n",
      "Batch: 39, Loss: 0.7074355483055115, Accuracy: 0.7587890625\n",
      "Batch: 40, Loss: 0.6967710852622986, Accuracy: 0.7734375\n",
      "Batch: 41, Loss: 0.6234128475189209, Accuracy: 0.80078125\n",
      "Batch: 42, Loss: 0.5372637510299683, Accuracy: 0.8154296875\n",
      "Batch: 43, Loss: 0.7308806777000427, Accuracy: 0.7548828125\n",
      "Batch: 44, Loss: 0.7459652423858643, Accuracy: 0.7568359375\n",
      "Batch: 45, Loss: 0.6644247770309448, Accuracy: 0.767578125\n",
      "Batch: 46, Loss: 0.6406848430633545, Accuracy: 0.7841796875\n",
      "Batch: 47, Loss: 0.6486040353775024, Accuracy: 0.8017578125\n",
      "Batch: 48, Loss: 0.6090486645698547, Accuracy: 0.7861328125\n",
      "Batch: 49, Loss: 0.7285904884338379, Accuracy: 0.7734375\n",
      "Batch: 50, Loss: 0.7384691834449768, Accuracy: 0.7587890625\n",
      "Batch: 51, Loss: 0.6965579986572266, Accuracy: 0.771484375\n",
      "Batch: 52, Loss: 0.6916040182113647, Accuracy: 0.767578125\n",
      "Batch: 53, Loss: 0.6642724275588989, Accuracy: 0.77734375\n",
      "Batch: 54, Loss: 0.6779783368110657, Accuracy: 0.78125\n",
      "Batch: 55, Loss: 0.7793384790420532, Accuracy: 0.7490234375\n",
      "Batch: 56, Loss: 0.776736855506897, Accuracy: 0.7431640625\n",
      "Batch: 57, Loss: 0.7162631750106812, Accuracy: 0.7705078125\n",
      "Batch: 58, Loss: 0.7977263927459717, Accuracy: 0.751953125\n",
      "Batch: 59, Loss: 0.6506578922271729, Accuracy: 0.7880859375\n",
      "Batch: 60, Loss: 0.6502106189727783, Accuracy: 0.78515625\n",
      "Batch: 61, Loss: 0.6993163824081421, Accuracy: 0.7705078125\n",
      "Batch: 62, Loss: 0.6893496513366699, Accuracy: 0.78125\n",
      "Batch: 63, Loss: 0.6933943033218384, Accuracy: 0.775390625\n",
      "Batch: 64, Loss: 0.6832496523857117, Accuracy: 0.775390625\n",
      "Batch: 65, Loss: 0.7231159806251526, Accuracy: 0.755859375\n",
      "Batch: 66, Loss: 0.6665751934051514, Accuracy: 0.7822265625\n",
      "Batch: 67, Loss: 0.7750157117843628, Accuracy: 0.7578125\n",
      "Batch: 68, Loss: 0.8033648729324341, Accuracy: 0.74609375\n",
      "Batch: 69, Loss: 0.7465579509735107, Accuracy: 0.7490234375\n",
      "Batch: 70, Loss: 0.685401201248169, Accuracy: 0.798828125\n",
      "Batch: 71, Loss: 0.7395403385162354, Accuracy: 0.748046875\n",
      "Batch: 72, Loss: 0.6525166034698486, Accuracy: 0.7822265625\n",
      "Batch: 73, Loss: 0.6354836225509644, Accuracy: 0.7998046875\n",
      "Batch: 74, Loss: 0.6285978555679321, Accuracy: 0.8046875\n",
      "Batch: 75, Loss: 0.6267188787460327, Accuracy: 0.7939453125\n",
      "Batch: 76, Loss: 0.7034913301467896, Accuracy: 0.767578125\n",
      "Batch: 77, Loss: 0.6499465703964233, Accuracy: 0.771484375\n",
      "Batch: 78, Loss: 0.5953428745269775, Accuracy: 0.8046875\n",
      "Batch: 79, Loss: 0.577389121055603, Accuracy: 0.818359375\n",
      "Batch: 80, Loss: 0.646882176399231, Accuracy: 0.7705078125\n",
      "Batch: 81, Loss: 0.7387956380844116, Accuracy: 0.744140625\n",
      "Batch: 82, Loss: 0.7157884836196899, Accuracy: 0.7783203125\n",
      "Batch: 83, Loss: 0.6011955142021179, Accuracy: 0.80078125\n",
      "Batch: 84, Loss: 0.6778526306152344, Accuracy: 0.7744140625\n",
      "Batch: 85, Loss: 0.6451787352561951, Accuracy: 0.79296875\n",
      "Batch: 86, Loss: 0.7818471193313599, Accuracy: 0.7578125\n",
      "Batch: 87, Loss: 0.651786208152771, Accuracy: 0.7880859375\n",
      "Batch: 88, Loss: 0.7526906728744507, Accuracy: 0.763671875\n",
      "Batch: 89, Loss: 0.7206665277481079, Accuracy: 0.763671875\n",
      "Batch: 90, Loss: 0.6730400323867798, Accuracy: 0.77734375\n",
      "Batch: 91, Loss: 0.6781183481216431, Accuracy: 0.7626953125\n",
      "Batch: 92, Loss: 0.7095950841903687, Accuracy: 0.7744140625\n",
      "Batch: 93, Loss: 0.6932643055915833, Accuracy: 0.759765625\n",
      "Batch: 94, Loss: 0.7215092182159424, Accuracy: 0.7548828125\n",
      "Batch: 95, Loss: 0.7285758852958679, Accuracy: 0.7421875\n",
      "Batch: 96, Loss: 0.6571618318557739, Accuracy: 0.7802734375\n",
      "Batch: 97, Loss: 0.5761229991912842, Accuracy: 0.8037109375\n",
      "Batch: 98, Loss: 0.7045990228652954, Accuracy: 0.7626953125\n",
      "Batch: 99, Loss: 0.6826234459877014, Accuracy: 0.7744140625\n",
      "Batch: 100, Loss: 0.669816255569458, Accuracy: 0.7802734375\n",
      "Batch: 101, Loss: 0.7149066925048828, Accuracy: 0.7626953125\n",
      "Batch: 102, Loss: 0.7070571184158325, Accuracy: 0.7734375\n",
      "Batch: 103, Loss: 0.7241479158401489, Accuracy: 0.7587890625\n",
      "Batch: 104, Loss: 0.6615452766418457, Accuracy: 0.77734375\n",
      "Batch: 105, Loss: 0.7321761846542358, Accuracy: 0.744140625\n",
      "Batch: 106, Loss: 0.6424758434295654, Accuracy: 0.7900390625\n",
      "Batch: 107, Loss: 0.6943025588989258, Accuracy: 0.7783203125\n",
      "Batch: 108, Loss: 0.7152189016342163, Accuracy: 0.751953125\n",
      "Batch: 109, Loss: 0.8054299354553223, Accuracy: 0.7314453125\n",
      "Batch: 110, Loss: 0.6719166040420532, Accuracy: 0.7734375\n",
      "Batch: 111, Loss: 0.7281602025032043, Accuracy: 0.755859375\n",
      "Batch: 112, Loss: 0.7053518295288086, Accuracy: 0.7734375\n",
      "Batch: 113, Loss: 0.663688600063324, Accuracy: 0.7841796875\n",
      "Batch: 114, Loss: 0.7641266584396362, Accuracy: 0.7548828125\n",
      "Batch: 115, Loss: 0.7723076343536377, Accuracy: 0.755859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 116, Loss: 0.7029178142547607, Accuracy: 0.7744140625\n",
      "Batch: 117, Loss: 0.7510679960250854, Accuracy: 0.7490234375\n",
      "Batch: 118, Loss: 0.6353241205215454, Accuracy: 0.7958984375\n",
      "Batch: 119, Loss: 0.6175761222839355, Accuracy: 0.798828125\n",
      "Batch: 120, Loss: 0.7268052101135254, Accuracy: 0.759765625\n",
      "Batch: 121, Loss: 0.7351177930831909, Accuracy: 0.7685546875\n",
      "Batch: 122, Loss: 0.6401435136795044, Accuracy: 0.7900390625\n",
      "Batch: 123, Loss: 0.6223461627960205, Accuracy: 0.794921875\n",
      "Batch: 124, Loss: 0.6988151669502258, Accuracy: 0.7724609375\n",
      "Batch: 125, Loss: 0.7522462606430054, Accuracy: 0.7578125\n",
      "Batch: 126, Loss: 0.6939936876296997, Accuracy: 0.7724609375\n",
      "Batch: 127, Loss: 0.62368243932724, Accuracy: 0.794921875\n",
      "Batch: 128, Loss: 0.7517359256744385, Accuracy: 0.7685546875\n",
      "Batch: 129, Loss: 0.6229994297027588, Accuracy: 0.796875\n",
      "Batch: 130, Loss: 0.7819428443908691, Accuracy: 0.734375\n",
      "Batch: 131, Loss: 0.6717187166213989, Accuracy: 0.76953125\n",
      "Batch: 132, Loss: 0.6996475458145142, Accuracy: 0.7666015625\n",
      "Batch: 133, Loss: 0.676901638507843, Accuracy: 0.787109375\n",
      "Batch: 134, Loss: 0.7189241647720337, Accuracy: 0.7509765625\n",
      "Batch: 135, Loss: 0.6405275464057922, Accuracy: 0.7919921875\n",
      "Batch: 136, Loss: 0.7168025970458984, Accuracy: 0.763671875\n",
      "Batch: 137, Loss: 0.6905403137207031, Accuracy: 0.7685546875\n",
      "Batch: 138, Loss: 0.6472182273864746, Accuracy: 0.771484375\n",
      "Batch: 139, Loss: 0.6328604221343994, Accuracy: 0.7783203125\n",
      "Batch: 140, Loss: 0.6657819747924805, Accuracy: 0.7890625\n",
      "Batch: 141, Loss: 0.7184882760047913, Accuracy: 0.759765625\n",
      "Batch: 142, Loss: 0.7588735222816467, Accuracy: 0.7587890625\n",
      "Batch: 143, Loss: 0.6627365350723267, Accuracy: 0.7734375\n",
      "Batch: 144, Loss: 0.6874634027481079, Accuracy: 0.7705078125\n",
      "Batch: 145, Loss: 0.6502134203910828, Accuracy: 0.771484375\n",
      "Batch: 146, Loss: 0.6978093385696411, Accuracy: 0.7568359375\n",
      "Batch: 147, Loss: 0.6957401037216187, Accuracy: 0.78125\n",
      "Batch: 148, Loss: 0.7312899231910706, Accuracy: 0.7587890625\n",
      "Batch: 149, Loss: 0.6532719135284424, Accuracy: 0.77734375\n",
      "Batch: 150, Loss: 0.6718617081642151, Accuracy: 0.763671875\n",
      "Batch: 151, Loss: 0.5860559940338135, Accuracy: 0.8076171875\n",
      "Saved Weights at epoch 70 to file Weights_70.h5\n",
      "Epoch 71/80\n",
      "Batch: 1, Loss: 0.9097687602043152, Accuracy: 0.7177734375\n",
      "Batch: 2, Loss: 0.7640990018844604, Accuracy: 0.732421875\n",
      "Batch: 3, Loss: 0.6653732061386108, Accuracy: 0.7724609375\n",
      "Batch: 4, Loss: 0.5878411531448364, Accuracy: 0.8125\n",
      "Batch: 5, Loss: 0.6537861824035645, Accuracy: 0.7861328125\n",
      "Batch: 6, Loss: 0.7122033834457397, Accuracy: 0.75\n",
      "Batch: 7, Loss: 0.6995013356208801, Accuracy: 0.7744140625\n",
      "Batch: 8, Loss: 0.6463281512260437, Accuracy: 0.7978515625\n",
      "Batch: 9, Loss: 0.6907884478569031, Accuracy: 0.7734375\n",
      "Batch: 10, Loss: 0.6472432017326355, Accuracy: 0.7802734375\n",
      "Batch: 11, Loss: 0.7496628165245056, Accuracy: 0.74609375\n",
      "Batch: 12, Loss: 0.7553836703300476, Accuracy: 0.7568359375\n",
      "Batch: 13, Loss: 0.6117457151412964, Accuracy: 0.791015625\n",
      "Batch: 14, Loss: 0.7749149799346924, Accuracy: 0.751953125\n",
      "Batch: 15, Loss: 0.5964728593826294, Accuracy: 0.8154296875\n",
      "Batch: 16, Loss: 0.679110050201416, Accuracy: 0.779296875\n",
      "Batch: 17, Loss: 0.7057137489318848, Accuracy: 0.767578125\n",
      "Batch: 18, Loss: 0.7429060935974121, Accuracy: 0.7626953125\n",
      "Batch: 19, Loss: 0.6637846231460571, Accuracy: 0.7890625\n",
      "Batch: 20, Loss: 0.6256903409957886, Accuracy: 0.7919921875\n",
      "Batch: 21, Loss: 0.6570217609405518, Accuracy: 0.7890625\n",
      "Batch: 22, Loss: 0.7674719095230103, Accuracy: 0.7548828125\n",
      "Batch: 23, Loss: 0.7176272869110107, Accuracy: 0.75390625\n",
      "Batch: 24, Loss: 0.7250499725341797, Accuracy: 0.748046875\n",
      "Batch: 25, Loss: 0.686281681060791, Accuracy: 0.7734375\n",
      "Batch: 26, Loss: 0.6080806255340576, Accuracy: 0.80078125\n",
      "Batch: 27, Loss: 0.6757391691207886, Accuracy: 0.7607421875\n",
      "Batch: 28, Loss: 0.7257031202316284, Accuracy: 0.7451171875\n",
      "Batch: 29, Loss: 0.6630289554595947, Accuracy: 0.765625\n",
      "Batch: 30, Loss: 0.5804482102394104, Accuracy: 0.810546875\n",
      "Batch: 31, Loss: 0.5974233150482178, Accuracy: 0.8125\n",
      "Batch: 32, Loss: 0.6380907297134399, Accuracy: 0.7822265625\n",
      "Batch: 33, Loss: 0.7345712184906006, Accuracy: 0.7666015625\n",
      "Batch: 34, Loss: 0.7753939628601074, Accuracy: 0.73046875\n",
      "Batch: 35, Loss: 0.726743221282959, Accuracy: 0.7744140625\n",
      "Batch: 36, Loss: 0.7055171728134155, Accuracy: 0.7646484375\n",
      "Batch: 37, Loss: 0.6903706789016724, Accuracy: 0.771484375\n",
      "Batch: 38, Loss: 0.7097405195236206, Accuracy: 0.7578125\n",
      "Batch: 39, Loss: 0.7169630527496338, Accuracy: 0.763671875\n",
      "Batch: 40, Loss: 0.6485297083854675, Accuracy: 0.7705078125\n",
      "Batch: 41, Loss: 0.637245774269104, Accuracy: 0.7998046875\n",
      "Batch: 42, Loss: 0.5800457000732422, Accuracy: 0.8115234375\n",
      "Batch: 43, Loss: 0.7237248420715332, Accuracy: 0.767578125\n",
      "Batch: 44, Loss: 0.7151167392730713, Accuracy: 0.755859375\n",
      "Batch: 45, Loss: 0.6504507064819336, Accuracy: 0.7646484375\n",
      "Batch: 46, Loss: 0.6208399534225464, Accuracy: 0.7939453125\n",
      "Batch: 47, Loss: 0.5974973440170288, Accuracy: 0.802734375\n",
      "Batch: 48, Loss: 0.6131682395935059, Accuracy: 0.787109375\n",
      "Batch: 49, Loss: 0.716171145439148, Accuracy: 0.7578125\n",
      "Batch: 50, Loss: 0.7079805135726929, Accuracy: 0.7705078125\n",
      "Batch: 51, Loss: 0.6917479038238525, Accuracy: 0.77734375\n",
      "Batch: 52, Loss: 0.6998072862625122, Accuracy: 0.7724609375\n",
      "Batch: 53, Loss: 0.633224606513977, Accuracy: 0.7724609375\n",
      "Batch: 54, Loss: 0.6818019151687622, Accuracy: 0.7568359375\n",
      "Batch: 55, Loss: 0.7774895429611206, Accuracy: 0.7490234375\n",
      "Batch: 56, Loss: 0.7479079961776733, Accuracy: 0.7548828125\n",
      "Batch: 57, Loss: 0.7095696926116943, Accuracy: 0.755859375\n",
      "Batch: 58, Loss: 0.7888422012329102, Accuracy: 0.7490234375\n",
      "Batch: 59, Loss: 0.6435483694076538, Accuracy: 0.79296875\n",
      "Batch: 60, Loss: 0.645213782787323, Accuracy: 0.787109375\n",
      "Batch: 61, Loss: 0.7313745021820068, Accuracy: 0.7685546875\n",
      "Batch: 62, Loss: 0.6641878485679626, Accuracy: 0.7822265625\n",
      "Batch: 63, Loss: 0.6830399632453918, Accuracy: 0.78125\n",
      "Batch: 64, Loss: 0.7073699831962585, Accuracy: 0.7685546875\n",
      "Batch: 65, Loss: 0.7119936943054199, Accuracy: 0.775390625\n",
      "Batch: 66, Loss: 0.6715283989906311, Accuracy: 0.7978515625\n",
      "Batch: 67, Loss: 0.7684952020645142, Accuracy: 0.748046875\n",
      "Batch: 68, Loss: 0.7852085828781128, Accuracy: 0.7392578125\n",
      "Batch: 69, Loss: 0.701734721660614, Accuracy: 0.755859375\n",
      "Batch: 70, Loss: 0.7027240991592407, Accuracy: 0.779296875\n",
      "Batch: 71, Loss: 0.7480207681655884, Accuracy: 0.7421875\n",
      "Batch: 72, Loss: 0.6161724328994751, Accuracy: 0.794921875\n",
      "Batch: 73, Loss: 0.6283859610557556, Accuracy: 0.7998046875\n",
      "Batch: 74, Loss: 0.6174527406692505, Accuracy: 0.796875\n",
      "Batch: 75, Loss: 0.622503936290741, Accuracy: 0.7958984375\n",
      "Batch: 76, Loss: 0.7200055122375488, Accuracy: 0.7587890625\n",
      "Batch: 77, Loss: 0.6319248676300049, Accuracy: 0.783203125\n",
      "Batch: 78, Loss: 0.6112485527992249, Accuracy: 0.8046875\n",
      "Batch: 79, Loss: 0.5658917427062988, Accuracy: 0.814453125\n",
      "Batch: 80, Loss: 0.6481928825378418, Accuracy: 0.7841796875\n",
      "Batch: 81, Loss: 0.7706299424171448, Accuracy: 0.75\n",
      "Batch: 82, Loss: 0.7032798528671265, Accuracy: 0.771484375\n",
      "Batch: 83, Loss: 0.5953347682952881, Accuracy: 0.8125\n",
      "Batch: 84, Loss: 0.6625994443893433, Accuracy: 0.78125\n",
      "Batch: 85, Loss: 0.6503217220306396, Accuracy: 0.7880859375\n",
      "Batch: 86, Loss: 0.8071686029434204, Accuracy: 0.744140625\n",
      "Batch: 87, Loss: 0.625126838684082, Accuracy: 0.7890625\n",
      "Batch: 88, Loss: 0.7330825328826904, Accuracy: 0.767578125\n",
      "Batch: 89, Loss: 0.7307299375534058, Accuracy: 0.76171875\n",
      "Batch: 90, Loss: 0.6534245014190674, Accuracy: 0.7880859375\n",
      "Batch: 91, Loss: 0.6592467427253723, Accuracy: 0.7890625\n",
      "Batch: 92, Loss: 0.6859354972839355, Accuracy: 0.78125\n",
      "Batch: 93, Loss: 0.6497608423233032, Accuracy: 0.787109375\n",
      "Batch: 94, Loss: 0.6874394416809082, Accuracy: 0.7568359375\n",
      "Batch: 95, Loss: 0.72605299949646, Accuracy: 0.763671875\n",
      "Batch: 96, Loss: 0.6617614030838013, Accuracy: 0.7890625\n",
      "Batch: 97, Loss: 0.5877522230148315, Accuracy: 0.7958984375\n",
      "Batch: 98, Loss: 0.6843478083610535, Accuracy: 0.7783203125\n",
      "Batch: 99, Loss: 0.6622802019119263, Accuracy: 0.771484375\n",
      "Batch: 100, Loss: 0.7219642996788025, Accuracy: 0.763671875\n",
      "Batch: 101, Loss: 0.7115051746368408, Accuracy: 0.7734375\n",
      "Batch: 102, Loss: 0.6937057971954346, Accuracy: 0.7734375\n",
      "Batch: 103, Loss: 0.6958922147750854, Accuracy: 0.775390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 104, Loss: 0.6607038974761963, Accuracy: 0.76953125\n",
      "Batch: 105, Loss: 0.7260980010032654, Accuracy: 0.7490234375\n",
      "Batch: 106, Loss: 0.6329860687255859, Accuracy: 0.7900390625\n",
      "Batch: 107, Loss: 0.6829231977462769, Accuracy: 0.7822265625\n",
      "Batch: 108, Loss: 0.6996545791625977, Accuracy: 0.751953125\n",
      "Batch: 109, Loss: 0.8150203227996826, Accuracy: 0.7353515625\n",
      "Batch: 110, Loss: 0.6118972897529602, Accuracy: 0.8017578125\n",
      "Batch: 111, Loss: 0.6970251202583313, Accuracy: 0.7734375\n",
      "Batch: 112, Loss: 0.6837810277938843, Accuracy: 0.7919921875\n",
      "Batch: 113, Loss: 0.6583574414253235, Accuracy: 0.779296875\n",
      "Batch: 114, Loss: 0.7561321258544922, Accuracy: 0.75\n",
      "Batch: 115, Loss: 0.7597610950469971, Accuracy: 0.7509765625\n",
      "Batch: 116, Loss: 0.7018503546714783, Accuracy: 0.771484375\n",
      "Batch: 117, Loss: 0.723837673664093, Accuracy: 0.755859375\n",
      "Batch: 118, Loss: 0.6104604601860046, Accuracy: 0.8076171875\n",
      "Batch: 119, Loss: 0.5732547044754028, Accuracy: 0.8056640625\n",
      "Batch: 120, Loss: 0.6915054321289062, Accuracy: 0.7587890625\n",
      "Batch: 121, Loss: 0.7364504933357239, Accuracy: 0.7490234375\n",
      "Batch: 122, Loss: 0.6259241104125977, Accuracy: 0.7900390625\n",
      "Batch: 123, Loss: 0.6145166158676147, Accuracy: 0.80078125\n",
      "Batch: 124, Loss: 0.6533589959144592, Accuracy: 0.78515625\n",
      "Batch: 125, Loss: 0.7435836791992188, Accuracy: 0.7578125\n",
      "Batch: 126, Loss: 0.6866886615753174, Accuracy: 0.76953125\n",
      "Batch: 127, Loss: 0.5963088870048523, Accuracy: 0.8271484375\n",
      "Batch: 128, Loss: 0.7837457656860352, Accuracy: 0.7509765625\n",
      "Batch: 129, Loss: 0.6160974502563477, Accuracy: 0.8056640625\n",
      "Batch: 130, Loss: 0.771742045879364, Accuracy: 0.7412109375\n",
      "Batch: 131, Loss: 0.6687097549438477, Accuracy: 0.7783203125\n",
      "Batch: 132, Loss: 0.6883673667907715, Accuracy: 0.77734375\n",
      "Batch: 133, Loss: 0.6280621886253357, Accuracy: 0.81640625\n",
      "Batch: 134, Loss: 0.7202646136283875, Accuracy: 0.7451171875\n",
      "Batch: 135, Loss: 0.6378545165061951, Accuracy: 0.791015625\n",
      "Batch: 136, Loss: 0.7000933289527893, Accuracy: 0.7744140625\n",
      "Batch: 137, Loss: 0.6866390705108643, Accuracy: 0.7578125\n",
      "Batch: 138, Loss: 0.6134688854217529, Accuracy: 0.79296875\n",
      "Batch: 139, Loss: 0.6510212421417236, Accuracy: 0.77734375\n",
      "Batch: 140, Loss: 0.6968833208084106, Accuracy: 0.7626953125\n",
      "Batch: 141, Loss: 0.7480032444000244, Accuracy: 0.751953125\n",
      "Batch: 142, Loss: 0.7544113397598267, Accuracy: 0.7626953125\n",
      "Batch: 143, Loss: 0.6831444501876831, Accuracy: 0.76171875\n",
      "Batch: 144, Loss: 0.6967217922210693, Accuracy: 0.77734375\n",
      "Batch: 145, Loss: 0.638323187828064, Accuracy: 0.7724609375\n",
      "Batch: 146, Loss: 0.6905438899993896, Accuracy: 0.7724609375\n",
      "Batch: 147, Loss: 0.7027289271354675, Accuracy: 0.767578125\n",
      "Batch: 148, Loss: 0.7583075761795044, Accuracy: 0.744140625\n",
      "Batch: 149, Loss: 0.6385349035263062, Accuracy: 0.78515625\n",
      "Batch: 150, Loss: 0.6455803513526917, Accuracy: 0.78125\n",
      "Batch: 151, Loss: 0.5905473828315735, Accuracy: 0.796875\n",
      "Epoch 72/80\n",
      "Batch: 1, Loss: 0.8872814774513245, Accuracy: 0.7255859375\n",
      "Batch: 2, Loss: 0.7479826807975769, Accuracy: 0.7314453125\n",
      "Batch: 3, Loss: 0.6660320162773132, Accuracy: 0.7939453125\n",
      "Batch: 4, Loss: 0.5943643450737, Accuracy: 0.8076171875\n",
      "Batch: 5, Loss: 0.6649500131607056, Accuracy: 0.779296875\n",
      "Batch: 6, Loss: 0.7033870816230774, Accuracy: 0.76171875\n",
      "Batch: 7, Loss: 0.6934720873832703, Accuracy: 0.76171875\n",
      "Batch: 8, Loss: 0.6323555707931519, Accuracy: 0.787109375\n",
      "Batch: 9, Loss: 0.6472879648208618, Accuracy: 0.79296875\n",
      "Batch: 10, Loss: 0.6609572172164917, Accuracy: 0.7802734375\n",
      "Batch: 11, Loss: 0.7873475551605225, Accuracy: 0.728515625\n",
      "Batch: 12, Loss: 0.7457101345062256, Accuracy: 0.748046875\n",
      "Batch: 13, Loss: 0.5908170938491821, Accuracy: 0.8125\n",
      "Batch: 14, Loss: 0.7715044021606445, Accuracy: 0.7421875\n",
      "Batch: 15, Loss: 0.6018050909042358, Accuracy: 0.802734375\n",
      "Batch: 16, Loss: 0.688683032989502, Accuracy: 0.7841796875\n",
      "Batch: 17, Loss: 0.7046527862548828, Accuracy: 0.7626953125\n",
      "Batch: 18, Loss: 0.7321206331253052, Accuracy: 0.7646484375\n",
      "Batch: 19, Loss: 0.6744354963302612, Accuracy: 0.771484375\n",
      "Batch: 20, Loss: 0.5988028645515442, Accuracy: 0.794921875\n",
      "Batch: 21, Loss: 0.6487284302711487, Accuracy: 0.787109375\n",
      "Batch: 22, Loss: 0.7408312559127808, Accuracy: 0.763671875\n",
      "Batch: 23, Loss: 0.7222049832344055, Accuracy: 0.7626953125\n",
      "Batch: 24, Loss: 0.7092152833938599, Accuracy: 0.763671875\n",
      "Batch: 25, Loss: 0.6718471050262451, Accuracy: 0.7685546875\n",
      "Batch: 26, Loss: 0.6002906560897827, Accuracy: 0.796875\n",
      "Batch: 27, Loss: 0.6695642471313477, Accuracy: 0.751953125\n",
      "Batch: 28, Loss: 0.7186576128005981, Accuracy: 0.76171875\n",
      "Batch: 29, Loss: 0.6403630375862122, Accuracy: 0.783203125\n",
      "Batch: 30, Loss: 0.574864387512207, Accuracy: 0.8095703125\n",
      "Batch: 31, Loss: 0.6165575385093689, Accuracy: 0.8046875\n",
      "Batch: 32, Loss: 0.6514261960983276, Accuracy: 0.787109375\n",
      "Batch: 33, Loss: 0.736034631729126, Accuracy: 0.763671875\n",
      "Batch: 34, Loss: 0.7945535778999329, Accuracy: 0.7294921875\n",
      "Batch: 35, Loss: 0.6945139765739441, Accuracy: 0.7841796875\n",
      "Batch: 36, Loss: 0.700812578201294, Accuracy: 0.775390625\n",
      "Batch: 37, Loss: 0.6922508478164673, Accuracy: 0.7705078125\n",
      "Batch: 38, Loss: 0.6957419514656067, Accuracy: 0.763671875\n",
      "Batch: 39, Loss: 0.7239218950271606, Accuracy: 0.7548828125\n",
      "Batch: 40, Loss: 0.6695882081985474, Accuracy: 0.7734375\n",
      "Batch: 41, Loss: 0.6085048913955688, Accuracy: 0.80859375\n",
      "Batch: 42, Loss: 0.5155591368675232, Accuracy: 0.826171875\n",
      "Batch: 43, Loss: 0.7182892560958862, Accuracy: 0.7548828125\n",
      "Batch: 44, Loss: 0.7238413691520691, Accuracy: 0.736328125\n",
      "Batch: 45, Loss: 0.6497447490692139, Accuracy: 0.7841796875\n",
      "Batch: 46, Loss: 0.6194392442703247, Accuracy: 0.791015625\n",
      "Batch: 47, Loss: 0.627561092376709, Accuracy: 0.7890625\n",
      "Batch: 48, Loss: 0.6209843158721924, Accuracy: 0.787109375\n",
      "Batch: 49, Loss: 0.7097509503364563, Accuracy: 0.767578125\n",
      "Batch: 50, Loss: 0.6923026442527771, Accuracy: 0.7783203125\n",
      "Batch: 51, Loss: 0.719881534576416, Accuracy: 0.759765625\n",
      "Batch: 52, Loss: 0.7035651206970215, Accuracy: 0.7724609375\n",
      "Batch: 53, Loss: 0.6392377614974976, Accuracy: 0.765625\n",
      "Batch: 54, Loss: 0.6604260206222534, Accuracy: 0.787109375\n",
      "Batch: 55, Loss: 0.7652422189712524, Accuracy: 0.7314453125\n",
      "Batch: 56, Loss: 0.7601728439331055, Accuracy: 0.75390625\n",
      "Batch: 57, Loss: 0.7425585985183716, Accuracy: 0.765625\n",
      "Batch: 58, Loss: 0.8144192695617676, Accuracy: 0.740234375\n",
      "Batch: 59, Loss: 0.6544266939163208, Accuracy: 0.7861328125\n",
      "Batch: 60, Loss: 0.6315920948982239, Accuracy: 0.8037109375\n",
      "Batch: 61, Loss: 0.7308018207550049, Accuracy: 0.7568359375\n",
      "Batch: 62, Loss: 0.6507308483123779, Accuracy: 0.7880859375\n",
      "Batch: 63, Loss: 0.7083403468132019, Accuracy: 0.7724609375\n",
      "Batch: 64, Loss: 0.7201316952705383, Accuracy: 0.759765625\n",
      "Batch: 65, Loss: 0.7079721689224243, Accuracy: 0.7666015625\n",
      "Batch: 66, Loss: 0.655553936958313, Accuracy: 0.7958984375\n",
      "Batch: 67, Loss: 0.7524240016937256, Accuracy: 0.759765625\n",
      "Batch: 68, Loss: 0.7837826013565063, Accuracy: 0.751953125\n",
      "Batch: 69, Loss: 0.7118926048278809, Accuracy: 0.7607421875\n",
      "Batch: 70, Loss: 0.6741954684257507, Accuracy: 0.78515625\n",
      "Batch: 71, Loss: 0.7052894234657288, Accuracy: 0.7587890625\n",
      "Batch: 72, Loss: 0.6122727394104004, Accuracy: 0.791015625\n",
      "Batch: 73, Loss: 0.6215648651123047, Accuracy: 0.8056640625\n",
      "Batch: 74, Loss: 0.6035141944885254, Accuracy: 0.8154296875\n",
      "Batch: 75, Loss: 0.6253963708877563, Accuracy: 0.7939453125\n",
      "Batch: 76, Loss: 0.708385705947876, Accuracy: 0.7607421875\n",
      "Batch: 77, Loss: 0.6294525861740112, Accuracy: 0.791015625\n",
      "Batch: 78, Loss: 0.5856176018714905, Accuracy: 0.810546875\n",
      "Batch: 79, Loss: 0.5496194958686829, Accuracy: 0.8251953125\n",
      "Batch: 80, Loss: 0.6379531621932983, Accuracy: 0.7841796875\n",
      "Batch: 81, Loss: 0.7504842877388, Accuracy: 0.7412109375\n",
      "Batch: 82, Loss: 0.691806435585022, Accuracy: 0.775390625\n",
      "Batch: 83, Loss: 0.6007531881332397, Accuracy: 0.8076171875\n",
      "Batch: 84, Loss: 0.6577741503715515, Accuracy: 0.7861328125\n",
      "Batch: 85, Loss: 0.6390087604522705, Accuracy: 0.779296875\n",
      "Batch: 86, Loss: 0.7698537111282349, Accuracy: 0.748046875\n",
      "Batch: 87, Loss: 0.6384634971618652, Accuracy: 0.791015625\n",
      "Batch: 88, Loss: 0.754899799823761, Accuracy: 0.7548828125\n",
      "Batch: 89, Loss: 0.7230910062789917, Accuracy: 0.775390625\n",
      "Batch: 90, Loss: 0.6252197623252869, Accuracy: 0.7939453125\n",
      "Batch: 91, Loss: 0.6606276035308838, Accuracy: 0.7880859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 92, Loss: 0.6700303554534912, Accuracy: 0.7841796875\n",
      "Batch: 93, Loss: 0.6708826422691345, Accuracy: 0.7890625\n",
      "Batch: 94, Loss: 0.690691351890564, Accuracy: 0.7578125\n",
      "Batch: 95, Loss: 0.7048401832580566, Accuracy: 0.763671875\n",
      "Batch: 96, Loss: 0.6715489625930786, Accuracy: 0.76953125\n",
      "Batch: 97, Loss: 0.5603817701339722, Accuracy: 0.8193359375\n",
      "Batch: 98, Loss: 0.7088226079940796, Accuracy: 0.76171875\n",
      "Batch: 99, Loss: 0.6726239919662476, Accuracy: 0.7724609375\n",
      "Batch: 100, Loss: 0.6900674700737, Accuracy: 0.77734375\n",
      "Batch: 101, Loss: 0.733795702457428, Accuracy: 0.763671875\n",
      "Batch: 102, Loss: 0.7124764323234558, Accuracy: 0.765625\n",
      "Batch: 103, Loss: 0.6752902865409851, Accuracy: 0.7841796875\n",
      "Batch: 104, Loss: 0.6605198383331299, Accuracy: 0.765625\n",
      "Batch: 105, Loss: 0.7349517345428467, Accuracy: 0.748046875\n",
      "Batch: 106, Loss: 0.6305868625640869, Accuracy: 0.787109375\n",
      "Batch: 107, Loss: 0.7051525712013245, Accuracy: 0.7841796875\n",
      "Batch: 108, Loss: 0.6677370667457581, Accuracy: 0.775390625\n",
      "Batch: 109, Loss: 0.8189689517021179, Accuracy: 0.7314453125\n",
      "Batch: 110, Loss: 0.633746862411499, Accuracy: 0.7900390625\n",
      "Batch: 111, Loss: 0.6925755739212036, Accuracy: 0.7763671875\n",
      "Batch: 112, Loss: 0.676491916179657, Accuracy: 0.7880859375\n",
      "Batch: 113, Loss: 0.6786550283432007, Accuracy: 0.783203125\n",
      "Batch: 114, Loss: 0.7497079968452454, Accuracy: 0.767578125\n",
      "Batch: 115, Loss: 0.7965819239616394, Accuracy: 0.7490234375\n",
      "Batch: 116, Loss: 0.7223533987998962, Accuracy: 0.7509765625\n",
      "Batch: 117, Loss: 0.7455763816833496, Accuracy: 0.7490234375\n",
      "Batch: 118, Loss: 0.6107457876205444, Accuracy: 0.8056640625\n",
      "Batch: 119, Loss: 0.5846766233444214, Accuracy: 0.8125\n",
      "Batch: 120, Loss: 0.681572675704956, Accuracy: 0.7666015625\n",
      "Batch: 121, Loss: 0.7259513139724731, Accuracy: 0.7666015625\n",
      "Batch: 122, Loss: 0.6353660821914673, Accuracy: 0.798828125\n",
      "Batch: 123, Loss: 0.6094049215316772, Accuracy: 0.7919921875\n",
      "Batch: 124, Loss: 0.6702472567558289, Accuracy: 0.7861328125\n",
      "Batch: 125, Loss: 0.7658913135528564, Accuracy: 0.7548828125\n",
      "Batch: 126, Loss: 0.7163393497467041, Accuracy: 0.7578125\n",
      "Batch: 127, Loss: 0.616085410118103, Accuracy: 0.8056640625\n",
      "Batch: 128, Loss: 0.7529796361923218, Accuracy: 0.7783203125\n",
      "Batch: 129, Loss: 0.6362500190734863, Accuracy: 0.7802734375\n",
      "Batch: 130, Loss: 0.7904779314994812, Accuracy: 0.7392578125\n",
      "Batch: 131, Loss: 0.6730599999427795, Accuracy: 0.77734375\n",
      "Batch: 132, Loss: 0.7240484952926636, Accuracy: 0.7578125\n",
      "Batch: 133, Loss: 0.6163198947906494, Accuracy: 0.8046875\n",
      "Batch: 134, Loss: 0.6753232479095459, Accuracy: 0.765625\n",
      "Batch: 135, Loss: 0.6382440328598022, Accuracy: 0.7958984375\n",
      "Batch: 136, Loss: 0.6726245880126953, Accuracy: 0.7802734375\n",
      "Batch: 137, Loss: 0.6995717287063599, Accuracy: 0.7578125\n",
      "Batch: 138, Loss: 0.6229726076126099, Accuracy: 0.802734375\n",
      "Batch: 139, Loss: 0.6213538646697998, Accuracy: 0.78515625\n",
      "Batch: 140, Loss: 0.6923233270645142, Accuracy: 0.78125\n",
      "Batch: 141, Loss: 0.7130154967308044, Accuracy: 0.7626953125\n",
      "Batch: 142, Loss: 0.7484177947044373, Accuracy: 0.767578125\n",
      "Batch: 143, Loss: 0.6738169193267822, Accuracy: 0.779296875\n",
      "Batch: 144, Loss: 0.6890136003494263, Accuracy: 0.77734375\n",
      "Batch: 145, Loss: 0.6319581270217896, Accuracy: 0.7744140625\n",
      "Batch: 146, Loss: 0.6726951599121094, Accuracy: 0.7705078125\n",
      "Batch: 147, Loss: 0.6914981007575989, Accuracy: 0.7685546875\n",
      "Batch: 148, Loss: 0.7409930229187012, Accuracy: 0.7529296875\n",
      "Batch: 149, Loss: 0.6415274143218994, Accuracy: 0.78125\n",
      "Batch: 150, Loss: 0.6448763012886047, Accuracy: 0.771484375\n",
      "Batch: 151, Loss: 0.5631290674209595, Accuracy: 0.8115234375\n",
      "Epoch 73/80\n",
      "Batch: 1, Loss: 0.9358625411987305, Accuracy: 0.71484375\n",
      "Batch: 2, Loss: 0.7612786293029785, Accuracy: 0.744140625\n",
      "Batch: 3, Loss: 0.6424587965011597, Accuracy: 0.7900390625\n",
      "Batch: 4, Loss: 0.5886795520782471, Accuracy: 0.8037109375\n",
      "Batch: 5, Loss: 0.6805036067962646, Accuracy: 0.7841796875\n",
      "Batch: 6, Loss: 0.7205759882926941, Accuracy: 0.76171875\n",
      "Batch: 7, Loss: 0.6908853054046631, Accuracy: 0.7763671875\n",
      "Batch: 8, Loss: 0.6510719656944275, Accuracy: 0.7841796875\n",
      "Batch: 9, Loss: 0.6650823354721069, Accuracy: 0.7744140625\n",
      "Batch: 10, Loss: 0.6444510221481323, Accuracy: 0.783203125\n",
      "Batch: 11, Loss: 0.7761813998222351, Accuracy: 0.73046875\n",
      "Batch: 12, Loss: 0.748702883720398, Accuracy: 0.7666015625\n",
      "Batch: 13, Loss: 0.5565282106399536, Accuracy: 0.8017578125\n",
      "Batch: 14, Loss: 0.7370541095733643, Accuracy: 0.7509765625\n",
      "Batch: 15, Loss: 0.5876327753067017, Accuracy: 0.8154296875\n",
      "Batch: 16, Loss: 0.6740642786026001, Accuracy: 0.7900390625\n",
      "Batch: 17, Loss: 0.6946637630462646, Accuracy: 0.77734375\n",
      "Batch: 18, Loss: 0.7185499668121338, Accuracy: 0.767578125\n",
      "Batch: 19, Loss: 0.7011544704437256, Accuracy: 0.763671875\n",
      "Batch: 20, Loss: 0.5973021984100342, Accuracy: 0.8046875\n",
      "Batch: 21, Loss: 0.6139956712722778, Accuracy: 0.7939453125\n",
      "Batch: 22, Loss: 0.759208083152771, Accuracy: 0.75390625\n",
      "Batch: 23, Loss: 0.7005059123039246, Accuracy: 0.7626953125\n",
      "Batch: 24, Loss: 0.6950441002845764, Accuracy: 0.7646484375\n",
      "Batch: 25, Loss: 0.6578395366668701, Accuracy: 0.779296875\n",
      "Batch: 26, Loss: 0.6054446697235107, Accuracy: 0.802734375\n",
      "Batch: 27, Loss: 0.6715804934501648, Accuracy: 0.7890625\n",
      "Batch: 28, Loss: 0.704170823097229, Accuracy: 0.7548828125\n",
      "Batch: 29, Loss: 0.6448326110839844, Accuracy: 0.77734375\n",
      "Batch: 30, Loss: 0.6188192367553711, Accuracy: 0.7978515625\n",
      "Batch: 31, Loss: 0.6244075894355774, Accuracy: 0.806640625\n",
      "Batch: 32, Loss: 0.6086587905883789, Accuracy: 0.802734375\n",
      "Batch: 33, Loss: 0.7153204679489136, Accuracy: 0.7578125\n",
      "Batch: 34, Loss: 0.7843974828720093, Accuracy: 0.740234375\n",
      "Batch: 35, Loss: 0.6957865953445435, Accuracy: 0.7666015625\n",
      "Batch: 36, Loss: 0.726293683052063, Accuracy: 0.7646484375\n",
      "Batch: 37, Loss: 0.7092600464820862, Accuracy: 0.759765625\n",
      "Batch: 38, Loss: 0.6854634284973145, Accuracy: 0.7744140625\n",
      "Batch: 39, Loss: 0.7066931128501892, Accuracy: 0.7666015625\n",
      "Batch: 40, Loss: 0.6609944105148315, Accuracy: 0.79296875\n",
      "Batch: 41, Loss: 0.6070244312286377, Accuracy: 0.79296875\n",
      "Batch: 42, Loss: 0.5398709774017334, Accuracy: 0.8037109375\n",
      "Batch: 43, Loss: 0.7196230888366699, Accuracy: 0.771484375\n",
      "Batch: 44, Loss: 0.7325317859649658, Accuracy: 0.7529296875\n",
      "Batch: 45, Loss: 0.6489155292510986, Accuracy: 0.7822265625\n",
      "Batch: 46, Loss: 0.6237620115280151, Accuracy: 0.7890625\n",
      "Batch: 47, Loss: 0.609745979309082, Accuracy: 0.8134765625\n",
      "Batch: 48, Loss: 0.6370845437049866, Accuracy: 0.779296875\n",
      "Batch: 49, Loss: 0.6906174421310425, Accuracy: 0.7744140625\n",
      "Batch: 50, Loss: 0.6951273679733276, Accuracy: 0.765625\n",
      "Batch: 51, Loss: 0.6751230955123901, Accuracy: 0.7724609375\n",
      "Batch: 52, Loss: 0.6654787063598633, Accuracy: 0.7626953125\n",
      "Batch: 53, Loss: 0.596141517162323, Accuracy: 0.79296875\n",
      "Batch: 54, Loss: 0.6604868173599243, Accuracy: 0.7666015625\n",
      "Batch: 55, Loss: 0.7433205842971802, Accuracy: 0.74609375\n",
      "Batch: 56, Loss: 0.7652623653411865, Accuracy: 0.74609375\n",
      "Batch: 57, Loss: 0.7180026173591614, Accuracy: 0.7666015625\n",
      "Batch: 58, Loss: 0.7928305268287659, Accuracy: 0.7451171875\n",
      "Batch: 59, Loss: 0.6464599370956421, Accuracy: 0.7744140625\n",
      "Batch: 60, Loss: 0.653547465801239, Accuracy: 0.7841796875\n",
      "Batch: 61, Loss: 0.7083861231803894, Accuracy: 0.7568359375\n",
      "Batch: 62, Loss: 0.6517500877380371, Accuracy: 0.7958984375\n",
      "Batch: 63, Loss: 0.7037556171417236, Accuracy: 0.76171875\n",
      "Batch: 64, Loss: 0.6809360384941101, Accuracy: 0.783203125\n",
      "Batch: 65, Loss: 0.7098673582077026, Accuracy: 0.765625\n",
      "Batch: 66, Loss: 0.6623467206954956, Accuracy: 0.7939453125\n",
      "Batch: 67, Loss: 0.7283722162246704, Accuracy: 0.763671875\n",
      "Batch: 68, Loss: 0.7942209243774414, Accuracy: 0.765625\n",
      "Batch: 69, Loss: 0.7355145215988159, Accuracy: 0.7509765625\n",
      "Batch: 70, Loss: 0.6775678396224976, Accuracy: 0.78125\n",
      "Batch: 71, Loss: 0.7223784923553467, Accuracy: 0.75\n",
      "Batch: 72, Loss: 0.6458531618118286, Accuracy: 0.779296875\n",
      "Batch: 73, Loss: 0.645599365234375, Accuracy: 0.7958984375\n",
      "Batch: 74, Loss: 0.5914173126220703, Accuracy: 0.8125\n",
      "Batch: 75, Loss: 0.6546933650970459, Accuracy: 0.7958984375\n",
      "Batch: 76, Loss: 0.70228111743927, Accuracy: 0.7666015625\n",
      "Batch: 77, Loss: 0.6395766735076904, Accuracy: 0.7890625\n",
      "Batch: 78, Loss: 0.5975296497344971, Accuracy: 0.802734375\n",
      "Batch: 79, Loss: 0.5733471512794495, Accuracy: 0.8134765625\n",
      "Batch: 80, Loss: 0.6385729908943176, Accuracy: 0.787109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 81, Loss: 0.7019449472427368, Accuracy: 0.74609375\n",
      "Batch: 82, Loss: 0.6947164535522461, Accuracy: 0.7744140625\n",
      "Batch: 83, Loss: 0.5766732096672058, Accuracy: 0.826171875\n",
      "Batch: 84, Loss: 0.6381161212921143, Accuracy: 0.7978515625\n",
      "Batch: 85, Loss: 0.6564186811447144, Accuracy: 0.7880859375\n",
      "Batch: 86, Loss: 0.7813245058059692, Accuracy: 0.7578125\n",
      "Batch: 87, Loss: 0.6490334272384644, Accuracy: 0.7919921875\n",
      "Batch: 88, Loss: 0.7244104146957397, Accuracy: 0.7548828125\n",
      "Batch: 89, Loss: 0.7219458222389221, Accuracy: 0.7587890625\n",
      "Batch: 90, Loss: 0.6448149681091309, Accuracy: 0.78515625\n",
      "Batch: 91, Loss: 0.661456823348999, Accuracy: 0.7744140625\n",
      "Batch: 92, Loss: 0.6719009280204773, Accuracy: 0.78515625\n",
      "Batch: 93, Loss: 0.6649823784828186, Accuracy: 0.76953125\n",
      "Batch: 94, Loss: 0.6925109028816223, Accuracy: 0.76953125\n",
      "Batch: 95, Loss: 0.7062122821807861, Accuracy: 0.755859375\n",
      "Batch: 96, Loss: 0.662621796131134, Accuracy: 0.7734375\n",
      "Batch: 97, Loss: 0.5580580234527588, Accuracy: 0.80859375\n",
      "Batch: 98, Loss: 0.6779362559318542, Accuracy: 0.78125\n",
      "Batch: 99, Loss: 0.6803191900253296, Accuracy: 0.7705078125\n",
      "Batch: 100, Loss: 0.7240743637084961, Accuracy: 0.7587890625\n",
      "Batch: 101, Loss: 0.7243592739105225, Accuracy: 0.763671875\n",
      "Batch: 102, Loss: 0.7097820043563843, Accuracy: 0.7607421875\n",
      "Batch: 103, Loss: 0.6921924352645874, Accuracy: 0.7744140625\n",
      "Batch: 104, Loss: 0.6556503772735596, Accuracy: 0.76953125\n",
      "Batch: 105, Loss: 0.7218306064605713, Accuracy: 0.771484375\n",
      "Batch: 106, Loss: 0.6491833925247192, Accuracy: 0.779296875\n",
      "Batch: 107, Loss: 0.6857823133468628, Accuracy: 0.787109375\n",
      "Batch: 108, Loss: 0.7013217806816101, Accuracy: 0.7763671875\n",
      "Batch: 109, Loss: 0.7994678020477295, Accuracy: 0.740234375\n",
      "Batch: 110, Loss: 0.6485098600387573, Accuracy: 0.7783203125\n",
      "Batch: 111, Loss: 0.7233483791351318, Accuracy: 0.75390625\n",
      "Batch: 112, Loss: 0.6982437372207642, Accuracy: 0.7666015625\n",
      "Batch: 113, Loss: 0.649810791015625, Accuracy: 0.7861328125\n",
      "Batch: 114, Loss: 0.7413840293884277, Accuracy: 0.759765625\n",
      "Batch: 115, Loss: 0.7673218250274658, Accuracy: 0.7548828125\n",
      "Batch: 116, Loss: 0.7043823003768921, Accuracy: 0.7685546875\n",
      "Batch: 117, Loss: 0.7131996154785156, Accuracy: 0.771484375\n",
      "Batch: 118, Loss: 0.5831027030944824, Accuracy: 0.806640625\n",
      "Batch: 119, Loss: 0.5884348750114441, Accuracy: 0.8154296875\n",
      "Batch: 120, Loss: 0.6830273270606995, Accuracy: 0.7626953125\n",
      "Batch: 121, Loss: 0.7591315507888794, Accuracy: 0.7421875\n",
      "Batch: 122, Loss: 0.6443959474563599, Accuracy: 0.7861328125\n",
      "Batch: 123, Loss: 0.6124538779258728, Accuracy: 0.798828125\n",
      "Batch: 124, Loss: 0.6651350259780884, Accuracy: 0.78515625\n",
      "Batch: 125, Loss: 0.6965280771255493, Accuracy: 0.765625\n",
      "Batch: 126, Loss: 0.6774755716323853, Accuracy: 0.765625\n",
      "Batch: 127, Loss: 0.6245025992393494, Accuracy: 0.8076171875\n",
      "Batch: 128, Loss: 0.7478246688842773, Accuracy: 0.7626953125\n",
      "Batch: 129, Loss: 0.6296674609184265, Accuracy: 0.7919921875\n",
      "Batch: 130, Loss: 0.7835984230041504, Accuracy: 0.7421875\n",
      "Batch: 131, Loss: 0.6905831098556519, Accuracy: 0.7607421875\n",
      "Batch: 132, Loss: 0.6908888816833496, Accuracy: 0.7783203125\n",
      "Batch: 133, Loss: 0.6508737802505493, Accuracy: 0.7802734375\n",
      "Batch: 134, Loss: 0.7093648910522461, Accuracy: 0.76171875\n",
      "Batch: 135, Loss: 0.6319375038146973, Accuracy: 0.7900390625\n",
      "Batch: 136, Loss: 0.7056101560592651, Accuracy: 0.7607421875\n",
      "Batch: 137, Loss: 0.6734239459037781, Accuracy: 0.775390625\n",
      "Batch: 138, Loss: 0.6155720949172974, Accuracy: 0.779296875\n",
      "Batch: 139, Loss: 0.618100106716156, Accuracy: 0.7822265625\n",
      "Batch: 140, Loss: 0.6871665716171265, Accuracy: 0.76953125\n",
      "Batch: 141, Loss: 0.7293538451194763, Accuracy: 0.751953125\n",
      "Batch: 142, Loss: 0.741981029510498, Accuracy: 0.76171875\n",
      "Batch: 143, Loss: 0.637758731842041, Accuracy: 0.791015625\n",
      "Batch: 144, Loss: 0.6545618772506714, Accuracy: 0.7841796875\n",
      "Batch: 145, Loss: 0.6350528597831726, Accuracy: 0.765625\n",
      "Batch: 146, Loss: 0.7004345655441284, Accuracy: 0.7646484375\n",
      "Batch: 147, Loss: 0.6828480958938599, Accuracy: 0.7666015625\n",
      "Batch: 148, Loss: 0.7406941056251526, Accuracy: 0.759765625\n",
      "Batch: 149, Loss: 0.6331071257591248, Accuracy: 0.7802734375\n",
      "Batch: 150, Loss: 0.6533877849578857, Accuracy: 0.7802734375\n",
      "Batch: 151, Loss: 0.5785090923309326, Accuracy: 0.8115234375\n",
      "Epoch 74/80\n",
      "Batch: 1, Loss: 0.8975384831428528, Accuracy: 0.7177734375\n",
      "Batch: 2, Loss: 0.7517392635345459, Accuracy: 0.732421875\n",
      "Batch: 3, Loss: 0.6681034564971924, Accuracy: 0.7568359375\n",
      "Batch: 4, Loss: 0.5983597636222839, Accuracy: 0.8046875\n",
      "Batch: 5, Loss: 0.6623433828353882, Accuracy: 0.7802734375\n",
      "Batch: 6, Loss: 0.6980310678482056, Accuracy: 0.76171875\n",
      "Batch: 7, Loss: 0.6906103491783142, Accuracy: 0.7685546875\n",
      "Batch: 8, Loss: 0.6312386989593506, Accuracy: 0.7939453125\n",
      "Batch: 9, Loss: 0.6699652671813965, Accuracy: 0.77734375\n",
      "Batch: 10, Loss: 0.6393925547599792, Accuracy: 0.7890625\n",
      "Batch: 11, Loss: 0.7637171149253845, Accuracy: 0.75\n",
      "Batch: 12, Loss: 0.7086212635040283, Accuracy: 0.7587890625\n",
      "Batch: 13, Loss: 0.5788818597793579, Accuracy: 0.8154296875\n",
      "Batch: 14, Loss: 0.737663984298706, Accuracy: 0.744140625\n",
      "Batch: 15, Loss: 0.6116863489151001, Accuracy: 0.8056640625\n",
      "Batch: 16, Loss: 0.6882902383804321, Accuracy: 0.783203125\n",
      "Batch: 17, Loss: 0.7214218378067017, Accuracy: 0.7568359375\n",
      "Batch: 18, Loss: 0.7503789663314819, Accuracy: 0.748046875\n",
      "Batch: 19, Loss: 0.7137178182601929, Accuracy: 0.7578125\n",
      "Batch: 20, Loss: 0.578682541847229, Accuracy: 0.814453125\n",
      "Batch: 21, Loss: 0.6337946653366089, Accuracy: 0.783203125\n",
      "Batch: 22, Loss: 0.7485686540603638, Accuracy: 0.759765625\n",
      "Batch: 23, Loss: 0.6957496404647827, Accuracy: 0.7626953125\n",
      "Batch: 24, Loss: 0.6990785598754883, Accuracy: 0.7626953125\n",
      "Batch: 25, Loss: 0.6830669641494751, Accuracy: 0.7744140625\n",
      "Batch: 26, Loss: 0.5749251842498779, Accuracy: 0.8037109375\n",
      "Batch: 27, Loss: 0.6829692721366882, Accuracy: 0.7587890625\n",
      "Batch: 28, Loss: 0.6960142254829407, Accuracy: 0.76171875\n",
      "Batch: 29, Loss: 0.6459835767745972, Accuracy: 0.7763671875\n",
      "Batch: 30, Loss: 0.5730384588241577, Accuracy: 0.8095703125\n",
      "Batch: 31, Loss: 0.5829317569732666, Accuracy: 0.8076171875\n",
      "Batch: 32, Loss: 0.6075055003166199, Accuracy: 0.7890625\n",
      "Batch: 33, Loss: 0.7086941003799438, Accuracy: 0.7705078125\n",
      "Batch: 34, Loss: 0.7455568313598633, Accuracy: 0.75390625\n",
      "Batch: 35, Loss: 0.6993488073348999, Accuracy: 0.78515625\n",
      "Batch: 36, Loss: 0.7052396535873413, Accuracy: 0.7841796875\n",
      "Batch: 37, Loss: 0.6603295207023621, Accuracy: 0.787109375\n",
      "Batch: 38, Loss: 0.6789126396179199, Accuracy: 0.767578125\n",
      "Batch: 39, Loss: 0.7119414806365967, Accuracy: 0.7685546875\n",
      "Batch: 40, Loss: 0.6891511678695679, Accuracy: 0.7734375\n",
      "Batch: 41, Loss: 0.6130513548851013, Accuracy: 0.794921875\n",
      "Batch: 42, Loss: 0.5030362606048584, Accuracy: 0.8310546875\n",
      "Batch: 43, Loss: 0.6967144012451172, Accuracy: 0.775390625\n",
      "Batch: 44, Loss: 0.6818152666091919, Accuracy: 0.767578125\n",
      "Batch: 45, Loss: 0.626030445098877, Accuracy: 0.798828125\n",
      "Batch: 46, Loss: 0.5866895914077759, Accuracy: 0.8154296875\n",
      "Batch: 47, Loss: 0.6111199855804443, Accuracy: 0.814453125\n",
      "Batch: 48, Loss: 0.6046218276023865, Accuracy: 0.78515625\n",
      "Batch: 49, Loss: 0.6645638942718506, Accuracy: 0.771484375\n",
      "Batch: 50, Loss: 0.7061405181884766, Accuracy: 0.7763671875\n",
      "Batch: 51, Loss: 0.6910468935966492, Accuracy: 0.771484375\n",
      "Batch: 52, Loss: 0.6761555671691895, Accuracy: 0.76953125\n",
      "Batch: 53, Loss: 0.6500169038772583, Accuracy: 0.7783203125\n",
      "Batch: 54, Loss: 0.6712003350257874, Accuracy: 0.7724609375\n",
      "Batch: 55, Loss: 0.7929773330688477, Accuracy: 0.7392578125\n",
      "Batch: 56, Loss: 0.75286865234375, Accuracy: 0.751953125\n",
      "Batch: 57, Loss: 0.7075362801551819, Accuracy: 0.7802734375\n",
      "Batch: 58, Loss: 0.7774858474731445, Accuracy: 0.7578125\n",
      "Batch: 59, Loss: 0.6139549612998962, Accuracy: 0.7958984375\n",
      "Batch: 60, Loss: 0.6250534057617188, Accuracy: 0.7861328125\n",
      "Batch: 61, Loss: 0.6833765506744385, Accuracy: 0.7763671875\n",
      "Batch: 62, Loss: 0.6651143431663513, Accuracy: 0.7822265625\n",
      "Batch: 63, Loss: 0.7000048756599426, Accuracy: 0.78125\n",
      "Batch: 64, Loss: 0.701388418674469, Accuracy: 0.7685546875\n",
      "Batch: 65, Loss: 0.6957268118858337, Accuracy: 0.7646484375\n",
      "Batch: 66, Loss: 0.6748325824737549, Accuracy: 0.7861328125\n",
      "Batch: 67, Loss: 0.7535635232925415, Accuracy: 0.75390625\n",
      "Batch: 68, Loss: 0.7533902525901794, Accuracy: 0.7578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 69, Loss: 0.6946702599525452, Accuracy: 0.7705078125\n",
      "Batch: 70, Loss: 0.6743495464324951, Accuracy: 0.7705078125\n",
      "Batch: 71, Loss: 0.7333358526229858, Accuracy: 0.7568359375\n",
      "Batch: 72, Loss: 0.5998212695121765, Accuracy: 0.794921875\n",
      "Batch: 73, Loss: 0.6344794034957886, Accuracy: 0.796875\n",
      "Batch: 74, Loss: 0.5963858366012573, Accuracy: 0.80078125\n",
      "Batch: 75, Loss: 0.6663759350776672, Accuracy: 0.7890625\n",
      "Batch: 76, Loss: 0.7034131288528442, Accuracy: 0.765625\n",
      "Batch: 77, Loss: 0.6516415476799011, Accuracy: 0.78125\n",
      "Batch: 78, Loss: 0.5648442506790161, Accuracy: 0.8134765625\n",
      "Batch: 79, Loss: 0.5605254173278809, Accuracy: 0.8251953125\n",
      "Batch: 80, Loss: 0.6442722082138062, Accuracy: 0.7763671875\n",
      "Batch: 81, Loss: 0.7399441599845886, Accuracy: 0.73828125\n",
      "Batch: 82, Loss: 0.7015491724014282, Accuracy: 0.7607421875\n",
      "Batch: 83, Loss: 0.5807463526725769, Accuracy: 0.8095703125\n",
      "Batch: 84, Loss: 0.6586782336235046, Accuracy: 0.7734375\n",
      "Batch: 85, Loss: 0.6604602932929993, Accuracy: 0.7822265625\n",
      "Batch: 86, Loss: 0.7899174690246582, Accuracy: 0.7548828125\n",
      "Batch: 87, Loss: 0.6492268443107605, Accuracy: 0.7880859375\n",
      "Batch: 88, Loss: 0.7254284620285034, Accuracy: 0.7587890625\n",
      "Batch: 89, Loss: 0.6827300190925598, Accuracy: 0.7841796875\n",
      "Batch: 90, Loss: 0.6373981237411499, Accuracy: 0.7978515625\n",
      "Batch: 91, Loss: 0.6505900025367737, Accuracy: 0.77734375\n",
      "Batch: 92, Loss: 0.6841378211975098, Accuracy: 0.7763671875\n",
      "Batch: 93, Loss: 0.6380256414413452, Accuracy: 0.7900390625\n",
      "Batch: 94, Loss: 0.6902261972427368, Accuracy: 0.771484375\n",
      "Batch: 95, Loss: 0.6948537826538086, Accuracy: 0.759765625\n",
      "Batch: 96, Loss: 0.6311501860618591, Accuracy: 0.7822265625\n",
      "Batch: 97, Loss: 0.5548216104507446, Accuracy: 0.8203125\n",
      "Batch: 98, Loss: 0.6994791030883789, Accuracy: 0.7587890625\n",
      "Batch: 99, Loss: 0.6646085977554321, Accuracy: 0.7822265625\n",
      "Batch: 100, Loss: 0.7144837379455566, Accuracy: 0.765625\n",
      "Batch: 101, Loss: 0.7244422435760498, Accuracy: 0.7578125\n",
      "Batch: 102, Loss: 0.7066595554351807, Accuracy: 0.7666015625\n",
      "Batch: 103, Loss: 0.6813936233520508, Accuracy: 0.7783203125\n",
      "Batch: 104, Loss: 0.6172318458557129, Accuracy: 0.7939453125\n",
      "Batch: 105, Loss: 0.7164149880409241, Accuracy: 0.7568359375\n",
      "Batch: 106, Loss: 0.6452231407165527, Accuracy: 0.7783203125\n",
      "Batch: 107, Loss: 0.6621009111404419, Accuracy: 0.787109375\n",
      "Batch: 108, Loss: 0.6874776482582092, Accuracy: 0.76953125\n",
      "Batch: 109, Loss: 0.8206216096878052, Accuracy: 0.736328125\n",
      "Batch: 110, Loss: 0.6478489637374878, Accuracy: 0.7900390625\n",
      "Batch: 111, Loss: 0.6905651092529297, Accuracy: 0.767578125\n",
      "Batch: 112, Loss: 0.6692047119140625, Accuracy: 0.7861328125\n",
      "Batch: 113, Loss: 0.674714982509613, Accuracy: 0.78125\n",
      "Batch: 114, Loss: 0.7250401973724365, Accuracy: 0.76171875\n",
      "Batch: 115, Loss: 0.7644138932228088, Accuracy: 0.7548828125\n",
      "Batch: 116, Loss: 0.7142535448074341, Accuracy: 0.765625\n",
      "Batch: 117, Loss: 0.7506561875343323, Accuracy: 0.7568359375\n",
      "Batch: 118, Loss: 0.6078477501869202, Accuracy: 0.80078125\n",
      "Batch: 119, Loss: 0.5967064499855042, Accuracy: 0.8095703125\n",
      "Batch: 120, Loss: 0.6951967477798462, Accuracy: 0.7685546875\n",
      "Batch: 121, Loss: 0.7540704607963562, Accuracy: 0.7431640625\n",
      "Batch: 122, Loss: 0.6273808479309082, Accuracy: 0.787109375\n",
      "Batch: 123, Loss: 0.6321969032287598, Accuracy: 0.7890625\n",
      "Batch: 124, Loss: 0.6781782507896423, Accuracy: 0.775390625\n",
      "Batch: 125, Loss: 0.7393652200698853, Accuracy: 0.7646484375\n",
      "Batch: 126, Loss: 0.724254846572876, Accuracy: 0.7568359375\n",
      "Batch: 127, Loss: 0.6318869590759277, Accuracy: 0.806640625\n",
      "Batch: 128, Loss: 0.7260543704032898, Accuracy: 0.767578125\n",
      "Batch: 129, Loss: 0.6392321586608887, Accuracy: 0.79296875\n",
      "Batch: 130, Loss: 0.7449669241905212, Accuracy: 0.767578125\n",
      "Batch: 131, Loss: 0.6858077645301819, Accuracy: 0.76953125\n",
      "Batch: 132, Loss: 0.6791747212409973, Accuracy: 0.767578125\n",
      "Batch: 133, Loss: 0.6957281827926636, Accuracy: 0.7626953125\n",
      "Batch: 134, Loss: 0.6682501435279846, Accuracy: 0.7666015625\n",
      "Batch: 135, Loss: 0.6182474493980408, Accuracy: 0.8037109375\n",
      "Batch: 136, Loss: 0.6824301481246948, Accuracy: 0.787109375\n",
      "Batch: 137, Loss: 0.6716743111610413, Accuracy: 0.7685546875\n",
      "Batch: 138, Loss: 0.6053263545036316, Accuracy: 0.798828125\n",
      "Batch: 139, Loss: 0.6519887447357178, Accuracy: 0.775390625\n",
      "Batch: 140, Loss: 0.6488425135612488, Accuracy: 0.783203125\n",
      "Batch: 141, Loss: 0.7028911113739014, Accuracy: 0.76953125\n",
      "Batch: 142, Loss: 0.7304461002349854, Accuracy: 0.7626953125\n",
      "Batch: 143, Loss: 0.6691247820854187, Accuracy: 0.77734375\n",
      "Batch: 144, Loss: 0.685420036315918, Accuracy: 0.7880859375\n",
      "Batch: 145, Loss: 0.6344072818756104, Accuracy: 0.7802734375\n",
      "Batch: 146, Loss: 0.681032657623291, Accuracy: 0.7705078125\n",
      "Batch: 147, Loss: 0.6837091445922852, Accuracy: 0.78125\n",
      "Batch: 148, Loss: 0.713840663433075, Accuracy: 0.7705078125\n",
      "Batch: 149, Loss: 0.661514401435852, Accuracy: 0.7783203125\n",
      "Batch: 150, Loss: 0.6600359678268433, Accuracy: 0.77734375\n",
      "Batch: 151, Loss: 0.5872015953063965, Accuracy: 0.7978515625\n",
      "Epoch 75/80\n",
      "Batch: 1, Loss: 0.8632516264915466, Accuracy: 0.71875\n",
      "Batch: 2, Loss: 0.7791293859481812, Accuracy: 0.72265625\n",
      "Batch: 3, Loss: 0.6540180444717407, Accuracy: 0.7841796875\n",
      "Batch: 4, Loss: 0.5773194432258606, Accuracy: 0.8154296875\n",
      "Batch: 5, Loss: 0.6461184620857239, Accuracy: 0.7978515625\n",
      "Batch: 6, Loss: 0.6644296646118164, Accuracy: 0.7880859375\n",
      "Batch: 7, Loss: 0.7064635753631592, Accuracy: 0.7705078125\n",
      "Batch: 8, Loss: 0.6563194990158081, Accuracy: 0.7705078125\n",
      "Batch: 9, Loss: 0.6649590134620667, Accuracy: 0.779296875\n",
      "Batch: 10, Loss: 0.6690514087677002, Accuracy: 0.7822265625\n",
      "Batch: 11, Loss: 0.745481550693512, Accuracy: 0.744140625\n",
      "Batch: 12, Loss: 0.7390470504760742, Accuracy: 0.7646484375\n",
      "Batch: 13, Loss: 0.5857245326042175, Accuracy: 0.8046875\n",
      "Batch: 14, Loss: 0.7703944444656372, Accuracy: 0.740234375\n",
      "Batch: 15, Loss: 0.592810332775116, Accuracy: 0.810546875\n",
      "Batch: 16, Loss: 0.6669147610664368, Accuracy: 0.783203125\n",
      "Batch: 17, Loss: 0.6997191905975342, Accuracy: 0.7666015625\n",
      "Batch: 18, Loss: 0.7270598411560059, Accuracy: 0.7587890625\n",
      "Batch: 19, Loss: 0.7049878835678101, Accuracy: 0.7685546875\n",
      "Batch: 20, Loss: 0.5758395195007324, Accuracy: 0.806640625\n",
      "Batch: 21, Loss: 0.6303750276565552, Accuracy: 0.791015625\n",
      "Batch: 22, Loss: 0.7395212650299072, Accuracy: 0.7626953125\n",
      "Batch: 23, Loss: 0.693646252155304, Accuracy: 0.7607421875\n",
      "Batch: 24, Loss: 0.6991499066352844, Accuracy: 0.751953125\n",
      "Batch: 25, Loss: 0.6762273907661438, Accuracy: 0.7724609375\n",
      "Batch: 26, Loss: 0.5781712532043457, Accuracy: 0.8125\n",
      "Batch: 27, Loss: 0.6517078876495361, Accuracy: 0.7802734375\n",
      "Batch: 28, Loss: 0.6820882558822632, Accuracy: 0.7705078125\n",
      "Batch: 29, Loss: 0.6593971848487854, Accuracy: 0.771484375\n",
      "Batch: 30, Loss: 0.5837916731834412, Accuracy: 0.810546875\n",
      "Batch: 31, Loss: 0.6110130548477173, Accuracy: 0.810546875\n",
      "Batch: 32, Loss: 0.6266871094703674, Accuracy: 0.78125\n",
      "Batch: 33, Loss: 0.7368413209915161, Accuracy: 0.7529296875\n",
      "Batch: 34, Loss: 0.7657727003097534, Accuracy: 0.73046875\n",
      "Batch: 35, Loss: 0.6926360130310059, Accuracy: 0.7705078125\n",
      "Batch: 36, Loss: 0.7055078744888306, Accuracy: 0.7685546875\n",
      "Batch: 37, Loss: 0.6957244277000427, Accuracy: 0.775390625\n",
      "Batch: 38, Loss: 0.6847821474075317, Accuracy: 0.763671875\n",
      "Batch: 39, Loss: 0.7061210870742798, Accuracy: 0.7666015625\n",
      "Batch: 40, Loss: 0.6619871854782104, Accuracy: 0.7783203125\n",
      "Batch: 41, Loss: 0.6088783740997314, Accuracy: 0.810546875\n",
      "Batch: 42, Loss: 0.5197594165802002, Accuracy: 0.830078125\n",
      "Batch: 43, Loss: 0.6902387142181396, Accuracy: 0.7724609375\n",
      "Batch: 44, Loss: 0.7275516986846924, Accuracy: 0.748046875\n",
      "Batch: 45, Loss: 0.658765435218811, Accuracy: 0.775390625\n",
      "Batch: 46, Loss: 0.6087801456451416, Accuracy: 0.8037109375\n",
      "Batch: 47, Loss: 0.5986277461051941, Accuracy: 0.8203125\n",
      "Batch: 48, Loss: 0.5918503999710083, Accuracy: 0.802734375\n",
      "Batch: 49, Loss: 0.7308892011642456, Accuracy: 0.7548828125\n",
      "Batch: 50, Loss: 0.6758086085319519, Accuracy: 0.779296875\n",
      "Batch: 51, Loss: 0.7018252611160278, Accuracy: 0.7685546875\n",
      "Batch: 52, Loss: 0.6759041547775269, Accuracy: 0.7861328125\n",
      "Batch: 53, Loss: 0.6372636556625366, Accuracy: 0.7880859375\n",
      "Batch: 54, Loss: 0.6843734383583069, Accuracy: 0.7783203125\n",
      "Batch: 55, Loss: 0.7838709950447083, Accuracy: 0.7353515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 56, Loss: 0.7451032996177673, Accuracy: 0.7529296875\n",
      "Batch: 57, Loss: 0.7148288488388062, Accuracy: 0.763671875\n",
      "Batch: 58, Loss: 0.79645836353302, Accuracy: 0.7265625\n",
      "Batch: 59, Loss: 0.6399675607681274, Accuracy: 0.7958984375\n",
      "Batch: 60, Loss: 0.6381860971450806, Accuracy: 0.7998046875\n",
      "Batch: 61, Loss: 0.6910956501960754, Accuracy: 0.775390625\n",
      "Batch: 62, Loss: 0.6600749492645264, Accuracy: 0.7900390625\n",
      "Batch: 63, Loss: 0.7207024693489075, Accuracy: 0.7646484375\n",
      "Batch: 64, Loss: 0.6815274357795715, Accuracy: 0.771484375\n",
      "Batch: 65, Loss: 0.654403805732727, Accuracy: 0.7900390625\n",
      "Batch: 66, Loss: 0.6248573660850525, Accuracy: 0.7939453125\n",
      "Batch: 67, Loss: 0.7435827255249023, Accuracy: 0.7451171875\n",
      "Batch: 68, Loss: 0.7878122925758362, Accuracy: 0.7412109375\n",
      "Batch: 69, Loss: 0.7042657136917114, Accuracy: 0.763671875\n",
      "Batch: 70, Loss: 0.6884610056877136, Accuracy: 0.78515625\n",
      "Batch: 71, Loss: 0.7204527258872986, Accuracy: 0.751953125\n",
      "Batch: 72, Loss: 0.6214612722396851, Accuracy: 0.7919921875\n",
      "Batch: 73, Loss: 0.627447247505188, Accuracy: 0.7900390625\n",
      "Batch: 74, Loss: 0.5891492366790771, Accuracy: 0.8134765625\n",
      "Batch: 75, Loss: 0.6189133524894714, Accuracy: 0.8095703125\n",
      "Batch: 76, Loss: 0.7029990553855896, Accuracy: 0.7734375\n",
      "Batch: 77, Loss: 0.6396708488464355, Accuracy: 0.7880859375\n",
      "Batch: 78, Loss: 0.5747382044792175, Accuracy: 0.80078125\n",
      "Batch: 79, Loss: 0.5651432275772095, Accuracy: 0.8037109375\n",
      "Batch: 80, Loss: 0.6476850509643555, Accuracy: 0.771484375\n",
      "Batch: 81, Loss: 0.731458306312561, Accuracy: 0.751953125\n",
      "Batch: 82, Loss: 0.7121423482894897, Accuracy: 0.7685546875\n",
      "Batch: 83, Loss: 0.596107542514801, Accuracy: 0.826171875\n",
      "Batch: 84, Loss: 0.6598992943763733, Accuracy: 0.7841796875\n",
      "Batch: 85, Loss: 0.6614540815353394, Accuracy: 0.7861328125\n",
      "Batch: 86, Loss: 0.792321503162384, Accuracy: 0.740234375\n",
      "Batch: 87, Loss: 0.6142145395278931, Accuracy: 0.7978515625\n",
      "Batch: 88, Loss: 0.7111684679985046, Accuracy: 0.775390625\n",
      "Batch: 89, Loss: 0.7500645518302917, Accuracy: 0.763671875\n",
      "Batch: 90, Loss: 0.6406162977218628, Accuracy: 0.79296875\n",
      "Batch: 91, Loss: 0.6110607385635376, Accuracy: 0.8046875\n",
      "Batch: 92, Loss: 0.6929298043251038, Accuracy: 0.7666015625\n",
      "Batch: 93, Loss: 0.6536412835121155, Accuracy: 0.7763671875\n",
      "Batch: 94, Loss: 0.6957534551620483, Accuracy: 0.771484375\n",
      "Batch: 95, Loss: 0.7038962244987488, Accuracy: 0.75\n",
      "Batch: 96, Loss: 0.6325885057449341, Accuracy: 0.7939453125\n",
      "Batch: 97, Loss: 0.5361019968986511, Accuracy: 0.8193359375\n",
      "Batch: 98, Loss: 0.6773954629898071, Accuracy: 0.7724609375\n",
      "Batch: 99, Loss: 0.6844423413276672, Accuracy: 0.7744140625\n",
      "Batch: 100, Loss: 0.682714581489563, Accuracy: 0.767578125\n",
      "Batch: 101, Loss: 0.733570396900177, Accuracy: 0.765625\n",
      "Batch: 102, Loss: 0.7061669826507568, Accuracy: 0.763671875\n",
      "Batch: 103, Loss: 0.6770800948143005, Accuracy: 0.7685546875\n",
      "Batch: 104, Loss: 0.6285313963890076, Accuracy: 0.791015625\n",
      "Batch: 105, Loss: 0.7081161737442017, Accuracy: 0.7724609375\n",
      "Batch: 106, Loss: 0.6264417767524719, Accuracy: 0.802734375\n",
      "Batch: 107, Loss: 0.6544977426528931, Accuracy: 0.7900390625\n",
      "Batch: 108, Loss: 0.6830916404724121, Accuracy: 0.7685546875\n",
      "Batch: 109, Loss: 0.7946339249610901, Accuracy: 0.736328125\n",
      "Batch: 110, Loss: 0.6336053013801575, Accuracy: 0.7939453125\n",
      "Batch: 111, Loss: 0.6591119766235352, Accuracy: 0.7763671875\n",
      "Batch: 112, Loss: 0.695709764957428, Accuracy: 0.783203125\n",
      "Batch: 113, Loss: 0.7111469507217407, Accuracy: 0.76171875\n",
      "Batch: 114, Loss: 0.7171007394790649, Accuracy: 0.767578125\n",
      "Batch: 115, Loss: 0.7641599178314209, Accuracy: 0.76953125\n",
      "Batch: 116, Loss: 0.7196747660636902, Accuracy: 0.755859375\n",
      "Batch: 117, Loss: 0.704005241394043, Accuracy: 0.77734375\n",
      "Batch: 118, Loss: 0.5873020887374878, Accuracy: 0.7998046875\n",
      "Batch: 119, Loss: 0.5639187097549438, Accuracy: 0.8017578125\n",
      "Batch: 120, Loss: 0.6815813779830933, Accuracy: 0.7880859375\n",
      "Batch: 121, Loss: 0.7187469601631165, Accuracy: 0.765625\n",
      "Batch: 122, Loss: 0.6334948539733887, Accuracy: 0.7890625\n",
      "Batch: 123, Loss: 0.6044058799743652, Accuracy: 0.798828125\n",
      "Batch: 124, Loss: 0.6637442111968994, Accuracy: 0.7841796875\n",
      "Batch: 125, Loss: 0.7563216686248779, Accuracy: 0.751953125\n",
      "Batch: 126, Loss: 0.7070625424385071, Accuracy: 0.765625\n",
      "Batch: 127, Loss: 0.5984750986099243, Accuracy: 0.806640625\n",
      "Batch: 128, Loss: 0.6968034505844116, Accuracy: 0.7841796875\n",
      "Batch: 129, Loss: 0.6373276710510254, Accuracy: 0.7763671875\n",
      "Batch: 130, Loss: 0.7580428123474121, Accuracy: 0.7548828125\n",
      "Batch: 131, Loss: 0.684074878692627, Accuracy: 0.7685546875\n",
      "Batch: 132, Loss: 0.7087849378585815, Accuracy: 0.7744140625\n",
      "Batch: 133, Loss: 0.6743735074996948, Accuracy: 0.775390625\n",
      "Batch: 134, Loss: 0.6717877388000488, Accuracy: 0.76171875\n",
      "Batch: 135, Loss: 0.6346368789672852, Accuracy: 0.791015625\n",
      "Batch: 136, Loss: 0.700654149055481, Accuracy: 0.78125\n",
      "Batch: 137, Loss: 0.6890727281570435, Accuracy: 0.765625\n",
      "Batch: 138, Loss: 0.6086325645446777, Accuracy: 0.775390625\n",
      "Batch: 139, Loss: 0.6413059234619141, Accuracy: 0.7802734375\n",
      "Batch: 140, Loss: 0.6734569072723389, Accuracy: 0.783203125\n",
      "Batch: 141, Loss: 0.729495644569397, Accuracy: 0.744140625\n",
      "Batch: 142, Loss: 0.7381185293197632, Accuracy: 0.744140625\n",
      "Batch: 143, Loss: 0.6345239281654358, Accuracy: 0.7763671875\n",
      "Batch: 144, Loss: 0.6902796626091003, Accuracy: 0.7666015625\n",
      "Batch: 145, Loss: 0.6545178890228271, Accuracy: 0.7685546875\n",
      "Batch: 146, Loss: 0.6875623464584351, Accuracy: 0.7685546875\n",
      "Batch: 147, Loss: 0.6733176708221436, Accuracy: 0.7763671875\n",
      "Batch: 148, Loss: 0.7290804982185364, Accuracy: 0.755859375\n",
      "Batch: 149, Loss: 0.6140096783638, Accuracy: 0.7900390625\n",
      "Batch: 150, Loss: 0.6508376598358154, Accuracy: 0.7783203125\n",
      "Batch: 151, Loss: 0.5800775289535522, Accuracy: 0.8017578125\n",
      "Epoch 76/80\n",
      "Batch: 1, Loss: 0.8773282170295715, Accuracy: 0.7080078125\n",
      "Batch: 2, Loss: 0.7063354253768921, Accuracy: 0.748046875\n",
      "Batch: 3, Loss: 0.6384068727493286, Accuracy: 0.7890625\n",
      "Batch: 4, Loss: 0.5757262110710144, Accuracy: 0.818359375\n",
      "Batch: 5, Loss: 0.652381420135498, Accuracy: 0.7958984375\n",
      "Batch: 6, Loss: 0.7109537720680237, Accuracy: 0.7490234375\n",
      "Batch: 7, Loss: 0.700592041015625, Accuracy: 0.7578125\n",
      "Batch: 8, Loss: 0.665685772895813, Accuracy: 0.7744140625\n",
      "Batch: 9, Loss: 0.6607533693313599, Accuracy: 0.7841796875\n",
      "Batch: 10, Loss: 0.6330723762512207, Accuracy: 0.775390625\n",
      "Batch: 11, Loss: 0.7406915426254272, Accuracy: 0.751953125\n",
      "Batch: 12, Loss: 0.7024165391921997, Accuracy: 0.771484375\n",
      "Batch: 13, Loss: 0.5635164976119995, Accuracy: 0.826171875\n",
      "Batch: 14, Loss: 0.7240499258041382, Accuracy: 0.7626953125\n",
      "Batch: 15, Loss: 0.5961105227470398, Accuracy: 0.8046875\n",
      "Batch: 16, Loss: 0.6482930779457092, Accuracy: 0.7802734375\n",
      "Batch: 17, Loss: 0.6813571453094482, Accuracy: 0.775390625\n",
      "Batch: 18, Loss: 0.7406473159790039, Accuracy: 0.759765625\n",
      "Batch: 19, Loss: 0.69200599193573, Accuracy: 0.7890625\n",
      "Batch: 20, Loss: 0.6030555367469788, Accuracy: 0.8056640625\n",
      "Batch: 21, Loss: 0.6363233327865601, Accuracy: 0.787109375\n",
      "Batch: 22, Loss: 0.74825519323349, Accuracy: 0.7578125\n",
      "Batch: 23, Loss: 0.6707614660263062, Accuracy: 0.771484375\n",
      "Batch: 24, Loss: 0.6955676674842834, Accuracy: 0.7548828125\n",
      "Batch: 25, Loss: 0.6521350741386414, Accuracy: 0.771484375\n",
      "Batch: 26, Loss: 0.5838655233383179, Accuracy: 0.810546875\n",
      "Batch: 27, Loss: 0.6619396209716797, Accuracy: 0.7763671875\n",
      "Batch: 28, Loss: 0.714012622833252, Accuracy: 0.7470703125\n",
      "Batch: 29, Loss: 0.660392165184021, Accuracy: 0.7763671875\n",
      "Batch: 30, Loss: 0.5883820652961731, Accuracy: 0.8125\n",
      "Batch: 31, Loss: 0.5968437790870667, Accuracy: 0.8046875\n",
      "Batch: 32, Loss: 0.615649402141571, Accuracy: 0.796875\n",
      "Batch: 33, Loss: 0.7270450592041016, Accuracy: 0.765625\n",
      "Batch: 34, Loss: 0.7662480473518372, Accuracy: 0.7490234375\n",
      "Batch: 35, Loss: 0.6753700971603394, Accuracy: 0.76953125\n",
      "Batch: 36, Loss: 0.6745669841766357, Accuracy: 0.767578125\n",
      "Batch: 37, Loss: 0.6725519895553589, Accuracy: 0.78515625\n",
      "Batch: 38, Loss: 0.705039381980896, Accuracy: 0.76953125\n",
      "Batch: 39, Loss: 0.7325564622879028, Accuracy: 0.74609375\n",
      "Batch: 40, Loss: 0.654609203338623, Accuracy: 0.7861328125\n",
      "Batch: 41, Loss: 0.5862332582473755, Accuracy: 0.8076171875\n",
      "Batch: 42, Loss: 0.5339657068252563, Accuracy: 0.8232421875\n",
      "Batch: 43, Loss: 0.7022801637649536, Accuracy: 0.7705078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 44, Loss: 0.6982318162918091, Accuracy: 0.775390625\n",
      "Batch: 45, Loss: 0.6602076292037964, Accuracy: 0.7705078125\n",
      "Batch: 46, Loss: 0.5880701541900635, Accuracy: 0.8076171875\n",
      "Batch: 47, Loss: 0.5884723663330078, Accuracy: 0.810546875\n",
      "Batch: 48, Loss: 0.6111805438995361, Accuracy: 0.791015625\n",
      "Batch: 49, Loss: 0.6946030855178833, Accuracy: 0.7666015625\n",
      "Batch: 50, Loss: 0.6747118830680847, Accuracy: 0.76953125\n",
      "Batch: 51, Loss: 0.6516150236129761, Accuracy: 0.7880859375\n",
      "Batch: 52, Loss: 0.6558507680892944, Accuracy: 0.7705078125\n",
      "Batch: 53, Loss: 0.6154992580413818, Accuracy: 0.7890625\n",
      "Batch: 54, Loss: 0.660515308380127, Accuracy: 0.775390625\n",
      "Batch: 55, Loss: 0.7641541957855225, Accuracy: 0.7412109375\n",
      "Batch: 56, Loss: 0.7562721967697144, Accuracy: 0.7568359375\n",
      "Batch: 57, Loss: 0.7116903066635132, Accuracy: 0.76171875\n",
      "Batch: 58, Loss: 0.7656683921813965, Accuracy: 0.75390625\n",
      "Batch: 59, Loss: 0.6276506185531616, Accuracy: 0.7939453125\n",
      "Batch: 60, Loss: 0.6256881952285767, Accuracy: 0.791015625\n",
      "Batch: 61, Loss: 0.6641285419464111, Accuracy: 0.775390625\n",
      "Batch: 62, Loss: 0.6539753079414368, Accuracy: 0.7900390625\n",
      "Batch: 63, Loss: 0.6557918787002563, Accuracy: 0.7734375\n",
      "Batch: 64, Loss: 0.6916453242301941, Accuracy: 0.771484375\n",
      "Batch: 65, Loss: 0.6725963354110718, Accuracy: 0.7744140625\n",
      "Batch: 66, Loss: 0.6298763751983643, Accuracy: 0.8056640625\n",
      "Batch: 67, Loss: 0.6992590427398682, Accuracy: 0.7705078125\n",
      "Batch: 68, Loss: 0.7927147150039673, Accuracy: 0.7451171875\n",
      "Batch: 69, Loss: 0.7207505702972412, Accuracy: 0.76953125\n",
      "Batch: 70, Loss: 0.6644006967544556, Accuracy: 0.806640625\n",
      "Batch: 71, Loss: 0.7144461870193481, Accuracy: 0.751953125\n",
      "Batch: 72, Loss: 0.59431391954422, Accuracy: 0.7939453125\n",
      "Batch: 73, Loss: 0.61689293384552, Accuracy: 0.796875\n",
      "Batch: 74, Loss: 0.5960707664489746, Accuracy: 0.8076171875\n",
      "Batch: 75, Loss: 0.6002242565155029, Accuracy: 0.8095703125\n",
      "Batch: 76, Loss: 0.684930145740509, Accuracy: 0.775390625\n",
      "Batch: 77, Loss: 0.6341842412948608, Accuracy: 0.7958984375\n",
      "Batch: 78, Loss: 0.5841059684753418, Accuracy: 0.8037109375\n",
      "Batch: 79, Loss: 0.5525794625282288, Accuracy: 0.83203125\n",
      "Batch: 80, Loss: 0.6298673748970032, Accuracy: 0.7939453125\n",
      "Batch: 81, Loss: 0.7466624975204468, Accuracy: 0.7421875\n",
      "Batch: 82, Loss: 0.7044188976287842, Accuracy: 0.7685546875\n",
      "Batch: 83, Loss: 0.577951192855835, Accuracy: 0.814453125\n",
      "Batch: 84, Loss: 0.6290371417999268, Accuracy: 0.7919921875\n",
      "Batch: 85, Loss: 0.6273062229156494, Accuracy: 0.7822265625\n",
      "Batch: 86, Loss: 0.7588339447975159, Accuracy: 0.7451171875\n",
      "Batch: 87, Loss: 0.5980907678604126, Accuracy: 0.7900390625\n",
      "Batch: 88, Loss: 0.7027337551116943, Accuracy: 0.7734375\n",
      "Batch: 89, Loss: 0.6902601718902588, Accuracy: 0.7890625\n",
      "Batch: 90, Loss: 0.6410726308822632, Accuracy: 0.796875\n",
      "Batch: 91, Loss: 0.6393694877624512, Accuracy: 0.775390625\n",
      "Batch: 92, Loss: 0.6626238226890564, Accuracy: 0.7763671875\n",
      "Batch: 93, Loss: 0.6805682182312012, Accuracy: 0.775390625\n",
      "Batch: 94, Loss: 0.6976560354232788, Accuracy: 0.7734375\n",
      "Batch: 95, Loss: 0.6800180077552795, Accuracy: 0.7626953125\n",
      "Batch: 96, Loss: 0.6463997960090637, Accuracy: 0.78125\n",
      "Batch: 97, Loss: 0.5523269176483154, Accuracy: 0.806640625\n",
      "Batch: 98, Loss: 0.6881389617919922, Accuracy: 0.7724609375\n",
      "Batch: 99, Loss: 0.6639937162399292, Accuracy: 0.771484375\n",
      "Batch: 100, Loss: 0.6783698201179504, Accuracy: 0.775390625\n",
      "Batch: 101, Loss: 0.7025697231292725, Accuracy: 0.775390625\n",
      "Batch: 102, Loss: 0.6971505880355835, Accuracy: 0.7734375\n",
      "Batch: 103, Loss: 0.6547873020172119, Accuracy: 0.7978515625\n",
      "Batch: 104, Loss: 0.6304465532302856, Accuracy: 0.796875\n",
      "Batch: 105, Loss: 0.6882809996604919, Accuracy: 0.763671875\n",
      "Batch: 106, Loss: 0.6338820457458496, Accuracy: 0.7958984375\n",
      "Batch: 107, Loss: 0.6794278621673584, Accuracy: 0.7880859375\n",
      "Batch: 108, Loss: 0.685969889163971, Accuracy: 0.7685546875\n",
      "Batch: 109, Loss: 0.7972576022148132, Accuracy: 0.7421875\n",
      "Batch: 110, Loss: 0.6392134428024292, Accuracy: 0.783203125\n",
      "Batch: 111, Loss: 0.7026596069335938, Accuracy: 0.7666015625\n",
      "Batch: 112, Loss: 0.6780502200126648, Accuracy: 0.771484375\n",
      "Batch: 113, Loss: 0.6745790243148804, Accuracy: 0.78125\n",
      "Batch: 114, Loss: 0.7449970841407776, Accuracy: 0.759765625\n",
      "Batch: 115, Loss: 0.7558157444000244, Accuracy: 0.7666015625\n",
      "Batch: 116, Loss: 0.7036272287368774, Accuracy: 0.771484375\n",
      "Batch: 117, Loss: 0.7130917906761169, Accuracy: 0.759765625\n",
      "Batch: 118, Loss: 0.6258569359779358, Accuracy: 0.794921875\n",
      "Batch: 119, Loss: 0.5743478536605835, Accuracy: 0.8095703125\n",
      "Batch: 120, Loss: 0.6809089183807373, Accuracy: 0.76953125\n",
      "Batch: 121, Loss: 0.7192211151123047, Accuracy: 0.7685546875\n",
      "Batch: 122, Loss: 0.6417895555496216, Accuracy: 0.802734375\n",
      "Batch: 123, Loss: 0.5882710814476013, Accuracy: 0.7958984375\n",
      "Batch: 124, Loss: 0.668136715888977, Accuracy: 0.7880859375\n",
      "Batch: 125, Loss: 0.7236193418502808, Accuracy: 0.7666015625\n",
      "Batch: 126, Loss: 0.6841055154800415, Accuracy: 0.765625\n",
      "Batch: 127, Loss: 0.5957581400871277, Accuracy: 0.8125\n",
      "Batch: 128, Loss: 0.7427597641944885, Accuracy: 0.7626953125\n",
      "Batch: 129, Loss: 0.6315062046051025, Accuracy: 0.7861328125\n",
      "Batch: 130, Loss: 0.7714903354644775, Accuracy: 0.755859375\n",
      "Batch: 131, Loss: 0.6910607814788818, Accuracy: 0.7578125\n",
      "Batch: 132, Loss: 0.685645341873169, Accuracy: 0.783203125\n",
      "Batch: 133, Loss: 0.6477710008621216, Accuracy: 0.7880859375\n",
      "Batch: 134, Loss: 0.6734374761581421, Accuracy: 0.7705078125\n",
      "Batch: 135, Loss: 0.6552907824516296, Accuracy: 0.7890625\n",
      "Batch: 136, Loss: 0.7052009105682373, Accuracy: 0.76953125\n",
      "Batch: 137, Loss: 0.6922675371170044, Accuracy: 0.7724609375\n",
      "Batch: 138, Loss: 0.6083651781082153, Accuracy: 0.7978515625\n",
      "Batch: 139, Loss: 0.6601205468177795, Accuracy: 0.7666015625\n",
      "Batch: 140, Loss: 0.6857264041900635, Accuracy: 0.7626953125\n",
      "Batch: 141, Loss: 0.7240845561027527, Accuracy: 0.7607421875\n",
      "Batch: 142, Loss: 0.7499757409095764, Accuracy: 0.7373046875\n",
      "Batch: 143, Loss: 0.6602063179016113, Accuracy: 0.7734375\n",
      "Batch: 144, Loss: 0.6780869960784912, Accuracy: 0.76171875\n",
      "Batch: 145, Loss: 0.6269004344940186, Accuracy: 0.783203125\n",
      "Batch: 146, Loss: 0.6838780045509338, Accuracy: 0.7724609375\n",
      "Batch: 147, Loss: 0.700664758682251, Accuracy: 0.7626953125\n",
      "Batch: 148, Loss: 0.7291420102119446, Accuracy: 0.751953125\n",
      "Batch: 149, Loss: 0.6445052623748779, Accuracy: 0.783203125\n",
      "Batch: 150, Loss: 0.6504083275794983, Accuracy: 0.78515625\n",
      "Batch: 151, Loss: 0.575839102268219, Accuracy: 0.802734375\n",
      "Epoch 77/80\n",
      "Batch: 1, Loss: 0.9141058921813965, Accuracy: 0.7138671875\n",
      "Batch: 2, Loss: 0.7792453765869141, Accuracy: 0.724609375\n",
      "Batch: 3, Loss: 0.6556388139724731, Accuracy: 0.783203125\n",
      "Batch: 4, Loss: 0.5778252482414246, Accuracy: 0.806640625\n",
      "Batch: 5, Loss: 0.6427525877952576, Accuracy: 0.7861328125\n",
      "Batch: 6, Loss: 0.7012004256248474, Accuracy: 0.775390625\n",
      "Batch: 7, Loss: 0.6802034378051758, Accuracy: 0.771484375\n",
      "Batch: 8, Loss: 0.6443625092506409, Accuracy: 0.775390625\n",
      "Batch: 9, Loss: 0.6411121487617493, Accuracy: 0.7802734375\n",
      "Batch: 10, Loss: 0.6291890144348145, Accuracy: 0.78515625\n",
      "Batch: 11, Loss: 0.740679919719696, Accuracy: 0.755859375\n",
      "Batch: 12, Loss: 0.7124202847480774, Accuracy: 0.7548828125\n",
      "Batch: 13, Loss: 0.5592077970504761, Accuracy: 0.8037109375\n",
      "Batch: 14, Loss: 0.7375692129135132, Accuracy: 0.7568359375\n",
      "Batch: 15, Loss: 0.5966359376907349, Accuracy: 0.8017578125\n",
      "Batch: 16, Loss: 0.6822428703308105, Accuracy: 0.7939453125\n",
      "Batch: 17, Loss: 0.687692403793335, Accuracy: 0.767578125\n",
      "Batch: 18, Loss: 0.7066366076469421, Accuracy: 0.765625\n",
      "Batch: 19, Loss: 0.6939586997032166, Accuracy: 0.783203125\n",
      "Batch: 20, Loss: 0.5940987467765808, Accuracy: 0.8037109375\n",
      "Batch: 21, Loss: 0.6432066559791565, Accuracy: 0.7802734375\n",
      "Batch: 22, Loss: 0.7442841529846191, Accuracy: 0.755859375\n",
      "Batch: 23, Loss: 0.6967017650604248, Accuracy: 0.76171875\n",
      "Batch: 24, Loss: 0.682549238204956, Accuracy: 0.7705078125\n",
      "Batch: 25, Loss: 0.6356836557388306, Accuracy: 0.7890625\n",
      "Batch: 26, Loss: 0.5832120180130005, Accuracy: 0.8017578125\n",
      "Batch: 27, Loss: 0.63912034034729, Accuracy: 0.767578125\n",
      "Batch: 28, Loss: 0.7282602190971375, Accuracy: 0.7509765625\n",
      "Batch: 29, Loss: 0.6353788375854492, Accuracy: 0.77734375\n",
      "Batch: 30, Loss: 0.5892225503921509, Accuracy: 0.8076171875\n",
      "Batch: 31, Loss: 0.5888652205467224, Accuracy: 0.80859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 32, Loss: 0.6080125570297241, Accuracy: 0.7919921875\n",
      "Batch: 33, Loss: 0.7245921492576599, Accuracy: 0.767578125\n",
      "Batch: 34, Loss: 0.7593650221824646, Accuracy: 0.7451171875\n",
      "Batch: 35, Loss: 0.6916241645812988, Accuracy: 0.7646484375\n",
      "Batch: 36, Loss: 0.6882265210151672, Accuracy: 0.7890625\n",
      "Batch: 37, Loss: 0.6773490309715271, Accuracy: 0.7763671875\n",
      "Batch: 38, Loss: 0.6676771640777588, Accuracy: 0.7763671875\n",
      "Batch: 39, Loss: 0.7009940147399902, Accuracy: 0.7666015625\n",
      "Batch: 40, Loss: 0.6422684192657471, Accuracy: 0.791015625\n",
      "Batch: 41, Loss: 0.6108037233352661, Accuracy: 0.7919921875\n",
      "Batch: 42, Loss: 0.5233389139175415, Accuracy: 0.8271484375\n",
      "Batch: 43, Loss: 0.6658971309661865, Accuracy: 0.7734375\n",
      "Batch: 44, Loss: 0.6941579580307007, Accuracy: 0.765625\n",
      "Batch: 45, Loss: 0.6287591457366943, Accuracy: 0.78515625\n",
      "Batch: 46, Loss: 0.5957440733909607, Accuracy: 0.798828125\n",
      "Batch: 47, Loss: 0.6154074668884277, Accuracy: 0.810546875\n",
      "Batch: 48, Loss: 0.6166465282440186, Accuracy: 0.78515625\n",
      "Batch: 49, Loss: 0.6870121359825134, Accuracy: 0.7705078125\n",
      "Batch: 50, Loss: 0.6801902055740356, Accuracy: 0.7685546875\n",
      "Batch: 51, Loss: 0.6866810321807861, Accuracy: 0.775390625\n",
      "Batch: 52, Loss: 0.649229884147644, Accuracy: 0.7939453125\n",
      "Batch: 53, Loss: 0.6197442412376404, Accuracy: 0.7890625\n",
      "Batch: 54, Loss: 0.6432152986526489, Accuracy: 0.7783203125\n",
      "Batch: 55, Loss: 0.7604682445526123, Accuracy: 0.755859375\n",
      "Batch: 56, Loss: 0.7169702053070068, Accuracy: 0.763671875\n",
      "Batch: 57, Loss: 0.7006939053535461, Accuracy: 0.7705078125\n",
      "Batch: 58, Loss: 0.7623149752616882, Accuracy: 0.7490234375\n",
      "Batch: 59, Loss: 0.6424676179885864, Accuracy: 0.7822265625\n",
      "Batch: 60, Loss: 0.6360898017883301, Accuracy: 0.7890625\n",
      "Batch: 61, Loss: 0.7005462646484375, Accuracy: 0.77734375\n",
      "Batch: 62, Loss: 0.6475809216499329, Accuracy: 0.798828125\n",
      "Batch: 63, Loss: 0.6879406571388245, Accuracy: 0.7734375\n",
      "Batch: 64, Loss: 0.6880836486816406, Accuracy: 0.775390625\n",
      "Batch: 65, Loss: 0.696306049823761, Accuracy: 0.7685546875\n",
      "Batch: 66, Loss: 0.6350743770599365, Accuracy: 0.8017578125\n",
      "Batch: 67, Loss: 0.7311211228370667, Accuracy: 0.759765625\n",
      "Batch: 68, Loss: 0.7842405438423157, Accuracy: 0.75\n",
      "Batch: 69, Loss: 0.6858817934989929, Accuracy: 0.767578125\n",
      "Batch: 70, Loss: 0.6376644372940063, Accuracy: 0.802734375\n",
      "Batch: 71, Loss: 0.742188572883606, Accuracy: 0.7490234375\n",
      "Batch: 72, Loss: 0.5954201221466064, Accuracy: 0.802734375\n",
      "Batch: 73, Loss: 0.5959824323654175, Accuracy: 0.814453125\n",
      "Batch: 74, Loss: 0.5726916790008545, Accuracy: 0.814453125\n",
      "Batch: 75, Loss: 0.6018449664115906, Accuracy: 0.8056640625\n",
      "Batch: 76, Loss: 0.6765927076339722, Accuracy: 0.771484375\n",
      "Batch: 77, Loss: 0.6156485080718994, Accuracy: 0.79296875\n",
      "Batch: 78, Loss: 0.5964314937591553, Accuracy: 0.806640625\n",
      "Batch: 79, Loss: 0.566848635673523, Accuracy: 0.8271484375\n",
      "Batch: 80, Loss: 0.6593273878097534, Accuracy: 0.7724609375\n",
      "Batch: 81, Loss: 0.7056115865707397, Accuracy: 0.7607421875\n",
      "Batch: 82, Loss: 0.6829944252967834, Accuracy: 0.767578125\n",
      "Batch: 83, Loss: 0.612763524055481, Accuracy: 0.8095703125\n",
      "Batch: 84, Loss: 0.6425497531890869, Accuracy: 0.7900390625\n",
      "Batch: 85, Loss: 0.6552965641021729, Accuracy: 0.7958984375\n",
      "Batch: 86, Loss: 0.7664846181869507, Accuracy: 0.765625\n",
      "Batch: 87, Loss: 0.5839243531227112, Accuracy: 0.8193359375\n",
      "Batch: 88, Loss: 0.7080273032188416, Accuracy: 0.78515625\n",
      "Batch: 89, Loss: 0.7139582633972168, Accuracy: 0.78515625\n",
      "Batch: 90, Loss: 0.6443390846252441, Accuracy: 0.779296875\n",
      "Batch: 91, Loss: 0.6302186250686646, Accuracy: 0.7880859375\n",
      "Batch: 92, Loss: 0.6861157417297363, Accuracy: 0.7763671875\n",
      "Batch: 93, Loss: 0.6539283990859985, Accuracy: 0.7919921875\n",
      "Batch: 94, Loss: 0.664880096912384, Accuracy: 0.7744140625\n",
      "Batch: 95, Loss: 0.7071571946144104, Accuracy: 0.7587890625\n",
      "Batch: 96, Loss: 0.6206605434417725, Accuracy: 0.7900390625\n",
      "Batch: 97, Loss: 0.5689839720726013, Accuracy: 0.79296875\n",
      "Batch: 98, Loss: 0.6561704874038696, Accuracy: 0.7783203125\n",
      "Batch: 99, Loss: 0.6833511590957642, Accuracy: 0.7626953125\n",
      "Batch: 100, Loss: 0.6620739698410034, Accuracy: 0.78125\n",
      "Batch: 101, Loss: 0.7016157507896423, Accuracy: 0.7666015625\n",
      "Batch: 102, Loss: 0.6896721124649048, Accuracy: 0.767578125\n",
      "Batch: 103, Loss: 0.6619282364845276, Accuracy: 0.7919921875\n",
      "Batch: 104, Loss: 0.659936249256134, Accuracy: 0.783203125\n",
      "Batch: 105, Loss: 0.719614565372467, Accuracy: 0.7685546875\n",
      "Batch: 106, Loss: 0.635838508605957, Accuracy: 0.7841796875\n",
      "Batch: 107, Loss: 0.6760852336883545, Accuracy: 0.775390625\n",
      "Batch: 108, Loss: 0.677047848701477, Accuracy: 0.7744140625\n",
      "Batch: 109, Loss: 0.7465232610702515, Accuracy: 0.7607421875\n",
      "Batch: 110, Loss: 0.6171613931655884, Accuracy: 0.7958984375\n",
      "Batch: 111, Loss: 0.6905132532119751, Accuracy: 0.77734375\n",
      "Batch: 112, Loss: 0.674167275428772, Accuracy: 0.787109375\n",
      "Batch: 113, Loss: 0.6665299534797668, Accuracy: 0.7783203125\n",
      "Batch: 114, Loss: 0.7388336658477783, Accuracy: 0.7578125\n",
      "Batch: 115, Loss: 0.7691538333892822, Accuracy: 0.7548828125\n",
      "Batch: 116, Loss: 0.6874393224716187, Accuracy: 0.767578125\n",
      "Batch: 117, Loss: 0.7198469638824463, Accuracy: 0.7744140625\n",
      "Batch: 118, Loss: 0.5915862321853638, Accuracy: 0.7998046875\n",
      "Batch: 119, Loss: 0.5680686831474304, Accuracy: 0.8076171875\n",
      "Batch: 120, Loss: 0.6605762839317322, Accuracy: 0.7802734375\n",
      "Batch: 121, Loss: 0.7236749529838562, Accuracy: 0.7529296875\n",
      "Batch: 122, Loss: 0.5956180691719055, Accuracy: 0.80078125\n",
      "Batch: 123, Loss: 0.6003801226615906, Accuracy: 0.802734375\n",
      "Batch: 124, Loss: 0.6541799902915955, Accuracy: 0.7822265625\n",
      "Batch: 125, Loss: 0.7136923670768738, Accuracy: 0.771484375\n",
      "Batch: 126, Loss: 0.6722760200500488, Accuracy: 0.7744140625\n",
      "Batch: 127, Loss: 0.5980565547943115, Accuracy: 0.8134765625\n",
      "Batch: 128, Loss: 0.7351322174072266, Accuracy: 0.7685546875\n",
      "Batch: 129, Loss: 0.6159483790397644, Accuracy: 0.798828125\n",
      "Batch: 130, Loss: 0.7824848890304565, Accuracy: 0.748046875\n",
      "Batch: 131, Loss: 0.6785709857940674, Accuracy: 0.7802734375\n",
      "Batch: 132, Loss: 0.7167974710464478, Accuracy: 0.751953125\n",
      "Batch: 133, Loss: 0.6589754819869995, Accuracy: 0.7734375\n",
      "Batch: 134, Loss: 0.6644785404205322, Accuracy: 0.7763671875\n",
      "Batch: 135, Loss: 0.6197518706321716, Accuracy: 0.8037109375\n",
      "Batch: 136, Loss: 0.6952985525131226, Accuracy: 0.779296875\n",
      "Batch: 137, Loss: 0.7005577683448792, Accuracy: 0.7705078125\n",
      "Batch: 138, Loss: 0.6079900860786438, Accuracy: 0.7978515625\n",
      "Batch: 139, Loss: 0.5982910394668579, Accuracy: 0.7861328125\n",
      "Batch: 140, Loss: 0.6466050148010254, Accuracy: 0.7783203125\n",
      "Batch: 141, Loss: 0.7218351364135742, Accuracy: 0.759765625\n",
      "Batch: 142, Loss: 0.7277896404266357, Accuracy: 0.7685546875\n",
      "Batch: 143, Loss: 0.6369354724884033, Accuracy: 0.779296875\n",
      "Batch: 144, Loss: 0.674983024597168, Accuracy: 0.783203125\n",
      "Batch: 145, Loss: 0.6386183500289917, Accuracy: 0.791015625\n",
      "Batch: 146, Loss: 0.6776211857795715, Accuracy: 0.765625\n",
      "Batch: 147, Loss: 0.6367989182472229, Accuracy: 0.779296875\n",
      "Batch: 148, Loss: 0.725058376789093, Accuracy: 0.7578125\n",
      "Batch: 149, Loss: 0.6305077075958252, Accuracy: 0.7763671875\n",
      "Batch: 150, Loss: 0.6556847095489502, Accuracy: 0.7734375\n",
      "Batch: 151, Loss: 0.5773652791976929, Accuracy: 0.8134765625\n",
      "Epoch 78/80\n",
      "Batch: 1, Loss: 0.8597033023834229, Accuracy: 0.724609375\n",
      "Batch: 2, Loss: 0.753962516784668, Accuracy: 0.7333984375\n",
      "Batch: 3, Loss: 0.6083061695098877, Accuracy: 0.7978515625\n",
      "Batch: 4, Loss: 0.5775457620620728, Accuracy: 0.81640625\n",
      "Batch: 5, Loss: 0.640365481376648, Accuracy: 0.787109375\n",
      "Batch: 6, Loss: 0.6976141333580017, Accuracy: 0.7607421875\n",
      "Batch: 7, Loss: 0.6699419617652893, Accuracy: 0.76953125\n",
      "Batch: 8, Loss: 0.6452761888504028, Accuracy: 0.7685546875\n",
      "Batch: 9, Loss: 0.6497950553894043, Accuracy: 0.7763671875\n",
      "Batch: 10, Loss: 0.6140903234481812, Accuracy: 0.80078125\n",
      "Batch: 11, Loss: 0.7293479442596436, Accuracy: 0.744140625\n",
      "Batch: 12, Loss: 0.7134888172149658, Accuracy: 0.763671875\n",
      "Batch: 13, Loss: 0.564493715763092, Accuracy: 0.8115234375\n",
      "Batch: 14, Loss: 0.7503261566162109, Accuracy: 0.75\n",
      "Batch: 15, Loss: 0.5703245997428894, Accuracy: 0.8193359375\n",
      "Batch: 16, Loss: 0.6526937484741211, Accuracy: 0.794921875\n",
      "Batch: 17, Loss: 0.6861892342567444, Accuracy: 0.7744140625\n",
      "Batch: 18, Loss: 0.6932646632194519, Accuracy: 0.7802734375\n",
      "Batch: 19, Loss: 0.6725588440895081, Accuracy: 0.783203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20, Loss: 0.5763198137283325, Accuracy: 0.806640625\n",
      "Batch: 21, Loss: 0.6234312653541565, Accuracy: 0.7919921875\n",
      "Batch: 22, Loss: 0.7313104271888733, Accuracy: 0.763671875\n",
      "Batch: 23, Loss: 0.6582440137863159, Accuracy: 0.779296875\n",
      "Batch: 24, Loss: 0.703904390335083, Accuracy: 0.767578125\n",
      "Batch: 25, Loss: 0.6492465138435364, Accuracy: 0.7900390625\n",
      "Batch: 26, Loss: 0.5761775970458984, Accuracy: 0.8076171875\n",
      "Batch: 27, Loss: 0.6412630081176758, Accuracy: 0.771484375\n",
      "Batch: 28, Loss: 0.6744866371154785, Accuracy: 0.755859375\n",
      "Batch: 29, Loss: 0.6236093044281006, Accuracy: 0.7958984375\n",
      "Batch: 30, Loss: 0.5587791204452515, Accuracy: 0.814453125\n",
      "Batch: 31, Loss: 0.5736687183380127, Accuracy: 0.8125\n",
      "Batch: 32, Loss: 0.5977579355239868, Accuracy: 0.7978515625\n",
      "Batch: 33, Loss: 0.6908916234970093, Accuracy: 0.7705078125\n",
      "Batch: 34, Loss: 0.7303498983383179, Accuracy: 0.7763671875\n",
      "Batch: 35, Loss: 0.6518499851226807, Accuracy: 0.7734375\n",
      "Batch: 36, Loss: 0.6948391795158386, Accuracy: 0.779296875\n",
      "Batch: 37, Loss: 0.6800761222839355, Accuracy: 0.76953125\n",
      "Batch: 38, Loss: 0.665520191192627, Accuracy: 0.7666015625\n",
      "Batch: 39, Loss: 0.7029977440834045, Accuracy: 0.7646484375\n",
      "Batch: 40, Loss: 0.6592313051223755, Accuracy: 0.7841796875\n",
      "Batch: 41, Loss: 0.6026707887649536, Accuracy: 0.798828125\n",
      "Batch: 42, Loss: 0.5150839686393738, Accuracy: 0.82421875\n",
      "Batch: 43, Loss: 0.6775082349777222, Accuracy: 0.771484375\n",
      "Batch: 44, Loss: 0.6750586628913879, Accuracy: 0.7763671875\n",
      "Batch: 45, Loss: 0.6348121762275696, Accuracy: 0.7783203125\n",
      "Batch: 46, Loss: 0.5912343263626099, Accuracy: 0.8115234375\n",
      "Batch: 47, Loss: 0.5987907648086548, Accuracy: 0.8115234375\n",
      "Batch: 48, Loss: 0.574064314365387, Accuracy: 0.810546875\n",
      "Batch: 49, Loss: 0.6978433132171631, Accuracy: 0.7685546875\n",
      "Batch: 50, Loss: 0.6558154821395874, Accuracy: 0.78125\n",
      "Batch: 51, Loss: 0.6773325204849243, Accuracy: 0.7763671875\n",
      "Batch: 52, Loss: 0.6559346318244934, Accuracy: 0.779296875\n",
      "Batch: 53, Loss: 0.6091382503509521, Accuracy: 0.7939453125\n",
      "Batch: 54, Loss: 0.682494044303894, Accuracy: 0.7783203125\n",
      "Batch: 55, Loss: 0.7502456903457642, Accuracy: 0.7578125\n",
      "Batch: 56, Loss: 0.7899032235145569, Accuracy: 0.7470703125\n",
      "Batch: 57, Loss: 0.7161113619804382, Accuracy: 0.7802734375\n",
      "Batch: 58, Loss: 0.770124614238739, Accuracy: 0.7490234375\n",
      "Batch: 59, Loss: 0.612436056137085, Accuracy: 0.802734375\n",
      "Batch: 60, Loss: 0.6058573722839355, Accuracy: 0.8095703125\n",
      "Batch: 61, Loss: 0.6838567852973938, Accuracy: 0.775390625\n",
      "Batch: 62, Loss: 0.6449234485626221, Accuracy: 0.783203125\n",
      "Batch: 63, Loss: 0.6614315509796143, Accuracy: 0.7744140625\n",
      "Batch: 64, Loss: 0.6592593193054199, Accuracy: 0.78515625\n",
      "Batch: 65, Loss: 0.6514710187911987, Accuracy: 0.7919921875\n",
      "Batch: 66, Loss: 0.6508737802505493, Accuracy: 0.7978515625\n",
      "Batch: 67, Loss: 0.7213717699050903, Accuracy: 0.771484375\n",
      "Batch: 68, Loss: 0.7951028347015381, Accuracy: 0.7421875\n",
      "Batch: 69, Loss: 0.7110716700553894, Accuracy: 0.7646484375\n",
      "Batch: 70, Loss: 0.6882960200309753, Accuracy: 0.78125\n",
      "Batch: 71, Loss: 0.705725908279419, Accuracy: 0.76171875\n",
      "Batch: 72, Loss: 0.6020137667655945, Accuracy: 0.7958984375\n",
      "Batch: 73, Loss: 0.6190530061721802, Accuracy: 0.7978515625\n",
      "Batch: 74, Loss: 0.5847487449645996, Accuracy: 0.82421875\n",
      "Batch: 75, Loss: 0.6133779883384705, Accuracy: 0.794921875\n",
      "Batch: 76, Loss: 0.7023370265960693, Accuracy: 0.76953125\n",
      "Batch: 77, Loss: 0.6224533319473267, Accuracy: 0.7880859375\n",
      "Batch: 78, Loss: 0.5676316022872925, Accuracy: 0.8125\n",
      "Batch: 79, Loss: 0.553705096244812, Accuracy: 0.818359375\n",
      "Batch: 80, Loss: 0.631811261177063, Accuracy: 0.7880859375\n",
      "Batch: 81, Loss: 0.7256952524185181, Accuracy: 0.74609375\n",
      "Batch: 82, Loss: 0.6925211548805237, Accuracy: 0.771484375\n",
      "Batch: 83, Loss: 0.5848387479782104, Accuracy: 0.8330078125\n",
      "Batch: 84, Loss: 0.6374515891075134, Accuracy: 0.7744140625\n",
      "Batch: 85, Loss: 0.653324544429779, Accuracy: 0.775390625\n",
      "Batch: 86, Loss: 0.7595788240432739, Accuracy: 0.771484375\n",
      "Batch: 87, Loss: 0.6044739484786987, Accuracy: 0.794921875\n",
      "Batch: 88, Loss: 0.6849412322044373, Accuracy: 0.7802734375\n",
      "Batch: 89, Loss: 0.7088817358016968, Accuracy: 0.7607421875\n",
      "Batch: 90, Loss: 0.619521975517273, Accuracy: 0.8056640625\n",
      "Batch: 91, Loss: 0.6115304231643677, Accuracy: 0.794921875\n",
      "Batch: 92, Loss: 0.6556904315948486, Accuracy: 0.77734375\n",
      "Batch: 93, Loss: 0.6365594863891602, Accuracy: 0.7744140625\n",
      "Batch: 94, Loss: 0.6903690099716187, Accuracy: 0.7744140625\n",
      "Batch: 95, Loss: 0.6808568835258484, Accuracy: 0.7578125\n",
      "Batch: 96, Loss: 0.665669858455658, Accuracy: 0.7841796875\n",
      "Batch: 97, Loss: 0.5327531099319458, Accuracy: 0.8193359375\n",
      "Batch: 98, Loss: 0.6702578067779541, Accuracy: 0.7783203125\n",
      "Batch: 99, Loss: 0.6435965299606323, Accuracy: 0.779296875\n",
      "Batch: 100, Loss: 0.6841579079627991, Accuracy: 0.7666015625\n",
      "Batch: 101, Loss: 0.6858724355697632, Accuracy: 0.771484375\n",
      "Batch: 102, Loss: 0.6713788509368896, Accuracy: 0.77734375\n",
      "Batch: 103, Loss: 0.6673647165298462, Accuracy: 0.783203125\n",
      "Batch: 104, Loss: 0.6260521411895752, Accuracy: 0.78125\n",
      "Batch: 105, Loss: 0.7242436408996582, Accuracy: 0.75390625\n",
      "Batch: 106, Loss: 0.6199915409088135, Accuracy: 0.7998046875\n",
      "Batch: 107, Loss: 0.6482493877410889, Accuracy: 0.8095703125\n",
      "Batch: 108, Loss: 0.6854569911956787, Accuracy: 0.779296875\n",
      "Batch: 109, Loss: 0.7649278044700623, Accuracy: 0.7470703125\n",
      "Batch: 110, Loss: 0.6197373270988464, Accuracy: 0.7880859375\n",
      "Batch: 111, Loss: 0.674888551235199, Accuracy: 0.7890625\n",
      "Batch: 112, Loss: 0.6608081459999084, Accuracy: 0.7802734375\n",
      "Batch: 113, Loss: 0.6521814465522766, Accuracy: 0.7900390625\n",
      "Batch: 114, Loss: 0.7107961177825928, Accuracy: 0.771484375\n",
      "Batch: 115, Loss: 0.7610777616500854, Accuracy: 0.767578125\n",
      "Batch: 116, Loss: 0.6716399788856506, Accuracy: 0.7705078125\n",
      "Batch: 117, Loss: 0.712009847164154, Accuracy: 0.7626953125\n",
      "Batch: 118, Loss: 0.5908887982368469, Accuracy: 0.80078125\n",
      "Batch: 119, Loss: 0.5734599232673645, Accuracy: 0.81640625\n",
      "Batch: 120, Loss: 0.6961896419525146, Accuracy: 0.771484375\n",
      "Batch: 121, Loss: 0.704567551612854, Accuracy: 0.7705078125\n",
      "Batch: 122, Loss: 0.6374025344848633, Accuracy: 0.7890625\n",
      "Batch: 123, Loss: 0.6188534498214722, Accuracy: 0.794921875\n",
      "Batch: 124, Loss: 0.6580811738967896, Accuracy: 0.7890625\n",
      "Batch: 125, Loss: 0.7213330268859863, Accuracy: 0.7509765625\n",
      "Batch: 126, Loss: 0.694351315498352, Accuracy: 0.7666015625\n",
      "Batch: 127, Loss: 0.5798925757408142, Accuracy: 0.822265625\n",
      "Batch: 128, Loss: 0.7624795436859131, Accuracy: 0.759765625\n",
      "Batch: 129, Loss: 0.6125798225402832, Accuracy: 0.7890625\n",
      "Batch: 130, Loss: 0.7632238268852234, Accuracy: 0.7470703125\n",
      "Batch: 131, Loss: 0.6631275415420532, Accuracy: 0.7880859375\n",
      "Batch: 132, Loss: 0.671664834022522, Accuracy: 0.7890625\n",
      "Batch: 133, Loss: 0.6578544974327087, Accuracy: 0.78515625\n",
      "Batch: 134, Loss: 0.6913395524024963, Accuracy: 0.7587890625\n",
      "Batch: 135, Loss: 0.6050804853439331, Accuracy: 0.8076171875\n",
      "Batch: 136, Loss: 0.6811169385910034, Accuracy: 0.7802734375\n",
      "Batch: 137, Loss: 0.6783500909805298, Accuracy: 0.763671875\n",
      "Batch: 138, Loss: 0.618920087814331, Accuracy: 0.7841796875\n",
      "Batch: 139, Loss: 0.6175674200057983, Accuracy: 0.7998046875\n",
      "Batch: 140, Loss: 0.6397445797920227, Accuracy: 0.7890625\n",
      "Batch: 141, Loss: 0.6936079263687134, Accuracy: 0.76953125\n",
      "Batch: 142, Loss: 0.7109395265579224, Accuracy: 0.7666015625\n",
      "Batch: 143, Loss: 0.6224318146705627, Accuracy: 0.791015625\n",
      "Batch: 144, Loss: 0.682811439037323, Accuracy: 0.771484375\n",
      "Batch: 145, Loss: 0.6378953456878662, Accuracy: 0.7861328125\n",
      "Batch: 146, Loss: 0.6785851120948792, Accuracy: 0.78125\n",
      "Batch: 147, Loss: 0.6717989444732666, Accuracy: 0.7685546875\n",
      "Batch: 148, Loss: 0.7047119140625, Accuracy: 0.7666015625\n",
      "Batch: 149, Loss: 0.60392826795578, Accuracy: 0.79296875\n",
      "Batch: 150, Loss: 0.6363811492919922, Accuracy: 0.78515625\n",
      "Batch: 151, Loss: 0.5444654226303101, Accuracy: 0.82421875\n",
      "Epoch 79/80\n",
      "Batch: 1, Loss: 0.8513928651809692, Accuracy: 0.7294921875\n",
      "Batch: 2, Loss: 0.7422358989715576, Accuracy: 0.7353515625\n",
      "Batch: 3, Loss: 0.6203415393829346, Accuracy: 0.8076171875\n",
      "Batch: 4, Loss: 0.57985520362854, Accuracy: 0.8046875\n",
      "Batch: 5, Loss: 0.6266868114471436, Accuracy: 0.7802734375\n",
      "Batch: 6, Loss: 0.6654309630393982, Accuracy: 0.7685546875\n",
      "Batch: 7, Loss: 0.6424335241317749, Accuracy: 0.775390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 8, Loss: 0.6415903568267822, Accuracy: 0.78515625\n",
      "Batch: 9, Loss: 0.6614282131195068, Accuracy: 0.7861328125\n",
      "Batch: 10, Loss: 0.629571795463562, Accuracy: 0.787109375\n",
      "Batch: 11, Loss: 0.7285956740379333, Accuracy: 0.763671875\n",
      "Batch: 12, Loss: 0.7285448312759399, Accuracy: 0.7568359375\n",
      "Batch: 13, Loss: 0.561111569404602, Accuracy: 0.8095703125\n",
      "Batch: 14, Loss: 0.7494210004806519, Accuracy: 0.7490234375\n",
      "Batch: 15, Loss: 0.5898087024688721, Accuracy: 0.7998046875\n",
      "Batch: 16, Loss: 0.6777321696281433, Accuracy: 0.7802734375\n",
      "Batch: 17, Loss: 0.6892622709274292, Accuracy: 0.7724609375\n",
      "Batch: 18, Loss: 0.7134425640106201, Accuracy: 0.75\n",
      "Batch: 19, Loss: 0.6523587703704834, Accuracy: 0.779296875\n",
      "Batch: 20, Loss: 0.5829240083694458, Accuracy: 0.8232421875\n",
      "Batch: 21, Loss: 0.6076602935791016, Accuracy: 0.8017578125\n",
      "Batch: 22, Loss: 0.7249583005905151, Accuracy: 0.7734375\n",
      "Batch: 23, Loss: 0.6566071510314941, Accuracy: 0.7880859375\n",
      "Batch: 24, Loss: 0.6809499263763428, Accuracy: 0.76953125\n",
      "Batch: 25, Loss: 0.6604242920875549, Accuracy: 0.7783203125\n",
      "Batch: 26, Loss: 0.567200779914856, Accuracy: 0.8095703125\n",
      "Batch: 27, Loss: 0.6529441475868225, Accuracy: 0.775390625\n",
      "Batch: 28, Loss: 0.6735187768936157, Accuracy: 0.7705078125\n",
      "Batch: 29, Loss: 0.6418213844299316, Accuracy: 0.7861328125\n",
      "Batch: 30, Loss: 0.555030107498169, Accuracy: 0.810546875\n",
      "Batch: 31, Loss: 0.6063517332077026, Accuracy: 0.7919921875\n",
      "Batch: 32, Loss: 0.622908890247345, Accuracy: 0.79296875\n",
      "Batch: 33, Loss: 0.6772730946540833, Accuracy: 0.76171875\n",
      "Batch: 34, Loss: 0.7457337975502014, Accuracy: 0.736328125\n",
      "Batch: 35, Loss: 0.6498600840568542, Accuracy: 0.775390625\n",
      "Batch: 36, Loss: 0.6725841164588928, Accuracy: 0.7724609375\n",
      "Batch: 37, Loss: 0.6412689685821533, Accuracy: 0.79296875\n",
      "Batch: 38, Loss: 0.6420681476593018, Accuracy: 0.7900390625\n",
      "Batch: 39, Loss: 0.7128667831420898, Accuracy: 0.76953125\n",
      "Batch: 40, Loss: 0.6405853629112244, Accuracy: 0.787109375\n",
      "Batch: 41, Loss: 0.6139410734176636, Accuracy: 0.791015625\n",
      "Batch: 42, Loss: 0.5213546752929688, Accuracy: 0.8212890625\n",
      "Batch: 43, Loss: 0.6876580119132996, Accuracy: 0.7744140625\n",
      "Batch: 44, Loss: 0.6789678335189819, Accuracy: 0.783203125\n",
      "Batch: 45, Loss: 0.6177172660827637, Accuracy: 0.78515625\n",
      "Batch: 46, Loss: 0.5953447818756104, Accuracy: 0.8125\n",
      "Batch: 47, Loss: 0.6186071634292603, Accuracy: 0.802734375\n",
      "Batch: 48, Loss: 0.5862166285514832, Accuracy: 0.8056640625\n",
      "Batch: 49, Loss: 0.6965092420578003, Accuracy: 0.755859375\n",
      "Batch: 50, Loss: 0.6784729957580566, Accuracy: 0.783203125\n",
      "Batch: 51, Loss: 0.6366021037101746, Accuracy: 0.7919921875\n",
      "Batch: 52, Loss: 0.6779288053512573, Accuracy: 0.779296875\n",
      "Batch: 53, Loss: 0.6161335110664368, Accuracy: 0.796875\n",
      "Batch: 54, Loss: 0.6581880450248718, Accuracy: 0.7763671875\n",
      "Batch: 55, Loss: 0.7514139413833618, Accuracy: 0.736328125\n",
      "Batch: 56, Loss: 0.7129178047180176, Accuracy: 0.771484375\n",
      "Batch: 57, Loss: 0.6829085946083069, Accuracy: 0.77734375\n",
      "Batch: 58, Loss: 0.7913389205932617, Accuracy: 0.7548828125\n",
      "Batch: 59, Loss: 0.6337988376617432, Accuracy: 0.791015625\n",
      "Batch: 60, Loss: 0.6077231168746948, Accuracy: 0.7998046875\n",
      "Batch: 61, Loss: 0.6749327182769775, Accuracy: 0.755859375\n",
      "Batch: 62, Loss: 0.6303790807723999, Accuracy: 0.796875\n",
      "Batch: 63, Loss: 0.6655500531196594, Accuracy: 0.7802734375\n",
      "Batch: 64, Loss: 0.6669763326644897, Accuracy: 0.7626953125\n",
      "Batch: 65, Loss: 0.6579633951187134, Accuracy: 0.7763671875\n",
      "Batch: 66, Loss: 0.6436625719070435, Accuracy: 0.7978515625\n",
      "Batch: 67, Loss: 0.7442843317985535, Accuracy: 0.748046875\n",
      "Batch: 68, Loss: 0.7732564806938171, Accuracy: 0.759765625\n",
      "Batch: 69, Loss: 0.6840027570724487, Accuracy: 0.7705078125\n",
      "Batch: 70, Loss: 0.6512826085090637, Accuracy: 0.8037109375\n",
      "Batch: 71, Loss: 0.6890283823013306, Accuracy: 0.7509765625\n",
      "Batch: 72, Loss: 0.5977765321731567, Accuracy: 0.8046875\n",
      "Batch: 73, Loss: 0.6238504648208618, Accuracy: 0.794921875\n",
      "Batch: 74, Loss: 0.5628450512886047, Accuracy: 0.818359375\n",
      "Batch: 75, Loss: 0.5926171541213989, Accuracy: 0.806640625\n",
      "Batch: 76, Loss: 0.6680983304977417, Accuracy: 0.7646484375\n",
      "Batch: 77, Loss: 0.621200680732727, Accuracy: 0.7919921875\n",
      "Batch: 78, Loss: 0.5973897576332092, Accuracy: 0.8017578125\n",
      "Batch: 79, Loss: 0.53508460521698, Accuracy: 0.8310546875\n",
      "Batch: 80, Loss: 0.6377904415130615, Accuracy: 0.78515625\n",
      "Batch: 81, Loss: 0.7022581100463867, Accuracy: 0.7646484375\n",
      "Batch: 82, Loss: 0.6810752153396606, Accuracy: 0.7744140625\n",
      "Batch: 83, Loss: 0.5686773061752319, Accuracy: 0.830078125\n",
      "Batch: 84, Loss: 0.637877345085144, Accuracy: 0.7998046875\n",
      "Batch: 85, Loss: 0.6416610479354858, Accuracy: 0.7939453125\n",
      "Batch: 86, Loss: 0.7597199082374573, Accuracy: 0.7509765625\n",
      "Batch: 87, Loss: 0.602648138999939, Accuracy: 0.798828125\n",
      "Batch: 88, Loss: 0.7089390158653259, Accuracy: 0.7646484375\n",
      "Batch: 89, Loss: 0.6867157220840454, Accuracy: 0.7900390625\n",
      "Batch: 90, Loss: 0.6127512454986572, Accuracy: 0.796875\n",
      "Batch: 91, Loss: 0.644586443901062, Accuracy: 0.78125\n",
      "Batch: 92, Loss: 0.647145688533783, Accuracy: 0.7841796875\n",
      "Batch: 93, Loss: 0.6652851104736328, Accuracy: 0.787109375\n",
      "Batch: 94, Loss: 0.6755660772323608, Accuracy: 0.755859375\n",
      "Batch: 95, Loss: 0.7019653916358948, Accuracy: 0.751953125\n",
      "Batch: 96, Loss: 0.6400414109230042, Accuracy: 0.7890625\n",
      "Batch: 97, Loss: 0.5495494604110718, Accuracy: 0.8173828125\n",
      "Batch: 98, Loss: 0.6558481454849243, Accuracy: 0.78125\n",
      "Batch: 99, Loss: 0.6718419790267944, Accuracy: 0.7900390625\n",
      "Batch: 100, Loss: 0.6855537295341492, Accuracy: 0.775390625\n",
      "Batch: 101, Loss: 0.7011905908584595, Accuracy: 0.763671875\n",
      "Batch: 102, Loss: 0.7012799382209778, Accuracy: 0.765625\n",
      "Batch: 103, Loss: 0.6756236553192139, Accuracy: 0.7802734375\n",
      "Batch: 104, Loss: 0.6338584423065186, Accuracy: 0.787109375\n",
      "Batch: 105, Loss: 0.7073894739151001, Accuracy: 0.7646484375\n",
      "Batch: 106, Loss: 0.6341391205787659, Accuracy: 0.79296875\n",
      "Batch: 107, Loss: 0.6573396921157837, Accuracy: 0.78125\n",
      "Batch: 108, Loss: 0.6901323795318604, Accuracy: 0.7724609375\n",
      "Batch: 109, Loss: 0.767997145652771, Accuracy: 0.7490234375\n",
      "Batch: 110, Loss: 0.6304894685745239, Accuracy: 0.78515625\n",
      "Batch: 111, Loss: 0.687951922416687, Accuracy: 0.7783203125\n",
      "Batch: 112, Loss: 0.6305227279663086, Accuracy: 0.794921875\n",
      "Batch: 113, Loss: 0.6839690208435059, Accuracy: 0.7744140625\n",
      "Batch: 114, Loss: 0.7215315103530884, Accuracy: 0.7724609375\n",
      "Batch: 115, Loss: 0.7191895246505737, Accuracy: 0.7568359375\n",
      "Batch: 116, Loss: 0.6640626192092896, Accuracy: 0.7578125\n",
      "Batch: 117, Loss: 0.6910836100578308, Accuracy: 0.775390625\n",
      "Batch: 118, Loss: 0.6064040660858154, Accuracy: 0.80859375\n",
      "Batch: 119, Loss: 0.5449970364570618, Accuracy: 0.8173828125\n",
      "Batch: 120, Loss: 0.6370395421981812, Accuracy: 0.79296875\n",
      "Batch: 121, Loss: 0.70755934715271, Accuracy: 0.7626953125\n",
      "Batch: 122, Loss: 0.6149893403053284, Accuracy: 0.8037109375\n",
      "Batch: 123, Loss: 0.5797622203826904, Accuracy: 0.80859375\n",
      "Batch: 124, Loss: 0.666816234588623, Accuracy: 0.7802734375\n",
      "Batch: 125, Loss: 0.7110247611999512, Accuracy: 0.7685546875\n",
      "Batch: 126, Loss: 0.6735279560089111, Accuracy: 0.7822265625\n",
      "Batch: 127, Loss: 0.597758412361145, Accuracy: 0.8017578125\n",
      "Batch: 128, Loss: 0.7448339462280273, Accuracy: 0.775390625\n",
      "Batch: 129, Loss: 0.6130187511444092, Accuracy: 0.7958984375\n",
      "Batch: 130, Loss: 0.7572383880615234, Accuracy: 0.7451171875\n",
      "Batch: 131, Loss: 0.6468578577041626, Accuracy: 0.7822265625\n",
      "Batch: 132, Loss: 0.6792371273040771, Accuracy: 0.775390625\n",
      "Batch: 133, Loss: 0.6583422422409058, Accuracy: 0.7783203125\n",
      "Batch: 134, Loss: 0.6306673288345337, Accuracy: 0.779296875\n",
      "Batch: 135, Loss: 0.6199454069137573, Accuracy: 0.798828125\n",
      "Batch: 136, Loss: 0.6721128225326538, Accuracy: 0.771484375\n",
      "Batch: 137, Loss: 0.6762512922286987, Accuracy: 0.7783203125\n",
      "Batch: 138, Loss: 0.6021262407302856, Accuracy: 0.7998046875\n",
      "Batch: 139, Loss: 0.6106006503105164, Accuracy: 0.7861328125\n",
      "Batch: 140, Loss: 0.6818839907646179, Accuracy: 0.7734375\n",
      "Batch: 141, Loss: 0.6952016353607178, Accuracy: 0.7724609375\n",
      "Batch: 142, Loss: 0.6957083940505981, Accuracy: 0.7646484375\n",
      "Batch: 143, Loss: 0.6498783826828003, Accuracy: 0.783203125\n",
      "Batch: 144, Loss: 0.6381300091743469, Accuracy: 0.791015625\n",
      "Batch: 145, Loss: 0.628990888595581, Accuracy: 0.7734375\n",
      "Batch: 146, Loss: 0.6730248928070068, Accuracy: 0.7685546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 147, Loss: 0.652895450592041, Accuracy: 0.783203125\n",
      "Batch: 148, Loss: 0.7141090631484985, Accuracy: 0.759765625\n",
      "Batch: 149, Loss: 0.6134890913963318, Accuracy: 0.80078125\n",
      "Batch: 150, Loss: 0.6529809236526489, Accuracy: 0.7763671875\n",
      "Batch: 151, Loss: 0.5405412316322327, Accuracy: 0.8203125\n",
      "Epoch 80/80\n",
      "Batch: 1, Loss: 0.8784704208374023, Accuracy: 0.740234375\n",
      "Batch: 2, Loss: 0.7270656824111938, Accuracy: 0.75\n",
      "Batch: 3, Loss: 0.6270932555198669, Accuracy: 0.7880859375\n",
      "Batch: 4, Loss: 0.5629788637161255, Accuracy: 0.8125\n",
      "Batch: 5, Loss: 0.6740407943725586, Accuracy: 0.78125\n",
      "Batch: 6, Loss: 0.663748025894165, Accuracy: 0.7880859375\n",
      "Batch: 7, Loss: 0.6758555173873901, Accuracy: 0.78125\n",
      "Batch: 8, Loss: 0.6195414662361145, Accuracy: 0.7734375\n",
      "Batch: 9, Loss: 0.6575390100479126, Accuracy: 0.7841796875\n",
      "Batch: 10, Loss: 0.6251243352890015, Accuracy: 0.794921875\n",
      "Batch: 11, Loss: 0.7423152327537537, Accuracy: 0.7548828125\n",
      "Batch: 12, Loss: 0.6955631971359253, Accuracy: 0.7685546875\n",
      "Batch: 13, Loss: 0.5636449456214905, Accuracy: 0.8173828125\n",
      "Batch: 14, Loss: 0.754285454750061, Accuracy: 0.7607421875\n",
      "Batch: 15, Loss: 0.5890127420425415, Accuracy: 0.8193359375\n",
      "Batch: 16, Loss: 0.6348557472229004, Accuracy: 0.794921875\n",
      "Batch: 17, Loss: 0.6681040525436401, Accuracy: 0.7890625\n",
      "Batch: 18, Loss: 0.7121410965919495, Accuracy: 0.765625\n",
      "Batch: 19, Loss: 0.661063015460968, Accuracy: 0.78515625\n",
      "Batch: 20, Loss: 0.5790741443634033, Accuracy: 0.818359375\n",
      "Batch: 21, Loss: 0.6254647970199585, Accuracy: 0.7822265625\n",
      "Batch: 22, Loss: 0.7051039934158325, Accuracy: 0.7685546875\n",
      "Batch: 23, Loss: 0.6890270709991455, Accuracy: 0.771484375\n",
      "Batch: 24, Loss: 0.669235348701477, Accuracy: 0.771484375\n",
      "Batch: 25, Loss: 0.6706236600875854, Accuracy: 0.7705078125\n",
      "Batch: 26, Loss: 0.5744419693946838, Accuracy: 0.806640625\n",
      "Batch: 27, Loss: 0.6514321565628052, Accuracy: 0.771484375\n",
      "Batch: 28, Loss: 0.695441484451294, Accuracy: 0.755859375\n",
      "Batch: 29, Loss: 0.6114253401756287, Accuracy: 0.802734375\n",
      "Batch: 30, Loss: 0.5569615960121155, Accuracy: 0.8125\n",
      "Batch: 31, Loss: 0.5977033376693726, Accuracy: 0.7939453125\n",
      "Batch: 32, Loss: 0.6127009391784668, Accuracy: 0.8017578125\n",
      "Batch: 33, Loss: 0.7068178057670593, Accuracy: 0.7724609375\n",
      "Batch: 34, Loss: 0.7743152379989624, Accuracy: 0.73046875\n",
      "Batch: 35, Loss: 0.6677702069282532, Accuracy: 0.7734375\n",
      "Batch: 36, Loss: 0.6692725419998169, Accuracy: 0.779296875\n",
      "Batch: 37, Loss: 0.6863582134246826, Accuracy: 0.779296875\n",
      "Batch: 38, Loss: 0.6700754165649414, Accuracy: 0.7822265625\n",
      "Batch: 39, Loss: 0.7075701355934143, Accuracy: 0.7666015625\n",
      "Batch: 40, Loss: 0.6571418046951294, Accuracy: 0.7802734375\n",
      "Batch: 41, Loss: 0.5872286558151245, Accuracy: 0.8046875\n",
      "Batch: 42, Loss: 0.5237516164779663, Accuracy: 0.8212890625\n",
      "Batch: 43, Loss: 0.7009263038635254, Accuracy: 0.7421875\n",
      "Batch: 44, Loss: 0.6638703346252441, Accuracy: 0.7880859375\n",
      "Batch: 45, Loss: 0.6086797118186951, Accuracy: 0.7890625\n",
      "Batch: 46, Loss: 0.595727264881134, Accuracy: 0.802734375\n",
      "Batch: 47, Loss: 0.571564793586731, Accuracy: 0.818359375\n",
      "Batch: 48, Loss: 0.5970399975776672, Accuracy: 0.7900390625\n",
      "Batch: 49, Loss: 0.6731693148612976, Accuracy: 0.78515625\n",
      "Batch: 50, Loss: 0.6651109457015991, Accuracy: 0.7744140625\n",
      "Batch: 51, Loss: 0.6537265777587891, Accuracy: 0.7666015625\n",
      "Batch: 52, Loss: 0.6476290225982666, Accuracy: 0.7802734375\n",
      "Batch: 53, Loss: 0.6061350703239441, Accuracy: 0.7919921875\n",
      "Batch: 54, Loss: 0.6378492712974548, Accuracy: 0.7763671875\n",
      "Batch: 55, Loss: 0.760148286819458, Accuracy: 0.748046875\n",
      "Batch: 56, Loss: 0.6982932090759277, Accuracy: 0.7734375\n",
      "Batch: 57, Loss: 0.7372943162918091, Accuracy: 0.755859375\n",
      "Batch: 58, Loss: 0.7390360832214355, Accuracy: 0.759765625\n",
      "Batch: 59, Loss: 0.6084222793579102, Accuracy: 0.8046875\n",
      "Batch: 60, Loss: 0.6312502026557922, Accuracy: 0.791015625\n",
      "Batch: 61, Loss: 0.684312641620636, Accuracy: 0.7626953125\n",
      "Batch: 62, Loss: 0.6344609260559082, Accuracy: 0.8017578125\n",
      "Batch: 63, Loss: 0.6759315729141235, Accuracy: 0.76953125\n",
      "Batch: 64, Loss: 0.6732911467552185, Accuracy: 0.7724609375\n",
      "Batch: 65, Loss: 0.6668044328689575, Accuracy: 0.7802734375\n",
      "Batch: 66, Loss: 0.6336581707000732, Accuracy: 0.798828125\n",
      "Batch: 67, Loss: 0.711228609085083, Accuracy: 0.7646484375\n",
      "Batch: 68, Loss: 0.7729697227478027, Accuracy: 0.748046875\n",
      "Batch: 69, Loss: 0.6726056933403015, Accuracy: 0.7705078125\n",
      "Batch: 70, Loss: 0.6392174959182739, Accuracy: 0.80859375\n",
      "Batch: 71, Loss: 0.6932482123374939, Accuracy: 0.76953125\n",
      "Batch: 72, Loss: 0.581522524356842, Accuracy: 0.8046875\n",
      "Batch: 73, Loss: 0.6417033672332764, Accuracy: 0.787109375\n",
      "Batch: 74, Loss: 0.5689217448234558, Accuracy: 0.8134765625\n",
      "Batch: 75, Loss: 0.5944246053695679, Accuracy: 0.7998046875\n",
      "Batch: 76, Loss: 0.6759756207466125, Accuracy: 0.7744140625\n",
      "Batch: 77, Loss: 0.6051005721092224, Accuracy: 0.7958984375\n",
      "Batch: 78, Loss: 0.5537635087966919, Accuracy: 0.8251953125\n",
      "Batch: 79, Loss: 0.535245418548584, Accuracy: 0.82421875\n",
      "Batch: 80, Loss: 0.641906201839447, Accuracy: 0.783203125\n",
      "Batch: 81, Loss: 0.7383922338485718, Accuracy: 0.7509765625\n",
      "Batch: 82, Loss: 0.6721858382225037, Accuracy: 0.779296875\n",
      "Batch: 83, Loss: 0.5745909214019775, Accuracy: 0.8173828125\n",
      "Batch: 84, Loss: 0.6277321577072144, Accuracy: 0.791015625\n",
      "Batch: 85, Loss: 0.6562349796295166, Accuracy: 0.771484375\n",
      "Batch: 86, Loss: 0.7378581762313843, Accuracy: 0.7490234375\n",
      "Batch: 87, Loss: 0.5932489037513733, Accuracy: 0.798828125\n",
      "Batch: 88, Loss: 0.7325366139411926, Accuracy: 0.755859375\n",
      "Batch: 89, Loss: 0.6885286569595337, Accuracy: 0.771484375\n",
      "Batch: 90, Loss: 0.6228639483451843, Accuracy: 0.7900390625\n",
      "Batch: 91, Loss: 0.631413459777832, Accuracy: 0.794921875\n",
      "Batch: 92, Loss: 0.6621646285057068, Accuracy: 0.7724609375\n",
      "Batch: 93, Loss: 0.6318208575248718, Accuracy: 0.7861328125\n",
      "Batch: 94, Loss: 0.6456435918807983, Accuracy: 0.7861328125\n",
      "Batch: 95, Loss: 0.6907068490982056, Accuracy: 0.7568359375\n",
      "Batch: 96, Loss: 0.6481733322143555, Accuracy: 0.7763671875\n",
      "Batch: 97, Loss: 0.551641583442688, Accuracy: 0.8125\n",
      "Batch: 98, Loss: 0.6429665088653564, Accuracy: 0.787109375\n",
      "Batch: 99, Loss: 0.6249386072158813, Accuracy: 0.791015625\n",
      "Batch: 100, Loss: 0.6443344354629517, Accuracy: 0.7880859375\n",
      "Batch: 101, Loss: 0.7062928080558777, Accuracy: 0.7568359375\n",
      "Batch: 102, Loss: 0.6934076547622681, Accuracy: 0.775390625\n",
      "Batch: 103, Loss: 0.6792516708374023, Accuracy: 0.7646484375\n",
      "Batch: 104, Loss: 0.6198835968971252, Accuracy: 0.7890625\n",
      "Batch: 105, Loss: 0.6948964595794678, Accuracy: 0.76953125\n",
      "Batch: 106, Loss: 0.5967667102813721, Accuracy: 0.791015625\n",
      "Batch: 107, Loss: 0.6735434532165527, Accuracy: 0.7763671875\n",
      "Batch: 108, Loss: 0.6680485010147095, Accuracy: 0.7705078125\n",
      "Batch: 109, Loss: 0.7478081583976746, Accuracy: 0.7490234375\n",
      "Batch: 110, Loss: 0.6203200817108154, Accuracy: 0.7939453125\n",
      "Batch: 111, Loss: 0.6694626808166504, Accuracy: 0.7763671875\n",
      "Batch: 112, Loss: 0.6527820229530334, Accuracy: 0.7900390625\n",
      "Batch: 113, Loss: 0.6483536958694458, Accuracy: 0.7939453125\n",
      "Batch: 114, Loss: 0.7038144469261169, Accuracy: 0.7890625\n",
      "Batch: 115, Loss: 0.7317410111427307, Accuracy: 0.7802734375\n",
      "Batch: 116, Loss: 0.6633217334747314, Accuracy: 0.7744140625\n",
      "Batch: 117, Loss: 0.6840343475341797, Accuracy: 0.76171875\n",
      "Batch: 118, Loss: 0.5643613934516907, Accuracy: 0.8017578125\n",
      "Batch: 119, Loss: 0.5387821197509766, Accuracy: 0.8330078125\n",
      "Batch: 120, Loss: 0.6487458348274231, Accuracy: 0.7744140625\n",
      "Batch: 121, Loss: 0.700095534324646, Accuracy: 0.763671875\n",
      "Batch: 122, Loss: 0.6140791177749634, Accuracy: 0.8017578125\n",
      "Batch: 123, Loss: 0.568785548210144, Accuracy: 0.798828125\n",
      "Batch: 124, Loss: 0.6418366432189941, Accuracy: 0.796875\n",
      "Batch: 125, Loss: 0.7516628503799438, Accuracy: 0.751953125\n",
      "Batch: 126, Loss: 0.6753803491592407, Accuracy: 0.78125\n",
      "Batch: 127, Loss: 0.557244062423706, Accuracy: 0.822265625\n",
      "Batch: 128, Loss: 0.7026510834693909, Accuracy: 0.7685546875\n",
      "Batch: 129, Loss: 0.6225268840789795, Accuracy: 0.79296875\n",
      "Batch: 130, Loss: 0.7445276379585266, Accuracy: 0.7568359375\n",
      "Batch: 131, Loss: 0.6468526124954224, Accuracy: 0.7763671875\n",
      "Batch: 132, Loss: 0.6729739904403687, Accuracy: 0.791015625\n",
      "Batch: 133, Loss: 0.6089736223220825, Accuracy: 0.7958984375\n",
      "Batch: 134, Loss: 0.6864000558853149, Accuracy: 0.7666015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 135, Loss: 0.5896015167236328, Accuracy: 0.810546875\n",
      "Batch: 136, Loss: 0.6477150917053223, Accuracy: 0.7939453125\n",
      "Batch: 137, Loss: 0.6595759391784668, Accuracy: 0.7734375\n",
      "Batch: 138, Loss: 0.5945322513580322, Accuracy: 0.80078125\n",
      "Batch: 139, Loss: 0.593050479888916, Accuracy: 0.78515625\n",
      "Batch: 140, Loss: 0.650367021560669, Accuracy: 0.7880859375\n",
      "Batch: 141, Loss: 0.698702335357666, Accuracy: 0.7607421875\n",
      "Batch: 142, Loss: 0.696868896484375, Accuracy: 0.779296875\n",
      "Batch: 143, Loss: 0.6461887359619141, Accuracy: 0.79296875\n",
      "Batch: 144, Loss: 0.6757009029388428, Accuracy: 0.779296875\n",
      "Batch: 145, Loss: 0.6117562055587769, Accuracy: 0.783203125\n",
      "Batch: 146, Loss: 0.6667803525924683, Accuracy: 0.7763671875\n",
      "Batch: 147, Loss: 0.6432229280471802, Accuracy: 0.7880859375\n",
      "Batch: 148, Loss: 0.6984781622886658, Accuracy: 0.7646484375\n",
      "Batch: 149, Loss: 0.6178109049797058, Accuracy: 0.7822265625\n",
      "Batch: 150, Loss: 0.6485364437103271, Accuracy: 0.779296875\n",
      "Batch: 151, Loss: 0.5648598670959473, Accuracy: 0.80859375\n",
      "Saved Weights at epoch 80 to file Weights_80.h5\n"
     ]
    }
   ],
   "source": [
    "file = open(os.path.join(data_directory, data_file), mode = 'r')\n",
    "data = file.read()\n",
    "file.close()\n",
    "if __name__ == \"__main__\":\n",
    "    training_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.686944</td>\n",
       "      <td>0.290039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.940787</td>\n",
       "      <td>0.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.617457</td>\n",
       "      <td>0.544922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.458334</td>\n",
       "      <td>0.561523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.372869</td>\n",
       "      <td>0.583984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.308803</td>\n",
       "      <td>0.602539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.252365</td>\n",
       "      <td>0.615234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.202019</td>\n",
       "      <td>0.619141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.167336</td>\n",
       "      <td>0.645508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.115653</td>\n",
       "      <td>0.657227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.082252</td>\n",
       "      <td>0.650391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.055321</td>\n",
       "      <td>0.670898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1.037503</td>\n",
       "      <td>0.673828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1.001244</td>\n",
       "      <td>0.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.984090</td>\n",
       "      <td>0.681641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.972532</td>\n",
       "      <td>0.685547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.993487</td>\n",
       "      <td>0.690430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.938375</td>\n",
       "      <td>0.696289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.951658</td>\n",
       "      <td>0.692383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.929368</td>\n",
       "      <td>0.709961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.899762</td>\n",
       "      <td>0.707031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.882277</td>\n",
       "      <td>0.713867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.886393</td>\n",
       "      <td>0.712891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.878032</td>\n",
       "      <td>0.711914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.877502</td>\n",
       "      <td>0.694336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.867237</td>\n",
       "      <td>0.707031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.840973</td>\n",
       "      <td>0.727539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.850250</td>\n",
       "      <td>0.727539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.857889</td>\n",
       "      <td>0.719727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.822875</td>\n",
       "      <td>0.735352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>0.678892</td>\n",
       "      <td>0.775391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>0.669174</td>\n",
       "      <td>0.768555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>0.673002</td>\n",
       "      <td>0.782227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>0.646273</td>\n",
       "      <td>0.782227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>0.665545</td>\n",
       "      <td>0.785156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>0.673534</td>\n",
       "      <td>0.774414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>0.663283</td>\n",
       "      <td>0.766602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>0.669686</td>\n",
       "      <td>0.777344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>0.643820</td>\n",
       "      <td>0.783203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>0.624793</td>\n",
       "      <td>0.797852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>0.636266</td>\n",
       "      <td>0.788086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>0.655554</td>\n",
       "      <td>0.767578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>0.595335</td>\n",
       "      <td>0.805664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>0.588688</td>\n",
       "      <td>0.802734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>0.629039</td>\n",
       "      <td>0.791016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>0.615948</td>\n",
       "      <td>0.801758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>0.626969</td>\n",
       "      <td>0.787109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>0.606696</td>\n",
       "      <td>0.792969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>0.597739</td>\n",
       "      <td>0.792969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>0.586056</td>\n",
       "      <td>0.807617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>0.590547</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>0.563129</td>\n",
       "      <td>0.811523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>0.578509</td>\n",
       "      <td>0.811523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>0.587202</td>\n",
       "      <td>0.797852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>0.580078</td>\n",
       "      <td>0.801758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>0.575839</td>\n",
       "      <td>0.802734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>0.577365</td>\n",
       "      <td>0.813477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>0.544465</td>\n",
       "      <td>0.824219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.820312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>0.564860</td>\n",
       "      <td>0.808594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epoch      Loss  Accuracy\n",
       "0       1  2.686944  0.290039\n",
       "1       2  1.940787  0.484375\n",
       "2       3  1.617457  0.544922\n",
       "3       4  1.458334  0.561523\n",
       "4       5  1.372869  0.583984\n",
       "5       6  1.308803  0.602539\n",
       "6       7  1.252365  0.615234\n",
       "7       8  1.202019  0.619141\n",
       "8       9  1.167336  0.645508\n",
       "9      10  1.115653  0.657227\n",
       "10     11  1.082252  0.650391\n",
       "11     12  1.055321  0.670898\n",
       "12     13  1.037503  0.673828\n",
       "13     14  1.001244  0.671875\n",
       "14     15  0.984090  0.681641\n",
       "15     16  0.972532  0.685547\n",
       "16     17  0.993487  0.690430\n",
       "17     18  0.938375  0.696289\n",
       "18     19  0.951658  0.692383\n",
       "19     20  0.929368  0.709961\n",
       "20     21  0.899762  0.707031\n",
       "21     22  0.882277  0.713867\n",
       "22     23  0.886393  0.712891\n",
       "23     24  0.878032  0.711914\n",
       "24     25  0.877502  0.694336\n",
       "25     26  0.867237  0.707031\n",
       "26     27  0.840973  0.727539\n",
       "27     28  0.850250  0.727539\n",
       "28     29  0.857889  0.719727\n",
       "29     30  0.822875  0.735352\n",
       "..    ...       ...       ...\n",
       "50     51  0.678892  0.775391\n",
       "51     52  0.669174  0.768555\n",
       "52     53  0.673002  0.782227\n",
       "53     54  0.646273  0.782227\n",
       "54     55  0.665545  0.785156\n",
       "55     56  0.673534  0.774414\n",
       "56     57  0.663283  0.766602\n",
       "57     58  0.669686  0.777344\n",
       "58     59  0.643820  0.783203\n",
       "59     60  0.624793  0.797852\n",
       "60     61  0.636266  0.788086\n",
       "61     62  0.655554  0.767578\n",
       "62     63  0.595335  0.805664\n",
       "63     64  0.588688  0.802734\n",
       "64     65  0.629039  0.791016\n",
       "65     66  0.615948  0.801758\n",
       "66     67  0.626969  0.787109\n",
       "67     68  0.606696  0.792969\n",
       "68     69  0.597739  0.792969\n",
       "69     70  0.586056  0.807617\n",
       "70     71  0.590547  0.796875\n",
       "71     72  0.563129  0.811523\n",
       "72     73  0.578509  0.811523\n",
       "73     74  0.587202  0.797852\n",
       "74     75  0.580078  0.801758\n",
       "75     76  0.575839  0.802734\n",
       "76     77  0.577365  0.813477\n",
       "77     78  0.544465  0.824219\n",
       "78     79  0.540541  0.820312\n",
       "79     80  0.564860  0.808594\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = pd.read_csv(os.path.join(data_directory, \"log.csv\"))\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
